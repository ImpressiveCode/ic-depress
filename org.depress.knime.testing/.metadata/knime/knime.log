2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : # Welcome to the KNIME Analytics Platform v3.1.0.v201512031304 (Build December 06, 2015 #
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : # Based on Eclipse, http://www.eclipse.org                                              #
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : # Copyright by KNIME GmbH, Konstanz, Germany and others.                                #
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : # Website: http://www.knime.org                                                         #
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : # E-mail: contact@knime.org                                                             #
2016-01-13 21:58:30,152 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # For more details see the KNIME log file:                                              #
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\knime.log
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : #---------------------------------------------------------------------------------------#
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # logging date=Wed Jan 13 21:58:30 CET 2016
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # java.version=1.8.0_60
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # java.vm.version=25.60-b23
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # java.vendor=Oracle Corporation
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # os.name=Windows 7
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # os.arch=amd64
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # number of CPUs=2
2016-01-13 21:58:30,168 : INFO  : main : NodeLogger :  :  : # assertions=off
2016-01-13 21:58:30,214 : INFO  : main : NodeLogger :  :  : # host=SONY-Komputer
2016-01-13 21:58:30,214 : INFO  : main : NodeLogger :  :  : # username=SONY
2016-01-13 21:58:30,214 : INFO  : main : NodeLogger :  :  : # max mem=910MB
2016-01-13 21:58:30,230 : INFO  : main : NodeLogger :  :  : # application=org.knime.product.KNIME_APPLICATION
2016-01-13 21:58:30,230 : INFO  : main : NodeLogger :  :  : # ID=01-9c587cb4eccee8b8
2016-01-13 21:58:30,230 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 21:58:37,853 : INFO  : main : StringHistory :  :  : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_database_drivers.txt' does not exist.
2016-01-13 21:58:37,853 : INFO  : main : StringHistory :  :  : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_database_urls.txt' does not exist.
2016-01-13 21:58:37,853 : DEBUG : main : DatabaseConnectionSettings :  :  : Settings database timeout to 15 seconds
2016-01-13 21:58:37,931 : DEBUG : main : DatabaseConnectionSettings :  :  : Database concurrency (sync via database connection) is true.
2016-01-13 21:58:37,931 : DEBUG : main : KNIMECorePlugin :  :  : Setting KNIME max thread count to 4
2016-01-13 21:58:37,931 : DEBUG : main : KNIMECorePlugin :  :  : Setting KNIME temp dir to "C:\Users\SONY\AppData\Local\Temp"
2016-01-13 21:58:38,024 : INFO  : main : KNIMECorePlugin :  :  : Setting console view log level to WARN
2016-01-13 21:58:38,258 : DEBUG : main : KnimeEncryption :  :  : Replacing current encryption key supplier "null" with this new one "org.knime.workbench.core.EclipseEncryptionKeySupplier@612af486".
2016-01-13 21:58:38,258 : DEBUG : main : DatabaseConnectionSettings :  :  : Settings database timeout to 15 seconds
2016-01-13 21:58:38,274 : DEBUG : main : KnimeEncryption :  :  : Replacing current encryption key supplier "org.knime.workbench.core.EclipseEncryptionKeySupplier@612af486" with this new one "org.knime.workbench.ui.masterkey.MasterKeyPreferencePage$1@1f45db49".
2016-01-13 21:58:38,820 : DEBUG : main : SvgPluginActivator :  :  : Added SVG export option to node view class
2016-01-13 21:58:39,865 : DEBUG : main : KnimeEnterpriseFileSystemPlugin :  :  : Started KNIME Enterprise Remote File System plug-in
2016-01-13 21:58:39,896 : INFO  : main : ExplorerMountTable :  :  : Mounted Explorer Temp Space 'knime-temp-space' - com.knime.explorer.tempspace
2016-01-13 21:58:40,068 : DEBUG : main : UpdateManager :  :  : Updating registered ServerSpaces every 2000 msec.
2016-01-13 21:58:42,196 : DEBUG : main : NodeTimer$GlobalNodeStats :  :  : Node usage file does not exist. Starting counts from scratch.
2016-01-13 21:58:42,249 : DEBUG : main : NodeContainer :  :  : ROOT  has new state: EXECUTED
2016-01-13 21:58:42,249 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 
2016-01-13 21:58:42,251 : DEBUG : main : NodeContainer :  :  : KNIME MetaNode Repository 1 has new state: EXECUTED
2016-01-13 21:58:42,252 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1
2016-01-13 21:58:42,254 : DEBUG : main : WorkflowManager :  :  : Added new subworkflow 1
2016-01-13 21:58:42,255 : DEBUG : main : WorkflowManager :  :  : Created project 1
2016-01-13 21:58:42,261 : DEBUG : main : RepositoryManager :  :  : Found category extension 'io' on path '/'
2016-01-13 21:58:42,264 : DEBUG : main : RepositoryManager :  :  : Found category extension 'manipulation' on path '/'
2016-01-13 21:58:42,267 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database' on path '/'
2016-01-13 21:58:42,270 : DEBUG : main : RepositoryManager :  :  : Found category extension 'view' on path '/'
2016-01-13 21:58:42,273 : DEBUG : main : RepositoryManager :  :  : Found category extension 'analytics' on path '/'
2016-01-13 21:58:42,276 : DEBUG : main : RepositoryManager :  :  : Found category extension 'toolintegration' on path '/'
2016-01-13 21:58:42,278 : DEBUG : main : RepositoryManager :  :  : Found category extension 'misc' on path '/'
2016-01-13 21:58:42,281 : DEBUG : main : RepositoryManager :  :  : Found category extension 'labs' on path '/'
2016-01-13 21:58:42,286 : DEBUG : main : RepositoryManager :  :  : Found category extension 'community' on path '/'
2016-01-13 21:58:42,289 : DEBUG : main : RepositoryManager :  :  : Found category extension 'social-media' on path '/'
2016-01-13 21:58:42,292 : DEBUG : main : RepositoryManager :  :  : Found category extension 'report' on path '/'
2016-01-13 21:58:42,295 : DEBUG : main : RepositoryManager :  :  : Found category extension 'chemistry' on path '/'
2016-01-13 21:58:42,298 : DEBUG : main : RepositoryManager :  :  : Found category extension 'applications' on path '/'
2016-01-13 21:58:42,301 : DEBUG : main : RepositoryManager :  :  : Found category extension 'struct-data' on path '/'
2016-01-13 21:58:42,304 : DEBUG : main : RepositoryManager :  :  : Found category extension 'scripting' on path '/'
2016-01-13 21:58:42,307 : DEBUG : main : RepositoryManager :  :  : Found category extension 'flowcontrol' on path '/'
2016-01-13 21:58:42,310 : DEBUG : main : RepositoryManager :  :  : Found category extension 'uncategorized' on path '/'
2016-01-13 21:58:42,313 : DEBUG : main : RepositoryManager :  :  : Found category extension 'testing' on path '/'
2016-01-13 21:58:42,315 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress' on path '/community'
2016-01-13 21:58:42,318 : DEBUG : main : RepositoryManager :  :  : Found category extension 'read' on path '/io'
2016-01-13 21:58:42,320 : DEBUG : main : RepositoryManager :  :  : Found category extension 'write' on path '/io'
2016-01-13 21:58:42,323 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column' on path '/manipulation'
2016-01-13 21:58:42,326 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row' on path '/manipulation'
2016-01-13 21:58:42,329 : DEBUG : main : RepositoryManager :  :  : Found category extension 'table' on path '/manipulation'
2016-01-13 21:58:42,332 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pmml' on path '/manipulation'
2016-01-13 21:58:42,334 : DEBUG : main : RepositoryManager :  :  : Found category extension 'property' on path '/view'
2016-01-13 21:58:42,335 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mining' on path '/analytics'
2016-01-13 21:58:42,338 : DEBUG : main : RepositoryManager :  :  : Found category extension 'statistics' on path '/analytics'
2016-01-13 21:58:42,339 : DEBUG : main : RepositoryManager :  :  : Found category extension 'io-other' on path '/io'
2016-01-13 21:58:42,341 : DEBUG : main : RepositoryManager :  :  : Found category extension 'java-snippet' on path '/scripting'
2016-01-13 21:58:42,344 : DEBUG : main : RepositoryManager :  :  : Found category extension 'view-util' on path '/view'
2016-01-13 21:58:42,345 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-io' on path '/database'
2016-01-13 21:58:42,346 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-manipulation' on path '/database'
2016-01-13 21:58:42,346 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-connector' on path '/database'
2016-01-13 21:58:42,347 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-utility' on path '/database'
2016-01-13 21:58:42,350 : DEBUG : main : RepositoryManager :  :  : Found category extension 'automation' on path '/flowcontrol'
2016-01-13 21:58:42,353 : DEBUG : main : RepositoryManager :  :  : Found category extension 'quickforms' on path '/flowcontrol'
2016-01-13 21:58:42,355 : DEBUG : main : RepositoryManager :  :  : Found category extension 'variables' on path '/flowcontrol'
2016-01-13 21:58:42,359 : DEBUG : main : RepositoryManager :  :  : Found category extension 'switches' on path '/flowcontrol'
2016-01-13 21:58:42,362 : DEBUG : main : RepositoryManager :  :  : Found category extension 'trycatch' on path '/flowcontrol'
2016-01-13 21:58:42,364 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/flowcontrol'
2016-01-13 21:58:42,365 : DEBUG : main : RepositoryManager :  :  : Found category extension 'filestore' on path '/testing'
2016-01-13 21:58:42,367 : DEBUG : main : RepositoryManager :  :  : Found category extension 'timeseries' on path '/applications'
2016-01-13 21:58:42,369 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress.scm' on path '/community/depress'
2016-01-13 21:58:42,370 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress.its' on path '/community/depress'
2016-01-13 21:58:42,370 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-other' on path '/manipulation/row'
2016-01-13 21:58:42,371 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-split+combine' on path '/manipulation/column'
2016-01-13 21:58:42,372 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-filter' on path '/manipulation/column'
2016-01-13 21:58:42,383 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-transform' on path '/manipulation/column'
2016-01-13 21:58:42,384 : DEBUG : main : RepositoryManager :  :  : Found category extension 'binning' on path '/manipulation/column'
2016-01-13 21:58:42,384 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-convert+replace' on path '/manipulation/column'
2016-01-13 21:58:42,385 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-filter' on path '/manipulation/row'
2016-01-13 21:58:42,386 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-transform' on path '/manipulation/row'
2016-01-13 21:58:42,387 : DEBUG : main : RepositoryManager :  :  : Found category extension 'clustering' on path '/analytics/mining'
2016-01-13 21:58:42,388 : DEBUG : main : RepositoryManager :  :  : Found category extension 'nn' on path '/analytics/mining'
2016-01-13 21:58:42,390 : DEBUG : main : RepositoryManager :  :  : Found category extension 'regression' on path '/analytics/statistics'
2016-01-13 21:58:42,391 : DEBUG : main : RepositoryManager :  :  : Found category extension 'rules' on path '/analytics/mining'
2016-01-13 21:58:42,392 : DEBUG : main : RepositoryManager :  :  : Found category extension 'dtree' on path '/analytics/mining'
2016-01-13 21:58:42,393 : DEBUG : main : RepositoryManager :  :  : Found category extension 'modeleval' on path '/analytics/mining'
2016-01-13 21:58:42,394 : DEBUG : main : RepositoryManager :  :  : Found category extension 'subgroup' on path '/analytics/mining'
2016-01-13 21:58:42,394 : DEBUG : main : RepositoryManager :  :  : Found category extension 'miscClass' on path '/analytics/mining'
2016-01-13 21:58:42,395 : DEBUG : main : RepositoryManager :  :  : Found category extension 'bayes' on path '/analytics/mining'
2016-01-13 21:58:42,396 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mds' on path '/analytics/mining'
2016-01-13 21:58:42,397 : DEBUG : main : RepositoryManager :  :  : Found category extension 'svm' on path '/analytics/mining'
2016-01-13 21:58:42,397 : DEBUG : main : RepositoryManager :  :  : Found category extension 'featureselection' on path '/analytics/mining'
2016-01-13 21:58:42,398 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pca' on path '/analytics/mining'
2016-01-13 21:58:42,401 : DEBUG : main : RepositoryManager :  :  : Found category extension 'weka' on path '/analytics/mining'
2016-01-13 21:58:42,402 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mining-pmml' on path '/analytics/mining'
2016-01-13 21:58:42,405 : DEBUG : main : RepositoryManager :  :  : Found category extension 'loopsupport' on path '/flowcontrol/'
2016-01-13 21:58:42,406 : DEBUG : main : RepositoryManager :  :  : Found category extension 'treeensemble' on path '/analytics/mining'
2016-01-13 21:58:42,407 : DEBUG : main : RepositoryManager :  :  : Found category extension 'regression' on path 'analytics/mining/treeensemble'
2016-01-13 21:58:42,409 : DEBUG : main : RepositoryManager :  :  : Found category extension 'ensembles' on path '/analytics/mining'
2016-01-13 21:58:42,412 : DEBUG : main : RepositoryManager :  :  : Found category extension 'hypothesis-testing' on path '/analytics/statistics'
2016-01-13 21:58:42,413 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/applications/timeseries'
2016-01-13 21:58:42,414 : DEBUG : main : RepositoryManager :  :  : Found category extension 'basisfunction' on path '/analytics/mining/rules'
2016-01-13 21:58:42,415 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mlp' on path '/analytics/mining/nn'
2016-01-13 21:58:42,416 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pnn' on path '/analytics/mining/nn'
2016-01-13 21:58:42,416 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/featureselection'
2016-01-13 21:58:42,419 : DEBUG : main : RepositoryManager :  :  : Found category extension 'crossvalidation' on path '/analytics/mining/modeleval'
2016-01-13 21:58:42,420 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/modeleval'
2016-01-13 21:58:42,421 : DEBUG : main : RepositoryManager :  :  : Found category extension 'classification' on path '/analytics/mining/treeensemble'
2016-01-13 21:58:42,421 : DEBUG : main : RepositoryManager :  :  : Found category extension 'ensembles-combine' on path '/analytics/mining/ensembles'
2016-01-13 21:58:42,423 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/ensembles'
2016-01-13 21:58:43,511 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.its.bugzilla': Bugzilla Adapter (Offline)
2016-01-13 21:58:43,529 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.its.jira': Jira Adapter (Offline)
2016-01-13 21:58:43,549 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.scm.gitoffline': Git SCM
2016-01-13 21:58:43,566 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.scm.svnoffline': SVN SCM
2016-01-13 21:58:43,601 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.smote.SmoteNodeFactory': SMOTE
2016-01-13 21:58:43,621 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.filereader.FileReaderNodeFactory': File Reader
2016-01-13 21:58:43,636 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.ColorManager2NodeFactory': Color Manager
2016-01-13 21:58:43,650 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.size.SizeManager2NodeFactory': Size Manager
2016-01-13 21:58:43,664 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.shape.ShapeManagerNodeFactory': Shape Manager
2016-01-13 21:58:43,678 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.ColorAppenderNodeFactory': Color Appender
2016-01-13 21:58:43,690 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.size.SizeAppenderNodeFactory': Size Appender
2016-01-13 21:58:43,704 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.shape.ShapeAppenderNodeFactory': Shape Appender
2016-01-13 21:58:43,718 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.table.TableNodeFactory': Interactive Table
2016-01-13 21:58:43,733 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.binner.BinnerNodeFactory': Numeric Binner
2016-01-13 21:58:43,749 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.binnerdictionary.BinByDictionaryNodeFactory': Binner (Dictionary)
2016-01-13 21:58:43,766 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.cache.CacheNodeFactory': Cache
2016-01-13 21:58:43,784 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.fuzzy.FuzzyBasisFunctionLearnerNodeFactory': Fuzzy Rule Learner
2016-01-13 21:58:43,921 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.fuzzy.FuzzyBasisFunctionPredictor2NodeFactory': Fuzzy Rule Predictor
2016-01-13 21:58:43,936 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.radial.RadialBasisFunctionLearnerNodeFactory': PNN Learner (DDA)
2016-01-13 21:58:43,948 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.radial.RadialBasisFunctionPredictor2NodeFactory': PNN Predictor
2016-01-13 21:58:43,995 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.csvwriter.CSVWriterNodeFactory': CSV Writer
2016-01-13 21:58:44,010 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.joiner.Joiner2NodeFactory': Joiner
2016-01-13 21:58:44,023 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.crossjoin.CrossJoinerNodeFactory': Cross Joiner
2016-01-13 21:58:44,035 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.split2.SplitNodeFactory2': Column Splitter
2016-01-13 21:58:44,047 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnappend.ColumnAppenderNodeFactory': Column Appender
2016-01-13 21:58:44,059 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.arffwriter.ARFFWriterNodeFactory': ARFF Writer
2016-01-13 21:58:44,070 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.sorter.SorterNodeFactory': Sorter
2016-01-13 21:58:44,082 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.arffreader.ARFFReaderNodeFactory': ARFF Reader
2016-01-13 21:58:44,096 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.csvreader.CSVReaderNodeFactory': CSV Reader
2016-01-13 21:58:44,107 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.linereader.LineReaderNodeFactory': Line Reader
2016-01-13 21:58:44,123 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.crosstable.CrosstabNodeFactory': Crosstab
2016-01-13 21:58:44,134 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.valcount.ValueCounterNodeFactory': Value Counter
2016-01-13 21:58:44,146 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize3.Normalize3NodeFactory': Normalizer
2016-01-13 21:58:44,157 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.PMMLNormalizerApplyNodeFactory': Normalizer Apply (PMML)
2016-01-13 21:58:44,171 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columnfilter.DataColumnSpecFilterPMMLNodeFactory': Column Filter (PMML)
2016-01-13 21:58:44,182 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.append.row.AppendedRowsNodeFactory': Concatenate
2016-01-13 21:58:44,190 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.append.row.AppendedRowsWithOptionalInNodeFactory': Concatenate (Optional in)
2016-01-13 21:58:44,202 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.row.RowFilterNodeFactory': Row Filter
2016-01-13 21:58:44,214 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.row.RowFilter2PortNodeFactory': Row Splitter
2016-01-13 21:58:44,224 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.shuffle.ShuffleNodeFactory': Shuffle
2016-01-13 21:58:44,235 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.sample.SamplingNodeFactory': Row Sampling
2016-01-13 21:58:44,247 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bootstrap.BootstrapNodeFactory': Bootstrap Sampling
2016-01-13 21:58:44,258 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.equalsizesampling.EqualSizeSamplingNodeFactory': Equal Size Sampling
2016-01-13 21:58:44,269 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.partition.PartitionNodeFactory': Partitioning
2016-01-13 21:58:44,284 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.fuzzycmeans.FuzzyClusterNodeFactory2': Fuzzy c-Means
2016-01-13 21:58:44,295 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.neural.mlp2.MLPPredictorNodeFactory': MultiLayerPerceptron Predictor
2016-01-13 21:58:44,325 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.predictor.PredictorReaderNodeFactory': Model Reader
2016-01-13 21:58:44,335 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.transpose.TransposeTableNodeFactory': Transpose
2016-01-13 21:58:44,344 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.extracttabledimension.ExtractTableDimensionNodeFactory': Extract Table Dimension
2016-01-13 21:58:44,354 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.extracttablespec.ExtractTableSpecNodeFactory': Extract Table Spec
2016-01-13 21:58:44,374 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.predictor2.DecTreePredictorNodeFactory': Decision Tree Predictor
2016-01-13 21:58:44,387 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.image.DecTreeToImageNodeFactory': Decision Tree To Image
2016-01-13 21:58:44,399 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.sota.SotaLearnerNodeFactory': SOTA Learner
2016-01-13 21:58:44,411 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rename.RenameNodeFactory': Column Rename
2016-01-13 21:58:45,322 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnrenameregex.ColumnRenameRegexNodeFactory': Column Rename (Regex)
2016-01-13 21:58:45,342 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.constantvalue.ConstantValueColumnNodeFactory': Constant Value Column
2016-01-13 21:58:45,414 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.create.CreateBitVectorNodeFactory': Create Bit Vector
2016-01-13 21:58:45,436 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.subgroupminer.SubgroupMinerFactory2': Association Rule Learner
2016-01-13 21:58:45,461 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.linear2.predict.GeneralRegressionPredictorNodeFactory': Regression Predictor
2016-01-13 21:58:45,478 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.table.read.ReadTableNodeFactory': Table Reader
2016-01-13 21:58:45,490 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.table.write.WriteTableNodeFactory': Table Writer
2016-01-13 21:58:45,497 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.create.CreateBitVectorNodeFactory': Create Bit Vector
2016-01-13 21:58:45,512 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.expand.ExpandBitVectorNodeFactory': Expand Bit Vector
2016-01-13 21:58:45,526 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.histogram.node.HistogramNodeFactory': Histogram (interactive)
2016-01-13 21:58:45,536 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.histogram.node.FixedColumnHistogramNodeFactory': Histogram
2016-01-13 21:58:45,544 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.NormalizeApplyNodeFactory': Normalizer (Apply)
2016-01-13 21:58:45,555 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.box.BoxPlotNodeFactory': Box Plot
2016-01-13 21:58:45,603 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.line.LinePlotterNodeFactory': Line Plot
2016-01-13 21:58:45,621 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.parcoord.ParallelCoordinateNodeFactory': Parallel Coordinates
2016-01-13 21:58:45,635 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.scatter.ScatterPlotterNodeFactory': Scatter Plot
2016-01-13 21:58:45,645 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.scattermatrix.ScatterMatrixNodeFactory': Scatter Matrix
2016-01-13 21:58:45,653 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.hilite': HiLite Row Splitter
2016-01-13 21:58:45,666 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.discretization.caim.modelcreator.CAIMDiscretizationNodeFactory': CAIM Binner
2016-01-13 21:58:45,674 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.discretization.caim.modelapply.DiscretizationApplyNodeFactory': CAIM Applier
2016-01-13 21:58:45,685 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rowkey2.RowKeyNodeFactory2': RowID
2016-01-13 21:58:45,694 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.knn.KnnNodeFactory': K Nearest Neighbor
2016-01-13 21:58:45,706 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.hierarchical.HierarchicalClusterNodeFactory': Hierarchical Clustering
2016-01-13 21:58:45,716 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.sota.predictor.SotaPredictorNodeFactory': SOTA Predictor
2016-01-13 21:58:45,729 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.pie.node.fixed.FixedPieNodeFactory': Pie chart
2016-01-13 21:58:45,738 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.pie.node.interactive.InteractivePieNodeFactory': Pie chart (interactive)
2016-01-13 21:58:45,751 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.groupby.GroupByNodeFactory': GroupBy
2016-01-13 21:58:45,761 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.ungroup.UngroupNodeFactory': Ungroup
2016-01-13 21:58:45,772 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pivot.Pivot2NodeFactory': Pivoting
2016-01-13 21:58:45,782 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bayes.naivebayes.predictor3.NaiveBayesPredictorNodeFactory2': Naive Bayes Predictor
2016-01-13 21:58:45,792 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.compute.CorrelationComputeNodeFactory': Linear Correlation
2016-01-13 21:58:45,799 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.compute.CorrelationComputeNodeFactory': Linear Correlation
2016-01-13 21:58:45,808 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.filter.CorrelationFilterNodeFactory': Correlation Filter
2016-01-13 21:58:45,819 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.lowvarfilter2.LowVarFilter2NodeFactory': Low Variance Filter
2016-01-13 21:58:45,829 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.mds.MDSNodeFactory': MDS
2016-01-13 21:58:45,838 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.mds.mdsprojection.MDSProjectionNodeFactory': MDS Projection
2016-01-13 21:58:45,848 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.svm.predictor2.SVMPredictorNodeFactory': SVM Predictor
2016-01-13 21:58:45,858 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colcompare.ColumnComparatorNodeFactory': Column Comparator
2016-01-13 21:58:45,866 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rowsplit.NumericRowSplitterNodeFactory': Numeric Row Splitter
2016-01-13 21:58:45,876 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringreplacer.StringReplacerNodeFactory': String Replacer
2016-01-13 21:58:45,886 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.dialog2.DomainNodeFactory': Domain Calculator
2016-01-13 21:58:45,896 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnumeric.EditNumericDomainNodeFactory': Edit Numeric Domain
2016-01-13 21:58:45,905 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnominal.dic.EditNominalDomainDicNodeFactory': Edit Nominal Domain (Dictionary)
2016-01-13 21:58:45,916 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnominal.EditNominalDomainNodeFactory': Edit Nominal Domain
2016-01-13 21:58:45,925 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.caseconvert.CaseConvertNodeFactory': Case Converter
2016-01-13 21:58:45,934 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringreplacer.dict.SearchReplaceDictNodeFactory': String Replace (Dictionary)
2016-01-13 21:58:45,943 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellsplit.CellSplitterNodeFactory': Cell Splitter
2016-01-13 21:58:45,952 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.numbertostring.NumberToStringNodeFactory': Number To String
2016-01-13 21:58:45,963 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.stringtonumber.StringToNumberNodeFactory': String To Number
2016-01-13 21:58:45,972 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntrans2.One2ManyCol2NodeFactory': One to Many
2016-01-13 21:58:45,981 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntrans2.Many2OneCol2NodeFactory': Many to One
2016-01-13 21:58:45,991 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colcombine2.ColCombine2NodeFactory': Column Combiner
2016-01-13 21:58:46,000 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnmerge.ColumnMergerNodeFactory': Column Merger
2016-01-13 21:58:46,008 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.assign.ClusterAssignerNodeFactory': Cluster Assigner
2016-01-13 21:58:46,020 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.accuracy.AccuracyScorerNodeFactory': Scorer
2016-01-13 21:58:46,036 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.numeric.NumericScorerNodeFactory': Numeric Scorer
2016-01-13 21:58:46,046 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.entrop.NewEntropyNodeFactory': Entropy Scorer
2016-01-13 21:58:46,055 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.roc.ROCNodeFactory': ROC Curve
2016-01-13 21:58:46,066 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.chem.node.viz.enrich2.EnrichmentPlotterFactory': Enrichment Plotter
2016-01-13 21:58:46,077 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBReaderNodeFactory': Database Reader
2016-01-13 21:58:46,086 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBReaderConnectionNodeFactory': Database Table Connector
2016-01-13 21:58:46,095 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DatabaseLoopingNodeFactory': Database Looping
2016-01-13 21:58:46,103 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBConnectionNodeFactory': Database Connection Table Reader
2016-01-13 21:58:46,111 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBRowFilterNodeFactory': Database Row Filter
2016-01-13 21:58:46,119 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBQueryNodeFactory2': Database Query
2016-01-13 21:58:46,127 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBColumnFilterNodeFactory': Database Column Filter
2016-01-13 21:58:46,135 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBSorterNodeFactory': Database Sorter
2016-01-13 21:58:46,147 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBGroupByNodeFactory': Database GroupBy
2016-01-13 21:58:46,157 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBJoinerNodeFactory': Database Joiner
2016-01-13 21:58:46,165 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBConnectionWriterNodeFactory': Database Connection Table Writer
2016-01-13 21:58:46,175 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBWriterNodeFactory': Database Writer
2016-01-13 21:58:46,185 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBUpdateNodeFactory': Database Update
2016-01-13 21:58:46,194 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBDeleteRowsNodeFactory': Database Delete
2016-01-13 21:58:46,203 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBSQLExecutorNodeFactory': Database SQL Executor
2016-01-13 21:58:46,211 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellsplitbypos.CellSplitterByPositionNodeFactory': Cell Splitter By Position
2016-01-13 21:58:46,222 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.condbox.ConditionalBoxPlotNodeFactory': Conditional Box Plot
2016-01-13 21:58:46,230 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnFilterRefNodeFactory': Reference Column Filter
2016-01-13 21:58:46,239 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.MissingValueColumnFilterNodeFactory': Missing Value Column Filter
2016-01-13 21:58:46,248 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowFilterRefNodeFactory': Reference Row Filter
2016-01-13 21:58:46,257 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.collection.list.create2.CollectionCreate2NodeFactory': Create Collection Column
2016-01-13 21:58:46,266 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.collection.list.split.CollectionSplitNodeFactory': Split Collection Column
2016-01-13 21:58:46,275 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.pmml.read.PMMLReaderNodeFactory': PMML Reader
2016-01-13 21:58:46,284 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.regexsplit.RegexSplitNodeFactory': Regex Split
2016-01-13 21:58:46,293 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.pmml.write.PMMLWriterNodeFactory': PMML Writer
2016-01-13 21:58:46,302 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.predictor.PredictorWriterNodeFactory': Model Writer
2016-01-13 21:58:46,311 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.writemage.WriteImageNodeFactory': Image Port Writer
2016-01-13 21:58:46,320 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.imagecolwriter.ImageColumnWriterNodeFactory': Image Column Writer
2016-01-13 21:58:46,329 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.liftchart.LiftChartNodeFactory': Lift Chart
2016-01-13 21:58:46,339 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.setoperator.SetOperatorNodeFactory': Set Operator
2016-01-13 21:58:46,349 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.xvalidation.XValidatePartitionerFactory': X-Partitioner
2016-01-13 21:58:46,359 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.xvalidation.AggregateOutputNodeFactory': X-Aggregator
2016-01-13 21:58:46,367 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopStartCountNodeFactory': Counting Loop Start
2016-01-13 21:58:46,384 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.chunk.LoopStartChunkNodeFactory': Chunk Loop Start
2016-01-13 21:58:46,392 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.columnlist2.ColumnListLoopStartNodeFactory': Column List Loop Start
2016-01-13 21:58:46,399 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.condition.LoopStartGenericNodeFactory': Generic Loop Start
2016-01-13 21:58:46,409 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.variableloophead.LoopStartVariableNodeFactory': Table Row To Variable Loop Start
2016-01-13 21:58:46,417 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopEndNodeFactory': Loop End
2016-01-13 21:58:46,427 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.condition.LoopEndConditionNodeFactory': Variable Condition Loop End
2016-01-13 21:58:46,434 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.extractvariables.ExtractVariablesNodeFactory': Extract Variables (Data)
2016-01-13 21:58:46,474 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.extractvariables.ExtractVariablesDBNodeFactory': Extract Variables (Database)
2016-01-13 21:58:46,482 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopStart1NodeFactory': Backward Feature Elimination Start (1:1)
2016-01-13 21:58:46,488 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopStart2NodeFactory': Backward Feature Elimination Start (2:2)
2016-01-13 21:58:46,497 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopEndNodeFactory': Backward Feature Elimination End
2016-01-13 21:58:46,506 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimFilterNodeFactory': Backward Feature Elimination Filter
2016-01-13 21:58:46,514 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.appendvariabletotable2.AppendVariableToTable2NodeFactory': Variable to Table Column
2016-01-13 21:58:46,523 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.variabletotablerow2.VariableToTable2NodeFactory': Variable to Table Row
2016-01-13 21:58:46,529 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.tablerowtovariable.TableToVariableNodeFactory': Table Row to Variable
2016-01-13 21:58:46,536 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.injectvariables.InjectVariablesNodeFactory': Inject Variables (Data)
2016-01-13 21:58:46,543 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.injectvariables.InjectVariablesDBNodeFactory': Inject Variables (Database)
2016-01-13 21:58:46,551 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.nominal.NominalValueRowFilterNodeFactory': Nominal Value Row Filter
2016-01-13 21:58:46,559 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopStartIntervalNodeFactory': Interval Loop Start
2016-01-13 21:58:46,568 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.breakpoint.BreakpointNodeFactory': Breakpoint
2016-01-13 21:58:46,578 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.unpivot2.Unpivot2NodeFactory': Unpivoting
2016-01-13 21:58:46,588 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCANodeFactory': PCA
2016-01-13 21:58:46,596 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAComputeNodeFactory': PCA Compute
2016-01-13 21:58:46,604 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAApplyNodeFactory': PCA Apply
2016-01-13 21:58:46,612 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAReverseNodeFactory': PCA Inversion
2016-01-13 21:58:46,621 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.double2int.DoubleToIntNodeFactory': Double To Int
2016-01-13 21:58:46,635 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.hilite.collector.InteractiveHiLiteCollectorNodeFactory': Interactive HiLite Collector
2016-01-13 21:58:46,643 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.exp.node.meta.looper.LoopEnd2NodeFactory': Loop End (2 ports)
2016-01-13 21:58:46,652 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.matcher.SubsetMatcherNodeFactory': Subset Matcher
2016-01-13 21:58:46,657 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.matcher.SubsetMatcherNodeFactory': Subset Matcher
2016-01-13 21:58:46,665 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.ImageToTableNodeFactory': Image To Table
2016-01-13 21:58:46,672 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.tablerowtoimage.TableRowToImageNodeFactory': Table To Image
2016-01-13 21:58:46,680 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.manualif.ManualIfNodeFactory': IF Switch
2016-01-13 21:58:46,688 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endif.EndifNodeFactory': End IF
2016-01-13 21:58:46,696 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.startcase.StartcaseNodeFactory': CASE Switch Data (Start)
2016-01-13 21:58:46,705 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endcase.EndcaseNodeFactory': CASE Switch Data (End)
2016-01-13 21:58:46,715 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.model.CaseStartModelNodeFactory': CASE Switch Model (Start)
2016-01-13 21:58:46,723 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endmodelcase.EndmodelcaseNodeFactory': CASE Switch Model (End)
2016-01-13 21:58:46,733 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.variable.CaseStartVariableNodeFactory': CASE Switch Variable (Start)
2016-01-13 21:58:46,739 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.variable.CaseEndVariableNodeFactory': CASE Switch Variable (End)
2016-01-13 21:58:46,746 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.emptytableswitch.EmptyTableSwitchNodeFactory': Empty Table Switch
2016-01-13 21:58:46,755 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntogrid2.ColumnToGrid2NodeFactory': Column to Grid
2016-01-13 21:58:46,763 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnheaderextract.ColumnHeaderExtractorNodeFactory': Extract Column Header
2016-01-13 21:58:46,772 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnheaderinsert.ColumnHeaderInsertNodeFactory': Insert Column Header
2016-01-13 21:58:46,780 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.addemptyrows.AddEmptyRowsNodeFactory': Add Empty Rows
2016-01-13 21:58:46,789 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellreplace.CellReplacerNodeFactory': Cell Replacer
2016-01-13 21:58:46,798 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.autobinner3.AutoBinnerLearnNodeFactory': Auto-Binner
2016-01-13 21:58:46,808 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.autobinner.apply.AutoBinnerApplyNodeFactory': Auto-Binner (Apply)
2016-01-13 21:58:46,816 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopEndJoin2NodeFactory': Loop End (Column Append)
2016-01-13 21:58:46,825 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.listfiles2.ListFilesNodeFactory': List Files
2016-01-13 21:58:46,833 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.tablecreator.TableCreator2NodeFactory': Table Creator
2016-01-13 21:58:46,842 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.sampledata.SampleDataNodeFactory': Data Generator
2016-01-13 21:58:46,850 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.createtablestructure.CreateTableStructureNodeFactory': Create Table Structure
2016-01-13 21:58:46,859 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.createtempdir.CreateTempDirectoryNodeFactory': Create Temp Dir
2016-01-13 21:58:46,869 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.sendmail.SendMailNodeFactory': Send Email
2016-01-13 21:58:46,877 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.extractsysprop.ReadSysPropertyNodeFactory': Extract System Properties
2016-01-13 21:58:46,886 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.extractcontextprop.ReadContextPropertyNodeFactory': Extract Context Properties
2016-01-13 21:58:46,892 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.PMMLNormalizerDeNodeFactory': Denormalizer (PMML)
2016-01-13 21:58:46,899 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.NormalizerDeNodeFactory': Denormalizer
2016-01-13 21:58:46,906 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.extract.ColorExtractNodeFactory': Extract Color
2016-01-13 21:58:46,924 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.categorytonumber2.CategoryToNumberNodeFactory2': Category To Number
2016-01-13 21:58:46,933 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.categorytonumber.CategoryToNumberApplyNodeFactory': Category To Number (Apply)
2016-01-13 21:58:46,939 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.column.DataColumnSpecFilterNodeFactory': Column Filter
2016-01-13 21:58:46,948 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rounddouble.RoundDoubleNodeFactory': Round Double
2016-01-13 21:58:46,957 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnresorter.ColumnResorterNodeFactory': Column Resorter
2016-01-13 21:58:46,967 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnlag.LagColumnNodeFactory': Lag Column
2016-01-13 21:58:46,985 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.datavalidator.DataValidatorNodeFactory': Table Validator
2016-01-13 21:58:46,995 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.datavalidator.DataValidatorSpecNodeFactory': Table Validator (Reference)
2016-01-13 21:58:47,002 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.mergevariables.MergeVariablesNodeFactory': Merge Variables
2016-01-13 21:58:47,011 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.group.GroupLoopStartNodeFactory': Group Loop Start
2016-01-13 21:58:47,019 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.variableloopend.VariableLoopEndNodeFactory': Variable Loop End
2016-01-13 21:58:47,028 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnaggregator.ColumnAggregatorNodeFactory': Column Aggregator
2016-01-13 21:58:47,038 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bytevector.create.CreateByteVectorNodeFactory': Create Byte Vector
2016-01-13 21:58:47,046 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bytevector.expand.ExpandByteVectorNodeFactory': Expand Byte Vector
2016-01-13 21:58:47,052 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.generictry.DataPortTryNodeFactory': Try (Data Ports)
2016-01-13 21:58:47,057 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.generictry.VariablePortTryNodeFactory': Try (Variable Ports)
2016-01-13 21:58:47,065 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.DataPortCatchNodeFactory': Catch Errors (Data Ports)
2016-01-13 21:58:47,069 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.VariablePortCatchNodeFactory': Catch Errors (Var Ports)
2016-01-13 21:58:47,074 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.DBPortCatchNodeFactory': Catch Errors (DB Ports)
2016-01-13 21:58:47,080 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.GenericPortCatchNodeFactory': Catch Errors (Generic Ports)
2016-01-13 21:58:47,086 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.inverter.ActiveBranchInverterNodeFactory': Active Branch Inverter
2016-01-13 21:58:47,093 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.tablecoltovariable.TableColumnToVariableNodeFactory': Table Column to Variable
2016-01-13 21:58:47,102 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.sleep.SleepNodeFactory': Wait...
2016-01-13 21:58:47,109 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.workflow.save.SaveWorkflowNodeFactory': Save Workflow
2016-01-13 21:58:47,117 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.timerinfo.TimerinfoNodeFactory': Timer Info
2016-01-13 21:58:47,124 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.globaltimerinfo.GlobalTimerinfoNodeFactory': Global Timer Info
2016-01-13 21:58:47,131 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopStartNodeFactory': Recursive Loop Start
2016-01-13 21:58:47,139 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopEndNodeFactory': Recursive Loop End
2016-01-13 21:58:47,146 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopStart2NodeFactory': Recursive Loop Start (2 ports)
2016-01-13 21:58:47,153 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopEnd2NodeFactory': Recursive Loop End (2 ports)
2016-01-13 21:58:47,161 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.xml2pmml.XML2PMMLNodeFactory': XML To PMML
2016-01-13 21:58:47,171 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.JDBCConnectorNodeFactory': Database Connector
2016-01-13 21:58:47,177 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.connection.DBTableSelectorNodeFactory': Database Table Selector
2016-01-13 21:58:47,185 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.SQLInjectNodeFactory': SQL Inject
2016-01-13 21:58:47,192 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.SQLExtractNodeFactory': SQL Extract
2016-01-13 21:58:47,199 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.drop.DBDropTableNodeFactory': Database Drop Table
2016-01-13 21:58:47,206 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.hilite.AutoHiLiteNodeFactory': HiLite Table
2016-01-13 21:58:47,215 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.coltypechanger.ColumnTypeChangerNodeFactory': Column Auto Type Cast
2016-01-13 21:58:47,225 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.fixedwidthfr.FixedWidthFRNodeFactory': Fixed Width File Reader
2016-01-13 21:58:47,233 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.targetshuffling.TargetShufflingNodeFactory': Target Shuffling
2016-01-13 21:58:47,328 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMeanMissingCellHandlerFactory
2016-01-13 21:58:47,499 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMeanMissingCellHandlerFactory
2016-01-13 21:58:47,522 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMovingAverageMissingCellHandlerFactory
2016-01-13 21:58:47,529 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMovingAverageMissingCellHandlerFactory
2016-01-13 21:58:47,543 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedDoubleValueMissingCellHandlerFactory
2016-01-13 21:58:47,571 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedDoubleValueMissingCellHandlerFactory
2016-01-13 21:58:47,586 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MaxMissingCellHandlerFactory
2016-01-13 21:58:47,588 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MaxMissingCellHandlerFactory
2016-01-13 21:58:47,599 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.IntegerMeanMissingCellHandlerFactory
2016-01-13 21:58:47,636 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.IntegerMeanMissingCellHandlerFactory
2016-01-13 21:58:47,645 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedIntegerValueMissingCellHandlerFactory
2016-01-13 21:58:47,648 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedIntegerValueMissingCellHandlerFactory
2016-01-13 21:58:47,685 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MinMissingCellHandlerFactory
2016-01-13 21:58:47,687 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MinMissingCellHandlerFactory
2016-01-13 21:58:47,693 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MostFrequentValueMissingCellHandlerFactory
2016-01-13 21:58:47,695 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MostFrequentValueMissingCellHandlerFactory
2016-01-13 21:58:47,703 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.NextMissingCellHandlerFactory
2016-01-13 21:58:47,705 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.NextMissingCellHandlerFactory
2016-01-13 21:58:47,711 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.RemoveRowMissingCellHandlerFactory
2016-01-13 21:58:47,712 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.RemoveRowMissingCellHandlerFactory
2016-01-13 21:58:47,718 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MedianNumberMissingCellHandlerFactory
2016-01-13 21:58:47,719 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MedianNumberMissingCellHandlerFactory
2016-01-13 21:58:47,725 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.PreviousMissingCellHandlerFactory
2016-01-13 21:58:47,726 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.PreviousMissingCellHandlerFactory
2016-01-13 21:58:47,734 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.LinearInterpolationMissingCellHandlerFactory
2016-01-13 21:58:47,737 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.LinearInterpolationMissingCellHandlerFactory
2016-01-13 21:58:47,737 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedStringValueMissingCellHandlerFactory
2016-01-13 21:58:47,737 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedStringValueMissingCellHandlerFactory
2016-01-13 21:58:47,737 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.AverageInterpolationMissingCellHandlerFactory
2016-01-13 21:58:47,752 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.AverageInterpolationMissingCellHandlerFactory
2016-01-13 21:58:47,752 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedLongValueMissingCellHandlerFactory
2016-01-13 21:58:47,752 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedLongValueMissingCellHandlerFactory
2016-01-13 21:58:47,784 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.missingval.compute.MissingValueHandlerNodeFactory': Missing Value
2016-01-13 21:58:47,799 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.missingval.apply.MissingValueApplyNodeFactory': Missing Value (Apply)
2016-01-13 21:58:47,799 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.numbertocategory.NumberToCategoryApplyNodeFactory': Number To Category (Apply)
2016-01-13 21:58:47,815 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.columnrename.DBColumnRenameNodeFactory': Database Column Rename
2016-01-13 21:58:47,815 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.normalize.NormalizerPMMLNodeFactory2': Normalizer (PMML)
2016-01-13 21:58:47,830 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.numbertostring.NumberToStringNodeFactory2': Number To String (PMML)
2016-01-13 21:58:47,830 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.stringtonumber.StringToNumberNodeFactory2': String To Number (PMML)
2016-01-13 21:58:47,846 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.binner.BinnerNodeFactory2': Numeric Binner (PMML)
2016-01-13 21:58:47,846 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columntrans2.One2ManyCol2PMMLNodeFactory2': One to Many (PMML)
2016-01-13 21:58:47,862 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columntrans2.Many2OneCol2PMMLNodeFactory2': Many to One (PMML)
2016-01-13 21:58:47,862 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.learner2.DecisionTreeLearnerNodeFactory3': Decision Tree Learner
2016-01-13 21:58:47,877 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.linear2.learner.LinReg2LearnerNodeFactory2': Linear Regression Learner
2016-01-13 21:58:47,893 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.polynomial.learner2.PolyRegLearnerNodeFactory2': Polynomial Regression Learner
2016-01-13 21:58:47,908 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.logistic.learner3.LogRegLearnerNodeFactory3': Logistic Regression Learner
2016-01-13 21:58:47,908 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.neural.rprop.RPropNodeFactory2': RProp MLP Learner
2016-01-13 21:58:47,940 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.svm.learner.SVMLearnerNodeFactory2': SVM Learner
2016-01-13 21:58:47,940 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bayes.naivebayes.learner2.NaiveBayesLearnerNodeFactory3': Naive Bayes Learner
2016-01-13 21:58:47,955 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.kmeans.ClusterNodeFactory': k-Means
2016-01-13 21:58:47,971 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.pivot.DBPivotNodeFactory': Database Pivot
2016-01-13 21:58:47,986 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.sampling.DBSamplingNodeFactory': Database Sampling
2016-01-13 21:58:47,986 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.auto.DBAutoBinnerNodeFactory': Database Auto-Binner
2016-01-13 21:58:48,002 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.numeric.DBNumericBinnerNodeFactory': Database Numeric-Binner
2016-01-13 21:58:48,002 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.apply.DBApplyBinnerNodeFactory': Database Apply-Binner
2016-01-13 21:58:48,018 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowSplitRefNodeFactory': Reference Row Splitter
2016-01-13 21:58:48,049 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnSplitRefNodeFactory': Reference Column Splitter
2016-01-13 21:58:48,064 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rank.RankNodeFactory': Rank
2016-01-13 21:58:48,080 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowSplitRefNodeFactory': Reference Row Splitter
2016-01-13 21:58:48,080 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnSplitRefNodeFactory': Reference Column Splitter
2016-01-13 21:58:48,096 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rank.RankNodeFactory': Rank
2016-01-13 21:58:48,111 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.learner.classification.TreeEnsembleClassificationLearnerNodeFactory': Tree Ensemble Learner
2016-01-13 21:58:48,111 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.predictor.classification.TreeEnsembleClassificationPredictorNodeFactory': Tree Ensemble Predictor
2016-01-13 21:58:48,127 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.modelextractor.TreeEnsembleModelExtractorNodeFactory': Tree Ensemble Model Extract
2016-01-13 21:58:48,127 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.learner.regression.TreeEnsembleRegressionLearnerNodeFactory': Tree Ensemble Learner (Regression)
2016-01-13 21:58:48,142 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.predictor.regression.TreeEnsembleRegressionPredictorNodeFactory': Tree Ensemble Predictor (Regression)
2016-01-13 21:58:48,158 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.learner.classification.RandomForestClassificationLearnerNodeFactory': Random Forest Learner
2016-01-13 21:58:48,158 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.learner.regression.RandomForestRegressionLearnerNodeFactory': Random Forest Learner (Regression)
2016-01-13 21:58:48,174 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.predictor.classification.RandomForestClassificationPredictorNodeFactory': Random Forest Predictor
2016-01-13 21:58:48,189 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.predictor.regression.RandomForestRegressionPredictorNodeFactory': Random Forest Predictor (Regression)
2016-01-13 21:58:48,189 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.regressiontree.learner.RegressionTreeLearnerNodeFactory': Simple Regression Tree Learner
2016-01-13 21:58:48,205 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.regressiontree.predictor.RegressionTreePredictorNodeFactory': Simple Regression Tree Predictor
2016-01-13 21:58:48,220 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.metalearning.pmmlporttocell.PMMLPortToCellNodeFactory': PMML To Cell
2016-01-13 21:58:48,220 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.modeltotable.ModelToTableNodeFactory': Model to Cell
2016-01-13 21:58:48,236 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.tabletomodel.TableToModelNodeFactory': Cell To Model
2016-01-13 21:58:48,236 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingLearnerLoopStartNodeFactory': Boosting Learner Loop Start
2016-01-13 21:58:48,252 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingLearnerLoopEndNodeFactory': Boosting Learner Loop End
2016-01-13 21:58:48,252 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingPredictorLoopStartNodeFactory': Boosting Predictor Loop Start
2016-01-13 21:58:48,267 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingPredictorLoopEndNodeFactory': Boosting Predictor Loop End
2016-01-13 21:58:48,267 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.bagging.ModelLoopStartNodeFactory': Model Loop Start
2016-01-13 21:58:48,298 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.bagging.ModelLoopEndNodeFactory': Model Loop End
2016-01-13 21:58:48,314 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.tabletopmmlport.TableToPMMLNodeFactory': Cell To PMML
2016-01-13 21:58:48,314 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.voting.VotingLoopEndNodeFactory': Voting Loop End
2016-01-13 21:58:48,330 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmmlpredict2.PMMLPredictor2NodeFactory': PMML Predictor
2016-01-13 21:58:48,330 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.combine.PMMLEnsembleNodeFactory': Table to PMML Ensemble
2016-01-13 21:58:48,345 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.totable.PMMLEnsemble2TableNodeFactory': PMML Ensemble to Table
2016-01-13 21:58:48,345 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.predictor2.PMMLEnsemblePredictor2NodeFactory': PMML Ensemble Predictor
2016-01-13 21:58:48,361 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.loopend.PMMLEnsembleLoopEndNodeFactory': PMML Ensemble Loop End
2016-01-13 21:58:48,376 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.predictionfusion.PredictionFusionNodeFactory': Prediction Fusion
2016-01-13 21:58:48,392 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.JavaScriptingNodeFactory': Java Snippet (simple)
2016-01-13 21:58:48,408 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.rowfilter.JavaRowFilterNodeFactory': Java Snippet Row Filter
2016-01-13 21:58:48,408 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.rowsplitter.JavaRowSplitterNodeFactory': Java Snippet Row Splitter
2016-01-13 21:58:48,423 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.editvar.JavaEditVariableNodeFactory': Java Edit Variable (simple)
2016-01-13 21:58:48,423 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.ifswitch.JavaIfSwitchNodeFactory': Java IF (Table)
2016-01-13 21:58:48,439 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.svg.node.sparklines.SparkLineNodeFactory': Spark Line Appender
2016-01-13 21:58:48,439 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.svg.node.radarplot.RadarplotAppenderFactory': Radar Plot Appender
2016-01-13 21:58:48,454 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.renderer2image.Renderer2ImageNodeFactory': Renderer to Image
2016-01-13 21:58:48,454 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.readimage.ReadImageFromUrlNodeFactory': Read Images
2016-01-13 21:58:48,470 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.stringtosvg.StringToSvgNodeFactory': String To SVG
2016-01-13 21:58:48,486 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.jsnippet.JavaSnippetNodeFactory': Java Snippet
2016-01-13 21:58:48,548 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.jsnippet.JavaEditVarNodeFactory': Java Edit Variable
2016-01-13 21:58:48,548 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineVariableNodeFactory': Rule Engine Variable
2016-01-13 21:58:48,564 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngineVariable2PortsNodeFactory': Rule Engine Variable (Dictionary)
2016-01-13 21:58:48,579 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringmanipulation.StringManipulationNodeFactory': String Manipulation
2016-01-13 21:58:48,595 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineNodeFactory': Rule Engine
2016-01-13 21:58:48,595 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineFilterNodeFactory': Rule-based Row Filter
2016-01-13 21:58:48,610 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineSplitterNodeFactory': Rule-based Row Splitter
2016-01-13 21:58:48,626 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngine2PortsNodeFactory': Rule Engine (Dictionary)
2016-01-13 21:58:48,657 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngineFilter2PortsNodeFactory': Rule-based Row Filter (Dictionary)
2016-01-13 21:58:48,657 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngine2PortsSplitterNodeFactory': Rule-based Row Splitter (Dictionary)
2016-01-13 21:58:48,688 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.pmml.PMMLRuleEditorNodeFactory': Ruleset Editor
2016-01-13 21:58:48,704 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.pmml.PMMLRuleSetPredictorNodeFactory': Ruleset Predictor
2016-01-13 21:58:48,704 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.totable.RulesToTableNodeFactory': Ruleset to Table
2016-01-13 21:58:48,720 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.decisiontree.FromDecisionTreeNodeFactory': Decision Tree to Ruleset
2016-01-13 21:58:48,720 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.OneSampleTTestNodeFactory': Single sample t-test
2016-01-13 21:58:48,735 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.TwoSampleTTestNodeFactory': Independent groups t-test
2016-01-13 21:58:48,751 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.PairedTTestNodeFactory': Paired t-test
2016-01-13 21:58:48,751 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.OneWayANOVANodeFactory': One-way ANOVA
2016-01-13 21:58:48,766 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.viz.extended.ExtendedStatisticsNodeFactory': Statistics
2016-01-13 21:58:48,782 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.disturber.DisturberNodeFactory': Disturber Node
2016-01-13 21:58:48,782 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.differModelContent.DiffModelContentFactory': Model Content Difference Checker
2016-01-13 21:58:48,782 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.blocking.BlockingNodeFactory': Block Programmatically
2016-01-13 21:58:48,798 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.failing.FailingNodeFactory': Fail in execution
2016-01-13 21:58:48,798 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.credentialsvalidate.CredentialsValidateNodeFactory': Credentials Validate Test
2016-01-13 21:58:48,813 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.datagenerator.TestDataNodeFactory': Test Data Generator
2016-01-13 21:58:48,813 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.executioncount.ExecutionCountNodeFactory': Count Execution Programmatically
2016-01-13 21:58:48,813 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.file.DifferFileNodeFactory': File Difference Checker
2016-01-13 21:58:48,829 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.imagecomp.ImageCompNodeFactory': Image Comparator (deprecated)
2016-01-13 21:58:48,829 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.differ.DifferenceCheckerNodeFactory': Table Difference Checker
2016-01-13 21:58:48,844 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.internal.nodes.image.ImageDifferNodeFactory': Image Difference Checker
2016-01-13 21:58:48,844 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.config.TestConfigNodeFactory': Testflow Configuration
2016-01-13 21:58:48,860 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.internal.nodes.pmml.PMMLDifferenceCheckerNodeFactory': PMML Difference Checker
2016-01-13 21:58:48,860 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.create.FileStoreCreateNodeFactory': Create FileStore Column
2016-01-13 21:58:48,860 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.check.FileStoreTestNodeFactory': Test FileStore Column
2016-01-13 21:58:48,876 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.createloopend.FileStoreCreateLoopEndNodeFactory': Create FileStore Column in LoopEnd
2016-01-13 21:58:48,876 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.fsloopend.LoopEndFileStorePortObjectTestNodeFactory': Test FileStore Port Object Loop End
2016-01-13 21:58:48,891 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.fsobject2cell.FileStoreObjectToCellNodeFactory': Test FileStore Port Object to Table
2016-01-13 21:58:48,891 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.logging.LoggerOptionNodeFactory': Logger Option
2016-01-13 21:58:48,907 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.filter.extract.ExtractFromToNodeFactory': Extract Time Window
2016-01-13 21:58:48,907 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.movavg.MovingAverageNodeFactory': Moving Average
2016-01-13 21:58:48,922 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.stringtotimestamp.String2DateNodeFactory': String to Date/Time
2016-01-13 21:58:48,922 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.diff.TimeDifferenceNodeFactory': Time Difference
2016-01-13 21:58:48,954 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.generator.DateGeneratorNodeFactory': Time Generator
2016-01-13 21:58:48,954 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.extract.TimeFieldExtractorNodeFactory': Time Field Extractor
2016-01-13 21:58:48,969 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.time2string.Time2StringNodeFactory': Time to String
2016-01-13 21:58:48,969 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.preset.TimePresetNodeFactory': Preset Date/Time
2016-01-13 21:58:48,985 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.mask.MaskTimeNodeFactory': Mask Date/Time
2016-01-13 21:58:49,000 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.extract.date.DateFieldExtractorNodeFactory': Date Field Extractor
2016-01-13 21:58:49,000 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.movagg.MovingAggregationNodeFactory': Moving Aggregation
2016-01-13 21:58:49,016 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.converter.DateShiftNodeFactory': Date/Time Shift 
2016-01-13 21:58:49,016 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Cross Validation/
2016-01-13 21:58:49,016 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Cross Validation
2016-01-13 21:58:49,063 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Cross Validation") is not locked
2016-01-13 21:58:49,063 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Cross Validation" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:49,094 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:0
2016-01-13 21:58:49,094 : DEBUG : main : NodeContainer :  :  : KNIME MetaNode Repository 1 has new state: IDLE
2016-01-13 21:58:49,110 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("X_Aggregator (#1)") is not locked
2016-01-13 21:58:49,125 : DEBUG : main : AggregateOutputNodeFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,328 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("X_Partitioner (#2)") is not locked
2016-01-13 21:58:49,344 : DEBUG : main : XValidatePartitionerFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,359 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("Decision Tree Learner (#14)") is not locked
2016-01-13 21:58:49,406 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,500 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("Decision Tree Predictor (#15)") is not locked
2016-01-13 21:58:49,515 : DEBUG : main : DecTreePredictorNodeFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,578 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:14(1) to node 1:0:15(1)
2016-01-13 21:58:49,593 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:2(1) to node 1:0:14(1)
2016-01-13 21:58:49,593 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:2(2) to node 1:0:15(2)
2016-01-13 21:58:49,593 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0(0) to node 1:0:2(1)
2016-01-13 21:58:49,593 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:1(2) to node 1:0(1)
2016-01-13 21:58:49,593 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:1(1) to node 1:0(0)
2016-01-13 21:58:49,593 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:15(1) to node 1:0:1(1)
2016-01-13 21:58:49,624 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Cross Validation"  with no errors
2016-01-13 21:58:49,624 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'cross_validation': Cross Validation
2016-01-13 21:58:49,624 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Feature Elimination/
2016-01-13 21:58:49,624 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Feature Elimination
2016-01-13 21:58:49,640 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Feature Elimination") is not locked
2016-01-13 21:58:49,640 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Feature Elimination" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:49,656 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:1
2016-01-13 21:58:49,656 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination Start _1_1_ (#1)") is not locked
2016-01-13 21:58:49,671 : DEBUG : main : BWElimLoopStart1NodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,671 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination Filter (#2)") is not locked
2016-01-13 21:58:49,687 : DEBUG : main : BWElimFilterNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,702 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination End (#3)") is not locked
2016-01-13 21:58:49,702 : DEBUG : main : BWElimLoopEndNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,718 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Partitioning (#7)") is not locked
2016-01-13 21:58:49,718 : DEBUG : main : PartitionNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,734 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Naive Bayes Learner (#8)") is not locked
2016-01-13 21:58:49,765 : DEBUG : main : NaiveBayesLearnerNodeFactory2 : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,765 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Naive Bayes Predictor (#9)") is not locked
2016-01-13 21:58:49,780 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:49,796 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:3(2) to node 1:1:2(1)
2016-01-13 21:58:49,796 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:8(1) to node 1:1:9(1)
2016-01-13 21:58:49,796 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:1(1) to node 1:1:7(1)
2016-01-13 21:58:49,796 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:9(1) to node 1:1:3(1)
2016-01-13 21:58:49,796 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:3(1) to node 1:1(0)
2016-01-13 21:58:49,796 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1(1) to node 1:1:2(2)
2016-01-13 21:58:49,796 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:2(1) to node 1:1(1)
2016-01-13 21:58:49,796 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:7(2) to node 1:1:9(2)
2016-01-13 21:58:49,812 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1(0) to node 1:1:1(1)
2016-01-13 21:58:49,812 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:7(1) to node 1:1:8(1)
2016-01-13 21:58:49,827 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Feature Elimination"  with no errors
2016-01-13 21:58:49,827 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'feature_elimination': Feature Elimination
2016-01-13 21:58:49,827 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Variables Loop (Data)/
2016-01-13 21:58:49,827 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Variables Loop (Data)
2016-01-13 21:58:49,843 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Variables Loop (Data)") is not locked
2016-01-13 21:58:49,843 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Data)" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:49,843 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:2
2016-01-13 21:58:49,843 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 21:58:49,858 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Row To Variable Loop Start (#3)") is not locked
2016-01-13 21:58:49,874 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Inject Variables _Data_ (#4)") is not locked
2016-01-13 21:58:49,890 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2:3(1) to node 1:2:4(2)
2016-01-13 21:58:49,890 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2(1) to node 1:2:3(1)
2016-01-13 21:58:49,890 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2(0) to node 1:2:4(1)
2016-01-13 21:58:49,890 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2:2(1) to node 1:2(0)
2016-01-13 21:58:49,921 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Data)"  with no errors
2016-01-13 21:58:49,921 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'variables_loop': Variables Loop (Data)
2016-01-13 21:58:49,921 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Variables Loop (Database)/
2016-01-13 21:58:49,921 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Variables Loop (Database)
2016-01-13 21:58:49,936 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Variables Loop (Database)") is not locked
2016-01-13 21:58:49,936 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Database)" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:49,936 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:3
2016-01-13 21:58:49,936 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 21:58:49,952 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Row To Variable Loop Start (#3)") is not locked
2016-01-13 21:58:49,952 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Inject Variables _Database_ (#4)") is not locked
2016-01-13 21:58:49,968 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3:3(1) to node 1:3:4(2)
2016-01-13 21:58:49,968 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3(1) to node 1:3:3(1)
2016-01-13 21:58:49,968 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3(0) to node 1:3:4(1)
2016-01-13 21:58:49,968 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3:2(1) to node 1:3(0)
2016-01-13 21:58:49,983 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Database)"  with no errors
2016-01-13 21:58:49,983 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'variables_loop_db': Variables Loop (Database)
2016-01-13 21:58:49,983 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Iterate list of files/
2016-01-13 21:58:49,983 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Iterate list of files
2016-01-13 21:58:49,999 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Iterate list of files") is not locked
2016-01-13 21:58:49,999 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Iterate list of files" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:49,999 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:4
2016-01-13 21:58:49,999 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("TableRow To Variable Loop Start (#2)") is not locked
2016-01-13 21:58:50,014 : DEBUG : main : LoopStartVariableNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,014 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("Loop End (#3)") is not locked
2016-01-13 21:58:50,030 : DEBUG : main : LoopEndNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,030 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("File Reader (#4)") is not locked
2016-01-13 21:58:50,046 : DEBUG : main : FileReaderNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,061 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:2(1) to node 1:4:4(0)
2016-01-13 21:58:50,061 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:4(1) to node 1:4:3(1)
2016-01-13 21:58:50,061 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:3(1) to node 1:4(0)
2016-01-13 21:58:50,061 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4(0) to node 1:4:2(1)
2016-01-13 21:58:50,124 : INFO  : main : StringHistory : File Reader : 1:4:4 : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_ASCIIfile.txt' does not exist.
2016-01-13 21:58:50,139 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Iterate list of files"  with no errors
2016-01-13 21:58:50,139 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'iterate_list_of_files': Iterate List of Files
2016-01-13 21:58:50,139 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Looper/
2016-01-13 21:58:50,139 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Looper
2016-01-13 21:58:50,139 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Looper") is not locked
2016-01-13 21:58:50,139 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Looper" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:50,155 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:5
2016-01-13 21:58:50,155 : DEBUG : main : FileNodeContainerMetaPersistor : Loop x-times : 1:5 : Workflow being loaded ("Counting Loop Start (#1)") is not locked
2016-01-13 21:58:50,202 : DEBUG : main : FileNodeContainerMetaPersistor : Loop x-times : 1:5 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 21:58:50,202 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:5:2(1) to node 1:5(0)
2016-01-13 21:58:50,202 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:5(0) to node 1:5:1(1)
2016-01-13 21:58:50,217 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Looper"  with no errors
2016-01-13 21:58:50,217 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'looper': Loop x-times
2016-01-13 21:58:50,217 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Boosting Learner/
2016-01-13 21:58:50,233 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Boosting Learner
2016-01-13 21:58:50,233 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Boosting Learner") is not locked
2016-01-13 21:58:50,233 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Learner" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:50,248 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:6
2016-01-13 21:58:50,248 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Boosting Learner Loop Start (#1)") is not locked
2016-01-13 21:58:50,264 : DEBUG : main : BoostingLearnerLoopStartNodeFactory : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,264 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Boosting Learner Loop End (#4)") is not locked
2016-01-13 21:58:50,280 : DEBUG : main : BoostingLearnerLoopEndNodeFactory : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,280 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Naive Bayes Learner (#7)") is not locked
2016-01-13 21:58:50,295 : DEBUG : main : NaiveBayesLearnerNodeFactory2 : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,295 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Naive Bayes Predictor (#8)") is not locked
2016-01-13 21:58:50,295 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,311 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:7(1) to node 1:6:4(1)
2016-01-13 21:58:50,311 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:1(1) to node 1:6:7(1)
2016-01-13 21:58:50,311 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:1(2) to node 1:6:8(2)
2016-01-13 21:58:50,311 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:4(1) to node 1:6(0)
2016-01-13 21:58:50,311 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:8(1) to node 1:6:4(2)
2016-01-13 21:58:50,311 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6(0) to node 1:6:1(1)
2016-01-13 21:58:50,311 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:7(1) to node 1:6:8(1)
2016-01-13 21:58:50,326 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Learner"  with no errors
2016-01-13 21:58:50,326 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.boosting_learner': Boosting Learner
2016-01-13 21:58:50,326 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Boosting Predictor/
2016-01-13 21:58:50,326 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Boosting Predictor
2016-01-13 21:58:50,326 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Boosting Predictor") is not locked
2016-01-13 21:58:50,326 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Predictor" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:50,342 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:7
2016-01-13 21:58:50,342 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Boosting Predictor Loop Start (#1)") is not locked
2016-01-13 21:58:50,358 : DEBUG : main : BoostingPredictorLoopStartNodeFactory : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,358 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Boosting Predictor Loop End (#3)") is not locked
2016-01-13 21:58:50,373 : DEBUG : main : BoostingPredictorLoopEndNodeFactory : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,373 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Naive Bayes Predictor (#4)") is not locked
2016-01-13 21:58:50,389 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,389 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:1(1) to node 1:7:4(1)
2016-01-13 21:58:50,389 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:4(1) to node 1:7:3(1)
2016-01-13 21:58:50,389 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7(1) to node 1:7:4(2)
2016-01-13 21:58:50,389 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:3(1) to node 1:7(0)
2016-01-13 21:58:50,389 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7(0) to node 1:7:1(1)
2016-01-13 21:58:50,436 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Predictor"  with no errors
2016-01-13 21:58:50,436 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.boosting_predictor': Boosting Predictor
2016-01-13 21:58:50,436 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Delegating/
2016-01-13 21:58:50,436 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Delegating
2016-01-13 21:58:50,451 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Delegating") is not locked
2016-01-13 21:58:50,451 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Delegating" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:50,451 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:8
2016-01-13 21:58:50,451 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Filter well (#61)") is not locked
2016-01-13 21:58:50,467 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Decision Tree Learner (#62)") is not locked
2016-01-13 21:58:50,482 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,482 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Recursive Loop Start (#63)") is not locked
2016-01-13 21:58:50,498 : DEBUG : main : RecursiveLoopStartNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,498 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Recursive Loop End (#64)") is not locked
2016-01-13 21:58:50,498 : DEBUG : main : RecursiveLoopEndNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,514 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("PMML Predictor (#65)") is not locked
2016-01-13 21:58:50,529 : DEBUG : main : PMMLPredictor2NodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,529 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Reference Column Filter (#66)") is not locked
2016-01-13 21:58:50,545 : DEBUG : main : ColumnFilterRefNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,545 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("PMML To Cell (#67)") is not locked
2016-01-13 21:58:50,592 : DEBUG : main : PMMLPortToCellNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:8:61
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8(0) to node 1:8:63(1)
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:62(1)
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:66(1) to node 1:8:64(2)
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:67(1) to node 1:8:64(1)
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:65(1) to node 1:8:61(0)
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:62(1) to node 1:8:67(1)
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:66(2)
2016-01-13 21:58:50,592 : DEBUG : main : Workflow :  :  : Triggering graph analysis on 1:8:61
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:65(2)
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:66(1)
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:62(1) to node 1:8:65(1)
2016-01-13 21:58:50,592 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:64(1) to node 1:8(0)
2016-01-13 21:58:50,607 : DEBUG : main : FileNodeContainerMetaPersistor : Filter well predicted rows : 1:8:61 : Workflow being loaded ("Joiner (#61)") is not locked
2016-01-13 21:58:50,607 : DEBUG : main : Joiner2NodeFactory : Filter well predicted rows : 1:8:61 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,623 : DEBUG : main : FileNodeContainerMetaPersistor : Filter well predicted rows : 1:8:61 : Workflow being loaded ("Reference Row Filter (#62)") is not locked
2016-01-13 21:58:50,623 : DEBUG : main : RowFilterRefNodeFactory : Filter well predicted rows : 1:8:61 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,638 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61:62(1) to node 1:8:61(0)
2016-01-13 21:58:50,638 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:62(1)
2016-01-13 21:58:50,638 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:61(1)
2016-01-13 21:58:50,638 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:61(2)
2016-01-13 21:58:50,638 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61:61(1) to node 1:8:61:62(2)
2016-01-13 21:58:50,654 : DEBUG : main : Workflow :  :  : Triggering graph analysis on 1:8:61
2016-01-13 21:58:50,670 : DEBUG : main : NodeContainer :  :  : Recursive Loop Start 1:8:63 has new state: IDLE
2016-01-13 21:58:50,670 : DEBUG : main : NodeContainer :  :  : Decision Tree Learner (deprecated) 1:8:62 has new state: IDLE
2016-01-13 21:58:50,670 : DEBUG : main : NodeContainer :  :  : PMML Predictor 1:8:65 has new state: IDLE
2016-01-13 21:58:50,670 : DEBUG : main : NodeContainer :  :  : PMML To Cell 1:8:67 has new state: IDLE
2016-01-13 21:58:50,670 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Delegating"  with warnings
2016-01-13 21:58:50,670 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.delegated_learning': Delegating
2016-01-13 21:58:50,685 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Bagging/
2016-01-13 21:58:50,685 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Bagging
2016-01-13 21:58:50,685 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Bagging") is not locked
2016-01-13 21:58:50,701 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Bagging" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:50,701 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:9
2016-01-13 21:58:50,701 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Model Loop End (#7)") is not locked
2016-01-13 21:58:50,716 : DEBUG : main : ModelLoopEndNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,716 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Model Loop Start (#8)") is not locked
2016-01-13 21:58:50,748 : DEBUG : main : ModelLoopStartNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,748 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Voting Loop End (#9)") is not locked
2016-01-13 21:58:50,763 : DEBUG : main : VotingLoopEndNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,763 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Chunk Loop Start (#12)") is not locked
2016-01-13 21:58:50,779 : DEBUG : main : LoopStartChunkNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,779 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Shuffle (#13)") is not locked
2016-01-13 21:58:50,794 : DEBUG : main : ShuffleNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,794 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Decision Tree Learner (#14)") is not locked
2016-01-13 21:58:50,810 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,810 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Decision Tree Predictor (#15)") is not locked
2016-01-13 21:58:50,810 : DEBUG : main : DecTreePredictorNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,826 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9(1) to node 1:9:15(2)
2016-01-13 21:58:50,826 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:13(1) to node 1:9:12(1)
2016-01-13 21:58:50,826 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:12(1) to node 1:9:14(1)
2016-01-13 21:58:50,826 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9(0) to node 1:9:13(1)
2016-01-13 21:58:50,826 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:9(1) to node 1:9(0)
2016-01-13 21:58:50,826 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:15(1) to node 1:9:9(1)
2016-01-13 21:58:50,826 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:8(1) to node 1:9:15(1)
2016-01-13 21:58:50,826 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:14(1) to node 1:9:7(1)
2016-01-13 21:58:50,826 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:7(1) to node 1:9:8(1)
2016-01-13 21:58:50,857 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Bagging"  with no errors
2016-01-13 21:58:50,857 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.bagging': Bagging
2016-01-13 21:58:50,857 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Seasonality Correction/
2016-01-13 21:58:50,857 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Seasonality Correction
2016-01-13 21:58:50,872 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Seasonality Correction") is not locked
2016-01-13 21:58:50,872 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Seasonality Correction" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:50,904 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:10
2016-01-13 21:58:50,904 : DEBUG : main : FileNodeContainerMetaPersistor : Seasonality Correction : 1:10 : Workflow being loaded ("Lag Column (#24)") is not locked
2016-01-13 21:58:50,919 : DEBUG : main : LagColumnNodeFactory : Seasonality Correction : 1:10 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,919 : DEBUG : main : FileNodeContainerMetaPersistor : Seasonality Correction : 1:10 : Workflow being loaded ("Java Snippet _simple_ (#25)") is not locked
2016-01-13 21:58:50,935 : DEBUG : main : JavaScriptingNodeFactory : Seasonality Correction : 1:10 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,935 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10:24(1) to node 1:10:25(1)
2016-01-13 21:58:50,935 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10:25(1) to node 1:10(0)
2016-01-13 21:58:50,935 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10(0) to node 1:10:24(1)
2016-01-13 21:58:50,950 : DEBUG : main : NodeContainer :  :  : Lag Column 1:10:24 has new state: IDLE
2016-01-13 21:58:50,950 : DEBUG : main : NodeContainer :  :  : Java Snippet (simple) 1:10:25 has new state: IDLE
2016-01-13 21:58:50,950 : DEBUG : main : NodeContainer :  :  : Seasonality Correction 1:10 has new state: IDLE
2016-01-13 21:58:50,950 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Seasonality Correction"  with warnings
2016-01-13 21:58:50,950 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'SeasonalityCorrection': Seasonality Correction
2016-01-13 21:58:50,950 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Time Series Auto-Prediction Training/
2016-01-13 21:58:50,966 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Time Series Auto-Prediction Training
2016-01-13 21:58:50,966 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Time Series Auto-Prediction Training") is not locked
2016-01-13 21:58:50,966 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Training" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:50,966 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:11
2016-01-13 21:58:50,966 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Partitioning (#147)") is not locked
2016-01-13 21:58:50,982 : DEBUG : main : PartitionNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,982 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Lag Column (#216)") is not locked
2016-01-13 21:58:50,997 : DEBUG : main : LagColumnNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:50,997 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Linear Regression Learner (#234)") is not locked
2016-01-13 21:58:51,013 : DEBUG : main : LinReg2LearnerNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:51,028 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:234(1) to node 1:11(0)
2016-01-13 21:58:51,028 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:234(2) to node 1:11(1)
2016-01-13 21:58:51,028 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11(0) to node 1:11:216(1)
2016-01-13 21:58:51,028 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:147(1) to node 1:11:234(1)
2016-01-13 21:58:51,028 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:216(1) to node 1:11:147(1)
2016-01-13 21:58:51,028 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:147(2) to node 1:11(2)
2016-01-13 21:58:51,044 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Training"  with no errors
2016-01-13 21:58:51,044 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'Time-SeriesAuto-PredictionTraining': Time-Series Auto-Prediction Training
2016-01-13 21:58:51,044 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Time Series Auto-Prediction Predictor/
2016-01-13 21:58:51,060 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Time Series Auto-Prediction Predictor
2016-01-13 21:58:51,060 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Time Series Auto-Prediction Predictor") is not locked
2016-01-13 21:58:51,060 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Predictor" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 21:58:51,060 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:12
2016-01-13 21:58:51,060 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Predictor : 1:12 : Workflow being loaded ("Numeric Scorer (#176)") is not locked
2016-01-13 21:58:51,075 : DEBUG : main : NumericScorerNodeFactory : Time Series Auto-Prediction Predictor : 1:12 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:51,091 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Predictor : 1:12 : Workflow being loaded ("Regression Predictor (#237)") is not locked
2016-01-13 21:58:51,091 : DEBUG : main : RegressionPredictorNodeFactory : Time Series Auto-Prediction Predictor : 1:12 : Factory is already initialized. Nothing to do.
2016-01-13 21:58:51,091 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12(1) to node 1:12:237(2)
2016-01-13 21:58:51,091 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:237(1) to node 1:12(0)
2016-01-13 21:58:51,091 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12(0) to node 1:12:237(1)
2016-01-13 21:58:51,091 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:237(1) to node 1:12:176(1)
2016-01-13 21:58:51,091 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:176(1) to node 1:12(1)
2016-01-13 21:58:51,106 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Predictor"  with no errors
2016-01-13 21:58:51,106 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'Time-SeriesAuto-PredictionPredictor': Time-Series Auto-Prediction Predictor
2016-01-13 21:58:51,372 : DEBUG : main : KNIMEEditorPlugin :  :  : Workflow SVG export not available, unable to instantiate "org.knime.workbench.editor.svgexport.exportservice.WorkflowSVGExportImpl"
2016-01-13 21:58:53,588 : ERROR : main : CategorySorter :  :  : CODING PROBLEM	After-ID 'toolintegration' of [Id: community Name: Community Nodes After-id: toolintegration] does not exist - in plug-in org.knime.base
2016-01-13 21:58:58,986 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".all" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 21:58:58,986 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".csv" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 21:58:58,986 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".csv.gz" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 21:58:58,986 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".pmml" registered for Node Factory: PMMLReaderNodeFactory.
2016-01-13 21:58:58,986 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".table" registered for Node Factory: ReadTableNodeFactory.
2016-01-13 21:58:58,986 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".tsv" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 21:58:58,986 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".txt" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 21:58:58,986 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".txt.gz" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 21:59:14,109 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 21:59:14,140 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 21:59:14,327 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 21:59:14,327 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on workflow.knime
2016-01-13 21:59:14,327 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 21:59:14,327 : DEBUG : main : WorkflowEditor :  :  : Resource File's project: file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/
2016-01-13 21:59:14,499 : INFO  : ModalContext : LoadWorkflowRunnable :  :  : New workflow created.
2016-01-13 21:59:14,515 : DEBUG : ModalContext : NodeContainer :  :  : Workflow Manager 2 has new state: EXECUTED
2016-01-13 21:59:14,515 : DEBUG : ModalContext : WorkflowManager :  :  : Created subworkflow 2
2016-01-13 21:59:14,515 : DEBUG : ModalContext : WorkflowManager :  :  : Added new subworkflow 2
2016-01-13 21:59:14,515 : DEBUG : ModalContext : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 21:59:14,515 : DEBUG : ModalContext : WorkflowManager :  :  : Created project 2
2016-01-13 21:59:14,515 : DEBUG : main : WorkflowEditor :  :  : Saving workflow Workflow Manager 2
2016-01-13 21:59:14,749 : DEBUG : main : ProjectWorkflowMap :  :  : Adding "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/" to project map (1 in total)
2016-01-13 21:59:14,749 : DEBUG : main : ProjectWorkflowMap :  :  : registering org.knime.workbench.editor2.WorkflowEditor@329a27ae to file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/. 1 registered clients now.
2016-01-13 21:59:25,674 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 21:59:25,674 : DEBUG : main : NodeContainer :  :  : Setting dirty flag on JiraOfflineTest 2
2016-01-13 21:59:25,674 : DEBUG : main : NodeContainer :  :  : Jira Adapter (Offline) 2:1 has new state: CONFIGURED
2016-01-13 21:59:25,674 : DEBUG : main : WorkflowManager :  :  : Added new node 2:1
2016-01-13 21:59:25,674 : DEBUG : main : NodeContainer :  :  : JiraOfflineTest 2 has new state: CONFIGURED
2016-01-13 21:59:25,689 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=NODE_ADDED;node=2:1;old=null;new=Jira Adapter (Offline) 2:1 (CONFIGURED);timestamp=2016-01-13 21:59:25]
2016-01-13 21:59:25,720 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=2;old=null;new=null;timestamp=2016-01-13 21:59:25]
2016-01-13 21:59:26,079 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 21:59:26,235 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 2:1 (CONFIGURED) )
2016-01-13 21:59:27,124 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 21:59:27,124 : DEBUG : main : NodeContainer :  :  : Jira Adapter (Offline) 2:2 has new state: CONFIGURED
2016-01-13 21:59:27,124 : DEBUG : main : WorkflowManager :  :  : Added new node 2:2
2016-01-13 21:59:27,514 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=NODE_ADDED;node=2:2;old=null;new=Jira Adapter (Offline) 2:2 (CONFIGURED);timestamp=2016-01-13 21:59:27]
2016-01-13 21:59:27,592 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 21:59:27,608 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 2:2 (CONFIGURED) )
2016-01-13 21:59:27,608 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 21:59:28,310 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 21:59:28,310 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 21:59:31,134 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 21:59:31,134 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 21:59:32,179 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 21:59:37,530 : DEBUG : main : WorkflowManager :  :  : Added new node 2:3
2016-01-13 21:59:37,530 : DEBUG : main : NodeContainer :  :  : JiraOfflineTest 2 has new state: IDLE
2016-01-13 21:59:37,530 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=NODE_ADDED;node=2:3;old=null;new=Table Difference Checker 2:3 (IDLE);timestamp=2016-01-13 21:59:37]
2016-01-13 21:59:37,764 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 21:59:37,779 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 2:3 (IDLE) )
2016-01-13 21:59:43,270 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 21:59:43,270 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 21:59:43,270 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 21:59:43,270 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on workflow.knime
2016-01-13 21:59:43,270 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 21:59:43,270 : DEBUG : main : WorkflowEditor :  :  : Resource File's project: file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/
2016-01-13 21:59:43,489 : DEBUG : ModalContext : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 21:59:43,504 : DEBUG : ModalContext : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 21:59:43,582 : DEBUG : ModalContext : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 21:59:43,598 : DEBUG : ModalContext : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 21:59:43,614 : DEBUG : ModalContext : DifferenceCheckerNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 21:59:43,614 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:2(1) to node 0:3(2)
2016-01-13 21:59:43,614 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:3(1)
2016-01-13 21:59:43,645 : DEBUG : ModalContext : Git SCM : Git SCM : 0:1 : Configure succeeded. (Git SCM)
2016-01-13 21:59:43,692 : DEBUG : ModalContext : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 21:59:43,692 : DEBUG : ModalContext : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest"  with no errors
2016-01-13 21:59:43,707 : DEBUG : main : ProjectWorkflowMap :  :  : Adding "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/" to project map (2 in total)
2016-01-13 21:59:43,707 : DEBUG : main : ProjectWorkflowMap :  :  : registering org.knime.workbench.editor2.WorkflowEditor@36003e90 to file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/. 1 registered clients now.
2016-01-13 21:59:43,723 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 21:59:43,723 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 21:59:43,723 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 21:59:43,723 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:1 (CONFIGURED) )
2016-01-13 21:59:43,754 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 21:59:43,754 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 21:59:43,754 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:2 (EXECUTED) )
2016-01-13 21:59:43,754 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 21:59:43,754 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 21:59:43,754 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:3 (CONFIGURED) )
2016-01-13 21:59:43,754 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 21:59:43,754 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 21:59:43,754 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 21:59:43,754 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 21:59:50,353 : DEBUG : main : NodeContainerEditPart :  :  : Table Difference Checker 2:3 (IDLE)
2016-01-13 22:00:00,109 : DEBUG : main : NodeContainerEditPart :  :  : Table Difference Checker 0:3 (CONFIGURED)
2016-01-13 22:00:00,109 : DEBUG : main : NodeContainerEditPart :  :  : Git SCM 0:2 (EXECUTED)
2016-01-13 22:00:03,541 : DEBUG : main : ResetAction :  :  : Resetting 1 node(s)
2016-01-13 22:00:03,541 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : reset
2016-01-13 22:00:03,541 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:00:03,541 : DEBUG : main : NodeContainer :  :  : Setting dirty flag on Table Difference Checker 0:3
2016-01-13 22:00:03,541 : DEBUG : main : NodeContainer :  :  : Setting dirty flag on GitOfflineTest 0
2016-01-13 22:00:03,541 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=0;old=null;new=null;timestamp=2016-01-13 22:00:03]
2016-01-13 22:00:03,541 : DEBUG : main : NodeContainer :  :  : Table Difference Checker 0:3 has new state: IDLE
2016-01-13 22:00:03,541 : DEBUG : main : Git SCM : Git SCM : 0:2 : reset
2016-01-13 22:00:03,541 : DEBUG : main : Git SCM : Git SCM : 0:2 : clean output ports.
2016-01-13 22:00:03,541 : DEBUG : main : NodeContainer :  :  : Setting dirty flag on Git SCM 0:2
2016-01-13 22:00:03,541 : DEBUG : main : NodeContainer :  :  : Git SCM 0:2 has new state: IDLE
2016-01-13 22:00:03,556 : DEBUG : main : Git SCM : Git SCM : 0:2 : Configure succeeded. (Git SCM)
2016-01-13 22:00:03,556 : DEBUG : main : NodeContainer :  :  : Git SCM 0:2 has new state: CONFIGURED
2016-01-13 22:00:03,556 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:00:03,556 : DEBUG : main : NodeContainer :  :  : Table Difference Checker 0:3 has new state: CONFIGURED
2016-01-13 22:00:04,976 : DEBUG : main : NodeContainerEditPart :  :  : Git SCM 0:2 (CONFIGURED)
2016-01-13 22:00:04,976 : DEBUG : main : NodeContainerEditPart :  :  : Git SCM 0:1 (CONFIGURED)
2016-01-13 22:00:07,410 : DEBUG : main : NodeContainerEditPart :  :  : Git SCM 0:1 (CONFIGURED)
2016-01-13 22:00:08,970 : DEBUG : main : NodeContainerEditPart :  :  : Git SCM 0:1 (CONFIGURED)
2016-01-13 22:00:14,554 : DEBUG : main : WorkflowEditor :  :  : Saving workflow GitOfflineTest 0
2016-01-13 22:00:14,788 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Replaced node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest\Git SCM (#2)"
2016-01-13 22:00:14,835 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Replaced node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest\Table Difference Checker (#3)"
2016-01-13 22:00:17,004 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 22:00:17,862 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 22:00:17,862 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 22:00:18,891 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 22:00:18,891 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 22:00:20,404 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 22:00:32,562 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 22:00:33,357 : DEBUG : main : CreateConnectionCommand :  :  : adding connection from 2:1 1 to 2:3 1
2016-01-13 22:00:33,373 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 2:1(1) to node 2:3(1)
2016-01-13 22:00:33,373 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=CONNECTION_ADDED;node=null;old=null;new=STD[2:1(1) -> 2:3( 1)];timestamp=2016-01-13 22:00:33]
2016-01-13 22:00:33,389 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:1(1) -> 2:3( 1)]
2016-01-13 22:00:33,389 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:00:33,389 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:1(1) -> 2:3( 1)]
2016-01-13 22:00:33,389 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:00:33,451 : DEBUG : KNIME-Node-Usage-Writer : NodeTimer$GlobalNodeStats :  :  : Successfully wrote node usage stats to file: D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\nodeusage_3.0.json
2016-01-13 22:00:34,886 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 22:00:34,886 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 22:00:35,760 : DEBUG : main : CreateConnectionCommand :  :  : adding connection from 2:2 1 to 2:3 2
2016-01-13 22:00:35,775 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:00:35,775 : DEBUG : main : NodeContainer :  :  : Table Difference Checker 2:3 has new state: CONFIGURED
2016-01-13 22:00:35,775 : DEBUG : main : NodeContainer :  :  : JiraOfflineTest 2 has new state: CONFIGURED
2016-01-13 22:00:35,775 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 2:2(1) to node 2:3(2)
2016-01-13 22:00:35,807 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=CONNECTION_ADDED;node=null;old=null;new=STD[2:2(1) -> 2:3( 2)];timestamp=2016-01-13 22:00:35]
2016-01-13 22:00:35,931 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:2(1) -> 2:3( 2)]
2016-01-13 22:00:35,931 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:00:35,931 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:2(1) -> 2:3( 2)]
2016-01-13 22:00:35,931 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:00:36,883 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 22:00:36,883 : DEBUG : main : NodeContainerEditPart :  :  : Table Difference Checker 2:3 (CONFIGURED)
2016-01-13 22:01:21,095 : DEBUG : main : NodeContainerEditPart :  :  : Table Difference Checker 2:3 (CONFIGURED)
2016-01-13 22:01:21,095 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 22:01:21,610 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 22:01:21,610 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 22:01:23,622 : INFO  : AWT-EventQueue-0 : StringHistory : Jira Adapter (Offline) : 2:1 : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_history.txt' does not exist.
2016-01-13 22:01:51,368 : WARN  : pool-2-thread-1 : KNIMEApplication$4 :  :  : Potential deadlock in AWT Event Queue detected. Full thread dump will follow as debug ouput.
2016-01-13 22:01:51,368 : DEBUG : pool-2-thread-1 : KNIMEApplication$4 :  :  : "AWT-EventQueue-0" Id=93 RUNNABLE (in native)
	at sun.java2d.d3d.D3DRenderQueue.flushBuffer(Native Method)
	at sun.java2d.d3d.D3DRenderQueue.flushBuffer(D3DRenderQueue.java:152)
	at sun.java2d.d3d.D3DRenderQueue.flushAndInvokeNow(D3DRenderQueue.java:142)
	at sun.java2d.d3d.D3DSurfaceData$D3DDataBufferNative.getElem(D3DSurfaceData.java:448)
	at sun.awt.image.DataBufferNative.getElem(DataBufferNative.java:75)
	at java.awt.image.DataBuffer.getElem(DataBuffer.java:329)
	at java.awt.image.SinglePixelPackedSampleModel.getDataElements(SinglePixelPackedSampleModel.java:409)
	at java.awt.image.Raster.getDataElements(Raster.java:1466)
	at sun.java2d.loops.OpaqueCopyAnyToArgb.Blit(CustomComponent.java:144)
	at sun.java2d.loops.GraphicsPrimitive.convertFrom(GraphicsPrimitive.java:560)
	at sun.java2d.loops.GraphicsPrimitive.convertFrom(GraphicsPrimitive.java:541)
	at sun.java2d.loops.MaskBlit$General.MaskBlit(MaskBlit.java:189)
	-  locked sun.java2d.loops.MaskBlit$General@6bc2d836
	at sun.java2d.loops.Blit$GeneralMaskBlit.Blit(Blit.java:204)
	at sun.java2d.pipe.DrawImage.blitSurfaceData(DrawImage.java:959)
	at sun.java2d.pipe.DrawImage.renderImageCopy(DrawImage.java:577)
	at sun.java2d.pipe.DrawImage.copyImage(DrawImage.java:67)
	at sun.java2d.pipe.DrawImage.copyImage(DrawImage.java:1014)
	at sun.java2d.pipe.ValidatePipe.copyImage(ValidatePipe.java:186)
	at sun.java2d.SunGraphics2D.drawImage(SunGraphics2D.java:3318)
	at sun.java2d.SunGraphics2D.drawImage(SunGraphics2D.java:3296)
	at sun.swing.CachedPainter.paintImage(CachedPainter.java:189)
	at sun.swing.CachedPainter.paint0(CachedPainter.java:151)
	at sun.swing.CachedPainter.paint(CachedPainter.java:111)
	-  locked java.lang.Class@435df9c5
	at com.sun.java.swing.plaf.windows.XPStyle$Skin.paintSkinRaw(XPStyle.java:615)
	at com.sun.java.swing.plaf.windows.AnimationController.paintSkin(AnimationController.java:256)
	-  locked com.sun.java.swing.plaf.windows.AnimationController@5d7ee789
	at com.sun.java.swing.plaf.windows.XPStyle$Skin.paintSkin(XPStyle.java:591)
	at com.sun.java.swing.plaf.windows.WindowsTabbedPaneUI.paintRotatedSkin(WindowsTabbedPaneUI.java:223)
	at com.sun.java.swing.plaf.windows.WindowsTabbedPaneUI.paintContentBorder(WindowsTabbedPaneUI.java:150)
	at javax.swing.plaf.basic.BasicTabbedPaneUI.paint(BasicTabbedPaneUI.java:791)
	at javax.swing.plaf.ComponentUI.update(ComponentUI.java:161)
	at javax.swing.JComponent.paintComponent(JComponent.java:780)
	at javax.swing.JComponent.paint(JComponent.java:1056)
	at javax.swing.JComponent.paintChildren(JComponent.java:889)
	-  locked java.awt.Component$AWTTreeLock@e933439
	at javax.swing.JComponent.paint(JComponent.java:1065)
	at java.awt.GraphicsCallback$PaintCallback.run(GraphicsCallback.java:39)
	at sun.awt.SunGraphicsCallback.runOneComponent(SunGraphicsCallback.java:79)
	at sun.awt.SunGraphicsCallback.runComponents(SunGraphicsCallback.java:116)
	at java.awt.Container.paint(Container.java:1975)
	at java.awt.Container.update(Container.java:1995)
	at sun.awt.RepaintArea.updateComponent(RepaintArea.java:255)
	at sun.awt.RepaintArea.paint(RepaintArea.java:232)
	at sun.awt.windows.WComponentPeer.handleEvent(WComponentPeer.java:358)
	at java.awt.Component.dispatchEventImpl(Component.java:4967)
	at java.awt.Container.dispatchEventImpl(Container.java:2294)
	at java.awt.Component.dispatchEvent(Component.java:4713)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:76)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:86)
	at java.awt.EventQueue$4.run(EventQueue.java:731)
	at java.awt.EventQueue$4.run(EventQueue.java:729)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:76)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:201)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)

	Number of locked synchronizers = 1
	- java.util.concurrent.locks.ReentrantLock$NonfairSync@73ed4eb5

"AWT-Shutdown" Id=94 WAITING on java.lang.Object@5fd212dc
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.Object@5fd212dc
	at java.lang.Object.wait(Object.java:502)
	at sun.awt.AWTAutoShutdown.run(AWTAutoShutdown.java:295)
	at java.lang.Thread.run(Thread.java:745)

"Unknown Progress Timer" Id=65 WAITING on java.util.ArrayList@75baf400
	at java.lang.Object.wait(Native Method)
	-  waiting on java.util.ArrayList@75baf400
	at java.lang.Object.wait(Object.java:502)
	at org.knime.workbench.editor2.figures.ProgressFigure$UnknownProgressTimer.run(ProgressFigure.java:552)

"KNIME-WFM-Parent-Notifier" Id=64 WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@629f3472
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@629f3472
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"KNIME-Workflow-Notifier" Id=63 WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@7b9e4672
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@7b9e4672
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"KNIME Sync Exec Dispatcher-1" Id=60 WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@3415ef2f
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@3415ef2f
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"[ThreadPool Manager] - Idle Thread" Id=51 WAITING on org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor@16ad0759
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor@16ad0759
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor.run(Executor.java:106)

"EventAdmin Async Event Dispatcher Thread" Id=50 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@d0a8d5a
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@d0a8d5a
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"KNIME Progress Timer" Id=47 TIMED_WAITING on java.util.TaskQueue@4aef75f
	at java.lang.Object.wait(Native Method)
	-  waiting on java.util.TaskQueue@4aef75f
	at java.util.TimerThread.mainLoop(Timer.java:552)
	at java.util.TimerThread.run(Timer.java:505)

"ServerSpace Update Timer" Id=44 TIMED_WAITING on java.util.TaskQueue@1f590c72
	at java.lang.Object.wait(Native Method)
	-  waiting on java.util.TaskQueue@1f590c72
	at java.util.TimerThread.mainLoop(Timer.java:552)
	at java.util.TimerThread.run(Timer.java:505)

"Worker-2" Id=39 TIMED_WAITING on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at org.eclipse.core.internal.jobs.WorkerPool.sleep(WorkerPool.java:188)
	at org.eclipse.core.internal.jobs.WorkerPool.startJob(WorkerPool.java:220)
	at org.eclipse.core.internal.jobs.Worker.run(Worker.java:52)

"Worker-1" Id=38 TIMED_WAITING on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at org.eclipse.core.internal.jobs.WorkerPool.sleep(WorkerPool.java:188)
	at org.eclipse.core.internal.jobs.WorkerPool.startJob(WorkerPool.java:220)
	at org.eclipse.core.internal.jobs.Worker.run(Worker.java:52)

"Java indexing" Id=37 WAITING on org.eclipse.jdt.internal.core.search.indexing.IndexManager@3809762e
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.jdt.internal.core.search.indexing.IndexManager@3809762e
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.jdt.internal.core.search.processing.JobManager.run(JobManager.java:382)
	at java.lang.Thread.run(Thread.java:745)

"pool-2-thread-1" Id=31 RUNNABLE
	at sun.management.ThreadImpl.dumpThreads0(Native Method)
	at sun.management.ThreadImpl.dumpAllThreads(ThreadImpl.java:446)
	at org.knime.core.util.GUIDeadlockDetector.createStacktrace(GUIDeadlockDetector.java:162)
	at org.knime.core.util.GUIDeadlockDetector$CheckTask.run(GUIDeadlockDetector.java:145)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

	Number of locked synchronizers = 1
	- java.util.concurrent.ThreadPoolExecutor$Worker@26f96b85

"pool-1-thread-1" Id=30 TIMED_WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4b6e6a7f
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4b6e6a7f
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"Provisioning Event Dispatcher" Id=28 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@1c03c5fc
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@1c03c5fc
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"AWT-Windows" Id=24 RUNNABLE
	at sun.awt.windows.WToolkit.eventLoop(Native Method)
	at sun.awt.windows.WToolkit.run(WToolkit.java:306)
	at java.lang.Thread.run(Thread.java:745)

"Java2D Disposer" Id=22 WAITING on java.lang.ref.ReferenceQueue$Lock@7fe8f14c
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.ref.ReferenceQueue$Lock@7fe8f14c
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
	at sun.java2d.Disposer.run(Disposer.java:148)
	at java.lang.Thread.run(Thread.java:745)

"EMF Reference Cleaner" Id=20 WAITING on java.lang.ref.ReferenceQueue$Lock@c235099
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.ref.ReferenceQueue$Lock@c235099
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
	at org.eclipse.emf.common.util.CommonUtil$1ReferenceClearingQueuePollingThread.run(CommonUtil.java:70)

"Worker-JM" Id=17 WAITING on java.util.ArrayList@3426eef0
	at java.lang.Object.wait(Native Method)
	-  waiting on java.util.ArrayList@3426eef0
	at org.eclipse.core.internal.jobs.InternalWorker.run(InternalWorker.java:59)

"Bundle File Closer" Id=16 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@3608f1ad
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@3608f1ad
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"[Timer] - Main Queue Handler" Id=15 TIMED_WAITING on java.lang.Object@ed214b1
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.Object@ed214b1
	at org.eclipse.equinox.internal.util.impl.tpt.timer.TimerImpl.run(TimerImpl.java:141)
	at java.lang.Thread.run(Thread.java:745)

"Start Level: Equinox Container: 9010c961-38ba-0015-1b75-9b5b0190577a" Id=13 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@18e32a6a
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@18e32a6a
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"Framework Event Dispatcher: Equinox Container: 9010c961-38ba-0015-1b75-9b5b0190577a" Id=12 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@1b3106e8
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@1b3106e8
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"Active Thread: Equinox Container: 9010c961-38ba-0015-1b75-9b5b0190577a" Id=10 TIMED_WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@6a4519ba
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@6a4519ba
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"Attach Listener" Id=5 RUNNABLE

"Signal Dispatcher" Id=4 RUNNABLE

"Finalizer" Id=3 WAITING on java.lang.ref.ReferenceQueue$Lock@74acefdf
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.ref.ReferenceQueue$Lock@74acefdf
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)

"Reference Handler" Id=2 WAITING on java.lang.ref.Reference$Lock@759d2b5a
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.ref.Reference$Lock@759d2b5a
	at java.lang.Object.wait(Object.java:502)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157)

"main" Id=1 RUNNABLE
	at org.eclipse.swt.internal.win32.OS.WaitMessage(Native Method)
	at org.eclipse.swt.widgets.Display.sleep(Display.java:4728)
	at org.knime.core.node.util.ViewUtils.invokeAndWaitInEDT(ViewUtils.java:164)
	at org.knime.core.node.NodeDialogPane.callOnCancel(NodeDialogPane.java:599)
	at org.knime.workbench.ui.wrapper.WrappedNodeDialog.doCancel(WrappedNodeDialog.java:437)
	at org.knime.workbench.ui.wrapper.WrappedNodeDialog.access$3(WrappedNodeDialog.java:433)
	at org.knime.workbench.ui.wrapper.WrappedNodeDialog$8.widgetSelected(WrappedNodeDialog.java:404)
	at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:248)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4362)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1113)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4180)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3769)
	at org.eclipse.jface.window.Window.runEventLoop(Window.java:827)
	at org.eclipse.jface.window.Window.open(Window.java:803)
	at org.knime.workbench.ui.wrapper.WrappedNodeDialog.open(WrappedNodeDialog.java:164)
	at org.knime.workbench.editor2.editparts.NodeContainerEditPart.openNodeDialog(NodeContainerEditPart.java:817)
	at org.knime.workbench.editor2.actions.OpenDialogAction.runOnNodes(OpenDialogAction.java:129)
	at org.knime.workbench.editor2.actions.AbstractNodeAction.runInSWT(AbstractNodeAction.java:156)
	at org.knime.workbench.editor2.actions.AbstractNodeAction$1.run(AbstractNodeAction.java:142)
	at org.eclipse.swt.widgets.Synchronizer.syncExec(Synchronizer.java:186)
	at org.eclipse.ui.internal.UISynchronizer.syncExec(UISynchronizer.java:145)
	at org.eclipse.swt.widgets.Display.syncExec(Display.java:4761)
	at org.knime.workbench.editor2.actions.AbstractNodeAction.run(AbstractNodeAction.java:139)
	at org.eclipse.jface.action.Action.runWithEvent(Action.java:473)
	at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:595)
	at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:511)
	at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:420)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4362)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1113)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4180)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3769)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$4.run(PartRenderingEngine.java:1127)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:337)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1018)
	at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:156)
	at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:654)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:337)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:598)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:132)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:380)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:235)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:669)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:608)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1515)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1488)


2016-01-13 22:02:31,378 : WARN  : pool-2-thread-1 : KNIMEApplication$4 :  :  : Potential deadlock in AWT Event Queue detected. Full thread dump will follow as debug ouput.
2016-01-13 22:02:31,378 : DEBUG : pool-2-thread-1 : KNIMEApplication$4 :  :  : "AWT-EventQueue-0" Id=102 RUNNABLE (in native)
	at sun.java2d.d3d.D3DRenderQueue.flushBuffer(Native Method)
	at sun.java2d.d3d.D3DRenderQueue.flushBuffer(D3DRenderQueue.java:152)
	at sun.java2d.d3d.D3DRenderQueue.flushAndInvokeNow(D3DRenderQueue.java:142)
	at sun.java2d.d3d.D3DSurfaceData$D3DDataBufferNative.getElem(D3DSurfaceData.java:448)
	at sun.awt.image.DataBufferNative.getElem(DataBufferNative.java:75)
	at java.awt.image.DataBuffer.getElem(DataBuffer.java:329)
	at java.awt.image.SinglePixelPackedSampleModel.getDataElements(SinglePixelPackedSampleModel.java:409)
	at java.awt.image.Raster.getDataElements(Raster.java:1466)
	at sun.java2d.loops.OpaqueCopyAnyToArgb.Blit(CustomComponent.java:144)
	at sun.java2d.loops.GraphicsPrimitive.convertFrom(GraphicsPrimitive.java:560)
	at sun.java2d.loops.GraphicsPrimitive.convertFrom(GraphicsPrimitive.java:541)
	at sun.java2d.loops.MaskBlit$General.MaskBlit(MaskBlit.java:189)
	-  locked sun.java2d.loops.MaskBlit$General@6bc2d836
	at sun.java2d.loops.Blit$GeneralMaskBlit.Blit(Blit.java:204)
	at sun.java2d.pipe.DrawImage.blitSurfaceData(DrawImage.java:959)
	at sun.java2d.pipe.DrawImage.renderImageCopy(DrawImage.java:577)
	at sun.java2d.pipe.DrawImage.copyImage(DrawImage.java:67)
	at sun.java2d.pipe.DrawImage.copyImage(DrawImage.java:1014)
	at sun.java2d.pipe.ValidatePipe.copyImage(ValidatePipe.java:186)
	at sun.java2d.SunGraphics2D.drawImage(SunGraphics2D.java:3318)
	at sun.java2d.SunGraphics2D.drawImage(SunGraphics2D.java:3296)
	at sun.swing.CachedPainter.paintImage(CachedPainter.java:189)
	at sun.swing.CachedPainter.paint0(CachedPainter.java:151)
	at sun.swing.CachedPainter.paint(CachedPainter.java:111)
	-  locked java.lang.Class@435df9c5
	at com.sun.java.swing.plaf.windows.XPStyle$Skin.paintSkinRaw(XPStyle.java:615)
	at com.sun.java.swing.plaf.windows.AnimationController.paintSkin(AnimationController.java:256)
	-  locked com.sun.java.swing.plaf.windows.AnimationController@5d7ee789
	at com.sun.java.swing.plaf.windows.XPStyle$Skin.paintSkin(XPStyle.java:591)
	at com.sun.java.swing.plaf.windows.WindowsTabbedPaneUI.paintRotatedSkin(WindowsTabbedPaneUI.java:223)
	at com.sun.java.swing.plaf.windows.WindowsTabbedPaneUI.paintContentBorder(WindowsTabbedPaneUI.java:150)
	at javax.swing.plaf.basic.BasicTabbedPaneUI.paint(BasicTabbedPaneUI.java:791)
	at javax.swing.plaf.ComponentUI.update(ComponentUI.java:161)
	at javax.swing.JComponent.paintComponent(JComponent.java:780)
	at javax.swing.JComponent.paint(JComponent.java:1056)
	at javax.swing.JComponent.paintChildren(JComponent.java:889)
	-  locked java.awt.Component$AWTTreeLock@e933439
	at javax.swing.JComponent.paint(JComponent.java:1065)
	at java.awt.GraphicsCallback$PaintCallback.run(GraphicsCallback.java:39)
	at sun.awt.SunGraphicsCallback.runOneComponent(SunGraphicsCallback.java:79)
	at sun.awt.SunGraphicsCallback.runComponents(SunGraphicsCallback.java:116)
	at java.awt.Container.paint(Container.java:1975)
	at java.awt.Container.update(Container.java:1995)
	at sun.awt.RepaintArea.updateComponent(RepaintArea.java:255)
	at sun.awt.RepaintArea.paint(RepaintArea.java:232)
	at sun.awt.windows.WComponentPeer.handleEvent(WComponentPeer.java:358)
	at java.awt.Component.dispatchEventImpl(Component.java:4967)
	at java.awt.Container.dispatchEventImpl(Container.java:2294)
	at java.awt.Component.dispatchEvent(Component.java:4713)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:76)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:86)
	at java.awt.EventQueue$4.run(EventQueue.java:731)
	at java.awt.EventQueue$4.run(EventQueue.java:729)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:76)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:201)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)

	Number of locked synchronizers = 1
	- java.util.concurrent.locks.ReentrantLock$NonfairSync@73ed4eb5

"AWT-Shutdown" Id=103 WAITING on java.lang.Object@5fd212dc
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.Object@5fd212dc
	at java.lang.Object.wait(Object.java:502)
	at sun.awt.AWTAutoShutdown.run(AWTAutoShutdown.java:295)
	at java.lang.Thread.run(Thread.java:745)

"Worker-3" Id=99 TIMED_WAITING on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at org.eclipse.core.internal.jobs.WorkerPool.sleep(WorkerPool.java:188)
	at org.eclipse.core.internal.jobs.WorkerPool.startJob(WorkerPool.java:220)
	at org.eclipse.core.internal.jobs.Worker.run(Worker.java:52)

"Unknown Progress Timer" Id=65 WAITING on java.util.ArrayList@75baf400
	at java.lang.Object.wait(Native Method)
	-  waiting on java.util.ArrayList@75baf400
	at java.lang.Object.wait(Object.java:502)
	at org.knime.workbench.editor2.figures.ProgressFigure$UnknownProgressTimer.run(ProgressFigure.java:552)

"KNIME-WFM-Parent-Notifier" Id=64 WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@629f3472
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@629f3472
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"KNIME-Workflow-Notifier" Id=63 WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@7b9e4672
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@7b9e4672
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"KNIME Sync Exec Dispatcher-1" Id=60 WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@3415ef2f
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@3415ef2f
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"[ThreadPool Manager] - Idle Thread" Id=51 WAITING on org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor@16ad0759
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor@16ad0759
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.equinox.internal.util.impl.tpt.threadpool.Executor.run(Executor.java:106)

"EventAdmin Async Event Dispatcher Thread" Id=50 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@d0a8d5a
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@d0a8d5a
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"KNIME Progress Timer" Id=47 TIMED_WAITING on java.util.TaskQueue@4aef75f
	at java.lang.Object.wait(Native Method)
	-  waiting on java.util.TaskQueue@4aef75f
	at java.util.TimerThread.mainLoop(Timer.java:552)
	at java.util.TimerThread.run(Timer.java:505)

"ServerSpace Update Timer" Id=44 TIMED_WAITING on java.util.TaskQueue@1f590c72
	at java.lang.Object.wait(Native Method)
	-  waiting on java.util.TaskQueue@1f590c72
	at java.util.TimerThread.mainLoop(Timer.java:552)
	at java.util.TimerThread.run(Timer.java:505)

"Worker-2" Id=39 TIMED_WAITING on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at org.eclipse.core.internal.jobs.WorkerPool.sleep(WorkerPool.java:188)
	at org.eclipse.core.internal.jobs.WorkerPool.startJob(WorkerPool.java:220)
	at org.eclipse.core.internal.jobs.Worker.run(Worker.java:52)

"Worker-1" Id=38 TIMED_WAITING on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.core.internal.jobs.WorkerPool@6130470f
	at org.eclipse.core.internal.jobs.WorkerPool.sleep(WorkerPool.java:188)
	at org.eclipse.core.internal.jobs.WorkerPool.startJob(WorkerPool.java:220)
	at org.eclipse.core.internal.jobs.Worker.run(Worker.java:52)

"Java indexing" Id=37 WAITING on org.eclipse.jdt.internal.core.search.indexing.IndexManager@3809762e
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.jdt.internal.core.search.indexing.IndexManager@3809762e
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.jdt.internal.core.search.processing.JobManager.run(JobManager.java:382)
	at java.lang.Thread.run(Thread.java:745)

"pool-2-thread-1" Id=31 RUNNABLE
	at sun.management.ThreadImpl.dumpThreads0(Native Method)
	at sun.management.ThreadImpl.dumpAllThreads(ThreadImpl.java:446)
	at org.knime.core.util.GUIDeadlockDetector.createStacktrace(GUIDeadlockDetector.java:162)
	at org.knime.core.util.GUIDeadlockDetector$CheckTask.run(GUIDeadlockDetector.java:145)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

	Number of locked synchronizers = 1
	- java.util.concurrent.ThreadPoolExecutor$Worker@26f96b85

"pool-1-thread-1" Id=30 TIMED_WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4b6e6a7f
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4b6e6a7f
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"Provisioning Event Dispatcher" Id=28 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@1c03c5fc
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@1c03c5fc
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"AWT-Windows" Id=24 RUNNABLE
	at sun.awt.windows.WToolkit.eventLoop(Native Method)
	at sun.awt.windows.WToolkit.run(WToolkit.java:306)
	at java.lang.Thread.run(Thread.java:745)

"Java2D Disposer" Id=22 WAITING on java.lang.ref.ReferenceQueue$Lock@7fe8f14c
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.ref.ReferenceQueue$Lock@7fe8f14c
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
	at sun.java2d.Disposer.run(Disposer.java:148)
	at java.lang.Thread.run(Thread.java:745)

"EMF Reference Cleaner" Id=20 WAITING on java.lang.ref.ReferenceQueue$Lock@c235099
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.ref.ReferenceQueue$Lock@c235099
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
	at org.eclipse.emf.common.util.CommonUtil$1ReferenceClearingQueuePollingThread.run(CommonUtil.java:70)

"Worker-JM" Id=17 WAITING on java.util.ArrayList@3426eef0
	at java.lang.Object.wait(Native Method)
	-  waiting on java.util.ArrayList@3426eef0
	at org.eclipse.core.internal.jobs.InternalWorker.run(InternalWorker.java:59)

"Bundle File Closer" Id=16 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@3608f1ad
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@3608f1ad
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"[Timer] - Main Queue Handler" Id=15 TIMED_WAITING on java.lang.Object@ed214b1
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.Object@ed214b1
	at org.eclipse.equinox.internal.util.impl.tpt.timer.TimerImpl.run(TimerImpl.java:141)
	at java.lang.Thread.run(Thread.java:745)

"Start Level: Equinox Container: 9010c961-38ba-0015-1b75-9b5b0190577a" Id=13 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@18e32a6a
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@18e32a6a
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"Framework Event Dispatcher: Equinox Container: 9010c961-38ba-0015-1b75-9b5b0190577a" Id=12 WAITING on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@1b3106e8
	at java.lang.Object.wait(Native Method)
	-  waiting on org.eclipse.osgi.framework.eventmgr.EventManager$EventThread@1b3106e8
	at java.lang.Object.wait(Object.java:502)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.getNextEvent(EventManager.java:400)
	at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:336)

"Active Thread: Equinox Container: 9010c961-38ba-0015-1b75-9b5b0190577a" Id=10 TIMED_WAITING on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@6a4519ba
	at sun.misc.Unsafe.park(Native Method)
	-  waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@6a4519ba
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

"Attach Listener" Id=5 RUNNABLE

"Signal Dispatcher" Id=4 RUNNABLE

"Finalizer" Id=3 WAITING on java.lang.ref.ReferenceQueue$Lock@74acefdf
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.ref.ReferenceQueue$Lock@74acefdf
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)

"Reference Handler" Id=2 WAITING on java.lang.ref.Reference$Lock@759d2b5a
	at java.lang.Object.wait(Native Method)
	-  waiting on java.lang.ref.Reference$Lock@759d2b5a
	at java.lang.Object.wait(Object.java:502)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157)

"main" Id=1 RUNNABLE
	at org.eclipse.swt.internal.win32.OS.WaitMessage(Native Method)
	at org.eclipse.swt.widgets.Display.sleep(Display.java:4728)
	at org.knime.core.node.util.ViewUtils.invokeAndWaitInEDT(ViewUtils.java:164)
	at org.knime.core.node.NodeDialogPane.finishEditingAndSaveSettingsTo(NodeDialogPane.java:722)
	at org.knime.core.node.workflow.NodeContainer.applySettingsFromDialog(NodeContainer.java:977)
	at org.knime.workbench.ui.wrapper.WrappedNodeDialog.doApply(WrappedNodeDialog.java:545)
	at org.knime.workbench.ui.wrapper.WrappedNodeDialog.doOK(WrappedNodeDialog.java:457)
	at org.knime.workbench.ui.wrapper.WrappedNodeDialog.access$5(WrappedNodeDialog.java:454)
	at org.knime.workbench.ui.wrapper.WrappedNodeDialog$6.widgetSelected(WrappedNodeDialog.java:383)
	at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:248)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4362)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1113)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4180)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3769)
	at org.eclipse.jface.window.Window.runEventLoop(Window.java:827)
	at org.eclipse.jface.window.Window.open(Window.java:803)
	at org.knime.workbench.ui.wrapper.WrappedNodeDialog.open(WrappedNodeDialog.java:164)
	at org.knime.workbench.editor2.editparts.NodeContainerEditPart.openNodeDialog(NodeContainerEditPart.java:817)
	at org.knime.workbench.editor2.actions.OpenDialogAction.runOnNodes(OpenDialogAction.java:129)
	at org.knime.workbench.editor2.actions.AbstractNodeAction.runInSWT(AbstractNodeAction.java:156)
	at org.knime.workbench.editor2.actions.AbstractNodeAction$1.run(AbstractNodeAction.java:142)
	at org.eclipse.swt.widgets.Synchronizer.syncExec(Synchronizer.java:186)
	at org.eclipse.ui.internal.UISynchronizer.syncExec(UISynchronizer.java:145)
	at org.eclipse.swt.widgets.Display.syncExec(Display.java:4761)
	at org.knime.workbench.editor2.actions.AbstractNodeAction.run(AbstractNodeAction.java:139)
	at org.eclipse.jface.action.Action.runWithEvent(Action.java:473)
	at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:595)
	at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:511)
	at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:420)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4362)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1113)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4180)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3769)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$4.run(PartRenderingEngine.java:1127)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:337)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1018)
	at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:156)
	at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:654)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:337)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:598)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)
	at org.knime.product.rcp.KNIMEApplication.start(KNIMEApplication.java:132)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:380)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:235)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:669)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:608)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1515)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1488)


2016-01-13 22:02:36,246 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : reset
2016-01-13 22:02:36,246 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:02:36,246 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: IDLE
2016-01-13 22:02:36,262 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : reset
2016-01-13 22:02:36,262 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : clean output ports.
2016-01-13 22:02:36,262 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: IDLE
2016-01-13 22:02:36,277 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:02:36,277 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: CONFIGURED
2016-01-13 22:02:36,277 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:02:36,277 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: CONFIGURED
2016-01-13 22:03:04,831 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : reset
2016-01-13 22:03:04,831 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:03:04,831 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: IDLE
2016-01-13 22:03:04,831 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : reset
2016-01-13 22:03:04,831 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : clean output ports.
2016-01-13 22:03:04,831 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: IDLE
2016-01-13 22:03:04,831 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:03:04,831 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: CONFIGURED
2016-01-13 22:03:04,831 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:03:04,831 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: CONFIGURED
2016-01-13 22:03:50,218 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : reset
2016-01-13 22:03:50,218 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:03:50,218 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: IDLE
2016-01-13 22:03:50,218 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : reset
2016-01-13 22:03:50,218 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : clean output ports.
2016-01-13 22:03:50,218 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: IDLE
2016-01-13 22:03:50,218 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:03:50,218 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: CONFIGURED
2016-01-13 22:03:50,218 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:03:50,218 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: CONFIGURED
2016-01-13 22:03:54,024 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : reset
2016-01-13 22:03:54,024 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:03:54,024 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: IDLE
2016-01-13 22:03:54,024 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : reset
2016-01-13 22:03:54,024 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : clean output ports.
2016-01-13 22:03:54,024 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: IDLE
2016-01-13 22:03:54,024 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:03:54,024 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: CONFIGURED
2016-01-13 22:03:54,024 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:03:54,024 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: CONFIGURED
2016-01-13 22:03:54,992 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : reset
2016-01-13 22:03:54,992 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:03:54,992 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: IDLE
2016-01-13 22:03:54,992 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : reset
2016-01-13 22:03:54,992 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : clean output ports.
2016-01-13 22:03:54,992 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: IDLE
2016-01-13 22:03:54,992 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:03:54,992 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: CONFIGURED
2016-01-13 22:03:54,992 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:03:54,992 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:1 : Table Difference Checker 2:3 has new state: CONFIGURED
2016-01-13 22:03:56,208 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:1 (CONFIGURED)
2016-01-13 22:03:56,208 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 22:04:04,235 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : reset
2016-01-13 22:04:04,235 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:04:04,235 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:2 : Table Difference Checker 2:3 has new state: IDLE
2016-01-13 22:04:04,235 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : reset
2016-01-13 22:04:04,235 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : clean output ports.
2016-01-13 22:04:04,235 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: IDLE
2016-01-13 22:04:04,235 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:04:04,235 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: CONFIGURED
2016-01-13 22:04:04,235 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:04:04,250 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:2 : Table Difference Checker 2:3 has new state: CONFIGURED
2016-01-13 22:04:05,233 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : reset
2016-01-13 22:04:05,233 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:04:05,233 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:2 : Table Difference Checker 2:3 has new state: IDLE
2016-01-13 22:04:05,233 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : reset
2016-01-13 22:04:05,233 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : clean output ports.
2016-01-13 22:04:05,233 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: IDLE
2016-01-13 22:04:05,249 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:04:05,249 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: CONFIGURED
2016-01-13 22:04:05,249 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:04:05,249 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 2:2 : Table Difference Checker 2:3 has new state: CONFIGURED
2016-01-13 22:04:28,448 : DEBUG : main : WorkflowEditor :  :  : Saving workflow JiraOfflineTest 2
2016-01-13 22:04:28,557 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Created node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest\Jira Adapter _Offline_ (#1)"
2016-01-13 22:04:28,588 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Created node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest\Jira Adapter _Offline_ (#2)"
2016-01-13 22:04:28,604 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Created node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest\Table Difference Checker (#3)"
2016-01-13 22:04:28,822 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:04:28,822 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:04:28,822 : DEBUG : main : ProjectWorkflowMap :  :  : unregistering org.knime.workbench.editor2.WorkflowEditor@329a27ae from file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/. 0 left.
2016-01-13 22:04:28,822 : DEBUG : main : ProjectWorkflowMap :  :  : Removing "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/" from project map (1 remaining)
2016-01-13 22:04:28,822 : DEBUG : main : WorkflowManager :  :  : Removing project "JiraOfflineTest 2"
2016-01-13 22:04:28,838 : DEBUG : main : DifferenceCheckerNodeModel : Table Difference Checker : 2:3 : Removing all (0) views from model.
2016-01-13 22:04:28,838 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:04:28,838 : DEBUG : main : JiraAdapterNodeModel : Jira Adapter (Offline) : 2:2 : Removing all (0) views from model.
2016-01-13 22:04:28,838 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : clean output ports.
2016-01-13 22:04:28,838 : DEBUG : main : JiraAdapterNodeModel : Jira Adapter (Offline) : 2:1 : Removing all (0) views from model.
2016-01-13 22:04:28,838 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : clean output ports.
2016-01-13 22:04:28,838 : DEBUG : main : WorkflowManager :  :  : Project "JiraOfflineTest 2" removed (2 remaining)
2016-01-13 22:04:28,994 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ================= Starting testflow WorkflowTests\JiraOfflineTest =================
2016-01-13 22:04:29,010 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ================= Average load: -1,00 =================
2016-01-13 22:04:29,010 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test load workflow -----------------
2016-01-13 22:04:29,072 : DEBUG : Worker-1 : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:04:29,103 : DEBUG : Worker-1 : WorkflowManager :  :  : Created subworkflow 2
2016-01-13 22:04:29,212 : DEBUG : Worker-1 : JiraAdapterNodeFactory : JiraOfflineTest : 2 : Factory is already initialized. Nothing to do.
2016-01-13 22:04:29,244 : DEBUG : Worker-1 : JiraAdapterNodeFactory : JiraOfflineTest : 2 : Factory is already initialized. Nothing to do.
2016-01-13 22:04:29,259 : DEBUG : Worker-1 : DifferenceCheckerNodeFactory : JiraOfflineTest : 2 : Factory is already initialized. Nothing to do.
2016-01-13 22:04:29,259 : DEBUG : Worker-1 : WorkflowManager :  :  : Added new connection from node 2:2(1) to node 2:3(2)
2016-01-13 22:04:29,259 : DEBUG : Worker-1 : WorkflowManager :  :  : Added new connection from node 2:1(1) to node 2:3(1)
2016-01-13 22:04:29,275 : DEBUG : Worker-1 : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:04:29,275 : DEBUG : Worker-1 : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:04:29,275 : DEBUG : Worker-1 : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:04:29,275 : DEBUG : Worker-1 : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest"  with no errors
2016-01-13 22:04:29,290 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:04:29,306 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:04:29,306 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:04:29,306 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on 2 - JiraOfflineTest
2016-01-13 22:04:29,306 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:04:29,337 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:04:29,337 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:04:29,337 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:04:29,353 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 2:1 (CONFIGURED) )
2016-01-13 22:04:29,353 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:1(1) -> 2:3( 1)]
2016-01-13 22:04:29,353 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:04:29,353 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 2:2 (CONFIGURED) )
2016-01-13 22:04:29,353 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:2(1) -> 2:3( 2)]
2016-01-13 22:04:29,353 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:04:29,353 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 2:3 (CONFIGURED) )
2016-01-13 22:04:29,353 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:1(1) -> 2:3( 1)]
2016-01-13 22:04:29,353 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:04:29,368 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:2(1) -> 2:3( 2)]
2016-01-13 22:04:29,368 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:04:29,602 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test load workflow -----------------
2016-01-13 22:04:29,602 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test open views -----------------
2016-01-13 22:04:29,602 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test open views -----------------
2016-01-13 22:04:29,602 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test execute workflow -----------------
2016-01-13 22:04:29,602 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on Jira Adapter (Offline) 2:2
2016-01-13 22:04:29,602 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on JiraOfflineTest 2
2016-01-13 22:04:29,602 : DEBUG : Worker-1 : NodeContainer :  :  : Jira Adapter (Offline) 2:2 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:04:29,618 : DEBUG : Worker-1 : NodeContainer :  :  : Jira Adapter (Offline) 2:2 has new state: CONFIGURED_QUEUED
2016-01-13 22:04:29,618 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on Jira Adapter (Offline) 2:1
2016-01-13 22:04:29,618 : DEBUG : Worker-1 : NodeContainer :  :  : Jira Adapter (Offline) 2:1 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:04:29,618 : DEBUG : Worker-1 : NodeContainer :  :  : Jira Adapter (Offline) 2:1 has new state: CONFIGURED_QUEUED
2016-01-13 22:04:29,618 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on Table Difference Checker 2:3
2016-01-13 22:04:29,618 : DEBUG : Worker-1 : NodeContainer :  :  : Table Difference Checker 2:3 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:04:29,618 : DEBUG : Worker-1 : NodeContainer :  :  : JiraOfflineTest 2 has new state: EXECUTING
2016-01-13 22:04:29,618 : DEBUG : Worker-1 : NodeContainer :  :  : ROOT  has new state: EXECUTING
2016-01-13 22:04:29,618 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 doBeforePreExecution
2016-01-13 22:04:29,618 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: PREEXECUTE
2016-01-13 22:04:29,618 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 doBeforeExecution
2016-01-13 22:04:29,618 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: EXECUTING
2016-01-13 22:04:29,634 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=2;old=null;new=null;timestamp=2016-01-13 22:04:29]
2016-01-13 22:04:29,634 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 2:1 : Adding handler fda7a8e9-a8e7-49a5-a12d-7ba8b43e663e (Jira Adapter (Offline) 2:1: <no directory>) - 1 in total
2016-01-13 22:04:29,634 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 Start execute
2016-01-13 22:04:29,649 : INFO  : KNIME-Worker-1 : ITSOfflineNodeModel : Jira Adapter (Offline) : 2:1 : Preparing to read jira entries.
2016-01-13 22:04:29,712 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 doBeforePreExecution
2016-01-13 22:04:29,712 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: PREEXECUTE
2016-01-13 22:04:29,712 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 doBeforeExecution
2016-01-13 22:04:29,712 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: EXECUTING
2016-01-13 22:04:29,712 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 2:2 : Adding handler 6a192c76-8dd9-4f41-9136-c65816086d60 (Jira Adapter (Offline) 2:2: <no directory>) - 2 in total
2016-01-13 22:04:29,842 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 Start execute
2016-01-13 22:04:29,844 : INFO  : KNIME-Worker-0 : ITSOfflineNodeModel : Jira Adapter (Offline) : 2:2 : Preparing to read jira entries.
2016-01-13 22:04:31,216 : INFO  : KNIME-Worker-1 : ITSOfflineNodeModel : Jira Adapter (Offline) : 2:1 : Transforming to jira entries.
2016-01-13 22:04:31,216 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-724
2016-01-13 22:04:31,232 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-724, created=Mon Dec 12 16:03:41 CET 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Tue Dec 20 22:14:16 CET 2011, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=RandomDataImpl.nextInt does not distribute uniformly for negative lower bound, link=https://issues.apache.org/jira/browse/MATH-724, description=&lt;p&gt;When using the RandomDataImpl.nextInt function to get a uniform sample in a &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt; interval, when the lower value is less than zero, the output is not uniformly distributed, as the lowest value is practically never returned.&lt;/p&gt;

&lt;p&gt;See the attached NextIntUniformTest.java file. It uses a &lt;span class="error"&gt;&amp;#91;-3, 5&amp;#93;&lt;/span&gt; interval. For several values between 0 and 1, testNextIntUniform1 prints the return value of RandomDataImpl.nextInt (as double and as int). We see that -2 through 5 are returned several times. The -3 value however, is only returned for 0.0, and is thus under-respresented in the integer samples. The output of test method testNextIntUniform2 also clearly shows that value -3 is never sampled.&lt;/p&gt;, comments=[&lt;p&gt;NextIntUniformTest.java: see issue description&lt;/p&gt;
, &lt;p&gt;Thanks for reporting this. The problem is in the rounding, which does not work correctly for negative values.  My first inclination is to test for negative lower bound and just shift the interval in that case.  Any better ideas?&lt;/p&gt;
, &lt;p&gt;math-724.patch: it first scales the [0..1) interval to [0..length), then discretizes it, and finally shifts it to &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;It may be a good idea to also add some tests for cases such as &lt;span class="error"&gt;&amp;#91;0,3&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-5, -3&amp;#93;&lt;/span&gt;, and see if the distribution of sampled values is uniform. It seems RandomDataTest.testNextInt does this using chiSquare, but since I'm not familiar with that, I'm not sure how to add more tests for the other lower/upper bound pairs...&lt;/p&gt;
, &lt;p&gt;I just ran the unit tests with my patch applied, an the following test, in RandomDataTest:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;@Test
    &lt;span class="code-keyword"&gt;public&lt;/span&gt; void testNextIntExtremeValues() {
        &lt;span class="code-object"&gt;int&lt;/span&gt; x = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        &lt;span class="code-object"&gt;int&lt;/span&gt; y = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        Assert.assertFalse(x == y);
    }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails, as does testNextLongExtremeValues. Both x and y become equal to Integer.MIN_VALUE, making x == y to become true, causing the assertion to fail...&lt;/p&gt;
, &lt;p&gt;Also note that RandomDataImpl.nextUniform uses a similar scale/shift method to transform the range. It may thus suffer from the same failure in case of extreme values...&lt;/p&gt;
, &lt;p&gt;math-724-v2.patch: 2nd patch.&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;I think all unit tests work now, including the ones for the Integer.MIN_VALUE to Integer.MAX_VALUE interval.&lt;/li&gt;
	&lt;li&gt;The original problem was that negative values were rounded up by the conversion from double to int, while positive numbers were rounded down. By using floor, we first round the numbers down, and then convert to integer, thus ensuring a proper uniform distribution.&lt;/li&gt;
	&lt;li&gt;Test cases for negative values are still missing... Could someone else add them?&lt;/li&gt;
	&lt;li&gt;RandomDataImpl.nextUniform: I haven't changed this, as the change that I used for integers does not have the desired effect for doubles... This may be caused by the fact that Double.MIN_VALUE is more negative than Double.MAX_VALUE is positive, but I'm not really sure. Maybe it is not even an issue for the nextUniform method?&lt;/li&gt;
&lt;/ul&gt;

, &lt;blockquote&gt;&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; the fact that Double.MIN_VALUE is more negative &lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="http://docs.oracle.com/javase/6/docs/api/java/lang/Double.html#MIN_VALUE"&gt;Double.Min_VALUE&lt;/a&gt; is a &lt;em&gt;positive&lt;/em&gt; number.&lt;/p&gt;
, &lt;blockquote&gt;&lt;p&gt;Double.Min_VALUE is a positive number.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops...&lt;/p&gt;

&lt;p&gt;OK, I uploaded a third version of the patch (math-724-v3.patch), which also applies the new formula for nextUniform. I included two test files (NextUniformTest3.java and NextIntTest3.java), that show the results for nextInt and nextUniform, for both the old and new formulas. As for as I can see, the new formula works equally well or better in all cases. Also, all existing unit tests pass.&lt;/p&gt;
, &lt;p&gt;Thanks for reporting and diagnosing this, Dennis.&lt;/p&gt;

&lt;p&gt;Slightly modified version of the third patch (just removing unecessary parens), along with tests, committed in r1221490.  The "negativeToPositiveRange" tests fail before the fix.  The change to nextUniform is also needed to prevent overflows. I changed the relevant test cases to use the TestUtils chisquare test, which is more straightforward and has better output.  This was added after the original versions of these tests were written.  Others in this class should be similarly updated.  Patches welcome to further tidy the tests, but this issue can be resolved.&lt;/p&gt;
], resolution=Fixed, reporter=dhendriks, assignees=[], commentAuthors=[dhendriks, psteitz, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,341 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-723
2016-01-13 22:04:31,341 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-723, created=Sun Dec 11 22:03:37 CET 2011, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Sun Dec 11 22:59:41 CET 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=BitStreamGenerators (MersenneTwister, Well generators) do not clear normal deviate cache on setSeed, link=https://issues.apache.org/jira/browse/MATH-723, description=&lt;p&gt;The BitStream generators generate normal deviates (for nextGaussian) in pairs, caching the last value generated. When reseeded, the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1213087.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,341 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-719
2016-01-13 22:04:31,341 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-719, created=Tue Dec 06 18:07:24 CET 2011, updated=Sat Mar 24 17:16:38 CET 2012, resolved=Mon Jan 23 12:28:07 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[], priority=Minor, summary=Strange deprecations in API, link=https://issues.apache.org/jira/browse/MATH-719, description=&lt;p&gt;Sorry if this doesn't belong here. I couldn't find any sort of mailing list or other feedback mechanism on the website.&lt;/p&gt;

&lt;p&gt;RealMatrix has some very odd deprecations. In particular inverse(), getDeterminant() and isSingular(). The last has the message:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Deprecated. as of release 2.0, replaced by the boolean negation of new LUDecompositionImpl(m).getSolver().isNonSingular()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's an implementation, not an interface. The whole point of having an interface is that &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I can query whether a matrix is singular withou having to know about LUDecompositions&lt;/li&gt;
	&lt;li&gt;You guys can change the implementation of isSingular() if something better pops up without us guys having to change our code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I'm not using these methods now, because they're deprecated, but I've basically recreated them in as static methods in a utility class. Wouldn't it be much better to just put code from the deprecation message into the method and remove the deprecation?&lt;/p&gt;, comments=[&lt;blockquote&gt;&lt;p&gt;Sorry if this doesn't belong here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Indeed, you'd better bring this kind of issue to the "dev" ML. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
The more so that there have been recent discussions about changing the matrix API and decisions ought to be made quite soon now.&lt;/p&gt;
, &lt;p&gt;Ah, so there is a mailing list. I guess I should have looked a little harder. I'll bring it up there.&lt;/p&gt;
, &lt;p&gt;It is unlikely that we can come up with a new design before the release of v3.0.&lt;br/&gt;
This must be thoroughly discussed first on the "dev" ML, together with other matrix interface issues.&lt;/p&gt;
], resolution=Unknown, reporter=pbloem, assignees=[], commentAuthors=[erans, pbloem], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,341 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-692
2016-01-13 22:04:31,341 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-692, created=Tue Oct 18 20:01:57 CEST 2011, updated=Sat Mar 24 17:16:26 CET 2012, resolved=Thu Feb 02 07:45:59 CET 2012, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 1.3
, 2.0
, 2.1
, 2.2
, 2.2.1
, 3.0
], fixVersion=[3.0
], priority=Minor, summary=Cumulative probability and inverse cumulative probability inconsistencies, link=https://issues.apache.org/jira/browse/MATH-692, description=&lt;p&gt;There are some inconsistencies in the documentation and implementation of functions regarding cumulative probabilities and inverse cumulative probabilities. More precisely, '&amp;lt;' and '&amp;lt;=' are not used in a consistent way.&lt;/p&gt;

&lt;p&gt;Besides I would move the function inverseCumulativeProbability(double) to the interface Distribution. A true inverse of the distribution function does neither exist for Distribution nor for ContinuosDistribution. Thus we need to define the inverse in terms of quantiles anyway, and this can already be done for Distribution.&lt;/p&gt;

&lt;p&gt;On the whole I would declare the (inverse) cumulative probability functions in the basic distribution interfaces as follows:&lt;/p&gt;

&lt;p&gt;Distribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(double x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(double x0, double x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1)&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;inverseCumulativeProbability(double p):&lt;br/&gt;
  returns the quantile function inf{x in R | P(X&amp;lt;=x) &amp;gt;= p} &lt;span class="error"&gt;&amp;#91;see also 2), 3), and 4)&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1) An aternative definition could be P(x0 &amp;lt;= X &amp;lt;= x1). But this requires to put the function probability(double x) or another cumulative probability function into the interface Distribution in order be able to calculate P(x0 &amp;lt;= X &amp;lt;= x1) in AbstractDistribution.&lt;br/&gt;
2) This definition is stricter than the definition in ContinuousDistribution, because the definition there does not specify what to do if there are multiple x satisfying P(X&amp;lt;=x) = p.&lt;br/&gt;
3) A modification could be defined for p=0: Returning sup{x in R | P(X&amp;lt;=x) = 0} would yield the infimum of the distribution's support instead of a mandatory -infinity.&lt;br/&gt;
4) This affects issue &lt;a href="https://issues.apache.org/jira/browse/MATH-540" title="AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug"&gt;&lt;del&gt;MATH-540&lt;/del&gt;&lt;/a&gt;. I'd prefere the definition from above for the following reasons:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;This definition simplifies inverse transform sampling (as mentioned in the other issue).&lt;/li&gt;
	&lt;li&gt;It is the standard textbook definition for the quantile function.&lt;/li&gt;
	&lt;li&gt;For integer distributions it has the advantage that the result doesn't change when switching to "x in Z", i.e. the result is independent of considering the intergers as sole set or as part of the reals.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ContinuousDistribution:&lt;br/&gt;
nothing to be added regarding (inverse) cumulative probability functions&lt;/p&gt;

&lt;p&gt;IntegerDistribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(int x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(int x0, int x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1) above&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;, comments=[&lt;p&gt;Thanks for raising this issue, Christian - especially now as we finalize the 3.0 API.&lt;/p&gt;

&lt;p&gt;I am +1 for these changes.  I agree that the inf-based definition of inverse cum is more standard and we are in a position now make the change, so I say lets do it.  I am also +1 on the move of this up to the distribution interface.  The reason we did not include it there originally was that we thought we might implement distributions for which we could not define inverses.  That has not happened in the last 8 years, so I think its safe enough to push it up.&lt;/p&gt;

&lt;p&gt;The code, test, user guide and doc changes for this have to be done carefully.  Patches most welcome.&lt;/p&gt;

&lt;p&gt;Is everyone else OK with this change?&lt;/p&gt;
, &lt;p&gt;I have neither used nor developed this part of CM, so my view on this is of but little value. Having said that, anything improving consistency can only be desirable, especially at this stage. So I'm all for it, and will be soon available (when I'm done on SYMMLQ) for an (novice on these issues) help.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;+1&lt;/p&gt;
, &lt;p&gt;Thanks for the feedback to all. Sbastien, thanks for offering your help. If you like and find time for it, you could implement AbstractDistribution.inverseCumulativeProbability(double p).&lt;/p&gt;

&lt;p&gt;I will provide some patches next week, but adjusting AbstractContinuousDistribution.inverseCumulativeProbability(double p) will take some more time.&lt;/p&gt;

&lt;p&gt;After thinking a little more about the structure of the interfaces, I'd like to put the function probability(double x) to Distribution anyway (independently of the thought in point 1) above).&lt;/p&gt;

&lt;p&gt;Are there any preferences on P(x0 &amp;lt;= X &amp;lt;= x1) or P(x0 &amp;lt; X &amp;lt;= x1) for cumulativeProbability(double x0, double x1)?&lt;/p&gt;
, &lt;p&gt;I am not sure it is really makes sense to add probability(double x) to the Distribution interface.  It would have to be defined as density (referring to the distribution function) to make sense in the continuous case, since defined as p(X = x) it would in most cases be identically 0 for continuous distributions.&lt;/p&gt;

&lt;p&gt;Regarding the cum definition, I am fine with P(x0 &amp;lt; X &amp;lt;= x1).&lt;/p&gt;
, &lt;p&gt;Happy to help on the inverse cumulative probability. You will have to be patient and forgieving with me, though, as I discover this part of CM.&lt;/p&gt;

&lt;p&gt;As for the definition, I think that one of the bounds should be excluded, so that these cumulative probabilities can be summed&lt;br/&gt;
P(a &amp;lt; X &amp;lt;= c) = P(a &amp;lt; X &amp;lt;= b) + P(b &amp;lt; X &amp;lt;= c),&lt;br/&gt;
even in the case of discrete PDFs.&lt;/p&gt;

&lt;p&gt;Whether the lower or upper bound should be excluded is another matter. I usually work with continuous pdfs, so I don't know if there is a common practice in the probability community. If there is none, I would tend to chose the following definition&lt;br/&gt;
P(x0 &amp;lt;= X &amp;lt; x1)&lt;br/&gt;
(sorry Phil!), because it would be consistent with the way things are usually indexed in java (a&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;.. a&lt;span class="error"&gt;&amp;#91;a.length-1&amp;#93;&lt;/span&gt;). See also &lt;tt&gt;org.apache.commons.math.util.MultidimensionalCounter&lt;/tt&gt;. Although this type of consistency is not an absolute requirement, I think it is nice for the user to have such simple principle: "lower bound always included, upper bound always excluded". Appart from this small point, I really have no objection to any choice.&lt;/p&gt;
, &lt;p&gt;Have a look at the default implementation of cum(x0,x1) now in AbstractDistribution.  I think the incorrectness in the documentation there may have been what triggered Christian to raise this issue.  The equation cum(a,b) = F(b) - F(a) where F is the distribution function is natural and what the impl there is trying to do.  In the discrete case, this equation fails, however, unless you define the cum to exclude the &lt;b&gt;lower&lt;/b&gt; endpoint.  That's why P(x0 &amp;lt; X &amp;lt;= x1) is a better definition.&lt;/p&gt;
, &lt;p&gt;OK, Phil, it makes perfect sense.&lt;/p&gt;
, &lt;p&gt;Good, the definition of cum(x0,x1) will be P(x0 &amp;lt; X &amp;lt;= x1). Phil, you are right: cum(x0,x1) in AbstractDistribution was a reason for raising this issue. Another reason was cum(int x0, int x1) in AbstractIntegerDistribution.&lt;/p&gt;

&lt;p&gt;The idea behind probability(double x) is in fact to define it as p(X = x) and to return 0 for continuous distributions. This function would be useful for discrete distributions not inheriting from IntergerDistribution and for distributions being composed of discrete and continuous parts.&lt;/p&gt;
, &lt;p&gt;I guess I am OK with pushing p&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/error.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt; up.  See related post to follow in commons-dev. &lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
I've started looking into this issue. As I said, you will have to be patient with me &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;.&lt;br/&gt;
I can see there already is a default implementation of &lt;tt&gt;AbstractContinuousDistribution.inverseCumulativeProbability&lt;/tt&gt;. So what exactly would you like me to do? Is this implementation fragile? Would you like me to improve robustness? Provide full testing?&lt;/p&gt;

&lt;p&gt;I think there might be issues when the PDF falls down to zero in a range (in which case the cum exhibits a plateau). The returned value might differ from the mathematical definition you proposed. Is this what you want me to work on? Have you already identified other issues?&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;

&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;

&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;

&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;
, &lt;p&gt;Another point for discussion:&lt;br/&gt;
I'd like to introduce&lt;br/&gt;
getDomainBracket(double p): returns double[]&lt;br/&gt;
to AbstractDistribution as helper function for inverseCumulativeProbability. This allows to avoid searching a bracket where a bracket can be specified directly.&lt;br/&gt;
The function getDomainBracket could be made abstract (which means to remove getInitialDomain, getDomainLowerBound, and getDomainUpperBound as these functions aren't needed any more), or it could have a default implementation (according to the corresponding part of the current implementation of inverseCumulativeProbability) which uses getInitialDomain, getDomainLowerBound, and getDomainUpperBound. However, getInitialDomain, getDomainLowerBound, and getDomainUpperBound should not be abstract in the latter case. Otherwise a derived class would be forced to implement something it potentially doesn't use. Thus the functions getInitialDomain, getDomainLowerBound, and getDomainUpperBound should have default implementations which either return default values (0, -infinity, +infinity) or throw an exception saying something like "has to be implemented".&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I'm working on it...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, for now, I'm concentrating on making the current impl in &lt;tt&gt;AbstractContinuousDistribution&lt;/tt&gt; more robust. The other impl should be easier.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current implementation uses a Brent solver. I think the solver itself is only one side of the issue. The other point is the algorithm used to bracket the solution, in order to ensure that the result is consistent with the definition of the cumprob. As for the &lt;tt&gt;DifferentiableUnivariateRealSolver&lt;/tt&gt;, I'm not too sure. I guess it depends on what is meant by "continuous distribution". For me, it means that the random variable takes values in a continuous set, and possibly its distribution is defined by a density. However, in my view, nothing prevents occurences of Dirac functions, in which case the cum sum is only piecewise C1. It's all a matter of definition, of course, and I'll ask the question on the forum to check whether or not people want to allow for such a situation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I'm very interested.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Please note that &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt; has been created specifically to handle plateaux.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;Here is the first patch for this issue (unfortunately with some delay). It adjusts the distributions with real domain to the definitions in this issue, and it mainly changes documentations.&lt;/p&gt;

&lt;p&gt;I could not move inverseCumulativeProbability(double) up to Distribution because there would be a conflict with IntegerDistribution.inverseCumulativeProbability(double): This method returns int. This problem will be removed by solving issue &lt;a href="https://issues.apache.org/jira/browse/MATH-703" title="Splitting up the distribution hierarchy"&gt;&lt;del&gt;MATH-703&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The implementation of inverseCumulativeProbability(double) is not changed as Sbastien is working on this.&lt;/p&gt;

&lt;p&gt;I will provide the patch for the integer distributions as soon as I have adjusted the test data to the new inequalities and reverified the adjusted test data.&lt;/p&gt;
, &lt;p&gt;All,&lt;br/&gt;
since I'm already working on this package, I'm happy to commit the patch on behalf of Christian. However, since I'm a relatively new committer, I would feel more confident if one of the "old, wise committers" could double check the svn log afterwards.&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hey, that's how it always works &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;  &lt;/p&gt;

&lt;p&gt;I don't know about "wise" but I certainly qualify as "old" by any standard, so will have a look once you have reviewed and committed.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
, &lt;p&gt;Patch &lt;tt&gt;Math-692_realDomain_patch1.patch&lt;/tt&gt; (20111108) applied in rev 1200179, with minor modifications (mostly checkstyle fixes).&lt;br/&gt;
Thanks Christian!&lt;/p&gt;
, &lt;p&gt;As mentioned by Sbastien in &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt;, the implementation of &lt;tt&gt;IntegerDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; can benefit from the ideas which came up for &lt;tt&gt;RealDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; in that thread.&lt;/p&gt;

&lt;p&gt;Thus I will remove &lt;tt&gt;getDomainLowerBound(double p)&lt;/tt&gt; and &lt;tt&gt;getDomainUpperBound(double p)&lt;/tt&gt; from the integer distributions. I checked that all current implementations of the lower/upper bound methods provide the whole support of the distribution as starting bracket. This means that using &lt;tt&gt;getSupportLowerBound()&lt;/tt&gt; and &lt;tt&gt;getSupportUpperBound()&lt;/tt&gt; for the starting bracket won't degrade the performance of the current distribution implementations. However, a user might want the improve the performance of his distribution implementations by providing a more targeted starting bracket for probability &lt;tt&gt;p&lt;/tt&gt;. Thus I will swap the solving step to a protected function &lt;tt&gt;solveInverseCumulativeProbability(double p, int lower, int upper)&lt;/tt&gt;, so that it gets easy to override &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; with an implementation which finds a better starting bracket.&lt;/p&gt;

&lt;p&gt;Furthermore, Phil's idea with Chebyshev's inequality can be applied to the generic implementation of &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; in order to get a better starting bracket.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
If you agree with that, I suggest that you also take care of &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;, as the two issues seem to be very much connected.&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;my changes in the integer distributions don't solve &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;. Instead I found a probably related problem with the Pascal distribution.&lt;/p&gt;

&lt;p&gt;The integer distribution patch for this issue still isn't ready. I will provide it next week.&lt;/p&gt;

&lt;p&gt;Christian&lt;/p&gt;
, &lt;p&gt;This is the patch which adjusts the integer distributions to the agreements above.&lt;/p&gt;

&lt;p&gt;The changes to the test cases for the random generators may be unexpected. But these changes initially were triggered by adjusting &lt;tt&gt;RandomDataTest.checkNextPoissonConsistency(double)&lt;/tt&gt; to the new contract for integer distributions. Then some random generator tests failed due to chance. While adjusting their seeds, I found some other tests with a high failure probability. Thus I also set some failure probabilities to 0.01 in order to find suitable seeds more quickly.&lt;/p&gt;

&lt;p&gt;My next task on this issue is to adjust the user guid.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
thanks for this contribution. I am away for a few days, but am very happy to commit this patch as soon as I am back, if you are not in too much of a hurry.&lt;br/&gt;
Thanks again,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Well, we've recently run into some troubles with SVN, but it seems everything is working fine again. Patch {{&lt;a href="https://issues.apache.org/jira/browse/MATH-692" title="Cumulative probability and inverse cumulative probability inconsistencies"&gt;&lt;del&gt;MATH-692&lt;/del&gt;&lt;/a&gt;_integerDomain_patch1.patch}} (with minor checkstyle changes) committed in revision &lt;tt&gt;1226041&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Please do not forget to run &lt;tt&gt;mvn clean; mvn site:site&lt;/tt&gt; and check the reports (in particular, &lt;tt&gt;checkstyle&lt;/tt&gt;) prior to submitting a patch!&lt;/p&gt;

&lt;p&gt;Thanks for this contribution.&lt;/p&gt;
, &lt;p&gt;The committed patch actually causes failure of &lt;tt&gt;Well1024Test&lt;/tt&gt; in &lt;tt&gt;o.a.c.m.random&lt;/tt&gt;.&lt;/p&gt;
, &lt;p&gt;Thanks for committing the patch, Sbastien. I see you already changed the seed in &lt;tt&gt;Well1024aTest&lt;/tt&gt;. This hopefully removes the failure.&lt;/p&gt;

&lt;p&gt;I'll have a look into Maven to prepare a better patch next time. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;I see you already changed the seed in Well1024aTest.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I did, but is this really how we want &lt;tt&gt;Well2004aTest&lt;/tt&gt; to pass?&lt;/p&gt;
, &lt;p&gt;I guess there is no alternative to this way of making probabilistic test cases pass. However, I understand your bad feeling with this kind of failure fixing. The problem is that probabilistic tests are quiet fuzzy: Neither a passed test nor a failed test provides a clear answer whether something is right or wrong in the implementation. There is just a high chance to pass such a test with a correct implementation. The chance for failure increases with an erroneous implementation due to systematic deviations in the generated data. These chances tell whether it is easy to find a seed which passes the tests or not. Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's exactly the point I've raised on the mailing-list: out of three seeds (100, 1000 and 1001), only one works. Of course, I would not dare to call that representative statistics, but I'm wondering whether or not we should be worried...&lt;/p&gt;
, &lt;p&gt;The issue about selection of an appropriate seed has been raised elsewhere. No definitive answer has been provided so far, so I suggest we consider this issue as solved for the time being.&lt;/p&gt;
], resolution=Fixed, reporter=cwinter, assignees=[], commentAuthors=[psteitz, celestin, mikl, cwinter], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,372 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-654
2016-01-13 22:04:31,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-654, created=Tue Aug 30 19:23:19 CEST 2011, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Thu Sep 01 02:14:02 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=ValueServer not deterministic for a fixed random number seed, link=https://issues.apache.org/jira/browse/MATH-654, description=&lt;p&gt;I have built an agent-based model using the Apache Commons Math library, which has come in handy.&lt;/p&gt;

&lt;p&gt;The ValueServer seemed particularly helpful, as explained at:&lt;br/&gt;
&lt;a href="http://commons.apache.org/math/userguide/random.html"&gt;http://commons.apache.org/math/userguide/random.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My simulation needs repeatable randomness, so I used this form of the ValueServer constructor:&lt;/p&gt;

&lt;p&gt;    ValueServer(RandomData randomData) &lt;br/&gt;
    Construct a ValueServer instance using a RandomData as its source of random data.&lt;br/&gt;
    // &lt;a href="http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html"&gt;http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, in my simulation, I found that the ValueServer did not act deterministically if I supplied the same random number seed.&lt;/p&gt;

&lt;p&gt;I have not inspected the source code, but I suspect that the ValueServer is not using the `randomData` generator correctly. If it was, then it should be deterministic.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  I assume you are using DIGEST_MODE.  If this is the case and you are comfortable compiling the code in trunk, the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-634" title="EmpiricalDistributionImpl should use a pluggable RandomGenerator"&gt;&lt;del&gt;MATH-634&lt;/del&gt;&lt;/a&gt; enables a workaround for this.  Using the reseed method added to EmpiricalDistributionImpl in trunk, you can use ValueServer's getEmpiricalDistribution to get the distribution and then invoke reseed.  Unfortunately, this method does not exist in any released version yet.&lt;/p&gt;

&lt;p&gt;The problem is that ValueServer#getNextDigest (what it does for getNext in DIGEST_MODE) delegates to EmpiricalDistributionImpl#getNextValue.  EmpiricalDistributionImpl has its own RandomData instance.  To fix this issue, EmpiricalDistirbutionImpl should add a constructor taking a RandomData and ValueServer should provide this.&lt;/p&gt;
, &lt;p&gt;Fixed in r1163875. ValueServer now exposes a reSeed method that when supplied a fixed seed will generate a fixed sequence in any stochastic mode. The RandomDataImpl that it uses internally is passed to the EmpiricalDistributionImpl it creates when used in DIGEST_MODE.  The changes for this issue include an incompatible (vs. 2.x) change: the constructor for EmpiricalDistributionImpl that previously took a RandomData now takes a RandomDataImpl.  The plan for 3.0 is to merge these.&lt;/p&gt;
], resolution=Fixed, reporter=d.james, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-640
2016-01-13 22:04:31,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-640, created=Tue Aug 02 21:06:35 CEST 2011, updated=Sat Mar 24 17:16:52 CET 2012, resolved=Wed Aug 03 06:17:43 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=AbstractRandomGenerator nextInt() and nextLong() default implementations generate only positive values, link=https://issues.apache.org/jira/browse/MATH-640, description=&lt;p&gt;The javadoc for these methods (and what is specified in the RandomGenerator interface) says that all int / long values should be in the range of these methods.  The default implementations provided in this class do not generate negative values.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1153338&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-618
2016-01-13 22:04:31,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-618, created=Wed Jul 13 22:23:43 CEST 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Thu Jul 14 08:08:54 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same, link=https://issues.apache.org/jira/browse/MATH-618, description=&lt;p&gt;For both Complex add and subtract, the javadoc states that&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;* If either &lt;span class="code-keyword"&gt;this&lt;/span&gt; or &amp;lt;code&amp;gt;rhs&amp;lt;/code&amp;gt; has a NaN value in either part,
     * {@link #NaN} is returned; otherwise Inifinite and NaN values are
     * returned in the parts of the result according to the rules &lt;span class="code-keyword"&gt;for&lt;/span&gt;
     * {@link java.lang.&lt;span class="code-object"&gt;Double&lt;/span&gt;} arithmetic&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1146573&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-588
2016-01-13 22:04:31,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-588, created=Sun Jun 12 20:19:07 CEST 2011, updated=Sat Mar 24 17:16:31 CET 2012, resolved=Sun Feb 05 20:54:50 CET 2012, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Weighted Mean evaluation may not have optimal numerics, link=https://issues.apache.org/jira/browse/MATH-588, description=&lt;p&gt;I recently got this in a test run&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;testWeightedConsistency(org.apache.commons.math.stat.descriptive.moment.MeanTest)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;0.002282165958997601&amp;gt; but was:&amp;lt;0.002282165958997157&amp;gt;
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:441)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:178)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:153)
	at org.apache.commons.math.stat.descriptive.UnivariateStatisticAbstractTest.testWeightedConsistency(UnivariateStatisticAbstractTest.java:170)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The correction formula used to compute the unweighted mean may not be appropriate or optimal in the presence of weights:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// Compute initial estimate using definitional formula
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; sumw = sum.evaluate(weights,begin,length);
&lt;span class="code-object"&gt;double&lt;/span&gt; xbarw = sum.evaluate(values, weights, begin, length) / sumw;

&lt;span class="code-comment"&gt;// Compute correction factor in second pass
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; correction = 0;
&lt;span class="code-keyword"&gt;for&lt;/span&gt; (&lt;span class="code-object"&gt;int&lt;/span&gt; i = begin; i &amp;lt; begin + length; i++) {
  correction += weights[i] * (values[i] - xbarw);
}
&lt;span class="code-keyword"&gt;return&lt;/span&gt; xbarw + (correction/sumw);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;, comments=[&lt;p&gt;Fixed it in r1240790.&lt;/p&gt;

&lt;p&gt;There was a too strict equality test using an relative error of 10-14 which resulted in certain unforunate cases of an absolute error of 10-18.&lt;/p&gt;
, &lt;p&gt;Corrected the equality test in r1240795 as it was leading to failure. In fact the test can range from very small to very large values which really requires a relative error estimate.&lt;/p&gt;

&lt;p&gt;The test is problematic in general, as it may contain values from very different scales (due to its random nature), leading to unavoidable precision errors in the above formula.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[tn], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-575
2016-01-13 22:04:31,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-575, created=Sat May 14 18:40:34 CEST 2011, updated=Sat Mar 24 17:16:54 CET 2012, resolved=Thu Feb 02 12:12:52 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=Exceptions in genetics package or not consistent with the rest of [math], link=https://issues.apache.org/jira/browse/MATH-575, description=&lt;p&gt;InvalidRepresentationException is checked and non-localized.  This exception should be placed in the &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; hierarchy.  The AbstractListChromosome constructor also throws a non-localised IAE, which should be replaced by an appropriate &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; exception.&lt;/p&gt;, comments=[&lt;p&gt;Phil started to work on this issue in r1135025.&lt;/p&gt;

&lt;p&gt;In r1235038 additional cleanups have been performed:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;add localized messages for all exceptions&lt;/li&gt;
	&lt;li&gt;add @throws to javadoc where appropriate&lt;/li&gt;
	&lt;li&gt;add final to method parameters&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What is missing:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;Phil mentioned that InvalidRepresentationException should be placed into &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, although I am not sure why, as it is not used outside the genetics package&lt;/li&gt;
	&lt;li&gt;add more custom exception classes specific to the genetics package (optional). By now mostly MathIllegalArgumentException or other appropriate ones have been used.&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;Thanks for working on this, but before you do start to make modifications, please assign the issue to yourself!&lt;/p&gt;

&lt;p&gt;For the changes themselves, I don't agree with the creation of those many localized messages: We have been trying to rationalize and reduce the number of those, by removing duplicates and combining several ones to convey the full explanation of the problem. See my reply to the commit message.&lt;/p&gt;
, &lt;p&gt;Fixed in r1235197.&lt;/p&gt;

&lt;p&gt;Thanks for your suggestions!&lt;/p&gt;
, &lt;p&gt;Thomas,&lt;br/&gt;
Could please check whether this issue is resolved? And if it is, mark it so? Thanks.&lt;/p&gt;
, &lt;p&gt;As from the original issue description, Phil intended to move the InvalidRepresentationException to the general o.a.c.m.exceptions package. I am not sure about this, that's why I kept it aside for the time being. If we agree on keeping it in the genetics package we can resolve this issue.&lt;/p&gt;
, &lt;p&gt;Phil had always been opposed to having all exceptions grouped in their own package; so I doubt that he meant to move that one over there... &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
Here, the description just indicates that the exception should become &lt;em&gt;unchecked&lt;/em&gt; and that the "detailed message" should be an element from the "LocalizedFormats" enum (i.e. derive from one of the base CM exceptions).&lt;/p&gt;
, &lt;p&gt;Ah ok, that makes it clear. When reading hierarchy I was just thinking in terms of packages rather than class hierarchy.&lt;/p&gt;

&lt;p&gt;Thus, I resolve this issue.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[tn], commentAuthors=[tn, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-555
2016-01-13 22:04:31,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-555, created=Mon Apr 04 06:13:04 CEST 2011, updated=Sat Mar 24 17:16:43 CET 2012, resolved=Mon Apr 04 06:53:13 CEST 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=MathUtils round method should propagate rather than wrap Runitme exceptions, link=https://issues.apache.org/jira/browse/MATH-555, description=&lt;p&gt;MathUtils.round(double, int, int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException, the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in trunk in r1088473&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-540
2016-01-13 22:04:31,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-540, created=Sun Mar 06 01:43:45 CET 2011, updated=Sat Mar 24 17:16:36 CET 2012, resolved=Sun Jun 12 07:58:50 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug, link=https://issues.apache.org/jira/browse/MATH-540, description=&lt;p&gt;The AbstractIntegerDistribution.inverseCumulativeProbability(...) function attempts to decrement the lower bound of discrete distributions to values that go below the lower bound.&lt;/p&gt;, comments=[&lt;p&gt;I don't think this is a bug.  Per the javadoc, the contract for inverse cum is&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/**
 * For a random variable {@code X} whose values are distributed according
 * to &lt;span class="code-keyword"&gt;this&lt;/span&gt; distribution, &lt;span class="code-keyword"&gt;this&lt;/span&gt; method returns the largest {@code x}, such
 * that {@code P(X &amp;lt; x) &amp;lt; p}.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This implies that if the first non-zero mass point has probability greater than p, the right value to return is one less than that value, which is whet the method will do.  Your example distribution throws NPE when trying to compute probabilities outside of its domain of support. &lt;/p&gt;
, &lt;p&gt;I'm looking at it like this.  I have very simple distribution like the one provided (Four sided dice).  I'm trying to write a simulation that draws values of x for a a set of uniform 0-1 probabilities.  So I'm expecting:&lt;/p&gt;

&lt;p&gt;0 When p is less than or equal to 0.25&lt;br/&gt;
1 When p is greater than 0.25 but less than or equal to 0.50&lt;br/&gt;
2 When p is greater than 0.50 but less than or equal to 0.75&lt;br/&gt;
3 When p is greater than 0.75 but less than or equal to 1.0&lt;/p&gt;

&lt;p&gt;So for the line &lt;/p&gt;

&lt;p&gt;int neverSucceeds = d.inverseCumulativeProbability(0.0001);&lt;/p&gt;

&lt;p&gt;I'm really expecting 0 to be returned.&lt;/p&gt;

&lt;p&gt;Make sense?&lt;/p&gt;
, &lt;p&gt;I see now that there actually does appear to be an error in the javadoc.  The implementation really returns the largest x such that p(X &amp;lt;= x) &amp;lt;= p.  In the discrete case, &amp;lt;= matters and I think both inequalities in the javadoc should be changed.&lt;/p&gt;

&lt;p&gt;In your example, if the probability distribution vanishes outside 0, 1, 2, 3 and puts .25 mass on each of these values, the inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;

&lt;p&gt;If you fix your distribution so that both probability and cumulativeProbability return correct values (rather than throwing NPEs) outside of the mass values, you should get -1 returned.&lt;/p&gt;
, &lt;p&gt;Reading your last comment a little more carefully, it looks like what you are trying to do is implement sampling.  IIUC, something like what you are suggesting should work - you just have an off-by-one problem vis-s-vis the contract of inverse cumulative probabilities as we define them.  I would be +1 for adding direct support for sampling from discrete distributions, but we should open a separate ticket for that.&lt;/p&gt;
, &lt;p&gt;OK - I'll close this one and open a separate ticket.&lt;/p&gt;
, &lt;p&gt;There is a javadoc bug that needs to be fixed here&lt;/p&gt;
, &lt;p&gt;Ooops - Thanks.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;...inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems to me that users would be better served if it returned 0 and that it is also correct to do so.&lt;/p&gt;

&lt;p&gt;In the definition we say "For a random variables X whose values are distributed according to this distribution...".&lt;/p&gt;

&lt;p&gt;Suppose the distribution was for a six sided dice.  One could assert that the distribution is only defined for the values 1,2,3,4,5,6.  In this case the inverseCumulativeDistribution returns 0, but that does not have any meaning.  So now developers are forced to define the meaning of 0 for a six sided dice implementation.  &lt;/p&gt;

&lt;p&gt;In Grad school we were taught the the inverse cumulative distribution is for sampling.  So for a six sided dice uniform probabilities less than 1/6 would return 1, less than 2/6 would return 2, etc.&lt;/p&gt;

&lt;p&gt;With the current implementation for values less than 1/6 we get 0 which is meaningless, and the only time we get 6 is when the uniform probability argument is 1.&lt;/p&gt;

&lt;p&gt;So if someone mistakenly tries to use the inverseCumulativeProbability function for sampling the results are going to be wacked.  What is the use case for the inverseCumulativeProbability the way it is right now?&lt;/p&gt;
, &lt;p&gt;You have a choice in defining the inverse cum whether to define it the way we have or to use and inf rather than a sup.  We can implement sampling using the current impl.  We just need to take into account the way the inverse cum is defined in AbstractIntegerDistribution.  &lt;/p&gt;
, &lt;p&gt;OK - I think it's starting to make more sense to me now.  So when implementing sampling we just add one to the value returned by inverseCumulativeDistribution, unless the uniform probability argument is 1?&lt;/p&gt;
, &lt;p&gt;I am sorry.  I forgot that we had in fact already implemented this in version 2.2. See AbstractIntegerDistribution#sample.  The base class implementation delegates to RandomDataImpl#nextInversionDeviate (adding one per the last comment).&lt;/p&gt;
, &lt;p&gt;Sorry for the noise. I closed the wrong ticket.  Still need to fix the javadoc to match behavior and user guide.&lt;/p&gt;
, &lt;p&gt;Javadoc fixed in trunk r1134866&lt;/p&gt;
], resolution=Fixed, reporter=ole, assignees=[], commentAuthors=[psteitz, ole], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-506
2016-01-13 22:04:31,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-506, created=Tue Feb 01 19:38:01 CET 2011, updated=Sat Mar 24 17:16:41 CET 2012, resolved=Sat Aug 20 23:14:57 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=The static field ChiSquareTestImpl.distribution serves no purpose, link=https://issues.apache.org/jira/browse/MATH-506, description=&lt;p&gt;The static field ChiSquareTestImpl.distribution serves no purpose.&lt;/p&gt;

&lt;p&gt;There is a setter for it, but in every case where the field is used, it is first overwritten with a new value.&lt;/p&gt;

&lt;p&gt;The field and the setter should be removed, and the methods that create a new instance should create a local variable instead.&lt;/p&gt;

&lt;p&gt;For Math 2.1, the field can be removed and the setter deprecated.&lt;/p&gt;, comments=[&lt;p&gt;Agreed.  Since the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; this instance field is unnecessary.&lt;/p&gt;
, &lt;p&gt;See the discussion in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; where it was decided to remove the distribution pluggability in 3.0.  In 2.x, the distribution is pluggable and the instance field is useful.  The 3.0 code in trunk removes the pluggability and makes the field useless.&lt;/p&gt;
, &lt;p&gt;Sorry - I thought I had checked the 2.x implementation as well, but obviously not, as it does use the field.&lt;/p&gt;

&lt;p&gt;However, we should still deprecate the setter in 2.2, as it is removed in 3.0 - OK?&lt;/p&gt;
, &lt;p&gt;Just tried removing the field and setter in 3.0, and found that the constructors rely on the setter (which is a separate bug, as the setter is not final - but easily fixable if required).&lt;/p&gt;

&lt;p&gt;The fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; merely removed deprecated code.&lt;/p&gt;

&lt;p&gt;It replaced "distribution.setDegreesOfFreedom(dof)" with "distribution = new ChiSquaredDistributionImpl(dof)" which is how the field became useless.&lt;/p&gt;

&lt;p&gt;There are two constructors which still create values for the distribution field.&lt;/p&gt;

&lt;p&gt;I don't know enough about the Math to know whether there would be any use cases for having additional methods that used a distribution provided by the class instance, rather than calculated by the individual methods (as at present).&lt;/p&gt;

&lt;p&gt;If there is no need for external provision of the distribution degree of freedom, then the constructor with parameter can be dropped.&lt;/p&gt;

&lt;p&gt;Otherwise, we need to add some methods that can use the provided distribution (which should be a final instance field).&lt;/p&gt;

&lt;p&gt;In any case, I think the setter needs to be dropped from 3.x&lt;/p&gt;
, &lt;p&gt;The instance field was there originally so that different ChiSquareDistribution implementations could be provided at construction time or via a setter (making the underlying ChiSquareDistribution pluggable).  &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; pointed to a different problem related to mutability of implementation instances.  The simplest solution to both problems is to eliminate the pluggability, which the change in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; does for this class.  The degrees of freedom are always computed from the data, so there is no need for the constructor that takes a distribution instance as argument.  Both the constructor and setter can be deprecated in 2.2 and removed in 3.0 unless we want to keep pluggability, which would require&lt;/p&gt;

&lt;p&gt;1) making the distribution field final (so removing the setter)&lt;br/&gt;
2) copying, rather than referencing the actual parameter provided to the constructor&lt;/p&gt;

&lt;p&gt;I am on the fence on this.  Maybe others can chime in (next week &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;p&gt;OK, I see now, thanks!&lt;/p&gt;
, &lt;p&gt;I removed the field (hence eliminating pluggability) in r1159916.  As of 3.0, the distribution classes are immutable, so to support pluggability a factory or class name rather than a distribution instance would have to be provided.  There is only one implementation provided by &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, so I do not see this as worth the effort and complexity to retain.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[psteitz], commentAuthors=[psteitz, sebb@apache.org], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-505
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-505, created=Tue Feb 01 01:28:56 CET 2011, updated=Sat Mar 24 17:16:40 CET 2012, resolved=Tue Feb 01 19:58:30 CET 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
], fixVersion=[3.0
], priority=Major, summary=TestUtils is thread-hostile, link=https://issues.apache.org/jira/browse/MATH-505, description=&lt;p&gt;TestUtils has several mutable static fields which are not synchronised, or volatile.&lt;/p&gt;

&lt;p&gt;If one of the fields is updated by thread A, there is no guarantee that thread B will see the full update - it may see a partially updated object.&lt;/p&gt;

&lt;p&gt;Furthermore, at least some of the static fields reference a mutable object, which can be changed whilst another thread is using it.&lt;/p&gt;

&lt;p&gt;As far as I can tell, this class must only ever be used by a single thread otherwise the results will be unpredictable.&lt;/p&gt;, comments=[&lt;p&gt;What fields, exactly?&lt;/p&gt;
, &lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/** Singleton TTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; TTest tTest = &lt;span class="code-keyword"&gt;new&lt;/span&gt; TTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; ChiSquareTest chiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; UnknownDistributionChiSquareTest unknownDistributionChiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton OneWayAnova instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; OneWayAnova oneWayAnova =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; OneWayAnovaImpl();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of the above may be changed by set methods. There is no synch.&lt;/p&gt;
, &lt;p&gt;OK, I was looking at the wrong TestUtils &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;

&lt;p&gt;The reason for this strange-looking setup is to allow the implementations to be pluggable at runtime.  "Hostile" is a harsh word, but this class is certainly &lt;b&gt;not&lt;/b&gt; threadsafe.  Ideas / patches to achieve the design goal with less "hostility" would be appreciated.&lt;/p&gt;

&lt;p&gt;I would have to double-check, but I don't think that there is any test instance state used by the methods in this class. &lt;/p&gt;
, &lt;p&gt;By thread-hostile, I mean that it is not possible in general for two different threads to use the class safely.&lt;br/&gt;
If one thread changes any of the static fields, there is no way of knowing how the methods called by the other thread will behave. This is partly because the values are not safely published currently, but even if they were, the threads don't know what settings will be used as they can be changed at any time by another thread.&lt;/p&gt;

&lt;p&gt;In general, any class which relies on mutable static state for its behaviour is thread-hostile.&lt;br/&gt;
The shared state cannot simultaneously satisfy two threads needing different behaviour.&lt;/p&gt;

&lt;p&gt;I think the only safe way for two threads to use the class as it stands is if they both synchronize on the class.&lt;br/&gt;
This will ensure safe publication of any field changes, and enforce serial usage which can guarantee the setting that will be used (but the lock will have to be held for the set call as well).&lt;/p&gt;

&lt;p&gt;ChiSquareTestImpl has a non-final instance field which means its value won't necessarily be safely published.&lt;br/&gt;
The field also has a setter which could be invoked by one thread while another was using it.&lt;/p&gt;

&lt;p&gt;TTestImpl is immutable (has no fields), and OneWayAnovaImpl can be made immutable, but other implementations of the interfaces might exist which are not immutable.&lt;/p&gt;

&lt;p&gt;The simplest way to make the class thread-safe would be to convert all the methods and fields from static to instance, but I don't know if that is acceptable.&lt;/p&gt;
, &lt;p&gt;Making the methods instance sort of defeats the purpose of the class.  None of the instance data in any of the static singletons is actually used or depended on by the methods of this class.  You are correct though that if one thread changes the impl for one of the singletons while another is using the class, the other could see a different than expected impl.  I think the practical likelihood of this is pretty much nil, as it is hard to imagine an application supplying two different implementations for the tests and wanting different threads to use different impls.  Personally, I would be happy just documenting the fact that the class is not threadsafe and if concurrent threads want to plug in different implementations, they need to synchronize on the class.  If this is not acceptable, my next preference would be to remove the pluggability - i.e., make the singletons final or get rid of them altogether, creating instances as needed for static method calls.  There is no initialization overhead creating the test classes.&lt;/p&gt;
, &lt;p&gt;@Phil: Please also keep in mind that M3 supports now (currently optional) parallel execution and it might be no longer a proper assumption that all tests are executed serially.&lt;/p&gt;
, &lt;p&gt;There is another possible option, which would be to fix the default implementations, and create new static methods that took an extra parameter for the implementation to be used.&lt;/p&gt;

&lt;p&gt;At present, changes to the static fields are not guaranteed to be published correctly. Making them volatile would fix this, but would not help with concurrent access.&lt;/p&gt;
, &lt;p&gt;Thanks, Joerg.  There should be no problems with the unit tests unless and until we introduce different tests that actually test the pluggability.  &lt;/p&gt;

&lt;p&gt;I thought about the additional parameter option, Sebb; but that again defeats the purpose of this "convenience class" - you might as well just instantiate the implementation and use it.&lt;/p&gt;

&lt;p&gt;I think the best solution is to just make the fields final and drop the getters and setters.  This is consistent with StatUtils.  So we should document the "hostility" issues in 2.2 and deprecate there and drop in 3.0.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[sebb@apache.org], commentAuthors=[psteitz, sebb@apache.org, joehni], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-484
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-484, created=Tue Jan 18 21:49:51 CET 2011, updated=Wed Mar 23 21:35:01 CET 2011, resolved=Mon Feb 14 15:20:29 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=events detection in ODE solvers is too complex and not robust, link=https://issues.apache.org/jira/browse/MATH-484, description=&lt;p&gt;All ODE solvers support multiple events detection since a long time. Events are specified by users by implementing the EventHandler interface. Events occur when the g(t, y) function evaluates to 0. When an event occurs, the solver step is shortened to make sure the event is located at the end of the step, and the event is triggered by calling the eventOccurred method in the user defined implementation class. Depending on the return value of this method, integration can continue, it can be stopped, or the state vector can be reset.&lt;/p&gt;

&lt;p&gt;Some ODE solvers are adaptive step size solvers. They can modify step size to match an integration error setting, increasing step size when error is low (thus reducing computing costs) or reducing step size when error is high (thus fulfilling accuracy requirements).&lt;/p&gt;

&lt;p&gt;The step adaptations due to events on one side and due to adaptive step size solvers are quite intricate by now, due to numerous fixes (&lt;a href="https://issues.apache.org/jira/browse/MATH-161" title="patch for Mantissa"&gt;&lt;del&gt;MATH-161&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-213" title="FirstOrderIntegrator.integrate does not give back integration stop time when an event handler stops integration"&gt;&lt;del&gt;MATH-213&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-358" title="ODE integrator goes past specified end of integration range"&gt;&lt;del&gt;MATH-358&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-421" title="restarting an ODE solver that has been stopped by an event doesn&amp;#39;t work"&gt;&lt;del&gt;MATH-421&lt;/del&gt;&lt;/a&gt; and also during standard maintenance - see for example r781157). The code is very difficult to maintain. It seems each bug fix introduces new bugs (r781157/&lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;) or tighten the link between adaptive step size and event detection (&lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;/r927202).&lt;/p&gt;

&lt;p&gt;A new bug discovered recently on an external library using a slightly modified version of this code could not be retroffitted into commons-math, despite the same problem is present. At the beginning of EventState.evaluateStep, the initial step may be exactly 0 thus preventing root solving, but preventing this size to drop to 0 would reopen &lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;. I could not fix both bugs at the same time.&lt;/p&gt;

&lt;p&gt;So it is now time to untangle events detection and adaptive step size, simplify code, and remove some inefficiency (event root solving is always done twice, once before step truncation and another time after truncation, of course with slightly different results, events shortened steps induce high computation load until the integrator recovers its optimal pace again, steps are rejected even when the event does not requires it ...).&lt;/p&gt;, comments=[&lt;p&gt;fixed in subversion repository as of r1061507 for branch 2.X and as of r1061508 for trunk&lt;/p&gt;
, &lt;p&gt;The fix introduced in r1061507 fails in several cases. If several events of the same type occur within a single long step, only the first one is triggered. If several events of different types occur during a backward integration, they are triggered in the wrong order (i.e. they are triggered in forward occurrence time order instead of backward).&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1070498 for branch 2.X and r1070499 for trunk&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-481
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-481, created=Mon Jan 17 18:15:41 CET 2011, updated=Wed Mar 23 21:33:40 CET 2011, resolved=Mon Jan 17 23:39:52 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=MathUtils.equals(double x, double y) disagrees with Javadoc, link=https://issues.apache.org/jira/browse/MATH-481, description=&lt;p&gt;MathUtils.equals(double x, double y) disagrees with Javadoc.&lt;/p&gt;

&lt;p&gt;The Javadoc says:&lt;/p&gt;

&lt;p&gt;Returns true iff they are equal as defined by  {@link #equals(double,double,int)}&lt;/p&gt;

&lt;p&gt;However, the code actually uses == and checks for NaN:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; &lt;span class="code-object"&gt;boolean&lt;/span&gt; equals(&lt;span class="code-object"&gt;double&lt;/span&gt; x, &lt;span class="code-object"&gt;double&lt;/span&gt; y) {
    &lt;span class="code-keyword"&gt;return&lt;/span&gt; (&lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(x) &amp;amp;&amp;amp; &lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(y)) || x == y;
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The method is deprecated, but it should probably still be consistent with its documentation.&lt;/p&gt;, comments=[&lt;p&gt;Corrected Javadoc in revision 1060117.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-465
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-465, created=Wed Jan 05 18:34:41 CET 2011, updated=Sat Mar 24 17:17:03 CET 2012, resolved=Wed Jul 20 14:20:51 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Incorrect matrix rank via SVD, link=https://issues.apache.org/jira/browse/MATH-465, description=&lt;p&gt;The getRank() function of SingularValueDecompositionImpl does not work properly. This problem is probably related to the numerical stability problems mentioned in &lt;a href="https://issues.apache.org/jira/browse/MATH-327"&gt;MATH-327&lt;/a&gt; and &lt;a href="https://issues.apache.org/jira/browse/MATH-320"&gt;MATH-320&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Example call with the standard matrix from R (rank 2):&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeHeader panelHeader" style="border-bottom-width: 1px;"&gt;&lt;b&gt;TestSVDRank.java&lt;/b&gt;&lt;/div&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.Array2DRowRealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.RealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecomposition;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecompositionImpl;

&lt;span class="code-keyword"&gt;public&lt;/span&gt; class TestSVDRank {
	&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; void main(&lt;span class="code-object"&gt;String&lt;/span&gt;[] args) {
		&lt;span class="code-object"&gt;double&lt;/span&gt;[][] d = { { 1, 1, 1 }, { 0, 0, 0 }, { 1, 2, 3 } };
		RealMatrix m = &lt;span class="code-keyword"&gt;new&lt;/span&gt; Array2DRowRealMatrix(d);
		SingularValueDecomposition svd = &lt;span class="code-keyword"&gt;new&lt;/span&gt; SingularValueDecompositionImpl(m);
		&lt;span class="code-object"&gt;int&lt;/span&gt; r = svd.getRank();
		&lt;span class="code-object"&gt;System&lt;/span&gt;.out.println(&lt;span class="code-quote"&gt;"Rank: "&lt;/span&gt;+r);
	}
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;The rank is computed as 3. This problem also occurs for larger matrices. I discovered the problem when trying to replace the corresponding JAMA method.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  Looks like it could as you suggest be related to &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt;.  &lt;/p&gt;
, &lt;p&gt;For now, pushing to 3.0.  If we get a fix for this and &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt; before 3.0 is ready, I may propose a 2.2.1 to include it.&lt;/p&gt;
, &lt;p&gt;My apologies if I am missing something, but here is what I noticed about the SVD. &lt;/p&gt;

&lt;p&gt;On lines 124-127 of SingularValueDecompositionImpl we have:&lt;/p&gt;

&lt;p&gt;        for (int i = 0; i &amp;lt; p; i++) {
            singularValues[i] = FastMath.sqrt(FastMath.abs(singularValues[i]));
        }&lt;/p&gt;

&lt;p&gt;This is potentially the offending line. First is the problem of negative eigenvalues. Negative variance in the principal components should probably be dealt with explicitly? Perhaps by throwing a MathException? Second, and the issue which this bug report deals with, is taking a square root of a very small number (&amp;lt;1) will return a larger number. If you apply the threshold test in getRank() (final double threshold = FastMath.max(m, n) * FastMath.ulp(singularValues&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;) )  prior to taking the square root, I believe this problem would be resolved. More importantly, philosophically, you test for zero variance. This is the appropriate test.&lt;/p&gt;

&lt;p&gt;Also, rank could be precalculated in the above loop. &lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1148714.&lt;/p&gt;

&lt;p&gt;This issue was fixed by changing SVD implementation according to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-611" title="A fast and stable SVD implementation from JAMA"&gt;&lt;del&gt;MATH-611&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
], resolution=Fixed, reporter=marisa, assignees=[], commentAuthors=[psteitz, gsteri1, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-464
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-464, created=Fri Dec 31 08:00:42 CET 2010, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Wed Aug 24 00:37:41 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Critical, summary=LegendreGaussIntegrator ignores defaultMaximalIterationCount and does 38 million iterations, link=https://issues.apache.org/jira/browse/MATH-464, description=&lt;p&gt;The following code results in count = 37801710 which is effectively an infinite loop for typical functions we are using&lt;br/&gt;
(in GeoGebra)&lt;/p&gt;

&lt;p&gt;The argument defaultMaximalIterationCount = 100 is being ignored&lt;/p&gt;

&lt;p&gt;This is the version we are using:&lt;br/&gt;
&lt;a href="http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java"&gt;http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    	LegendreGaussIntegrator gauss = new LegendreGaussIntegrator(5, 100);&lt;/p&gt;

&lt;p&gt;	try {
		double result = gauss.integrate(new testFun(), -10, 0.32462367623786328);
	} catch (Exception ee) {
		ee.printStackTrace();
	}&lt;/p&gt;



&lt;p&gt;class testFun implements UnivariateRealFunction {&lt;/p&gt;

&lt;p&gt;    public double value(double x) throws FunctionEvaluationException {
    	count ++;
        if (x&amp;gt;=0 &amp;amp;&amp;amp; x&amp;lt;=5) return 0.2; else return 0;
    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.&lt;/p&gt;

&lt;p&gt;The problem here is not with the iteration count.  In the example above, only 26 iterations are executed and the method returns the correct value.  What is causing the number of function evaluations to be so large is that each iteration involves multiple function evaluations.   I need to dig more deeply into the algorithm to determine what (if anything) the problem is, but what is causing the high number of function evaluations is the following&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// prepare next iteration
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; ratio = FastMath.min(4, FastMath.pow(delta / limit, 0.5 / abscissas.length));
n = FastMath.max((&lt;span class="code-object"&gt;int&lt;/span&gt;) (ratio * n), n + 1);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the example, delta / limit becomes large, causing n to increase rapidly.  As n increases, the number of function evaluations increases.&lt;/p&gt;
, &lt;p&gt;I am now thinking that this is not a bug, but a consequence of the fact that the integrand in the example is not at all well-approximated by a polynomial.  With a small-enough stepsize, the algorithm does converge, but requiring the large number of function evaluations above.  Here are some stepsize values for the example and the associated absolute error:&lt;/p&gt;

&lt;p&gt;n 8 error 0.05738431110184819&lt;br/&gt;
n 28 error 0.027423287634332688&lt;br/&gt;
n 100 error 8.62162720248888E-5&lt;br/&gt;
n 249 error 5.308122631570711E-4&lt;br/&gt;
n 650 error 4.3582615516528367E-4&lt;br/&gt;
n 1641 error 2.519984967931377E-4&lt;br/&gt;
n 3829 error 5.838605030586419E-5&lt;br/&gt;
...&lt;br/&gt;
 n 1102593 error 6.71416523906343E-8&lt;/p&gt;

&lt;p&gt;The last entry is from the last (26th) iteration.  I haven't verified the rationale for the updating formula for n above, but it does appear warranted in this case to increase n quickly as large n (= small stepsize) is required to get a decent estimate of the integral using Gaussian quadrature.&lt;/p&gt;
, &lt;p&gt;Perhaps we should also provide higher order formulas, using either a fixed set of precomputed constants or a way to compute the coefficients for any order.&lt;/p&gt;
, &lt;p&gt;Moving to 3.0.  I don't think this is a bug, but points to a couple of possible enhancements:&lt;/p&gt;

&lt;p&gt;1) higher order formulas (+0 on this suggestion from Luc - IMO the example and others like it are not suitable for Legendre-Gauss)&lt;br/&gt;
2) bound on the number of function evaluations (I vaguely recall us talking about this elsewhere, but can't find the reference.  If anyone else can, pls add.)&lt;/p&gt;
, &lt;p&gt;We restarted a thread about this a few days after the previous comment on this issue.&lt;br/&gt;
The thread can be read here: &lt;a href="http://markmail.org/thread/rnazrggnnuehz4qv"&gt;http://markmail.org/thread/rnazrggnnuehz4qv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think adding maxEvaluations while still preserving the existing maxIterations would be fine.&lt;/p&gt;
, &lt;p&gt;Coming back to this issue.&lt;/p&gt;

&lt;p&gt;I would propose to follow the same pattern we used for root solvers: adding a maxEval parameter in the top level integrate interface declaration. So we would have the same kind of configuration, with tolerances set at integrator/solver level and maxEval and function pointer passed at integrate/solve method call.&lt;/p&gt;

&lt;p&gt;Since we are just in the phase we change interfaces, this would be a good time to add this parameter.&lt;/p&gt;

&lt;p&gt;Does this seems reasonable ?&lt;/p&gt;
, &lt;p&gt;+1 for your suggestion, Luc.  Lets try to get this into 3.0.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1160914.&lt;/p&gt;

&lt;p&gt;The API of the integrators has been changed for consistency with solvers API. Now the main convergence parameters are set in the constructor and remain fixed, but a maximal number of function evaluation must be provided at each call to the integration method.&lt;/p&gt;

&lt;p&gt;Thanks for the report&lt;/p&gt;
], resolution=Fixed, reporter=murkle, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=180, timeSpent=null]
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-453
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-453, created=Mon Dec 06 03:01:08 CET 2010, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Mon Dec 06 13:53:56 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function, link=https://issues.apache.org/jira/browse/MATH-453, description=&lt;p&gt;RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function.&lt;/p&gt;

&lt;p&gt;As this explains how to recode deprecated method calls, it ought to be corrected before release.&lt;/p&gt;, comments=[&lt;p&gt;Removed references to the &lt;tt&gt;analysis.function&lt;/tt&gt; package (revision 1042610).&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[erans], commentAuthors=[erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-434
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-434, created=Sun Nov 07 04:55:32 CET 2010, updated=Sat Mar 24 17:16:29 CET 2012, resolved=Sat Apr 09 21:21:59 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=SimplexSolver returns unfeasible solution, link=https://issues.apache.org/jira/browse/MATH-434, description=&lt;p&gt;The SimplexSolver is returning an unfeasible solution:&lt;/p&gt;

&lt;p&gt;import java.util.ArrayList;&lt;br/&gt;
import java.text.DecimalFormat;&lt;br/&gt;
import org.apache.commons.math.linear.ArrayRealVector;&lt;br/&gt;
import org.apache.commons.math.optimization.GoalType;&lt;br/&gt;
import org.apache.commons.math.optimization.OptimizationException;&lt;br/&gt;
import org.apache.commons.math.optimization.linear.*;&lt;/p&gt;

&lt;p&gt;public class SimplexSolverBug {&lt;/p&gt;

&lt;p&gt;    public static void main(String[] args) throws OptimizationException {&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction c = new LinearObjectiveFunction(new double[]{0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d}, 0.0d);&lt;/p&gt;

&lt;p&gt;        ArrayList&amp;lt;LinearConstraint&amp;gt; cnsts = new ArrayList&amp;lt;LinearConstraint&amp;gt;(5);&lt;br/&gt;
        LinearConstraint cnst;&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, -0.1d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.EQ, -0.1d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, -1e-18d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 1.0d, 0.0d, -0.0128588d, 1e-5d}, Relationship.EQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 0.0d, 1.0d, 1e-5d, -0.0128586d}, Relationship.EQ, 1e-10d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, -1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, -1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, 1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;/p&gt;

&lt;p&gt;        DecimalFormat df = new java.text.DecimalFormat("0.#####E0");&lt;/p&gt;

&lt;p&gt;        System.out.println("Constraints:");&lt;br/&gt;
        for(LinearConstraint con : cnsts) {
            for (int i = 0; i &amp;lt; con.getCoefficients().getDimension(); ++i)
                System.out.print(df.format(con.getCoefficients().getData()[i]) + " ");
            System.out.println(con.getRelationship() + " " + con.getValue());
        }&lt;/p&gt;

&lt;p&gt;        SimplexSolver simplex = new SimplexSolver(1e-7);&lt;br/&gt;
        double[] sol = simplex.optimize(c, cnsts, GoalType.MINIMIZE, false).getPointRef();&lt;br/&gt;
        System.out.println("Solution:\n" + new ArrayRealVector(sol));&lt;br/&gt;
        System.out.println("Second constraint is violated!");&lt;br/&gt;
    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;It's an odd problem, but something I ran across.  I tracked the problem to the getPivotRow routine in SimplexSolver.  It was choosing a pivot that resulted in a negative right-hand-side.  I recommend a fix by replacing&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
                ...&lt;br/&gt;
with&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;br/&gt;
                ...&lt;/p&gt;

&lt;p&gt;I believe this would be more appropriate (and at least resolves this particular problem).&lt;/p&gt;

&lt;p&gt;Also, you may want to consider making a change in getPivotColumn to replace&lt;br/&gt;
            ...&lt;br/&gt;
            if (MathUtils.compareTo(tableau.getEntry(0, i), minValue, epsilon) &amp;lt; 0) {&lt;br/&gt;
            ...&lt;br/&gt;
with&lt;br/&gt;
            ...&lt;br/&gt;
            if (tableau.getEntry(0, i) &amp;lt; minValue) &lt;br/&gt;
            ...&lt;br/&gt;
because I don't see the point of biasing earlier columns when multiple entries are within epsilon of each other.  Why not pick the absolute smallest.  I don't know that any problem can result from doing it the other way, but the latter may be a safer bet.&lt;/p&gt;

&lt;p&gt;VERY IMPORTANT: I discovered another bug that occurs when not restricting to non-negatives.  In SimplexTableu::getSolution(), &lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) &lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = 0;&lt;br/&gt;
          ...&lt;br/&gt;
should be&lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) {&lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = (restrictToNonNegative ? 0 : -mostNegative);&lt;br/&gt;
          ...&lt;br/&gt;
If necessary, I can give an example of where this bug causes a problem, but it should be fairly obvious why this was wrong.&lt;/p&gt;, comments=[&lt;p&gt;My original suggested fix had a potential for overflow errors (since minRatio is initialized to Double.MAX_VALUE).  Also, I added another suggestion and pointed out another bug which leads to invalid solutions.&lt;/p&gt;
, &lt;p&gt;Could you attach unit tests that demonstrate each problem?  Thank you.&lt;/p&gt;
, &lt;p&gt;I'll try to send some examples soon.  I'm noticing more problems with the right-hand-side going negative and want to cover all bases (as much as possible).&lt;/p&gt;
, &lt;p&gt;Code, and resulting output, that illustrates issues with the SimplexSolver.&lt;/p&gt;
, &lt;p&gt;Pushing out to 3.0.&lt;/p&gt;
, &lt;p&gt;Hey, sorry I took so long to look at this.  I've had very little time and am not working on this stuff anymore.  I'm honestly not going to be able to look at this stuff much moving forward, so hopefully there's a Commons Math contributor that can act as a reviewer.&lt;/p&gt;

&lt;p&gt;When you say it's choosing a pivot with a negative RHS, I'm assuming that means it's not within the epsilon?&lt;br/&gt;
Why would it be more appropriate to divide by the entry?  I'm not sure I see why you'd want to use a bigger epsilon when the entry is 0.1 and a smaller epsilon when the entry is 10.  Maybe we should just make the default epsilon smaller?  I'm no expert with floating point math so I'm not real sure how to set the epsilon and just made up a value.&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
...&lt;br/&gt;
with&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;/p&gt;
, &lt;p&gt;Attached a patch for the reported problems.&lt;br/&gt;
The problems can be split into two groups:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;wrong solution calculation with negative&lt;br/&gt;
   variables&lt;/li&gt;
	&lt;li&gt;failing to select an appropriate pivot&lt;br/&gt;
   row when values are below a given &lt;br/&gt;
   epsilon&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch addresses both problems:&lt;/p&gt;

&lt;p&gt; 1. fix in SimplexTableau.getSolution()&lt;br/&gt;
 2. use BigReal for arbitrary precision  &lt;br/&gt;
    support when selecting the pivot row&lt;/p&gt;

&lt;p&gt;Additionally, 4 test cases are included, as well as a minor typo fix for a method name.&lt;/p&gt;

&lt;p&gt;The fixed epsilon is also used in some other places of the code, this may also create problems under certain circumstances. So if this patch is accepted, the other places could also be adapted.&lt;/p&gt;
, &lt;p&gt;Thanks Thomas.&lt;/p&gt;

&lt;p&gt;I had a look at the patch. I'm not a big fan of using BigReal, mainly when we don't specify a scale and we don't link it to the choice for epsilon. Also reading back Ben comments, I wonder if we should not replace epsilon by an integer number of ulps with a default set to a very small value (say something like 10 ulps).&lt;/p&gt;

&lt;p&gt;What problem did you see in the accuracy of the variables to use BigReal ?&lt;/p&gt;
, &lt;p&gt;Hi Luc,&lt;/p&gt;

&lt;p&gt;my initial idea was to use an epsilon that is adjusted to the magnitude of the respective value used for comparison. To be honest, I was not aware of &lt;span class="error"&gt;&amp;#91;Math,FastMath&amp;#93;&lt;/span&gt;.ulp, therefore I went with BigReal/BigDecimal to circumvent the problem in another way (by using an arbitrary precision datatype). After reading your comment, I investigated more into the problem, e.g. using &lt;a href="http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm"&gt;http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm&lt;/a&gt;, and addressed it (hopefully correct) in the way you proposed.&lt;/p&gt;

&lt;p&gt;Though, I had to split up the epsilon test into two categories:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;general comparison of floating-point values: using ulp, as values can be arbitrarily small&lt;/li&gt;
	&lt;li&gt;algorithm convergence check: using a standard epsilon, as the algorithm may not converge due to limited precision of&lt;br/&gt;
    the double datatype otherwise&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Please find attached my updated patch, any comments are welcome (e.g. I was unsure whether to expose the maxUlps parameter in the constructor, or to use a generic comparison epsilon, e.g. using FastMath.ulp(1d) instead of one adjusted to the current value in question).&lt;/p&gt;
, &lt;p&gt;updated patch, incorporating comments from luc&lt;/p&gt;
, &lt;p&gt;&lt;span class="error"&gt;&amp;#91;Pardon the possibly nave questions.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In "SimplexTableau":&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Why not use directly "equals(double, double, int)" from "MathUtils" instead of computing an epsilon with "getEpsilon"?&lt;/li&gt;
	&lt;li&gt;Why is the "isOptimal" method not using the adjusted "epsilon" (at line 385)?&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;hmm, I feel a bit stupid now, as I have re-implemented MathUtils.equals(double, double, int) but in a mediocre way. So all calls to getEpsilon should be replaced with the equivalent MathUtils.equals.&lt;/p&gt;

&lt;p&gt;for the isOptimal:&lt;/p&gt;

&lt;p&gt;the idea was to have a user-defined threshold for the convergence criteria, which defaults to the original value of 1e-6. Using the same adjusted epsilon would possibly lead to more iterations as before. As the feasibility check in SimplexSolver.solvePhase1 has to use a static epsilon for convergence reasons, I thought to use the same epsilon in isOptimal makes sense for symmetry reasons (use the same epsilon to check for convergence /feasibility).&lt;/p&gt;

&lt;p&gt;But it's good that you raise these points, because I was hesitating myself what is the best way to go forward, as I am also not considering myself a floating-point expert. I am mainly interested in the simplex algorithm, that's why I have chosen to provide a patch for this (very nice) implementation of it.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1090656.&lt;br/&gt;
Path applied with a very small change: adding the maxUlps parameter to the detailed constructor.&lt;/p&gt;

&lt;p&gt;Thanks for the report and thanks for the patch.&lt;/p&gt;
, &lt;p&gt;Thanks for accepting the patch. The comparison using maxUlps has already been adapted according to &lt;a href="https://issues.apache.org/jira/browse/MATH-557" title="add a compareTo method to MathUtils that use a number of ulps for equality tolerance"&gt;&lt;del&gt;MATH-557&lt;/del&gt;&lt;/a&gt;, but it was missing for SimplexTableau. The cleanup patch fixes this and also renames the test names for similarity.&lt;/p&gt;
, &lt;p&gt;Cleanup patch applied.&lt;/p&gt;

&lt;p&gt;thanks again&lt;/p&gt;
], resolution=Fixed, reporter=wmwitzel, assignees=[], commentAuthors=[wmwitzel, erans, psteitz, bmccann, tn, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-429
2016-01-13 22:04:31,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-429, created=Fri Oct 22 10:01:54 CEST 2010, updated=Wed Mar 23 21:25:46 CET 2011, resolved=Sat Oct 23 21:35:26 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Blocker, summary=KMeansPlusPlusClusterer breaks by division by zero, link=https://issues.apache.org/jira/browse/MATH-429, description=&lt;p&gt;For a certain space, KMeansPlusPlusClusterer  breaks. This is a blocker because this space occurs in our domain. &lt;/p&gt;, comments=[&lt;p&gt;The testcase which breaks KMeansPlusPlusClusterer&lt;/p&gt;
, &lt;p&gt;You have encountered one classical problem with k-means: at some stage (here at the first iteration), one of the clusters becomes empty.&lt;br/&gt;
This case is currently no handled by commons-math (which is a bug, so we have to fix it).&lt;br/&gt;
When a cluster is empty, a new centroid must be defined from the other clusters. There are different strategies:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;take the point farthest from any cluster&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest distance variance&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest number of points&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;My prefered choice would be 2, what do other people think ?&lt;/p&gt;
, &lt;p&gt;How about make it configurable?  Take a look at how the Mallet project did it:&lt;/p&gt;

&lt;p&gt;&lt;a href="http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html"&gt;http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By the way, I have suggested that they try to enter the Incubator here at the ASF and they seem somewhat receptive to the idea!&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1026666 for branche 2.X and as of r1026667 for trunk.&lt;br/&gt;
Users can now choose among four different strategies to deal with empty clusters:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;split the cluster with largest distance variance,&lt;/li&gt;
	&lt;li&gt;split the cluster with largest number of points,&lt;/li&gt;
	&lt;li&gt;create a cluster around the point farthest from its centroid,&lt;/li&gt;
	&lt;li&gt;generate an error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The default is to split according to largest variance.&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erikvaningen, assignees=[], commentAuthors=[erikvaningen, luc, jwcarman], timeEstimate=180, timeSpent=null]
2016-01-13 22:04:32,324 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-421
2016-01-13 22:04:32,340 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-421, created=Wed Sep 29 20:24:56 CEST 2010, updated=Wed Mar 23 21:23:12 CET 2011, resolved=Wed Sep 29 21:51:49 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=restarting an ODE solver that has been stopped by an event doesn't work, link=https://issues.apache.org/jira/browse/MATH-421, description=&lt;p&gt;If an ODE solver is setup with an EventHandler that return STOP when the even is triggered, the integrators stops (which is exactly the expected behavior).&lt;br/&gt;
If however the user want to restart the solver from the final state reached at the event with the same configuration (expecting the event to be triggered again at a later time), then the integrator may fail to start. It can get stuck at the previous event.&lt;/p&gt;

&lt;p&gt;The occurrence of the bug depends on the residual sign of the g function which is not exactly 0, it depends on the convergence of the first event.&lt;/p&gt;

&lt;p&gt;As this use case is fairly general, event occurring less than epsilon after the solver start in the first step should be ignored, where epsilon is the convergence threshold of the event. The sign of the g function should be evaluated after this initial ignore zone, not exactly at beginning (if there are no event at the very beginning g(t0) and g(t0+epsilon) have the same sign, so this does not hurt ; if there is an event at the very beginning, g(t0) and g(t0+epsilon) have opposite signs and we want to start with the second one. Of course, the sign of epsilon depend on the integration direction (forward or backward).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository, as of r1002827 for branch 2.X and 1002829 for trunk (3.0)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,340 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-414
2016-01-13 22:04:32,340 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-414, created=Tue Aug 31 13:01:44 CEST 2010, updated=Wed Mar 23 21:20:43 CET 2011, resolved=Tue Nov 30 12:57:23 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=ConvergenceException in NormalDistributionImpl.cumulativeProbability(), link=https://issues.apache.org/jira/browse/MATH-414, description=&lt;p&gt;I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.&lt;br/&gt;
For instance in the following code:&lt;/p&gt;

&lt;p&gt;	@Test&lt;br/&gt;
	public void testCumulative() {&lt;br/&gt;
		final NormalDistribution nd = new NormalDistributionImpl();&lt;br/&gt;
		for (int i = 0; i &amp;lt; 500; i++) {&lt;br/&gt;
			final double val = Math.exp&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/information.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt;;&lt;br/&gt;
			try {
				System.out.println("val = " + val + " cumulative = " + nd.cumulativeProbability(val));
			} catch (MathException e) {
				e.printStackTrace();
				fail();
			}&lt;br/&gt;
		}&lt;br/&gt;
	}&lt;/p&gt;

&lt;p&gt;In version 2.0, I get no exception. &lt;/p&gt;

&lt;p&gt;My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.&lt;/p&gt;, comments=[&lt;p&gt;The difference between 2.0 and 2.1 is due to the changes in ContinuedFraction included in the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-282" title="ChiSquaredDistributionImpl.cumulativeProbability &amp;gt; 1"&gt;&lt;del&gt;MATH-282&lt;/del&gt;&lt;/a&gt;.  For very large values, continued fractions are diverging to NaN. The suggested fix will work, but at this point, I wonder if we should just move the top-coding out of the catch - i.e., test the arguments and return 0 or 1 for extreme values without attempting the approximation.&lt;/p&gt;
, &lt;p&gt;I am leaning toward adding top-coding outside of the catch.  Based on the inequality p(Z &amp;gt; t) &amp;lt; exp(-t^2/2) derived in &lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; and Double.MIN_VALUE  = 2^-1074, I get that tail probabilities are not distinguishable from 0 for |t| &amp;gt; 39, so I propose that we top-code at 40 outside the catch.  Appreciate others checking my arithmetic.&lt;/p&gt;

&lt;p&gt;&lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href="http://www.johndcook.com/normalbounds.pdf"&gt;http://www.johndcook.com/normalbounds.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Your suggestion seems good to me.&lt;br/&gt;
I've check exp(-t^2/2) becomes lower than Double.MIN_VALUE/2 (i.e. rounds to 0) when |t|&amp;gt; 38.604&lt;/p&gt;
, &lt;p&gt;Fixed in r1040471&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=gustav.ryd, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=120, timeSpent=null]
2016-01-13 22:04:32,340 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-411
2016-01-13 22:04:32,340 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-411, created=Sun Aug 29 00:14:32 CEST 2010, updated=Wed Mar 23 21:20:06 CET 2011, resolved=Mon Sep 13 04:04:01 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression newSampleData methods inconsistently create / omit intercepts, link=https://issues.apache.org/jira/browse/MATH-411, description=&lt;p&gt;The newSampleData(double[], nrows, ncols) method used in the unit tests adds a unitary column to the design matrix, resulting in an intercept term being estimated among the regression parameters.  The other newSampleData methods do not do this, forcing users to add the column of "1"s to estimate models with intercept.  Behavior should be consistent and users should not have to add the column.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r993574.  Modified multiple regression newSample methods to ensure that by default in all cases, regression models are estimated with intercept terms.  Prior to the fix for this issue,  newXSampleData(double[][]), newSampleData(double[], double[][]) and newSampleData(double[], double[][], double[][]) all required columns of "1's  to be inserted into the x[][] arrays to create a model with an intercept term;while newSampleData(double[], int, int) created a model including an intercept term without requiring the unitary column.  All methods have  been changed to eliminate the need for users to add unitary columns to specify regression models.&lt;/p&gt;

&lt;p&gt;Leaving open until &lt;a href="https://issues.apache.org/jira/browse/MATH-409" title="Multiple Regression API should allow specification of whether or not to estimate intercept term"&gt;&lt;del&gt;MATH-409&lt;/del&gt;&lt;/a&gt; is resolved. &lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,340 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-409
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-409, created=Tue Aug 24 11:55:32 CEST 2010, updated=Wed Mar 23 21:19:13 CET 2011, resolved=Mon Sep 13 04:02:43 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression API should allow specification of whether or not to estimate intercept term, link=https://issues.apache.org/jira/browse/MATH-409, description=&lt;p&gt;The OLS and GLS regression APIs should support estimating models including intercepts using design matrices including only variable data.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r996404 (both trunk and 2.x branch)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-408
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-408, created=Mon Aug 23 05:11:23 CEST 2010, updated=Wed Mar 23 21:18:48 CET 2011, resolved=Sun Dec 12 22:49:44 CET 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=GLSMultipleLinearRegression has no nontrivial validation tests, link=https://issues.apache.org/jira/browse/MATH-408, description=&lt;p&gt;There are no non-trivial tests verifying the computations for GLSMultipleLinearRegression.  Tests verifying computations against analytically determined models, R or some other reference package / datasets should be added to ensure that the statistics reported by this class are valid.&lt;/p&gt;, comments=[&lt;p&gt;Added a non-trivial test in r1044935.  While still not really a full verification test, it does at least verify that the GLS impl provided does better than OLS for models with error structure conforming to its covariance matrix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-407
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-407, created=Mon Aug 23 05:07:08 CEST 2010, updated=Wed Mar 23 21:18:29 CET 2011, resolved=Mon Sep 20 03:57:59 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Documentation improvements for multiple regression classes, link=https://issues.apache.org/jira/browse/MATH-407, description=&lt;p&gt;The user guide examples showing how to set up and estimate linear models using OLS and GLS multiple regression need to be updated to reflect changes in the API.  The javadoc for these classes and user guide descriptions also need to be improved to make it clear how to estimate a model with an intercept term.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r998761&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-406
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-406, created=Sat Aug 14 23:57:56 CEST 2010, updated=Wed Mar 23 21:18:04 CET 2011, resolved=Sun Aug 15 00:02:03 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Wrong weight handling in Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-406, description=&lt;p&gt;A comparison with a Fortran version of Levenberg-Marquardt reveals that when observations have different weights, the 2.1 version reaches a value of the function which does not necessary correspond to the minimum&lt;/p&gt;, comments=[&lt;p&gt;Correction patch.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-405
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-405, created=Wed Aug 11 15:24:39 CEST 2010, updated=Wed Mar 23 21:17:42 CET 2011, resolved=Wed Aug 11 15:46:55 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Inconsistent result from Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-405, description=&lt;p&gt;Levenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost&lt;/p&gt;, comments=[&lt;p&gt;Correction patch&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,355 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-404
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-404, created=Mon Aug 09 13:44:12 CEST 2010, updated=Sat Mar 24 17:17:04 CET 2012, resolved=Mon Aug 30 15:53:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Confusing interface for "LevenbergMarquardtOptimizer", link=https://issues.apache.org/jira/browse/MATH-404, description=&lt;p&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; which in turn implements &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt;. That interface mandates methods for setting and getting a &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;.&lt;br/&gt;
In v2.1, however, that checker is never used! The convergence check is performed using parameters specific to the Levenberg-Marquardt algorithm. Such circumvention of the superclass interface is confusing and leads to totally unexpected behaviour (such as changing the values of the thresholds of the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; being ineffective).&lt;br/&gt;
In the development version, the default constructor of &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; sets the the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; field to "null" and when such is the case, the behaviour is as in v2.1. Although it is documented, this is still confusing since it is impossible to use &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; through its &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt; interface: When using the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;, one does not know what parameters to use in order to reproduce the results obtained with the LM-specific convergence check (i.e. how to reproduce the result from v2.1).&lt;br/&gt;
Unless I'm missing something, I think that there should be an LM-specific implementation of &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; that, when given the usual relative and absolute thresholds, can perform a check that will give the same result as the currently specific check (when the "checker" field is "null").&lt;/p&gt;, comments=[&lt;p&gt;The problem was identified and discussed as &lt;a href="https://issues.apache.org/jira/browse/MATH-362" title="LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it"&gt;&lt;del&gt;MATH-362&lt;/del&gt;&lt;/a&gt;. It was decided to let both convergence methods available.&lt;/p&gt;

&lt;p&gt;The reason there are two different way is that the Levenberg-Marquardt implementation originally came from Netlib and I kept the way it behaved. I think the general interface with the new generic convergence was set up later and at that time I forgot to implement it properly, so the settings were ignored.&lt;/p&gt;

&lt;p&gt;Reporter of issue 362 explicitly asked to keep the ortho-tolerance setting and this setting does not fit with the general scheme.&lt;/p&gt;
, &lt;p&gt;Sorry I hadn't followed that other report.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was decided to let both convergence methods available. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is &lt;tt&gt;null&lt;/tt&gt; or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;

&lt;p&gt;As explained above, from an OOP point-of-view, it is surprising that a class completely circumvents its base class interface.&lt;br/&gt;
At least one of the following is wrong:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; has a second interface for convergence checking&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; defines the interface for  convergence checking&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; does not fit with the general scheme.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;br/&gt;
Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;

&lt;p&gt;If it is really impossible to fit LM within the hierarchy it currently belongs to, then it should not belong to it, since one cannot leverage the advantages of "interface programming" anyways.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is null or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or LevenbergMarquardtOptimizer needs to be changed and the orthogonality concept be finally discarded.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I know, and I am not happy with this. However, I don't want LevenbergMarquardtOptimizer to be special. It &lt;em&gt;must&lt;/em&gt; fit. We can take the opportunity of a 3.0 major release to fix this problem too, with some incompatible changes. What would you propose for this ?&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;What would you propose for this ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don't know.&lt;/p&gt;

&lt;p&gt;However, it seems that this "non-fitting checker" case is not isolated. I wanted to replace the original check in "BrentOptimizer" (package "optimization.univariate") by a call to an appropriate subclass of "RealConvergenceChecker", but here too there are more values to be considered than those stored in a pair of "RealPointValuePair". The check needs&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the "current" point&lt;/li&gt;
	&lt;li&gt;the points at both interval ends&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;but it does not use the "previous" point.&lt;/p&gt;

&lt;p&gt;So it seems that this also does not fit with the "converged" method of the "RealConvergenceChecker" interface.&lt;/p&gt;

&lt;p&gt;At first sight, I'd say that there should be a more general "ConvergenceChecker" (not existing yet) interface. Maybe using generics...&lt;/p&gt;
, &lt;p&gt;I'm trying to define a more general "ConvergenceChecker" interface. This is an incompatible change.&lt;/p&gt;
, &lt;p&gt;Final resolution is delegated to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-413"&gt;MATH-413&lt;/a&gt;.&lt;/p&gt;
], resolution=Unknown, reporter=erans, assignees=[erans], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-395
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-395, created=Sun Jul 25 23:26:33 CEST 2010, updated=Wed Mar 23 21:14:58 CET 2011, resolved=Wed Jul 28 14:11:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Bugs in "BrentOptimizer", link=https://issues.apache.org/jira/browse/MATH-395, description=&lt;p&gt;I apologize for having provided a buggy implementation of Brent's optimization algorithm (class "BrentOptimizer" in package "optimization.univariate").&lt;br/&gt;
The unit tests didn't show that there was something wrong, although (from the "changes.xml" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.&lt;br/&gt;
Comparing with an implementation in Python, I could figure out the fixes. I'll modify "BrentOptimizer" and add a test. I also propose to change the name of the unit test class from "BrentMinimizerTest" to "BrentOptimizerTest".&lt;/p&gt;, comments=[&lt;p&gt;Bugs corrected in revision 979257.&lt;br/&gt;
Not resolving yet because the implementation still does not behave as the Python one. I've added a unit test that indicates the discrepancies (with "XXX" markers).&lt;/p&gt;
, &lt;p&gt;Last bug fixed in revision 980032.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;This revision also contains the modifications due to the changes in &amp;quot;AbstractUnivariateRealOptimizer&amp;quot;.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The test comparing with Python has been removed because a tracing of the execution paths (in Python and Java) showed that the remaining discrepancies were due to different values being used for the "golden ratio" constant.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[erans], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-392
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-392, created=Wed Jul 21 20:43:10 CEST 2010, updated=Wed Mar 23 21:13:58 CET 2011, resolved=Sun Aug 22 15:16:29 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=calculateYVariance in OLS/GLSMultipleLinearRegression uses residuals not Y vars, link=https://issues.apache.org/jira/browse/MATH-392, description=&lt;p&gt;Implementation of OLS/GLSMultipleLinearRegression is:&lt;br/&gt;
@Override&lt;br/&gt;
173        protected double calculateYVariance() {
174            RealVector residuals = calculateResiduals();
175            return residuals.dotProduct(residuals) /
176                   (X.getRowDimension() - X.getColumnDimension());
177        }&lt;/p&gt;

&lt;p&gt;This gives variance of residuals not variance of the dependent (Y) variable as the documentation suggests.&lt;/p&gt;, comments=[&lt;p&gt;Thank you for reporting this.  Patches welcome!&lt;/p&gt;
, &lt;p&gt;Can't test a patch as I'm not able to build current repository version:&lt;br/&gt;
math/src/test/java/org/apache/commons/math/optimization/univariate/BrentOptimizerTest.java:&lt;span class="error"&gt;&amp;#91;28,39&amp;#93;&lt;/span&gt; cannot find symbol&lt;br/&gt;
symbol  : class SincFunction&lt;/p&gt;

&lt;p&gt;Implementation for both GLS/OLS:&lt;/p&gt;

&lt;p&gt;protected double calculateYVariance() {
    return new Variance().evaluate(Y);
}&lt;/p&gt;
, &lt;p&gt;There was an error in a file committed this afternoon. It should be OK now.&lt;/p&gt;
, &lt;p&gt;corrected implementations of calculateYVariance() for OLS/GLSMultipleRegression&lt;/p&gt;

&lt;p&gt;added unit tests for both calculateYVariance implementations&lt;/p&gt;

&lt;p&gt;fixed AbstractMultipleRegression.estimateRegressionParametersStandardErrors() to use residuals &lt;/p&gt;
, &lt;p&gt;Fixed in 987897.   I added calcluate/estimateErrorVariance methods to return what was previously incorrectly reported as "Y variance."&lt;br/&gt;
Thanks for the patch!&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=markdevaney, assignees=[], commentAuthors=[psteitz, markdevaney, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-391
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-391, created=Wed Jul 21 10:57:46 CEST 2010, updated=Wed Mar 23 21:13:27 CET 2011, resolved=Sun Oct 03 18:43:11 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Inconsistent behaviour of constructors in ArrayRealVector class, link=https://issues.apache.org/jira/browse/MATH-391, description=&lt;p&gt;ArrayRealVector(double[] d) allows to construct a zero-length vector, but ArrayRealVector(double[] d, boolean copyArray) doesn't. Both should allow this as zero-length vectors are mathematically well-defined objects and they are useful boundary cases in many algorithms.&lt;/p&gt;

&lt;p&gt;This breaks some arithmetic operators (addition) on zero-length real vectors which worked in 2.0 but don't work in 2.1&lt;/p&gt;, comments=[&lt;p&gt;I agree that the code should be consistent.  I agree as well that a zero-dimensional vector is legit.   Can anyone explain why ArrayRealVector(double[] d, boolean copyArray) requires positive length?&lt;/p&gt;
, &lt;p&gt;Most probably my bad ...&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1003993 for barnch 2.X and r1003994 for trunk.&lt;br/&gt;
Note that the same problem occurred also in ArrayFieldVector but the fix is different. For Field-based vectors, we need to get the field, so either we use a non-empty array and retrieve the field from the first array element or we add a parameter for the field and allow the array to be empty. The two choices are now possible, as new constructors have been added and the javadoc updated to explain this behavior.&lt;br/&gt;
Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-390
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-390, created=Wed Jul 21 00:47:21 CEST 2010, updated=Wed Jul 21 01:32:12 CEST 2010, resolved=Wed Jul 21 01:32:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Major, summary=Simplex Solver is very inaccurate on a large problem, even a very low value for epsilon, link=https://issues.apache.org/jira/browse/MATH-390, description=&lt;p&gt;I'm currently playing with a program for solving a rather simple chess puzzle. The goal is to place 12 knights on a 8x8 board, such that each field is either attacked by a knight, or contains a knight. To solve this problem (and different variants) I want to use a handcrafted Branch and Bound algorithm that uses Linear Programming to calculate an upperbound on the number of fields that can be covered by a certain amount of knights.&lt;/p&gt;

&lt;p&gt;The idea is to create variables for each field that has to be covered, and to create variables for each field to contain a knight. A cover variable can only become positive if a corresponding knight variable for an adjacent field is also positive, there is a limit to the amount of knights we may place (so the sum of all knight variables cannot be larger than 12) and the cover variables cannot be larger than one. Also, only the cover variables have a coefficient of one in the objective function, all other variables have zero. Because we want to cover the entire board our goal will be to maximize the objective function, since we want to maximize the number of fields that are covered.&lt;/p&gt;

&lt;p&gt;Since a basic chessboard has 64 fields and since it is possible to cover the chessboard with 12 knights, we know there is an integer solution that has value 64. Since we are solving a relaxed variant of the problem, the value should be at least 64. However, when I use the Simplex Solver, I get a value of around 58.6, which is much too low. Even when I relax the constraints in such a fashion that 64 knights may be placed on the board, the solution value remains the same. I've lowered the value of epsilon as much as I can and it still gives the incorrect value. What makes it worse is that the calculation is totally useless as an upperbound (if the value would have been around 70, it would have been an upperbound at least).&lt;/p&gt;

&lt;p&gt;I've heard that using the revised simplex method is a lot better with respect to stacked errors, so I am not sure this is really a bug, or just a problem that arises when the two phase simplex method is used for large problems.&lt;/p&gt;

&lt;p&gt;I will try to attach a code example that implements the problem (but possibly isn't that readable).&lt;/p&gt;, comments=[&lt;p&gt;Example of the 8x8 Knight covering Chess problem. The objective value should at least be 64, but it is around 59.&lt;/p&gt;
, &lt;p&gt;Hmm, it seems I made a programming mistake in the type of the relationship: I used an equality where I should have used a greater-equals. I created a much nicer version of the example, which actually works. Feel free to use it for an example or something.&lt;/p&gt;

&lt;p&gt;My bad, I will close the issue.&lt;/p&gt;
, &lt;p&gt;The correct and more readable example, which actually works.&lt;/p&gt;
, &lt;p&gt;It seems I made a programming error. I included a correct example to solve the problem.&lt;/p&gt;
], resolution=Fixed, reporter=pcbouman, assignees=[], commentAuthors=[pcbouman], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-380
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-380, created=Thu Jun 24 18:47:54 CEST 2010, updated=Sat Mar 24 17:16:33 CET 2012, resolved=Sat Oct 01 15:54:20 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Minor, summary=Need to (re)initialize dYdY0 for multiple integrate with FirstOrderIntegratorWithJacobians, link=https://issues.apache.org/jira/browse/MATH-380, description=&lt;p&gt;There is a lack in the method integrate of FirstOrderIntegratorWithJacobians. The jacobian DYDY0 can't be initialized by the user, unlike DFDP with DF0DP.&lt;br/&gt;
So, for several successive integrations, the matrix is reinitialized to identity and that is not what we might want.&lt;/p&gt;, comments=[&lt;p&gt;You are perfectly right.&lt;/p&gt;

&lt;p&gt;The FirstOrderIntegratorWithJacobians class is a brand new one and it clearly has some design flaws.&lt;br/&gt;
It will most probably be deprecated in its current form and replaced by a new mechanism, better integrated (sorry for the joke) with the standard ODE solvers.&lt;br/&gt;
The ability for user to set an initial value for dydy0 will be present in the new design, but will probably not be back-ported to the current one.&lt;br/&gt;
In the meantime, you can save the final value of the jacobian matrix dydy0 after first part of integration, which we could call dy1dy0 as it represents dy(t1)/dy(t0). Start the second part from t1 to t2 that will reset the initial matrix to identity and hence compute compute dy(t2)/dy(t1) and do the multiplication by yourself of the two matrices to really get what you need: dy(t2)/dy(t1) = dy(t2)/dy(t1) * dy(t1)/dy(t0).&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue &lt;/p&gt;
, &lt;p&gt;changing target fix version to 3.0.&lt;br/&gt;
Fixing this and several other problems requires a complete rewrite of the jacobians computation with ODE, and this rewrite implies user interfaces changes, so it cannot be fixed before 3.0.&lt;/p&gt;
, &lt;p&gt;A first attempt to implement Jacobians computation again in ODE has been committed in subversion repository as of r1175409.&lt;br/&gt;
This implementation still lacks the ability for step handlers to also retrieve the additional equations and their derivatives.&lt;br/&gt;
This implementation is based on the Orekit one described here: &lt;a href="https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf"&gt;https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1176745.&lt;/p&gt;
], resolution=Fixed, reporter=pparraud, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-377
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-377, created=Thu Jun 17 11:06:03 CEST 2010, updated=Wed Mar 23 21:08:36 CET 2011, resolved=Sun Jul 25 21:49:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=weight versus sigma in AbstractLeastSquares, link=https://issues.apache.org/jira/browse/MATH-377, description=&lt;p&gt;In AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.&lt;/p&gt;

&lt;p&gt; Once corrected, getRMS() can even reduce&lt;/p&gt;

&lt;p&gt; public double getRMS() {return Math.sqrt(getChiSquare()/rows);}&lt;/p&gt;, comments=[&lt;p&gt;It is not clear to me exactly what is being computed in getChiSquare.  Step 0 is to get an actual definition in the javadoc for what it is trying to compute.  I agree it seems odd to be dividing by residual weights; but I could be missing the intent.&lt;/p&gt;
, &lt;p&gt;OK, let us define ChiSquare as the sum of the weighted square of the residual in order to be consistent with the rest of the definitions in that class.  That would also be consistent with what users expect from a parameter labeled 'weight' rather than 'sigma'.  If we reach consensus on that definition, I can take care of that issue.&lt;/p&gt;
, &lt;p&gt;I could be missing something, but I see no reason that the weighted sum of squared residuals computed here (after the proposed change) should in general follow a chi-square distribution or be related to a chi-square test statistic of any kind.   Why is it called chi-square?  Sorry if I am missing something simple here.&lt;/p&gt;
, &lt;p&gt;I guess if you assume normalliy distributed errors, it makes sense, so drop the last comment and I am +1 for the change (with definition added to the javadoc).&lt;/p&gt;
, &lt;p&gt;Indeed, the confusion comes from the fact that, in some textbooks, each residual is divided by 'sigma_i' which leads to a weight of 1/(sigma_i^2).  In CM, we adopted the terminology 'weight' without reference to sigma.  I will change the javadoc accordingly.&lt;/p&gt;
, &lt;p&gt;Patch to correct issue &lt;a href="https://issues.apache.org/jira/browse/MATH-377" title="weight versus sigma in AbstractLeastSquares"&gt;&lt;del&gt;MATH-377&lt;/del&gt;&lt;/a&gt;.  The change in getChiSquare let to a tiny update in one of Levenberg-Marquardt unit tests.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[psteitz, dimpbx, luc], timeEstimate=1, timeSpent=null]
2016-01-13 22:04:32,371 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-373
2016-01-13 22:04:32,386 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-373, created=Mon Jun 07 16:54:00 CEST 2010, updated=Sat Mar 24 17:16:56 CET 2012, resolved=Thu Sep 02 06:52:33 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=StatUtils.sum returns NaN for zero-length arrays, link=https://issues.apache.org/jira/browse/MATH-373, description=&lt;p&gt;StatUtils.sum returns NaN for zero-length arrays, which is:&lt;/p&gt;

&lt;p&gt;1. inconsistent with the mathematical notion of sum: in maths, sum_{i=0}^{N-1} a_i will be 0 for N=0. In particular, the identity&lt;br/&gt;
&lt;br/&gt;
sum_{i=0}^{k-1} a_i + sum_{i=k}^{N-1} = sum_{i=0}^{N-1}&lt;/p&gt;

&lt;p&gt;is broken for k = 0, since NaN + x = NaN, not x.&lt;/p&gt;

&lt;p&gt;2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition, as NaNs propagate silently and require manual tracing during the debugging)&lt;/p&gt;

&lt;p&gt;3. enforces "special case" handling when the user expects that the summed array can have a zero length.&lt;/p&gt;

&lt;p&gt;The correct behaviour is, in my opinion, to return 0.0, not NaN in the above case.&lt;/p&gt;, comments=[&lt;p&gt;I agree with the reasoning here, and we should do it this way in 3.0.  However it is an incompatible change to do in a point release, so I'm going to wait for more feed back from other developers before I make any changes to the current code.&lt;/p&gt;

&lt;p&gt;I'm thinking that adding a method to AbstractUnivariateStatistic that looks like:&lt;br/&gt;
   protected boolean test( final double[] values,  final int begin,   final int length, final boolean allowEmpty)&lt;/p&gt;

&lt;p&gt;that would have the test:&lt;br/&gt;
   if(length == 0 &amp;amp;&amp;amp; !allowEmpty)&lt;br/&gt;
        return false;&lt;/p&gt;

&lt;p&gt;The current test method can call the new one with allowEmpty=false for backwards compatibility.  Then we can decide on which statistics should have a zero value on the empty set.&lt;/p&gt;
, &lt;p&gt;The consensus of the commons-math developers is that, since the current behavior is documented in 2.x, that this will have to wait for 3.0.  Fixing this in 2.x would introduce a too large incompatibility change to include in 2.x.&lt;/p&gt;

&lt;p&gt;I can attach a patch against 2.x that fixes this, as long as anybody using the patch understands that it isn't supported.&lt;/p&gt;

, &lt;p&gt;Possibly crazy idea: &lt;/p&gt;

&lt;p&gt;if Math 3.0 is going to change package names (which may be necessary), one could introduce the fix using a math3 package name?&lt;/p&gt;
, &lt;p&gt;IIRC, changing the package name had been suggested and discussed for 2.0.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;One argument is that, to be consistent,  you&amp;#39;d have to change the name at every major release...&amp;#93;&lt;/span&gt;&lt;/p&gt;
, &lt;p&gt;Speaking as a maintainer of client code which uses ACM, I'd rather cope with occasional incompatibilities in the same packages, than have to change ALL my client code to keep up with the package name changes after every release. A reason to change the package name would be if you wanted to use the old and new version side by side, but that would not be a common usage pattern for ACM, I think.&lt;/p&gt;
, &lt;p&gt;As Gilles mentioned, changing the package name for commons-math was discussed and voted on for 2.x.  The result of the vote was to keep the package name, since commons-math won't usually be provided by a third party library.  Since nothing much has changed, I can't see that commons-math would change it's package for version 3.0.&lt;/p&gt;
, &lt;p&gt;This will be fixed in the 3.0 build.&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[billbarker, sebb@apache.org, erans, rwerp], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,386 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-369
2016-01-13 22:04:32,386 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-369, created=Mon May 03 17:48:27 CEST 2010, updated=Wed Mar 23 21:05:06 CET 2011, resolved=Mon May 03 20:43:59 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Minor, summary=BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException, link=https://issues.apache.org/jira/browse/MATH-369, description=&lt;p&gt;Method &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  &lt;/p&gt;

&lt;p&gt;invokes &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(double min, double max) &lt;/p&gt;

&lt;p&gt;which throws NullPointerException, as member variable&lt;/p&gt;

&lt;p&gt;    UnivariateRealSolverImpl.f &lt;/p&gt;

&lt;p&gt;is null.&lt;/p&gt;

&lt;p&gt;Instead the method:&lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)&lt;/p&gt;

&lt;p&gt;should be called.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;/p&gt;

&lt;p&gt;invoke:&lt;/p&gt;

&lt;p&gt;     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);&lt;/p&gt;

&lt;p&gt;NullPointerException will be thrown.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository as of r940565.&lt;br/&gt;
Thanks for the report and for the fix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sasunpundev@abv.bg, assignees=[], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,386 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-368
2016-01-13 22:04:32,386 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-368, created=Thu Apr 29 05:41:10 CEST 2010, updated=Wed Mar 23 21:04:17 CET 2011, resolved=Mon May 10 01:07:24 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=OpenMapRealVector.getSparcity should be getSparsity, link=https://issues.apache.org/jira/browse/MATH-368, description=&lt;p&gt;The term for describing the ratio of nonzero elements to zero elements in a matrix/vector is sparsity, not sparcity.  Suggest renaming getSparcity() to getSparsity()&lt;/p&gt;, comments=[&lt;p&gt;The policy of this project is to not remove methods from the public API in a point release.  However, the misspelled method has been deprecated and the correctly spelled method has been added.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,386 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-367
2016-01-13 22:04:32,386 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-367, created=Thu Apr 22 20:31:06 CEST 2010, updated=Wed Mar 23 21:03:42 CET 2011, resolved=Mon May 10 03:17:14 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=AbstractRealVector.sparseIterator fails when vector has exactly one non-zero entry, link=https://issues.apache.org/jira/browse/MATH-367, description=&lt;p&gt;The following program:&lt;br/&gt;
===&lt;br/&gt;
import java.util.Iterator;&lt;br/&gt;
import org.apache.commons.math.linear.*;&lt;/p&gt;

&lt;p&gt;public class SparseIteratorTester&lt;br/&gt;
{&lt;br/&gt;
    public static void main(String[] args) {&lt;br/&gt;
        double vdata[] = { 0.0, 1.0, 0.0 };&lt;br/&gt;
        RealVector v = new ArrayRealVector(vdata);&lt;br/&gt;
        Iterator&amp;lt;RealVector.Entry&amp;gt; iter = v.sparseIterator();&lt;br/&gt;
        while(iter.hasNext()) {
            RealVector.Entry entry = iter.next();
            System.out.printf("%d: %f\n", entry.getIndex(), entry.getValue());
        }   &lt;br/&gt;
    }       &lt;br/&gt;
} &lt;br/&gt;
===&lt;br/&gt;
generates this output:&lt;/p&gt;

&lt;p&gt;1: 1.000000&lt;br/&gt;
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: -1&lt;br/&gt;
	at org.apache.commons.math.linear.ArrayRealVector.getEntry(ArrayRealVector.java:995)&lt;br/&gt;
	at org.apache.commons.math.linear.AbstractRealVector$EntryImpl.getValue(AbstractRealVector.java:850)&lt;br/&gt;
	at test.SparseIteratorTester.main(SparseIteratorTester.java:13)&lt;br/&gt;
===&lt;/p&gt;

&lt;p&gt;This patch fixes it, and simplifies AbstractRealVector.SparseEntryIterator  (sorry, i don't see any form entry for attaching a file)&lt;br/&gt;
===&lt;br/&gt;
Index: src/main/java/org/apache/commons/math/linear/AbstractRealVector.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(revision 936985)&lt;br/&gt;
+++ src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(working copy)&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.commons.math.linear;&lt;/p&gt;

&lt;p&gt; import java.util.Iterator;&lt;br/&gt;
+import java.util.NoSuchElementException;&lt;/p&gt;

&lt;p&gt; import org.apache.commons.math.FunctionEvaluationException;&lt;br/&gt;
 import org.apache.commons.math.MathRuntimeException;&lt;br/&gt;
@@ -875,40 +876,25 @@&lt;br/&gt;
         /** Dimension of the vector. */&lt;br/&gt;
         private final int dim;&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Temporary entry (reused on each call to {@link #next()}. */&lt;/li&gt;
	&lt;li&gt;private EntryImpl tmp = new EntryImpl();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;/** Current entry. */&lt;br/&gt;
+        /** Last entry returned by #next(). */&lt;br/&gt;
         private EntryImpl current;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Next entry. */&lt;br/&gt;
+        /** Next entry for #next() to return. */&lt;br/&gt;
         private EntryImpl next;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** Simple constructor. */&lt;br/&gt;
         protected SparseEntryIterator() {&lt;br/&gt;
             dim = getDimension();&lt;br/&gt;
             current = new EntryImpl();&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (current.getValue() == 0) {
-                advance(current);
-            }&lt;/li&gt;
	&lt;li&gt;if(current.getIndex() &amp;gt;= 0){
-                // There is at least one non-zero entry
-                next = new EntryImpl();
-                next.setIndex(current.getIndex());
+            next = new EntryImpl();
+            if(next.getValue() == 0)
                 advance(next);
-            } else {
-                // The vector consists of only zero entries, so deny having a next
-                current = null;
-            }&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Advance an entry up to the next non null one.&lt;br/&gt;
+        /** Advance an entry up to the next nonzero value.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param e entry to advance&lt;br/&gt;
          */&lt;br/&gt;
         protected void advance(EntryImpl e) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (e == null) {
-                return;
-            }&lt;br/&gt;
             do {
                 e.setIndex(e.getIndex() + 1);
             } while (e.getIndex() &amp;lt; dim &amp;amp;&amp;amp; e.getValue() == 0);&lt;br/&gt;
@@ -919,22 +905,17 @@&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;br/&gt;
         public boolean hasNext() {
-            return current != null;
+            return next.getIndex() &amp;gt;= 0;
         }&lt;br/&gt;
 &lt;br/&gt;
         /** {@inheritDoc} */&lt;br/&gt;
         public Entry next() {&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;tmp.setIndex(current.getIndex());&lt;/li&gt;
	&lt;li&gt;if (next != null) {&lt;/li&gt;
	&lt;li&gt;current.setIndex(next.getIndex());&lt;/li&gt;
	&lt;li&gt;advance(next);&lt;/li&gt;
	&lt;li&gt;if (next.getIndex() &amp;lt; 0) {
-                    next = null;
-                }&lt;/li&gt;
	&lt;li&gt;} else {
-                current = null;
-            }&lt;/li&gt;
	&lt;li&gt;return tmp;&lt;br/&gt;
+            int index = next.getIndex();&lt;br/&gt;
+            if(index &amp;lt; 0)&lt;br/&gt;
+                throw new NoSuchElementException();&lt;br/&gt;
+            current.setIndex(index);&lt;br/&gt;
+            advance(next);&lt;br/&gt;
+            return current;&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;/p&gt;, comments=[&lt;p&gt;patch fixing the bug&lt;/p&gt;
, &lt;p&gt;I've applied your patch (with a couple of style tweaks).  It should be available in the next release of commons-math.&lt;/p&gt;

&lt;p&gt;Thank you for your contribution.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[ashuang, billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,386 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-365
2016-01-13 22:04:32,386 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-365, created=Tue Apr 20 16:21:20 CEST 2010, updated=Wed Mar 23 21:02:52 CET 2011, resolved=Wed Apr 21 16:35:53 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=Issue with "SmoothingBicubicSplineInterpolator", link=https://issues.apache.org/jira/browse/MATH-365, description=&lt;p&gt;I figured out that the name of this class is misleading as the implementation doesn't perform the intended smoothing.&lt;/p&gt;

&lt;p&gt;In order to solve this issue, I propose to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;deprecate the "SmoothingBicubicSplineInterpolator" class&lt;/li&gt;
	&lt;li&gt;create a "BicubicSplineInterpolator" class (similar to the above class but with the useless code removed)&lt;/li&gt;
	&lt;li&gt;remove the "SmoothingBicubicSplineInterpolatorTest" class&lt;/li&gt;
	&lt;li&gt;add a "BicubicSplineInterpolatorTest" with essentially the same contents as the above one&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Then I would also add a new "SmoothingPolynomialBicubicSplineInterpolator" where I used the "PolynomialFitter" class to smooth the input data along both dimensions before the interpolating function is computed.&lt;/p&gt;

&lt;p&gt;Does someone object to these changes?&lt;/p&gt;, comments=[&lt;p&gt;removing the test class would badly impact test coverage, so it would be better to simply deprecae it also and to remove the library class and its associated test class together when releasing 3.0&lt;/p&gt;
, &lt;p&gt;revision 936295.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,449 : INFO  : KNIME-Worker-0 : ITSOfflineNodeModel : Jira Adapter (Offline) : 2:2 : Transforming to jira entries.
2016-01-13 22:04:32,542 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-362
2016-01-13 22:04:32,542 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-362, created=Tue Apr 06 13:38:46 CEST 2010, updated=Wed Mar 23 21:02:00 CET 2011, resolved=Sat May 29 20:16:50 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it, link=https://issues.apache.org/jira/browse/MATH-362, description=&lt;p&gt;LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.&lt;/p&gt;, comments=[&lt;p&gt;Ooops. You are right.&lt;br/&gt;
The Levenberg-Marquardt optimizer uses specific convergence parameters which can be set by   setInitialStepBoundFactor, setCostRelativeTolerance, setParRelativeTolerance and setOrthoTolerance.&lt;br/&gt;
The most important convergence tuning are either setCostRelativeTolerance for a convergence on the cost itself or setParRelativeTolerance for a convergence on the parameters.&lt;/p&gt;

&lt;p&gt;I'm not sure how to solve this. Do the existing tuning parameters fit your needs or not ? Some convergence criteria can be expressed with both methods, but not all. Should we keep both setting as alternate methods or should we remove one and rely on the remaining one ?&lt;/p&gt;
, &lt;p&gt;I would keep using orthoTolerance as it is used now:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;292                if (maxCosine &amp;lt;= orthoTolerance) {&lt;br/&gt;
293                    // convergence has been reached&lt;br/&gt;
294                    return new VectorialPointValuePair(point, objective);&lt;br/&gt;
295                }&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;and then use costRelativeTolerance &amp;amp; parRelativeTolerance if and only if the convergence checker is null, otherwise use the convergence checker and ignore {costRelativeTolerance, parRelativeTolerance}.&lt;/p&gt;

&lt;p&gt;What I am missing now is the ability to bail out if the absolute distance from the target falls below some value ("close enough").&lt;/p&gt;
, &lt;p&gt;I've spent that last few days trying to find a good curve fitting library for Java and got excited when I learned of Commons Math.  Unfortunately, its curve fitting is very unreliable.  I'm hoping that this bug is what is causing the problems that I'm seeing.  I'm comparing data from NIST and results from DataFitX and it is apparent that Commons Math is not yet up to the task.  My fingers are crossed that its quality in the curve fitting area will be improved in the near future.  Keep up the good work Apache.&lt;/p&gt;

&lt;p&gt;I've opened an issue about the problems I'm seeing, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Double check how you use it, Matt. I have succesfully used this curve fitting in production.&lt;/p&gt;
, &lt;p&gt;Matt, could you please describe the problem you encounter more precisely (i.e. with numerical examples) and preferably in a new JIRA issue ? We will check if the two problems are related and link the issues afterwards if it appears they are.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
, &lt;p&gt;It's good to see such quick responses.  I'll open a new JIRA issue and spend some time putting together code, data and a detailed description of the problem I'm seeing.  Thanks Apache for all your hard work.&lt;/p&gt;

&lt;p&gt;I've opened an issue regarding the problem, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r949433.&lt;br/&gt;
Thanks for reporting the issue&lt;/p&gt;
, &lt;p&gt;Thank you.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=roman.werpachowski, assignees=[], commentAuthors=[luc, roman.werpachowski, mprice], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,558 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry, issueId: MATH-288
2016-01-13 22:04:32,558 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:1 : Transforming issue entry:ITSDataType [issueId=MATH-288, created=Tue Aug 25 00:31:11 CEST 2009, updated=Wed Apr 14 02:30:17 CEST 2010, resolved=Tue Aug 25 20:10:08 CEST 2009, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.1
], priority=Major, summary=SimplexSolver not working as expected 2, link=https://issues.apache.org/jira/browse/MATH-288, description=&lt;p&gt;SimplexSolver didn't find the optimal solution.&lt;/p&gt;

&lt;p&gt;Program for Lpsolve:&lt;br/&gt;
=====================&lt;br/&gt;
/* Objective function */&lt;br/&gt;
max: 7 a 3 b;&lt;/p&gt;

&lt;p&gt;/* Constraints */&lt;br/&gt;
R1: +3 a -5 c &amp;lt;= 0;&lt;br/&gt;
R2: +2 a -5 d &amp;lt;= 0;&lt;br/&gt;
R3: +2 b -5 c &amp;lt;= 0;&lt;br/&gt;
R4: +3 b -5 d &amp;lt;= 0;&lt;br/&gt;
R5: +3 a +2 b &amp;lt;= 5;&lt;br/&gt;
R6: +2 a +3 b &amp;lt;= 5;&lt;/p&gt;

&lt;p&gt;/* Variable bounds */&lt;br/&gt;
a &amp;lt;= 1;&lt;br/&gt;
b &amp;lt;= 1;&lt;br/&gt;
=====================&lt;br/&gt;
Results(correct): a = 1, b = 1, value = 10&lt;/p&gt;


&lt;p&gt;Program for SimplexSolve:&lt;br/&gt;
=====================&lt;br/&gt;
LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]{7, 3, 0, 0}, 0);&lt;br/&gt;
Collection&amp;lt;LinearConstraint&amp;gt; podmienky = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{1, 0, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 1, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 0, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 0, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 2, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 3, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 2, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 3, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
RealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);&lt;br/&gt;
=====================&lt;br/&gt;
Results(incorrect): a = 1, b = 0.5, value = 8.5&lt;/p&gt;

&lt;p&gt;P.S. I used the latest software from the repository (including &lt;a href="https://issues.apache.org/jira/browse/MATH-286" title="SimplexSolver not working as expected?"&gt;&lt;del&gt;MATH-286&lt;/del&gt;&lt;/a&gt; fix).&lt;/p&gt;, comments=[&lt;p&gt;Thanks for the bug report.  I've confirmed this is an issue.&lt;/p&gt;

&lt;p&gt;Here's a slightly smaller version of the problem that causes the same bug, which might be easier for debugging:&lt;/p&gt;

&lt;p&gt;MAX 7 a + 3 b&lt;br/&gt;
s.t.&lt;br/&gt;
3 a -5 c &amp;lt;= 0&lt;br/&gt;
2 a -5 d &amp;lt;= 0&lt;br/&gt;
3 b -5 d &amp;lt;= 0&lt;br/&gt;
a &amp;lt;= 1&lt;br/&gt;
b &amp;lt;= 1&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 7, 3, 0, 0 }, 0 );&lt;br/&gt;
        Collection&amp;lt;LinearConstraint&amp;gt; constraints = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 3, 0, -5, 0 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 2, 0, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 3, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0 }, Relationship.LEQ, 1.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 0 }, Relationship.LEQ, 1.0));&lt;/p&gt;

&lt;p&gt;        SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
        RealPointValuePair solution = solver.optimize(f, constraints, GoalType.MAXIMIZE, true);&lt;br/&gt;
        assertEquals(10.0, solution.getValue(), .0000001);&lt;/p&gt;
, &lt;p&gt;Patch attached.  It was a 1 character bug.  I was saying to only do the minimum ratio test if the entry is &amp;gt;= 0, but it should have been &amp;gt; 0 (dividing by 0 is never good :o)&lt;br/&gt;
Thanks again for the bug report.&lt;/p&gt;
, &lt;p&gt;resolved in subversion repository as of r807738&lt;br/&gt;
patch applied (except for debug print function)&lt;br/&gt;
thanks for the repoart and thanks for the patch&lt;/p&gt;
], resolution=Fixed, reporter=kefa, assignees=[], commentAuthors=[bmccann, luc], timeEstimate=480, timeSpent=null]
2016-01-13 22:04:32,558 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-724
2016-01-13 22:04:32,574 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-724, created=Mon Dec 12 16:03:41 CET 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Tue Dec 20 22:14:16 CET 2011, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=RandomDataImpl.nextInt does not distribute uniformly for negative lower bound, link=https://issues.apache.org/jira/browse/MATH-724, description=&lt;p&gt;When using the RandomDataImpl.nextInt function to get a uniform sample in a &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt; interval, when the lower value is less than zero, the output is not uniformly distributed, as the lowest value is practically never returned.&lt;/p&gt;

&lt;p&gt;See the attached NextIntUniformTest.java file. It uses a &lt;span class="error"&gt;&amp;#91;-3, 5&amp;#93;&lt;/span&gt; interval. For several values between 0 and 1, testNextIntUniform1 prints the return value of RandomDataImpl.nextInt (as double and as int). We see that -2 through 5 are returned several times. The -3 value however, is only returned for 0.0, and is thus under-respresented in the integer samples. The output of test method testNextIntUniform2 also clearly shows that value -3 is never sampled.&lt;/p&gt;, comments=[&lt;p&gt;NextIntUniformTest.java: see issue description&lt;/p&gt;
, &lt;p&gt;Thanks for reporting this. The problem is in the rounding, which does not work correctly for negative values.  My first inclination is to test for negative lower bound and just shift the interval in that case.  Any better ideas?&lt;/p&gt;
, &lt;p&gt;math-724.patch: it first scales the [0..1) interval to [0..length), then discretizes it, and finally shifts it to &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;It may be a good idea to also add some tests for cases such as &lt;span class="error"&gt;&amp;#91;0,3&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-5, -3&amp;#93;&lt;/span&gt;, and see if the distribution of sampled values is uniform. It seems RandomDataTest.testNextInt does this using chiSquare, but since I'm not familiar with that, I'm not sure how to add more tests for the other lower/upper bound pairs...&lt;/p&gt;
, &lt;p&gt;I just ran the unit tests with my patch applied, an the following test, in RandomDataTest:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;@Test
    &lt;span class="code-keyword"&gt;public&lt;/span&gt; void testNextIntExtremeValues() {
        &lt;span class="code-object"&gt;int&lt;/span&gt; x = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        &lt;span class="code-object"&gt;int&lt;/span&gt; y = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        Assert.assertFalse(x == y);
    }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails, as does testNextLongExtremeValues. Both x and y become equal to Integer.MIN_VALUE, making x == y to become true, causing the assertion to fail...&lt;/p&gt;
, &lt;p&gt;Also note that RandomDataImpl.nextUniform uses a similar scale/shift method to transform the range. It may thus suffer from the same failure in case of extreme values...&lt;/p&gt;
, &lt;p&gt;math-724-v2.patch: 2nd patch.&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;I think all unit tests work now, including the ones for the Integer.MIN_VALUE to Integer.MAX_VALUE interval.&lt;/li&gt;
	&lt;li&gt;The original problem was that negative values were rounded up by the conversion from double to int, while positive numbers were rounded down. By using floor, we first round the numbers down, and then convert to integer, thus ensuring a proper uniform distribution.&lt;/li&gt;
	&lt;li&gt;Test cases for negative values are still missing... Could someone else add them?&lt;/li&gt;
	&lt;li&gt;RandomDataImpl.nextUniform: I haven't changed this, as the change that I used for integers does not have the desired effect for doubles... This may be caused by the fact that Double.MIN_VALUE is more negative than Double.MAX_VALUE is positive, but I'm not really sure. Maybe it is not even an issue for the nextUniform method?&lt;/li&gt;
&lt;/ul&gt;

, &lt;blockquote&gt;&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; the fact that Double.MIN_VALUE is more negative &lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="http://docs.oracle.com/javase/6/docs/api/java/lang/Double.html#MIN_VALUE"&gt;Double.Min_VALUE&lt;/a&gt; is a &lt;em&gt;positive&lt;/em&gt; number.&lt;/p&gt;
, &lt;blockquote&gt;&lt;p&gt;Double.Min_VALUE is a positive number.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops...&lt;/p&gt;

&lt;p&gt;OK, I uploaded a third version of the patch (math-724-v3.patch), which also applies the new formula for nextUniform. I included two test files (NextUniformTest3.java and NextIntTest3.java), that show the results for nextInt and nextUniform, for both the old and new formulas. As for as I can see, the new formula works equally well or better in all cases. Also, all existing unit tests pass.&lt;/p&gt;
, &lt;p&gt;Thanks for reporting and diagnosing this, Dennis.&lt;/p&gt;

&lt;p&gt;Slightly modified version of the third patch (just removing unecessary parens), along with tests, committed in r1221490.  The "negativeToPositiveRange" tests fail before the fix.  The change to nextUniform is also needed to prevent overflows. I changed the relevant test cases to use the TestUtils chisquare test, which is more straightforward and has better output.  This was added after the original versions of these tests were written.  Others in this class should be similarly updated.  Patches welcome to further tidy the tests, but this issue can be resolved.&lt;/p&gt;
], resolution=Fixed, reporter=dhendriks, assignees=[], commentAuthors=[dhendriks, psteitz, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,574 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-723
2016-01-13 22:04:32,574 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-723, created=Sun Dec 11 22:03:37 CET 2011, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Sun Dec 11 22:59:41 CET 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=BitStreamGenerators (MersenneTwister, Well generators) do not clear normal deviate cache on setSeed, link=https://issues.apache.org/jira/browse/MATH-723, description=&lt;p&gt;The BitStream generators generate normal deviates (for nextGaussian) in pairs, caching the last value generated. When reseeded, the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1213087.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,574 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-719
2016-01-13 22:04:32,574 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-719, created=Tue Dec 06 18:07:24 CET 2011, updated=Sat Mar 24 17:16:38 CET 2012, resolved=Mon Jan 23 12:28:07 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[], priority=Minor, summary=Strange deprecations in API, link=https://issues.apache.org/jira/browse/MATH-719, description=&lt;p&gt;Sorry if this doesn't belong here. I couldn't find any sort of mailing list or other feedback mechanism on the website.&lt;/p&gt;

&lt;p&gt;RealMatrix has some very odd deprecations. In particular inverse(), getDeterminant() and isSingular(). The last has the message:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Deprecated. as of release 2.0, replaced by the boolean negation of new LUDecompositionImpl(m).getSolver().isNonSingular()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's an implementation, not an interface. The whole point of having an interface is that &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I can query whether a matrix is singular withou having to know about LUDecompositions&lt;/li&gt;
	&lt;li&gt;You guys can change the implementation of isSingular() if something better pops up without us guys having to change our code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I'm not using these methods now, because they're deprecated, but I've basically recreated them in as static methods in a utility class. Wouldn't it be much better to just put code from the deprecation message into the method and remove the deprecation?&lt;/p&gt;, comments=[&lt;blockquote&gt;&lt;p&gt;Sorry if this doesn't belong here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Indeed, you'd better bring this kind of issue to the "dev" ML. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
The more so that there have been recent discussions about changing the matrix API and decisions ought to be made quite soon now.&lt;/p&gt;
, &lt;p&gt;Ah, so there is a mailing list. I guess I should have looked a little harder. I'll bring it up there.&lt;/p&gt;
, &lt;p&gt;It is unlikely that we can come up with a new design before the release of v3.0.&lt;br/&gt;
This must be thoroughly discussed first on the "dev" ML, together with other matrix interface issues.&lt;/p&gt;
], resolution=Unknown, reporter=pbloem, assignees=[], commentAuthors=[erans, pbloem], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-692
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-692, created=Tue Oct 18 20:01:57 CEST 2011, updated=Sat Mar 24 17:16:26 CET 2012, resolved=Thu Feb 02 07:45:59 CET 2012, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 1.3
, 2.0
, 2.1
, 2.2
, 2.2.1
, 3.0
], fixVersion=[3.0
], priority=Minor, summary=Cumulative probability and inverse cumulative probability inconsistencies, link=https://issues.apache.org/jira/browse/MATH-692, description=&lt;p&gt;There are some inconsistencies in the documentation and implementation of functions regarding cumulative probabilities and inverse cumulative probabilities. More precisely, '&amp;lt;' and '&amp;lt;=' are not used in a consistent way.&lt;/p&gt;

&lt;p&gt;Besides I would move the function inverseCumulativeProbability(double) to the interface Distribution. A true inverse of the distribution function does neither exist for Distribution nor for ContinuosDistribution. Thus we need to define the inverse in terms of quantiles anyway, and this can already be done for Distribution.&lt;/p&gt;

&lt;p&gt;On the whole I would declare the (inverse) cumulative probability functions in the basic distribution interfaces as follows:&lt;/p&gt;

&lt;p&gt;Distribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(double x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(double x0, double x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1)&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;inverseCumulativeProbability(double p):&lt;br/&gt;
  returns the quantile function inf{x in R | P(X&amp;lt;=x) &amp;gt;= p} &lt;span class="error"&gt;&amp;#91;see also 2), 3), and 4)&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1) An aternative definition could be P(x0 &amp;lt;= X &amp;lt;= x1). But this requires to put the function probability(double x) or another cumulative probability function into the interface Distribution in order be able to calculate P(x0 &amp;lt;= X &amp;lt;= x1) in AbstractDistribution.&lt;br/&gt;
2) This definition is stricter than the definition in ContinuousDistribution, because the definition there does not specify what to do if there are multiple x satisfying P(X&amp;lt;=x) = p.&lt;br/&gt;
3) A modification could be defined for p=0: Returning sup{x in R | P(X&amp;lt;=x) = 0} would yield the infimum of the distribution's support instead of a mandatory -infinity.&lt;br/&gt;
4) This affects issue &lt;a href="https://issues.apache.org/jira/browse/MATH-540" title="AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug"&gt;&lt;del&gt;MATH-540&lt;/del&gt;&lt;/a&gt;. I'd prefere the definition from above for the following reasons:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;This definition simplifies inverse transform sampling (as mentioned in the other issue).&lt;/li&gt;
	&lt;li&gt;It is the standard textbook definition for the quantile function.&lt;/li&gt;
	&lt;li&gt;For integer distributions it has the advantage that the result doesn't change when switching to "x in Z", i.e. the result is independent of considering the intergers as sole set or as part of the reals.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ContinuousDistribution:&lt;br/&gt;
nothing to be added regarding (inverse) cumulative probability functions&lt;/p&gt;

&lt;p&gt;IntegerDistribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(int x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(int x0, int x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1) above&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;, comments=[&lt;p&gt;Thanks for raising this issue, Christian - especially now as we finalize the 3.0 API.&lt;/p&gt;

&lt;p&gt;I am +1 for these changes.  I agree that the inf-based definition of inverse cum is more standard and we are in a position now make the change, so I say lets do it.  I am also +1 on the move of this up to the distribution interface.  The reason we did not include it there originally was that we thought we might implement distributions for which we could not define inverses.  That has not happened in the last 8 years, so I think its safe enough to push it up.&lt;/p&gt;

&lt;p&gt;The code, test, user guide and doc changes for this have to be done carefully.  Patches most welcome.&lt;/p&gt;

&lt;p&gt;Is everyone else OK with this change?&lt;/p&gt;
, &lt;p&gt;I have neither used nor developed this part of CM, so my view on this is of but little value. Having said that, anything improving consistency can only be desirable, especially at this stage. So I'm all for it, and will be soon available (when I'm done on SYMMLQ) for an (novice on these issues) help.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;+1&lt;/p&gt;
, &lt;p&gt;Thanks for the feedback to all. Sbastien, thanks for offering your help. If you like and find time for it, you could implement AbstractDistribution.inverseCumulativeProbability(double p).&lt;/p&gt;

&lt;p&gt;I will provide some patches next week, but adjusting AbstractContinuousDistribution.inverseCumulativeProbability(double p) will take some more time.&lt;/p&gt;

&lt;p&gt;After thinking a little more about the structure of the interfaces, I'd like to put the function probability(double x) to Distribution anyway (independently of the thought in point 1) above).&lt;/p&gt;

&lt;p&gt;Are there any preferences on P(x0 &amp;lt;= X &amp;lt;= x1) or P(x0 &amp;lt; X &amp;lt;= x1) for cumulativeProbability(double x0, double x1)?&lt;/p&gt;
, &lt;p&gt;I am not sure it is really makes sense to add probability(double x) to the Distribution interface.  It would have to be defined as density (referring to the distribution function) to make sense in the continuous case, since defined as p(X = x) it would in most cases be identically 0 for continuous distributions.&lt;/p&gt;

&lt;p&gt;Regarding the cum definition, I am fine with P(x0 &amp;lt; X &amp;lt;= x1).&lt;/p&gt;
, &lt;p&gt;Happy to help on the inverse cumulative probability. You will have to be patient and forgieving with me, though, as I discover this part of CM.&lt;/p&gt;

&lt;p&gt;As for the definition, I think that one of the bounds should be excluded, so that these cumulative probabilities can be summed&lt;br/&gt;
P(a &amp;lt; X &amp;lt;= c) = P(a &amp;lt; X &amp;lt;= b) + P(b &amp;lt; X &amp;lt;= c),&lt;br/&gt;
even in the case of discrete PDFs.&lt;/p&gt;

&lt;p&gt;Whether the lower or upper bound should be excluded is another matter. I usually work with continuous pdfs, so I don't know if there is a common practice in the probability community. If there is none, I would tend to chose the following definition&lt;br/&gt;
P(x0 &amp;lt;= X &amp;lt; x1)&lt;br/&gt;
(sorry Phil!), because it would be consistent with the way things are usually indexed in java (a&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;.. a&lt;span class="error"&gt;&amp;#91;a.length-1&amp;#93;&lt;/span&gt;). See also &lt;tt&gt;org.apache.commons.math.util.MultidimensionalCounter&lt;/tt&gt;. Although this type of consistency is not an absolute requirement, I think it is nice for the user to have such simple principle: "lower bound always included, upper bound always excluded". Appart from this small point, I really have no objection to any choice.&lt;/p&gt;
, &lt;p&gt;Have a look at the default implementation of cum(x0,x1) now in AbstractDistribution.  I think the incorrectness in the documentation there may have been what triggered Christian to raise this issue.  The equation cum(a,b) = F(b) - F(a) where F is the distribution function is natural and what the impl there is trying to do.  In the discrete case, this equation fails, however, unless you define the cum to exclude the &lt;b&gt;lower&lt;/b&gt; endpoint.  That's why P(x0 &amp;lt; X &amp;lt;= x1) is a better definition.&lt;/p&gt;
, &lt;p&gt;OK, Phil, it makes perfect sense.&lt;/p&gt;
, &lt;p&gt;Good, the definition of cum(x0,x1) will be P(x0 &amp;lt; X &amp;lt;= x1). Phil, you are right: cum(x0,x1) in AbstractDistribution was a reason for raising this issue. Another reason was cum(int x0, int x1) in AbstractIntegerDistribution.&lt;/p&gt;

&lt;p&gt;The idea behind probability(double x) is in fact to define it as p(X = x) and to return 0 for continuous distributions. This function would be useful for discrete distributions not inheriting from IntergerDistribution and for distributions being composed of discrete and continuous parts.&lt;/p&gt;
, &lt;p&gt;I guess I am OK with pushing p&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/error.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt; up.  See related post to follow in commons-dev. &lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
I've started looking into this issue. As I said, you will have to be patient with me &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;.&lt;br/&gt;
I can see there already is a default implementation of &lt;tt&gt;AbstractContinuousDistribution.inverseCumulativeProbability&lt;/tt&gt;. So what exactly would you like me to do? Is this implementation fragile? Would you like me to improve robustness? Provide full testing?&lt;/p&gt;

&lt;p&gt;I think there might be issues when the PDF falls down to zero in a range (in which case the cum exhibits a plateau). The returned value might differ from the mathematical definition you proposed. Is this what you want me to work on? Have you already identified other issues?&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;

&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;

&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;

&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;
, &lt;p&gt;Another point for discussion:&lt;br/&gt;
I'd like to introduce&lt;br/&gt;
getDomainBracket(double p): returns double[]&lt;br/&gt;
to AbstractDistribution as helper function for inverseCumulativeProbability. This allows to avoid searching a bracket where a bracket can be specified directly.&lt;br/&gt;
The function getDomainBracket could be made abstract (which means to remove getInitialDomain, getDomainLowerBound, and getDomainUpperBound as these functions aren't needed any more), or it could have a default implementation (according to the corresponding part of the current implementation of inverseCumulativeProbability) which uses getInitialDomain, getDomainLowerBound, and getDomainUpperBound. However, getInitialDomain, getDomainLowerBound, and getDomainUpperBound should not be abstract in the latter case. Otherwise a derived class would be forced to implement something it potentially doesn't use. Thus the functions getInitialDomain, getDomainLowerBound, and getDomainUpperBound should have default implementations which either return default values (0, -infinity, +infinity) or throw an exception saying something like "has to be implemented".&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I'm working on it...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, for now, I'm concentrating on making the current impl in &lt;tt&gt;AbstractContinuousDistribution&lt;/tt&gt; more robust. The other impl should be easier.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current implementation uses a Brent solver. I think the solver itself is only one side of the issue. The other point is the algorithm used to bracket the solution, in order to ensure that the result is consistent with the definition of the cumprob. As for the &lt;tt&gt;DifferentiableUnivariateRealSolver&lt;/tt&gt;, I'm not too sure. I guess it depends on what is meant by "continuous distribution". For me, it means that the random variable takes values in a continuous set, and possibly its distribution is defined by a density. However, in my view, nothing prevents occurences of Dirac functions, in which case the cum sum is only piecewise C1. It's all a matter of definition, of course, and I'll ask the question on the forum to check whether or not people want to allow for such a situation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I'm very interested.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Please note that &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt; has been created specifically to handle plateaux.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;Here is the first patch for this issue (unfortunately with some delay). It adjusts the distributions with real domain to the definitions in this issue, and it mainly changes documentations.&lt;/p&gt;

&lt;p&gt;I could not move inverseCumulativeProbability(double) up to Distribution because there would be a conflict with IntegerDistribution.inverseCumulativeProbability(double): This method returns int. This problem will be removed by solving issue &lt;a href="https://issues.apache.org/jira/browse/MATH-703" title="Splitting up the distribution hierarchy"&gt;&lt;del&gt;MATH-703&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The implementation of inverseCumulativeProbability(double) is not changed as Sbastien is working on this.&lt;/p&gt;

&lt;p&gt;I will provide the patch for the integer distributions as soon as I have adjusted the test data to the new inequalities and reverified the adjusted test data.&lt;/p&gt;
, &lt;p&gt;All,&lt;br/&gt;
since I'm already working on this package, I'm happy to commit the patch on behalf of Christian. However, since I'm a relatively new committer, I would feel more confident if one of the "old, wise committers" could double check the svn log afterwards.&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hey, that's how it always works &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;  &lt;/p&gt;

&lt;p&gt;I don't know about "wise" but I certainly qualify as "old" by any standard, so will have a look once you have reviewed and committed.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
, &lt;p&gt;Patch &lt;tt&gt;Math-692_realDomain_patch1.patch&lt;/tt&gt; (20111108) applied in rev 1200179, with minor modifications (mostly checkstyle fixes).&lt;br/&gt;
Thanks Christian!&lt;/p&gt;
, &lt;p&gt;As mentioned by Sbastien in &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt;, the implementation of &lt;tt&gt;IntegerDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; can benefit from the ideas which came up for &lt;tt&gt;RealDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; in that thread.&lt;/p&gt;

&lt;p&gt;Thus I will remove &lt;tt&gt;getDomainLowerBound(double p)&lt;/tt&gt; and &lt;tt&gt;getDomainUpperBound(double p)&lt;/tt&gt; from the integer distributions. I checked that all current implementations of the lower/upper bound methods provide the whole support of the distribution as starting bracket. This means that using &lt;tt&gt;getSupportLowerBound()&lt;/tt&gt; and &lt;tt&gt;getSupportUpperBound()&lt;/tt&gt; for the starting bracket won't degrade the performance of the current distribution implementations. However, a user might want the improve the performance of his distribution implementations by providing a more targeted starting bracket for probability &lt;tt&gt;p&lt;/tt&gt;. Thus I will swap the solving step to a protected function &lt;tt&gt;solveInverseCumulativeProbability(double p, int lower, int upper)&lt;/tt&gt;, so that it gets easy to override &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; with an implementation which finds a better starting bracket.&lt;/p&gt;

&lt;p&gt;Furthermore, Phil's idea with Chebyshev's inequality can be applied to the generic implementation of &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; in order to get a better starting bracket.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
If you agree with that, I suggest that you also take care of &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;, as the two issues seem to be very much connected.&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;my changes in the integer distributions don't solve &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;. Instead I found a probably related problem with the Pascal distribution.&lt;/p&gt;

&lt;p&gt;The integer distribution patch for this issue still isn't ready. I will provide it next week.&lt;/p&gt;

&lt;p&gt;Christian&lt;/p&gt;
, &lt;p&gt;This is the patch which adjusts the integer distributions to the agreements above.&lt;/p&gt;

&lt;p&gt;The changes to the test cases for the random generators may be unexpected. But these changes initially were triggered by adjusting &lt;tt&gt;RandomDataTest.checkNextPoissonConsistency(double)&lt;/tt&gt; to the new contract for integer distributions. Then some random generator tests failed due to chance. While adjusting their seeds, I found some other tests with a high failure probability. Thus I also set some failure probabilities to 0.01 in order to find suitable seeds more quickly.&lt;/p&gt;

&lt;p&gt;My next task on this issue is to adjust the user guid.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
thanks for this contribution. I am away for a few days, but am very happy to commit this patch as soon as I am back, if you are not in too much of a hurry.&lt;br/&gt;
Thanks again,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Well, we've recently run into some troubles with SVN, but it seems everything is working fine again. Patch {{&lt;a href="https://issues.apache.org/jira/browse/MATH-692" title="Cumulative probability and inverse cumulative probability inconsistencies"&gt;&lt;del&gt;MATH-692&lt;/del&gt;&lt;/a&gt;_integerDomain_patch1.patch}} (with minor checkstyle changes) committed in revision &lt;tt&gt;1226041&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Please do not forget to run &lt;tt&gt;mvn clean; mvn site:site&lt;/tt&gt; and check the reports (in particular, &lt;tt&gt;checkstyle&lt;/tt&gt;) prior to submitting a patch!&lt;/p&gt;

&lt;p&gt;Thanks for this contribution.&lt;/p&gt;
, &lt;p&gt;The committed patch actually causes failure of &lt;tt&gt;Well1024Test&lt;/tt&gt; in &lt;tt&gt;o.a.c.m.random&lt;/tt&gt;.&lt;/p&gt;
, &lt;p&gt;Thanks for committing the patch, Sbastien. I see you already changed the seed in &lt;tt&gt;Well1024aTest&lt;/tt&gt;. This hopefully removes the failure.&lt;/p&gt;

&lt;p&gt;I'll have a look into Maven to prepare a better patch next time. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;I see you already changed the seed in Well1024aTest.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I did, but is this really how we want &lt;tt&gt;Well2004aTest&lt;/tt&gt; to pass?&lt;/p&gt;
, &lt;p&gt;I guess there is no alternative to this way of making probabilistic test cases pass. However, I understand your bad feeling with this kind of failure fixing. The problem is that probabilistic tests are quiet fuzzy: Neither a passed test nor a failed test provides a clear answer whether something is right or wrong in the implementation. There is just a high chance to pass such a test with a correct implementation. The chance for failure increases with an erroneous implementation due to systematic deviations in the generated data. These chances tell whether it is easy to find a seed which passes the tests or not. Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's exactly the point I've raised on the mailing-list: out of three seeds (100, 1000 and 1001), only one works. Of course, I would not dare to call that representative statistics, but I'm wondering whether or not we should be worried...&lt;/p&gt;
, &lt;p&gt;The issue about selection of an appropriate seed has been raised elsewhere. No definitive answer has been provided so far, so I suggest we consider this issue as solved for the time being.&lt;/p&gt;
], resolution=Fixed, reporter=cwinter, assignees=[], commentAuthors=[psteitz, celestin, mikl, cwinter], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-654
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-654, created=Tue Aug 30 19:23:19 CEST 2011, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Thu Sep 01 02:14:02 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=ValueServer not deterministic for a fixed random number seed, link=https://issues.apache.org/jira/browse/MATH-654, description=&lt;p&gt;I have built an agent-based model using the Apache Commons Math library, which has come in handy.&lt;/p&gt;

&lt;p&gt;The ValueServer seemed particularly helpful, as explained at:&lt;br/&gt;
&lt;a href="http://commons.apache.org/math/userguide/random.html"&gt;http://commons.apache.org/math/userguide/random.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My simulation needs repeatable randomness, so I used this form of the ValueServer constructor:&lt;/p&gt;

&lt;p&gt;    ValueServer(RandomData randomData) &lt;br/&gt;
    Construct a ValueServer instance using a RandomData as its source of random data.&lt;br/&gt;
    // &lt;a href="http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html"&gt;http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, in my simulation, I found that the ValueServer did not act deterministically if I supplied the same random number seed.&lt;/p&gt;

&lt;p&gt;I have not inspected the source code, but I suspect that the ValueServer is not using the `randomData` generator correctly. If it was, then it should be deterministic.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  I assume you are using DIGEST_MODE.  If this is the case and you are comfortable compiling the code in trunk, the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-634" title="EmpiricalDistributionImpl should use a pluggable RandomGenerator"&gt;&lt;del&gt;MATH-634&lt;/del&gt;&lt;/a&gt; enables a workaround for this.  Using the reseed method added to EmpiricalDistributionImpl in trunk, you can use ValueServer's getEmpiricalDistribution to get the distribution and then invoke reseed.  Unfortunately, this method does not exist in any released version yet.&lt;/p&gt;

&lt;p&gt;The problem is that ValueServer#getNextDigest (what it does for getNext in DIGEST_MODE) delegates to EmpiricalDistributionImpl#getNextValue.  EmpiricalDistributionImpl has its own RandomData instance.  To fix this issue, EmpiricalDistirbutionImpl should add a constructor taking a RandomData and ValueServer should provide this.&lt;/p&gt;
, &lt;p&gt;Fixed in r1163875. ValueServer now exposes a reSeed method that when supplied a fixed seed will generate a fixed sequence in any stochastic mode. The RandomDataImpl that it uses internally is passed to the EmpiricalDistributionImpl it creates when used in DIGEST_MODE.  The changes for this issue include an incompatible (vs. 2.x) change: the constructor for EmpiricalDistributionImpl that previously took a RandomData now takes a RandomDataImpl.  The plan for 3.0 is to merge these.&lt;/p&gt;
], resolution=Fixed, reporter=d.james, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-640
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-640, created=Tue Aug 02 21:06:35 CEST 2011, updated=Sat Mar 24 17:16:52 CET 2012, resolved=Wed Aug 03 06:17:43 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=AbstractRandomGenerator nextInt() and nextLong() default implementations generate only positive values, link=https://issues.apache.org/jira/browse/MATH-640, description=&lt;p&gt;The javadoc for these methods (and what is specified in the RandomGenerator interface) says that all int / long values should be in the range of these methods.  The default implementations provided in this class do not generate negative values.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1153338&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-618
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-618, created=Wed Jul 13 22:23:43 CEST 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Thu Jul 14 08:08:54 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same, link=https://issues.apache.org/jira/browse/MATH-618, description=&lt;p&gt;For both Complex add and subtract, the javadoc states that&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;* If either &lt;span class="code-keyword"&gt;this&lt;/span&gt; or &amp;lt;code&amp;gt;rhs&amp;lt;/code&amp;gt; has a NaN value in either part,
     * {@link #NaN} is returned; otherwise Inifinite and NaN values are
     * returned in the parts of the result according to the rules &lt;span class="code-keyword"&gt;for&lt;/span&gt;
     * {@link java.lang.&lt;span class="code-object"&gt;Double&lt;/span&gt;} arithmetic&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1146573&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-588
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-588, created=Sun Jun 12 20:19:07 CEST 2011, updated=Sat Mar 24 17:16:31 CET 2012, resolved=Sun Feb 05 20:54:50 CET 2012, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Weighted Mean evaluation may not have optimal numerics, link=https://issues.apache.org/jira/browse/MATH-588, description=&lt;p&gt;I recently got this in a test run&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;testWeightedConsistency(org.apache.commons.math.stat.descriptive.moment.MeanTest)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;0.002282165958997601&amp;gt; but was:&amp;lt;0.002282165958997157&amp;gt;
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:441)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:178)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:153)
	at org.apache.commons.math.stat.descriptive.UnivariateStatisticAbstractTest.testWeightedConsistency(UnivariateStatisticAbstractTest.java:170)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The correction formula used to compute the unweighted mean may not be appropriate or optimal in the presence of weights:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// Compute initial estimate using definitional formula
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; sumw = sum.evaluate(weights,begin,length);
&lt;span class="code-object"&gt;double&lt;/span&gt; xbarw = sum.evaluate(values, weights, begin, length) / sumw;

&lt;span class="code-comment"&gt;// Compute correction factor in second pass
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; correction = 0;
&lt;span class="code-keyword"&gt;for&lt;/span&gt; (&lt;span class="code-object"&gt;int&lt;/span&gt; i = begin; i &amp;lt; begin + length; i++) {
  correction += weights[i] * (values[i] - xbarw);
}
&lt;span class="code-keyword"&gt;return&lt;/span&gt; xbarw + (correction/sumw);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;, comments=[&lt;p&gt;Fixed it in r1240790.&lt;/p&gt;

&lt;p&gt;There was a too strict equality test using an relative error of 10-14 which resulted in certain unforunate cases of an absolute error of 10-18.&lt;/p&gt;
, &lt;p&gt;Corrected the equality test in r1240795 as it was leading to failure. In fact the test can range from very small to very large values which really requires a relative error estimate.&lt;/p&gt;

&lt;p&gt;The test is problematic in general, as it may contain values from very different scales (due to its random nature), leading to unavoidable precision errors in the above formula.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[tn], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-575
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-575, created=Sat May 14 18:40:34 CEST 2011, updated=Sat Mar 24 17:16:54 CET 2012, resolved=Thu Feb 02 12:12:52 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=Exceptions in genetics package or not consistent with the rest of [math], link=https://issues.apache.org/jira/browse/MATH-575, description=&lt;p&gt;InvalidRepresentationException is checked and non-localized.  This exception should be placed in the &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; hierarchy.  The AbstractListChromosome constructor also throws a non-localised IAE, which should be replaced by an appropriate &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; exception.&lt;/p&gt;, comments=[&lt;p&gt;Phil started to work on this issue in r1135025.&lt;/p&gt;

&lt;p&gt;In r1235038 additional cleanups have been performed:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;add localized messages for all exceptions&lt;/li&gt;
	&lt;li&gt;add @throws to javadoc where appropriate&lt;/li&gt;
	&lt;li&gt;add final to method parameters&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What is missing:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;Phil mentioned that InvalidRepresentationException should be placed into &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, although I am not sure why, as it is not used outside the genetics package&lt;/li&gt;
	&lt;li&gt;add more custom exception classes specific to the genetics package (optional). By now mostly MathIllegalArgumentException or other appropriate ones have been used.&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;Thanks for working on this, but before you do start to make modifications, please assign the issue to yourself!&lt;/p&gt;

&lt;p&gt;For the changes themselves, I don't agree with the creation of those many localized messages: We have been trying to rationalize and reduce the number of those, by removing duplicates and combining several ones to convey the full explanation of the problem. See my reply to the commit message.&lt;/p&gt;
, &lt;p&gt;Fixed in r1235197.&lt;/p&gt;

&lt;p&gt;Thanks for your suggestions!&lt;/p&gt;
, &lt;p&gt;Thomas,&lt;br/&gt;
Could please check whether this issue is resolved? And if it is, mark it so? Thanks.&lt;/p&gt;
, &lt;p&gt;As from the original issue description, Phil intended to move the InvalidRepresentationException to the general o.a.c.m.exceptions package. I am not sure about this, that's why I kept it aside for the time being. If we agree on keeping it in the genetics package we can resolve this issue.&lt;/p&gt;
, &lt;p&gt;Phil had always been opposed to having all exceptions grouped in their own package; so I doubt that he meant to move that one over there... &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
Here, the description just indicates that the exception should become &lt;em&gt;unchecked&lt;/em&gt; and that the "detailed message" should be an element from the "LocalizedFormats" enum (i.e. derive from one of the base CM exceptions).&lt;/p&gt;
, &lt;p&gt;Ah ok, that makes it clear. When reading hierarchy I was just thinking in terms of packages rather than class hierarchy.&lt;/p&gt;

&lt;p&gt;Thus, I resolve this issue.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[tn], commentAuthors=[tn, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-555
2016-01-13 22:04:32,589 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-555, created=Mon Apr 04 06:13:04 CEST 2011, updated=Sat Mar 24 17:16:43 CET 2012, resolved=Mon Apr 04 06:53:13 CEST 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=MathUtils round method should propagate rather than wrap Runitme exceptions, link=https://issues.apache.org/jira/browse/MATH-555, description=&lt;p&gt;MathUtils.round(double, int, int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException, the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in trunk in r1088473&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,620 : INFO  : KNIME-Worker-1 : ITSOfflineNodeModel : Jira Adapter (Offline) : 2:1 : Jira table created.
2016-01-13 22:04:32,620 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 End execute (2 secs)
2016-01-13 22:04:32,620 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 doBeforePostExecution
2016-01-13 22:04:32,620 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: POSTEXECUTE
2016-01-13 22:04:32,620 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 doAfterExecute - success
2016-01-13 22:04:32,620 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 2:1 : Jira Adapter (Offline) 2:1 has new state: EXECUTED
2016-01-13 22:04:32,620 : DEBUG : KNIME-Worker-1 : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-540
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-540, created=Sun Mar 06 01:43:45 CET 2011, updated=Sat Mar 24 17:16:36 CET 2012, resolved=Sun Jun 12 07:58:50 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug, link=https://issues.apache.org/jira/browse/MATH-540, description=&lt;p&gt;The AbstractIntegerDistribution.inverseCumulativeProbability(...) function attempts to decrement the lower bound of discrete distributions to values that go below the lower bound.&lt;/p&gt;, comments=[&lt;p&gt;I don't think this is a bug.  Per the javadoc, the contract for inverse cum is&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/**
 * For a random variable {@code X} whose values are distributed according
 * to &lt;span class="code-keyword"&gt;this&lt;/span&gt; distribution, &lt;span class="code-keyword"&gt;this&lt;/span&gt; method returns the largest {@code x}, such
 * that {@code P(X &amp;lt; x) &amp;lt; p}.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This implies that if the first non-zero mass point has probability greater than p, the right value to return is one less than that value, which is whet the method will do.  Your example distribution throws NPE when trying to compute probabilities outside of its domain of support. &lt;/p&gt;
, &lt;p&gt;I'm looking at it like this.  I have very simple distribution like the one provided (Four sided dice).  I'm trying to write a simulation that draws values of x for a a set of uniform 0-1 probabilities.  So I'm expecting:&lt;/p&gt;

&lt;p&gt;0 When p is less than or equal to 0.25&lt;br/&gt;
1 When p is greater than 0.25 but less than or equal to 0.50&lt;br/&gt;
2 When p is greater than 0.50 but less than or equal to 0.75&lt;br/&gt;
3 When p is greater than 0.75 but less than or equal to 1.0&lt;/p&gt;

&lt;p&gt;So for the line &lt;/p&gt;

&lt;p&gt;int neverSucceeds = d.inverseCumulativeProbability(0.0001);&lt;/p&gt;

&lt;p&gt;I'm really expecting 0 to be returned.&lt;/p&gt;

&lt;p&gt;Make sense?&lt;/p&gt;
, &lt;p&gt;I see now that there actually does appear to be an error in the javadoc.  The implementation really returns the largest x such that p(X &amp;lt;= x) &amp;lt;= p.  In the discrete case, &amp;lt;= matters and I think both inequalities in the javadoc should be changed.&lt;/p&gt;

&lt;p&gt;In your example, if the probability distribution vanishes outside 0, 1, 2, 3 and puts .25 mass on each of these values, the inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;

&lt;p&gt;If you fix your distribution so that both probability and cumulativeProbability return correct values (rather than throwing NPEs) outside of the mass values, you should get -1 returned.&lt;/p&gt;
, &lt;p&gt;Reading your last comment a little more carefully, it looks like what you are trying to do is implement sampling.  IIUC, something like what you are suggesting should work - you just have an off-by-one problem vis-s-vis the contract of inverse cumulative probabilities as we define them.  I would be +1 for adding direct support for sampling from discrete distributions, but we should open a separate ticket for that.&lt;/p&gt;
, &lt;p&gt;OK - I'll close this one and open a separate ticket.&lt;/p&gt;
, &lt;p&gt;There is a javadoc bug that needs to be fixed here&lt;/p&gt;
, &lt;p&gt;Ooops - Thanks.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;...inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems to me that users would be better served if it returned 0 and that it is also correct to do so.&lt;/p&gt;

&lt;p&gt;In the definition we say "For a random variables X whose values are distributed according to this distribution...".&lt;/p&gt;

&lt;p&gt;Suppose the distribution was for a six sided dice.  One could assert that the distribution is only defined for the values 1,2,3,4,5,6.  In this case the inverseCumulativeDistribution returns 0, but that does not have any meaning.  So now developers are forced to define the meaning of 0 for a six sided dice implementation.  &lt;/p&gt;

&lt;p&gt;In Grad school we were taught the the inverse cumulative distribution is for sampling.  So for a six sided dice uniform probabilities less than 1/6 would return 1, less than 2/6 would return 2, etc.&lt;/p&gt;

&lt;p&gt;With the current implementation for values less than 1/6 we get 0 which is meaningless, and the only time we get 6 is when the uniform probability argument is 1.&lt;/p&gt;

&lt;p&gt;So if someone mistakenly tries to use the inverseCumulativeProbability function for sampling the results are going to be wacked.  What is the use case for the inverseCumulativeProbability the way it is right now?&lt;/p&gt;
, &lt;p&gt;You have a choice in defining the inverse cum whether to define it the way we have or to use and inf rather than a sup.  We can implement sampling using the current impl.  We just need to take into account the way the inverse cum is defined in AbstractIntegerDistribution.  &lt;/p&gt;
, &lt;p&gt;OK - I think it's starting to make more sense to me now.  So when implementing sampling we just add one to the value returned by inverseCumulativeDistribution, unless the uniform probability argument is 1?&lt;/p&gt;
, &lt;p&gt;I am sorry.  I forgot that we had in fact already implemented this in version 2.2. See AbstractIntegerDistribution#sample.  The base class implementation delegates to RandomDataImpl#nextInversionDeviate (adding one per the last comment).&lt;/p&gt;
, &lt;p&gt;Sorry for the noise. I closed the wrong ticket.  Still need to fix the javadoc to match behavior and user guide.&lt;/p&gt;
, &lt;p&gt;Javadoc fixed in trunk r1134866&lt;/p&gt;
], resolution=Fixed, reporter=ole, assignees=[], commentAuthors=[psteitz, ole], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-506
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-506, created=Tue Feb 01 19:38:01 CET 2011, updated=Sat Mar 24 17:16:41 CET 2012, resolved=Sat Aug 20 23:14:57 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=The static field ChiSquareTestImpl.distribution serves no purpose, link=https://issues.apache.org/jira/browse/MATH-506, description=&lt;p&gt;The static field ChiSquareTestImpl.distribution serves no purpose.&lt;/p&gt;

&lt;p&gt;There is a setter for it, but in every case where the field is used, it is first overwritten with a new value.&lt;/p&gt;

&lt;p&gt;The field and the setter should be removed, and the methods that create a new instance should create a local variable instead.&lt;/p&gt;

&lt;p&gt;For Math 2.1, the field can be removed and the setter deprecated.&lt;/p&gt;, comments=[&lt;p&gt;Agreed.  Since the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; this instance field is unnecessary.&lt;/p&gt;
, &lt;p&gt;See the discussion in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; where it was decided to remove the distribution pluggability in 3.0.  In 2.x, the distribution is pluggable and the instance field is useful.  The 3.0 code in trunk removes the pluggability and makes the field useless.&lt;/p&gt;
, &lt;p&gt;Sorry - I thought I had checked the 2.x implementation as well, but obviously not, as it does use the field.&lt;/p&gt;

&lt;p&gt;However, we should still deprecate the setter in 2.2, as it is removed in 3.0 - OK?&lt;/p&gt;
, &lt;p&gt;Just tried removing the field and setter in 3.0, and found that the constructors rely on the setter (which is a separate bug, as the setter is not final - but easily fixable if required).&lt;/p&gt;

&lt;p&gt;The fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; merely removed deprecated code.&lt;/p&gt;

&lt;p&gt;It replaced "distribution.setDegreesOfFreedom(dof)" with "distribution = new ChiSquaredDistributionImpl(dof)" which is how the field became useless.&lt;/p&gt;

&lt;p&gt;There are two constructors which still create values for the distribution field.&lt;/p&gt;

&lt;p&gt;I don't know enough about the Math to know whether there would be any use cases for having additional methods that used a distribution provided by the class instance, rather than calculated by the individual methods (as at present).&lt;/p&gt;

&lt;p&gt;If there is no need for external provision of the distribution degree of freedom, then the constructor with parameter can be dropped.&lt;/p&gt;

&lt;p&gt;Otherwise, we need to add some methods that can use the provided distribution (which should be a final instance field).&lt;/p&gt;

&lt;p&gt;In any case, I think the setter needs to be dropped from 3.x&lt;/p&gt;
, &lt;p&gt;The instance field was there originally so that different ChiSquareDistribution implementations could be provided at construction time or via a setter (making the underlying ChiSquareDistribution pluggable).  &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; pointed to a different problem related to mutability of implementation instances.  The simplest solution to both problems is to eliminate the pluggability, which the change in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; does for this class.  The degrees of freedom are always computed from the data, so there is no need for the constructor that takes a distribution instance as argument.  Both the constructor and setter can be deprecated in 2.2 and removed in 3.0 unless we want to keep pluggability, which would require&lt;/p&gt;

&lt;p&gt;1) making the distribution field final (so removing the setter)&lt;br/&gt;
2) copying, rather than referencing the actual parameter provided to the constructor&lt;/p&gt;

&lt;p&gt;I am on the fence on this.  Maybe others can chime in (next week &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;p&gt;OK, I see now, thanks!&lt;/p&gt;
, &lt;p&gt;I removed the field (hence eliminating pluggability) in r1159916.  As of 3.0, the distribution classes are immutable, so to support pluggability a factory or class name rather than a distribution instance would have to be provided.  There is only one implementation provided by &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, so I do not see this as worth the effort and complexity to retain.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[psteitz], commentAuthors=[psteitz, sebb@apache.org], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-505
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-505, created=Tue Feb 01 01:28:56 CET 2011, updated=Sat Mar 24 17:16:40 CET 2012, resolved=Tue Feb 01 19:58:30 CET 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
], fixVersion=[3.0
], priority=Major, summary=TestUtils is thread-hostile, link=https://issues.apache.org/jira/browse/MATH-505, description=&lt;p&gt;TestUtils has several mutable static fields which are not synchronised, or volatile.&lt;/p&gt;

&lt;p&gt;If one of the fields is updated by thread A, there is no guarantee that thread B will see the full update - it may see a partially updated object.&lt;/p&gt;

&lt;p&gt;Furthermore, at least some of the static fields reference a mutable object, which can be changed whilst another thread is using it.&lt;/p&gt;

&lt;p&gt;As far as I can tell, this class must only ever be used by a single thread otherwise the results will be unpredictable.&lt;/p&gt;, comments=[&lt;p&gt;What fields, exactly?&lt;/p&gt;
, &lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/** Singleton TTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; TTest tTest = &lt;span class="code-keyword"&gt;new&lt;/span&gt; TTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; ChiSquareTest chiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; UnknownDistributionChiSquareTest unknownDistributionChiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton OneWayAnova instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; OneWayAnova oneWayAnova =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; OneWayAnovaImpl();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of the above may be changed by set methods. There is no synch.&lt;/p&gt;
, &lt;p&gt;OK, I was looking at the wrong TestUtils &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;

&lt;p&gt;The reason for this strange-looking setup is to allow the implementations to be pluggable at runtime.  "Hostile" is a harsh word, but this class is certainly &lt;b&gt;not&lt;/b&gt; threadsafe.  Ideas / patches to achieve the design goal with less "hostility" would be appreciated.&lt;/p&gt;

&lt;p&gt;I would have to double-check, but I don't think that there is any test instance state used by the methods in this class. &lt;/p&gt;
, &lt;p&gt;By thread-hostile, I mean that it is not possible in general for two different threads to use the class safely.&lt;br/&gt;
If one thread changes any of the static fields, there is no way of knowing how the methods called by the other thread will behave. This is partly because the values are not safely published currently, but even if they were, the threads don't know what settings will be used as they can be changed at any time by another thread.&lt;/p&gt;

&lt;p&gt;In general, any class which relies on mutable static state for its behaviour is thread-hostile.&lt;br/&gt;
The shared state cannot simultaneously satisfy two threads needing different behaviour.&lt;/p&gt;

&lt;p&gt;I think the only safe way for two threads to use the class as it stands is if they both synchronize on the class.&lt;br/&gt;
This will ensure safe publication of any field changes, and enforce serial usage which can guarantee the setting that will be used (but the lock will have to be held for the set call as well).&lt;/p&gt;

&lt;p&gt;ChiSquareTestImpl has a non-final instance field which means its value won't necessarily be safely published.&lt;br/&gt;
The field also has a setter which could be invoked by one thread while another was using it.&lt;/p&gt;

&lt;p&gt;TTestImpl is immutable (has no fields), and OneWayAnovaImpl can be made immutable, but other implementations of the interfaces might exist which are not immutable.&lt;/p&gt;

&lt;p&gt;The simplest way to make the class thread-safe would be to convert all the methods and fields from static to instance, but I don't know if that is acceptable.&lt;/p&gt;
, &lt;p&gt;Making the methods instance sort of defeats the purpose of the class.  None of the instance data in any of the static singletons is actually used or depended on by the methods of this class.  You are correct though that if one thread changes the impl for one of the singletons while another is using the class, the other could see a different than expected impl.  I think the practical likelihood of this is pretty much nil, as it is hard to imagine an application supplying two different implementations for the tests and wanting different threads to use different impls.  Personally, I would be happy just documenting the fact that the class is not threadsafe and if concurrent threads want to plug in different implementations, they need to synchronize on the class.  If this is not acceptable, my next preference would be to remove the pluggability - i.e., make the singletons final or get rid of them altogether, creating instances as needed for static method calls.  There is no initialization overhead creating the test classes.&lt;/p&gt;
, &lt;p&gt;@Phil: Please also keep in mind that M3 supports now (currently optional) parallel execution and it might be no longer a proper assumption that all tests are executed serially.&lt;/p&gt;
, &lt;p&gt;There is another possible option, which would be to fix the default implementations, and create new static methods that took an extra parameter for the implementation to be used.&lt;/p&gt;

&lt;p&gt;At present, changes to the static fields are not guaranteed to be published correctly. Making them volatile would fix this, but would not help with concurrent access.&lt;/p&gt;
, &lt;p&gt;Thanks, Joerg.  There should be no problems with the unit tests unless and until we introduce different tests that actually test the pluggability.  &lt;/p&gt;

&lt;p&gt;I thought about the additional parameter option, Sebb; but that again defeats the purpose of this "convenience class" - you might as well just instantiate the implementation and use it.&lt;/p&gt;

&lt;p&gt;I think the best solution is to just make the fields final and drop the getters and setters.  This is consistent with StatUtils.  So we should document the "hostility" issues in 2.2 and deprecate there and drop in 3.0.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[sebb@apache.org], commentAuthors=[psteitz, sebb@apache.org, joehni], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-484
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-484, created=Tue Jan 18 21:49:51 CET 2011, updated=Wed Mar 23 21:35:01 CET 2011, resolved=Mon Feb 14 15:20:29 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=events detection in ODE solvers is too complex and not robust, link=https://issues.apache.org/jira/browse/MATH-484, description=&lt;p&gt;All ODE solvers support multiple events detection since a long time. Events are specified by users by implementing the EventHandler interface. Events occur when the g(t, y) function evaluates to 0. When an event occurs, the solver step is shortened to make sure the event is located at the end of the step, and the event is triggered by calling the eventOccurred method in the user defined implementation class. Depending on the return value of this method, integration can continue, it can be stopped, or the state vector can be reset.&lt;/p&gt;

&lt;p&gt;Some ODE solvers are adaptive step size solvers. They can modify step size to match an integration error setting, increasing step size when error is low (thus reducing computing costs) or reducing step size when error is high (thus fulfilling accuracy requirements).&lt;/p&gt;

&lt;p&gt;The step adaptations due to events on one side and due to adaptive step size solvers are quite intricate by now, due to numerous fixes (&lt;a href="https://issues.apache.org/jira/browse/MATH-161" title="patch for Mantissa"&gt;&lt;del&gt;MATH-161&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-213" title="FirstOrderIntegrator.integrate does not give back integration stop time when an event handler stops integration"&gt;&lt;del&gt;MATH-213&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-358" title="ODE integrator goes past specified end of integration range"&gt;&lt;del&gt;MATH-358&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-421" title="restarting an ODE solver that has been stopped by an event doesn&amp;#39;t work"&gt;&lt;del&gt;MATH-421&lt;/del&gt;&lt;/a&gt; and also during standard maintenance - see for example r781157). The code is very difficult to maintain. It seems each bug fix introduces new bugs (r781157/&lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;) or tighten the link between adaptive step size and event detection (&lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;/r927202).&lt;/p&gt;

&lt;p&gt;A new bug discovered recently on an external library using a slightly modified version of this code could not be retroffitted into commons-math, despite the same problem is present. At the beginning of EventState.evaluateStep, the initial step may be exactly 0 thus preventing root solving, but preventing this size to drop to 0 would reopen &lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;. I could not fix both bugs at the same time.&lt;/p&gt;

&lt;p&gt;So it is now time to untangle events detection and adaptive step size, simplify code, and remove some inefficiency (event root solving is always done twice, once before step truncation and another time after truncation, of course with slightly different results, events shortened steps induce high computation load until the integrator recovers its optimal pace again, steps are rejected even when the event does not requires it ...).&lt;/p&gt;, comments=[&lt;p&gt;fixed in subversion repository as of r1061507 for branch 2.X and as of r1061508 for trunk&lt;/p&gt;
, &lt;p&gt;The fix introduced in r1061507 fails in several cases. If several events of the same type occur within a single long step, only the first one is triggered. If several events of different types occur during a backward integration, they are triggered in the wrong order (i.e. they are triggered in forward occurrence time order instead of backward).&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1070498 for branch 2.X and r1070499 for trunk&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-481
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-481, created=Mon Jan 17 18:15:41 CET 2011, updated=Wed Mar 23 21:33:40 CET 2011, resolved=Mon Jan 17 23:39:52 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=MathUtils.equals(double x, double y) disagrees with Javadoc, link=https://issues.apache.org/jira/browse/MATH-481, description=&lt;p&gt;MathUtils.equals(double x, double y) disagrees with Javadoc.&lt;/p&gt;

&lt;p&gt;The Javadoc says:&lt;/p&gt;

&lt;p&gt;Returns true iff they are equal as defined by  {@link #equals(double,double,int)}&lt;/p&gt;

&lt;p&gt;However, the code actually uses == and checks for NaN:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; &lt;span class="code-object"&gt;boolean&lt;/span&gt; equals(&lt;span class="code-object"&gt;double&lt;/span&gt; x, &lt;span class="code-object"&gt;double&lt;/span&gt; y) {
    &lt;span class="code-keyword"&gt;return&lt;/span&gt; (&lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(x) &amp;amp;&amp;amp; &lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(y)) || x == y;
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The method is deprecated, but it should probably still be consistent with its documentation.&lt;/p&gt;, comments=[&lt;p&gt;Corrected Javadoc in revision 1060117.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-465
2016-01-13 22:04:32,652 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-465, created=Wed Jan 05 18:34:41 CET 2011, updated=Sat Mar 24 17:17:03 CET 2012, resolved=Wed Jul 20 14:20:51 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Incorrect matrix rank via SVD, link=https://issues.apache.org/jira/browse/MATH-465, description=&lt;p&gt;The getRank() function of SingularValueDecompositionImpl does not work properly. This problem is probably related to the numerical stability problems mentioned in &lt;a href="https://issues.apache.org/jira/browse/MATH-327"&gt;MATH-327&lt;/a&gt; and &lt;a href="https://issues.apache.org/jira/browse/MATH-320"&gt;MATH-320&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Example call with the standard matrix from R (rank 2):&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeHeader panelHeader" style="border-bottom-width: 1px;"&gt;&lt;b&gt;TestSVDRank.java&lt;/b&gt;&lt;/div&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.Array2DRowRealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.RealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecomposition;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecompositionImpl;

&lt;span class="code-keyword"&gt;public&lt;/span&gt; class TestSVDRank {
	&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; void main(&lt;span class="code-object"&gt;String&lt;/span&gt;[] args) {
		&lt;span class="code-object"&gt;double&lt;/span&gt;[][] d = { { 1, 1, 1 }, { 0, 0, 0 }, { 1, 2, 3 } };
		RealMatrix m = &lt;span class="code-keyword"&gt;new&lt;/span&gt; Array2DRowRealMatrix(d);
		SingularValueDecomposition svd = &lt;span class="code-keyword"&gt;new&lt;/span&gt; SingularValueDecompositionImpl(m);
		&lt;span class="code-object"&gt;int&lt;/span&gt; r = svd.getRank();
		&lt;span class="code-object"&gt;System&lt;/span&gt;.out.println(&lt;span class="code-quote"&gt;"Rank: "&lt;/span&gt;+r);
	}
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;The rank is computed as 3. This problem also occurs for larger matrices. I discovered the problem when trying to replace the corresponding JAMA method.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  Looks like it could as you suggest be related to &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt;.  &lt;/p&gt;
, &lt;p&gt;For now, pushing to 3.0.  If we get a fix for this and &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt; before 3.0 is ready, I may propose a 2.2.1 to include it.&lt;/p&gt;
, &lt;p&gt;My apologies if I am missing something, but here is what I noticed about the SVD. &lt;/p&gt;

&lt;p&gt;On lines 124-127 of SingularValueDecompositionImpl we have:&lt;/p&gt;

&lt;p&gt;        for (int i = 0; i &amp;lt; p; i++) {
            singularValues[i] = FastMath.sqrt(FastMath.abs(singularValues[i]));
        }&lt;/p&gt;

&lt;p&gt;This is potentially the offending line. First is the problem of negative eigenvalues. Negative variance in the principal components should probably be dealt with explicitly? Perhaps by throwing a MathException? Second, and the issue which this bug report deals with, is taking a square root of a very small number (&amp;lt;1) will return a larger number. If you apply the threshold test in getRank() (final double threshold = FastMath.max(m, n) * FastMath.ulp(singularValues&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;) )  prior to taking the square root, I believe this problem would be resolved. More importantly, philosophically, you test for zero variance. This is the appropriate test.&lt;/p&gt;

&lt;p&gt;Also, rank could be precalculated in the above loop. &lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1148714.&lt;/p&gt;

&lt;p&gt;This issue was fixed by changing SVD implementation according to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-611" title="A fast and stable SVD implementation from JAMA"&gt;&lt;del&gt;MATH-611&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
], resolution=Fixed, reporter=marisa, assignees=[], commentAuthors=[psteitz, gsteri1, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,667 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-464
2016-01-13 22:04:32,667 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-464, created=Fri Dec 31 08:00:42 CET 2010, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Wed Aug 24 00:37:41 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Critical, summary=LegendreGaussIntegrator ignores defaultMaximalIterationCount and does 38 million iterations, link=https://issues.apache.org/jira/browse/MATH-464, description=&lt;p&gt;The following code results in count = 37801710 which is effectively an infinite loop for typical functions we are using&lt;br/&gt;
(in GeoGebra)&lt;/p&gt;

&lt;p&gt;The argument defaultMaximalIterationCount = 100 is being ignored&lt;/p&gt;

&lt;p&gt;This is the version we are using:&lt;br/&gt;
&lt;a href="http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java"&gt;http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    	LegendreGaussIntegrator gauss = new LegendreGaussIntegrator(5, 100);&lt;/p&gt;

&lt;p&gt;	try {
		double result = gauss.integrate(new testFun(), -10, 0.32462367623786328);
	} catch (Exception ee) {
		ee.printStackTrace();
	}&lt;/p&gt;



&lt;p&gt;class testFun implements UnivariateRealFunction {&lt;/p&gt;

&lt;p&gt;    public double value(double x) throws FunctionEvaluationException {
    	count ++;
        if (x&amp;gt;=0 &amp;amp;&amp;amp; x&amp;lt;=5) return 0.2; else return 0;
    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.&lt;/p&gt;

&lt;p&gt;The problem here is not with the iteration count.  In the example above, only 26 iterations are executed and the method returns the correct value.  What is causing the number of function evaluations to be so large is that each iteration involves multiple function evaluations.   I need to dig more deeply into the algorithm to determine what (if anything) the problem is, but what is causing the high number of function evaluations is the following&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// prepare next iteration
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; ratio = FastMath.min(4, FastMath.pow(delta / limit, 0.5 / abscissas.length));
n = FastMath.max((&lt;span class="code-object"&gt;int&lt;/span&gt;) (ratio * n), n + 1);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the example, delta / limit becomes large, causing n to increase rapidly.  As n increases, the number of function evaluations increases.&lt;/p&gt;
, &lt;p&gt;I am now thinking that this is not a bug, but a consequence of the fact that the integrand in the example is not at all well-approximated by a polynomial.  With a small-enough stepsize, the algorithm does converge, but requiring the large number of function evaluations above.  Here are some stepsize values for the example and the associated absolute error:&lt;/p&gt;

&lt;p&gt;n 8 error 0.05738431110184819&lt;br/&gt;
n 28 error 0.027423287634332688&lt;br/&gt;
n 100 error 8.62162720248888E-5&lt;br/&gt;
n 249 error 5.308122631570711E-4&lt;br/&gt;
n 650 error 4.3582615516528367E-4&lt;br/&gt;
n 1641 error 2.519984967931377E-4&lt;br/&gt;
n 3829 error 5.838605030586419E-5&lt;br/&gt;
...&lt;br/&gt;
 n 1102593 error 6.71416523906343E-8&lt;/p&gt;

&lt;p&gt;The last entry is from the last (26th) iteration.  I haven't verified the rationale for the updating formula for n above, but it does appear warranted in this case to increase n quickly as large n (= small stepsize) is required to get a decent estimate of the integral using Gaussian quadrature.&lt;/p&gt;
, &lt;p&gt;Perhaps we should also provide higher order formulas, using either a fixed set of precomputed constants or a way to compute the coefficients for any order.&lt;/p&gt;
, &lt;p&gt;Moving to 3.0.  I don't think this is a bug, but points to a couple of possible enhancements:&lt;/p&gt;

&lt;p&gt;1) higher order formulas (+0 on this suggestion from Luc - IMO the example and others like it are not suitable for Legendre-Gauss)&lt;br/&gt;
2) bound on the number of function evaluations (I vaguely recall us talking about this elsewhere, but can't find the reference.  If anyone else can, pls add.)&lt;/p&gt;
, &lt;p&gt;We restarted a thread about this a few days after the previous comment on this issue.&lt;br/&gt;
The thread can be read here: &lt;a href="http://markmail.org/thread/rnazrggnnuehz4qv"&gt;http://markmail.org/thread/rnazrggnnuehz4qv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think adding maxEvaluations while still preserving the existing maxIterations would be fine.&lt;/p&gt;
, &lt;p&gt;Coming back to this issue.&lt;/p&gt;

&lt;p&gt;I would propose to follow the same pattern we used for root solvers: adding a maxEval parameter in the top level integrate interface declaration. So we would have the same kind of configuration, with tolerances set at integrator/solver level and maxEval and function pointer passed at integrate/solve method call.&lt;/p&gt;

&lt;p&gt;Since we are just in the phase we change interfaces, this would be a good time to add this parameter.&lt;/p&gt;

&lt;p&gt;Does this seems reasonable ?&lt;/p&gt;
, &lt;p&gt;+1 for your suggestion, Luc.  Lets try to get this into 3.0.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1160914.&lt;/p&gt;

&lt;p&gt;The API of the integrators has been changed for consistency with solvers API. Now the main convergence parameters are set in the constructor and remain fixed, but a maximal number of function evaluation must be provided at each call to the integration method.&lt;/p&gt;

&lt;p&gt;Thanks for the report&lt;/p&gt;
], resolution=Fixed, reporter=murkle, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=180, timeSpent=null]
2016-01-13 22:04:32,667 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-453
2016-01-13 22:04:32,667 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-453, created=Mon Dec 06 03:01:08 CET 2010, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Mon Dec 06 13:53:56 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function, link=https://issues.apache.org/jira/browse/MATH-453, description=&lt;p&gt;RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function.&lt;/p&gt;

&lt;p&gt;As this explains how to recode deprecated method calls, it ought to be corrected before release.&lt;/p&gt;, comments=[&lt;p&gt;Removed references to the &lt;tt&gt;analysis.function&lt;/tt&gt; package (revision 1042610).&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[erans], commentAuthors=[erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,683 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-434
2016-01-13 22:04:32,683 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-434, created=Sun Nov 07 04:55:32 CET 2010, updated=Sat Mar 24 17:16:29 CET 2012, resolved=Sat Apr 09 21:21:59 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=SimplexSolver returns unfeasible solution, link=https://issues.apache.org/jira/browse/MATH-434, description=&lt;p&gt;The SimplexSolver is returning an unfeasible solution:&lt;/p&gt;

&lt;p&gt;import java.util.ArrayList;&lt;br/&gt;
import java.text.DecimalFormat;&lt;br/&gt;
import org.apache.commons.math.linear.ArrayRealVector;&lt;br/&gt;
import org.apache.commons.math.optimization.GoalType;&lt;br/&gt;
import org.apache.commons.math.optimization.OptimizationException;&lt;br/&gt;
import org.apache.commons.math.optimization.linear.*;&lt;/p&gt;

&lt;p&gt;public class SimplexSolverBug {&lt;/p&gt;

&lt;p&gt;    public static void main(String[] args) throws OptimizationException {&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction c = new LinearObjectiveFunction(new double[]{0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d}, 0.0d);&lt;/p&gt;

&lt;p&gt;        ArrayList&amp;lt;LinearConstraint&amp;gt; cnsts = new ArrayList&amp;lt;LinearConstraint&amp;gt;(5);&lt;br/&gt;
        LinearConstraint cnst;&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, -0.1d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.EQ, -0.1d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, -1e-18d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 1.0d, 0.0d, -0.0128588d, 1e-5d}, Relationship.EQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 0.0d, 1.0d, 1e-5d, -0.0128586d}, Relationship.EQ, 1e-10d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, -1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, -1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, 1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;/p&gt;

&lt;p&gt;        DecimalFormat df = new java.text.DecimalFormat("0.#####E0");&lt;/p&gt;

&lt;p&gt;        System.out.println("Constraints:");&lt;br/&gt;
        for(LinearConstraint con : cnsts) {
            for (int i = 0; i &amp;lt; con.getCoefficients().getDimension(); ++i)
                System.out.print(df.format(con.getCoefficients().getData()[i]) + " ");
            System.out.println(con.getRelationship() + " " + con.getValue());
        }&lt;/p&gt;

&lt;p&gt;        SimplexSolver simplex = new SimplexSolver(1e-7);&lt;br/&gt;
        double[] sol = simplex.optimize(c, cnsts, GoalType.MINIMIZE, false).getPointRef();&lt;br/&gt;
        System.out.println("Solution:\n" + new ArrayRealVector(sol));&lt;br/&gt;
        System.out.println("Second constraint is violated!");&lt;br/&gt;
    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;It's an odd problem, but something I ran across.  I tracked the problem to the getPivotRow routine in SimplexSolver.  It was choosing a pivot that resulted in a negative right-hand-side.  I recommend a fix by replacing&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
                ...&lt;br/&gt;
with&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;br/&gt;
                ...&lt;/p&gt;

&lt;p&gt;I believe this would be more appropriate (and at least resolves this particular problem).&lt;/p&gt;

&lt;p&gt;Also, you may want to consider making a change in getPivotColumn to replace&lt;br/&gt;
            ...&lt;br/&gt;
            if (MathUtils.compareTo(tableau.getEntry(0, i), minValue, epsilon) &amp;lt; 0) {&lt;br/&gt;
            ...&lt;br/&gt;
with&lt;br/&gt;
            ...&lt;br/&gt;
            if (tableau.getEntry(0, i) &amp;lt; minValue) &lt;br/&gt;
            ...&lt;br/&gt;
because I don't see the point of biasing earlier columns when multiple entries are within epsilon of each other.  Why not pick the absolute smallest.  I don't know that any problem can result from doing it the other way, but the latter may be a safer bet.&lt;/p&gt;

&lt;p&gt;VERY IMPORTANT: I discovered another bug that occurs when not restricting to non-negatives.  In SimplexTableu::getSolution(), &lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) &lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = 0;&lt;br/&gt;
          ...&lt;br/&gt;
should be&lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) {&lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = (restrictToNonNegative ? 0 : -mostNegative);&lt;br/&gt;
          ...&lt;br/&gt;
If necessary, I can give an example of where this bug causes a problem, but it should be fairly obvious why this was wrong.&lt;/p&gt;, comments=[&lt;p&gt;My original suggested fix had a potential for overflow errors (since minRatio is initialized to Double.MAX_VALUE).  Also, I added another suggestion and pointed out another bug which leads to invalid solutions.&lt;/p&gt;
, &lt;p&gt;Could you attach unit tests that demonstrate each problem?  Thank you.&lt;/p&gt;
, &lt;p&gt;I'll try to send some examples soon.  I'm noticing more problems with the right-hand-side going negative and want to cover all bases (as much as possible).&lt;/p&gt;
, &lt;p&gt;Code, and resulting output, that illustrates issues with the SimplexSolver.&lt;/p&gt;
, &lt;p&gt;Pushing out to 3.0.&lt;/p&gt;
, &lt;p&gt;Hey, sorry I took so long to look at this.  I've had very little time and am not working on this stuff anymore.  I'm honestly not going to be able to look at this stuff much moving forward, so hopefully there's a Commons Math contributor that can act as a reviewer.&lt;/p&gt;

&lt;p&gt;When you say it's choosing a pivot with a negative RHS, I'm assuming that means it's not within the epsilon?&lt;br/&gt;
Why would it be more appropriate to divide by the entry?  I'm not sure I see why you'd want to use a bigger epsilon when the entry is 0.1 and a smaller epsilon when the entry is 10.  Maybe we should just make the default epsilon smaller?  I'm no expert with floating point math so I'm not real sure how to set the epsilon and just made up a value.&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
...&lt;br/&gt;
with&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;/p&gt;
, &lt;p&gt;Attached a patch for the reported problems.&lt;br/&gt;
The problems can be split into two groups:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;wrong solution calculation with negative&lt;br/&gt;
   variables&lt;/li&gt;
	&lt;li&gt;failing to select an appropriate pivot&lt;br/&gt;
   row when values are below a given &lt;br/&gt;
   epsilon&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch addresses both problems:&lt;/p&gt;

&lt;p&gt; 1. fix in SimplexTableau.getSolution()&lt;br/&gt;
 2. use BigReal for arbitrary precision  &lt;br/&gt;
    support when selecting the pivot row&lt;/p&gt;

&lt;p&gt;Additionally, 4 test cases are included, as well as a minor typo fix for a method name.&lt;/p&gt;

&lt;p&gt;The fixed epsilon is also used in some other places of the code, this may also create problems under certain circumstances. So if this patch is accepted, the other places could also be adapted.&lt;/p&gt;
, &lt;p&gt;Thanks Thomas.&lt;/p&gt;

&lt;p&gt;I had a look at the patch. I'm not a big fan of using BigReal, mainly when we don't specify a scale and we don't link it to the choice for epsilon. Also reading back Ben comments, I wonder if we should not replace epsilon by an integer number of ulps with a default set to a very small value (say something like 10 ulps).&lt;/p&gt;

&lt;p&gt;What problem did you see in the accuracy of the variables to use BigReal ?&lt;/p&gt;
, &lt;p&gt;Hi Luc,&lt;/p&gt;

&lt;p&gt;my initial idea was to use an epsilon that is adjusted to the magnitude of the respective value used for comparison. To be honest, I was not aware of &lt;span class="error"&gt;&amp;#91;Math,FastMath&amp;#93;&lt;/span&gt;.ulp, therefore I went with BigReal/BigDecimal to circumvent the problem in another way (by using an arbitrary precision datatype). After reading your comment, I investigated more into the problem, e.g. using &lt;a href="http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm"&gt;http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm&lt;/a&gt;, and addressed it (hopefully correct) in the way you proposed.&lt;/p&gt;

&lt;p&gt;Though, I had to split up the epsilon test into two categories:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;general comparison of floating-point values: using ulp, as values can be arbitrarily small&lt;/li&gt;
	&lt;li&gt;algorithm convergence check: using a standard epsilon, as the algorithm may not converge due to limited precision of&lt;br/&gt;
    the double datatype otherwise&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Please find attached my updated patch, any comments are welcome (e.g. I was unsure whether to expose the maxUlps parameter in the constructor, or to use a generic comparison epsilon, e.g. using FastMath.ulp(1d) instead of one adjusted to the current value in question).&lt;/p&gt;
, &lt;p&gt;updated patch, incorporating comments from luc&lt;/p&gt;
, &lt;p&gt;&lt;span class="error"&gt;&amp;#91;Pardon the possibly nave questions.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In "SimplexTableau":&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Why not use directly "equals(double, double, int)" from "MathUtils" instead of computing an epsilon with "getEpsilon"?&lt;/li&gt;
	&lt;li&gt;Why is the "isOptimal" method not using the adjusted "epsilon" (at line 385)?&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;hmm, I feel a bit stupid now, as I have re-implemented MathUtils.equals(double, double, int) but in a mediocre way. So all calls to getEpsilon should be replaced with the equivalent MathUtils.equals.&lt;/p&gt;

&lt;p&gt;for the isOptimal:&lt;/p&gt;

&lt;p&gt;the idea was to have a user-defined threshold for the convergence criteria, which defaults to the original value of 1e-6. Using the same adjusted epsilon would possibly lead to more iterations as before. As the feasibility check in SimplexSolver.solvePhase1 has to use a static epsilon for convergence reasons, I thought to use the same epsilon in isOptimal makes sense for symmetry reasons (use the same epsilon to check for convergence /feasibility).&lt;/p&gt;

&lt;p&gt;But it's good that you raise these points, because I was hesitating myself what is the best way to go forward, as I am also not considering myself a floating-point expert. I am mainly interested in the simplex algorithm, that's why I have chosen to provide a patch for this (very nice) implementation of it.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1090656.&lt;br/&gt;
Path applied with a very small change: adding the maxUlps parameter to the detailed constructor.&lt;/p&gt;

&lt;p&gt;Thanks for the report and thanks for the patch.&lt;/p&gt;
, &lt;p&gt;Thanks for accepting the patch. The comparison using maxUlps has already been adapted according to &lt;a href="https://issues.apache.org/jira/browse/MATH-557" title="add a compareTo method to MathUtils that use a number of ulps for equality tolerance"&gt;&lt;del&gt;MATH-557&lt;/del&gt;&lt;/a&gt;, but it was missing for SimplexTableau. The cleanup patch fixes this and also renames the test names for similarity.&lt;/p&gt;
, &lt;p&gt;Cleanup patch applied.&lt;/p&gt;

&lt;p&gt;thanks again&lt;/p&gt;
], resolution=Fixed, reporter=wmwitzel, assignees=[], commentAuthors=[wmwitzel, erans, psteitz, bmccann, tn, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,683 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-429
2016-01-13 22:04:32,683 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-429, created=Fri Oct 22 10:01:54 CEST 2010, updated=Wed Mar 23 21:25:46 CET 2011, resolved=Sat Oct 23 21:35:26 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Blocker, summary=KMeansPlusPlusClusterer breaks by division by zero, link=https://issues.apache.org/jira/browse/MATH-429, description=&lt;p&gt;For a certain space, KMeansPlusPlusClusterer  breaks. This is a blocker because this space occurs in our domain. &lt;/p&gt;, comments=[&lt;p&gt;The testcase which breaks KMeansPlusPlusClusterer&lt;/p&gt;
, &lt;p&gt;You have encountered one classical problem with k-means: at some stage (here at the first iteration), one of the clusters becomes empty.&lt;br/&gt;
This case is currently no handled by commons-math (which is a bug, so we have to fix it).&lt;br/&gt;
When a cluster is empty, a new centroid must be defined from the other clusters. There are different strategies:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;take the point farthest from any cluster&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest distance variance&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest number of points&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;My prefered choice would be 2, what do other people think ?&lt;/p&gt;
, &lt;p&gt;How about make it configurable?  Take a look at how the Mallet project did it:&lt;/p&gt;

&lt;p&gt;&lt;a href="http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html"&gt;http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By the way, I have suggested that they try to enter the Incubator here at the ASF and they seem somewhat receptive to the idea!&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1026666 for branche 2.X and as of r1026667 for trunk.&lt;br/&gt;
Users can now choose among four different strategies to deal with empty clusters:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;split the cluster with largest distance variance,&lt;/li&gt;
	&lt;li&gt;split the cluster with largest number of points,&lt;/li&gt;
	&lt;li&gt;create a cluster around the point farthest from its centroid,&lt;/li&gt;
	&lt;li&gt;generate an error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The default is to split according to largest variance.&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erikvaningen, assignees=[], commentAuthors=[erikvaningen, luc, jwcarman], timeEstimate=180, timeSpent=null]
2016-01-13 22:04:32,698 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-421
2016-01-13 22:04:32,698 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-421, created=Wed Sep 29 20:24:56 CEST 2010, updated=Wed Mar 23 21:23:12 CET 2011, resolved=Wed Sep 29 21:51:49 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=restarting an ODE solver that has been stopped by an event doesn't work, link=https://issues.apache.org/jira/browse/MATH-421, description=&lt;p&gt;If an ODE solver is setup with an EventHandler that return STOP when the even is triggered, the integrators stops (which is exactly the expected behavior).&lt;br/&gt;
If however the user want to restart the solver from the final state reached at the event with the same configuration (expecting the event to be triggered again at a later time), then the integrator may fail to start. It can get stuck at the previous event.&lt;/p&gt;

&lt;p&gt;The occurrence of the bug depends on the residual sign of the g function which is not exactly 0, it depends on the convergence of the first event.&lt;/p&gt;

&lt;p&gt;As this use case is fairly general, event occurring less than epsilon after the solver start in the first step should be ignored, where epsilon is the convergence threshold of the event. The sign of the g function should be evaluated after this initial ignore zone, not exactly at beginning (if there are no event at the very beginning g(t0) and g(t0+epsilon) have the same sign, so this does not hurt ; if there is an event at the very beginning, g(t0) and g(t0+epsilon) have opposite signs and we want to start with the second one. Of course, the sign of epsilon depend on the integration direction (forward or backward).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository, as of r1002827 for branch 2.X and 1002829 for trunk (3.0)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,698 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-414
2016-01-13 22:04:32,698 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-414, created=Tue Aug 31 13:01:44 CEST 2010, updated=Wed Mar 23 21:20:43 CET 2011, resolved=Tue Nov 30 12:57:23 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=ConvergenceException in NormalDistributionImpl.cumulativeProbability(), link=https://issues.apache.org/jira/browse/MATH-414, description=&lt;p&gt;I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.&lt;br/&gt;
For instance in the following code:&lt;/p&gt;

&lt;p&gt;	@Test&lt;br/&gt;
	public void testCumulative() {&lt;br/&gt;
		final NormalDistribution nd = new NormalDistributionImpl();&lt;br/&gt;
		for (int i = 0; i &amp;lt; 500; i++) {&lt;br/&gt;
			final double val = Math.exp&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/information.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt;;&lt;br/&gt;
			try {
				System.out.println("val = " + val + " cumulative = " + nd.cumulativeProbability(val));
			} catch (MathException e) {
				e.printStackTrace();
				fail();
			}&lt;br/&gt;
		}&lt;br/&gt;
	}&lt;/p&gt;

&lt;p&gt;In version 2.0, I get no exception. &lt;/p&gt;

&lt;p&gt;My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.&lt;/p&gt;, comments=[&lt;p&gt;The difference between 2.0 and 2.1 is due to the changes in ContinuedFraction included in the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-282" title="ChiSquaredDistributionImpl.cumulativeProbability &amp;gt; 1"&gt;&lt;del&gt;MATH-282&lt;/del&gt;&lt;/a&gt;.  For very large values, continued fractions are diverging to NaN. The suggested fix will work, but at this point, I wonder if we should just move the top-coding out of the catch - i.e., test the arguments and return 0 or 1 for extreme values without attempting the approximation.&lt;/p&gt;
, &lt;p&gt;I am leaning toward adding top-coding outside of the catch.  Based on the inequality p(Z &amp;gt; t) &amp;lt; exp(-t^2/2) derived in &lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; and Double.MIN_VALUE  = 2^-1074, I get that tail probabilities are not distinguishable from 0 for |t| &amp;gt; 39, so I propose that we top-code at 40 outside the catch.  Appreciate others checking my arithmetic.&lt;/p&gt;

&lt;p&gt;&lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href="http://www.johndcook.com/normalbounds.pdf"&gt;http://www.johndcook.com/normalbounds.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Your suggestion seems good to me.&lt;br/&gt;
I've check exp(-t^2/2) becomes lower than Double.MIN_VALUE/2 (i.e. rounds to 0) when |t|&amp;gt; 38.604&lt;/p&gt;
, &lt;p&gt;Fixed in r1040471&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=gustav.ryd, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=120, timeSpent=null]
2016-01-13 22:04:32,698 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-411
2016-01-13 22:04:32,698 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-411, created=Sun Aug 29 00:14:32 CEST 2010, updated=Wed Mar 23 21:20:06 CET 2011, resolved=Mon Sep 13 04:04:01 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression newSampleData methods inconsistently create / omit intercepts, link=https://issues.apache.org/jira/browse/MATH-411, description=&lt;p&gt;The newSampleData(double[], nrows, ncols) method used in the unit tests adds a unitary column to the design matrix, resulting in an intercept term being estimated among the regression parameters.  The other newSampleData methods do not do this, forcing users to add the column of "1"s to estimate models with intercept.  Behavior should be consistent and users should not have to add the column.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r993574.  Modified multiple regression newSample methods to ensure that by default in all cases, regression models are estimated with intercept terms.  Prior to the fix for this issue,  newXSampleData(double[][]), newSampleData(double[], double[][]) and newSampleData(double[], double[][], double[][]) all required columns of "1's  to be inserted into the x[][] arrays to create a model with an intercept term;while newSampleData(double[], int, int) created a model including an intercept term without requiring the unitary column.  All methods have  been changed to eliminate the need for users to add unitary columns to specify regression models.&lt;/p&gt;

&lt;p&gt;Leaving open until &lt;a href="https://issues.apache.org/jira/browse/MATH-409" title="Multiple Regression API should allow specification of whether or not to estimate intercept term"&gt;&lt;del&gt;MATH-409&lt;/del&gt;&lt;/a&gt; is resolved. &lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,698 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-409
2016-01-13 22:04:32,698 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-409, created=Tue Aug 24 11:55:32 CEST 2010, updated=Wed Mar 23 21:19:13 CET 2011, resolved=Mon Sep 13 04:02:43 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression API should allow specification of whether or not to estimate intercept term, link=https://issues.apache.org/jira/browse/MATH-409, description=&lt;p&gt;The OLS and GLS regression APIs should support estimating models including intercepts using design matrices including only variable data.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r996404 (both trunk and 2.x branch)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,698 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-408
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-408, created=Mon Aug 23 05:11:23 CEST 2010, updated=Wed Mar 23 21:18:48 CET 2011, resolved=Sun Dec 12 22:49:44 CET 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=GLSMultipleLinearRegression has no nontrivial validation tests, link=https://issues.apache.org/jira/browse/MATH-408, description=&lt;p&gt;There are no non-trivial tests verifying the computations for GLSMultipleLinearRegression.  Tests verifying computations against analytically determined models, R or some other reference package / datasets should be added to ensure that the statistics reported by this class are valid.&lt;/p&gt;, comments=[&lt;p&gt;Added a non-trivial test in r1044935.  While still not really a full verification test, it does at least verify that the GLS impl provided does better than OLS for models with error structure conforming to its covariance matrix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-407
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-407, created=Mon Aug 23 05:07:08 CEST 2010, updated=Wed Mar 23 21:18:29 CET 2011, resolved=Mon Sep 20 03:57:59 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Documentation improvements for multiple regression classes, link=https://issues.apache.org/jira/browse/MATH-407, description=&lt;p&gt;The user guide examples showing how to set up and estimate linear models using OLS and GLS multiple regression need to be updated to reflect changes in the API.  The javadoc for these classes and user guide descriptions also need to be improved to make it clear how to estimate a model with an intercept term.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r998761&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-406
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-406, created=Sat Aug 14 23:57:56 CEST 2010, updated=Wed Mar 23 21:18:04 CET 2011, resolved=Sun Aug 15 00:02:03 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Wrong weight handling in Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-406, description=&lt;p&gt;A comparison with a Fortran version of Levenberg-Marquardt reveals that when observations have different weights, the 2.1 version reaches a value of the function which does not necessary correspond to the minimum&lt;/p&gt;, comments=[&lt;p&gt;Correction patch.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-405
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-405, created=Wed Aug 11 15:24:39 CEST 2010, updated=Wed Mar 23 21:17:42 CET 2011, resolved=Wed Aug 11 15:46:55 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Inconsistent result from Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-405, description=&lt;p&gt;Levenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost&lt;/p&gt;, comments=[&lt;p&gt;Correction patch&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-404
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-404, created=Mon Aug 09 13:44:12 CEST 2010, updated=Sat Mar 24 17:17:04 CET 2012, resolved=Mon Aug 30 15:53:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Confusing interface for "LevenbergMarquardtOptimizer", link=https://issues.apache.org/jira/browse/MATH-404, description=&lt;p&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; which in turn implements &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt;. That interface mandates methods for setting and getting a &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;.&lt;br/&gt;
In v2.1, however, that checker is never used! The convergence check is performed using parameters specific to the Levenberg-Marquardt algorithm. Such circumvention of the superclass interface is confusing and leads to totally unexpected behaviour (such as changing the values of the thresholds of the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; being ineffective).&lt;br/&gt;
In the development version, the default constructor of &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; sets the the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; field to "null" and when such is the case, the behaviour is as in v2.1. Although it is documented, this is still confusing since it is impossible to use &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; through its &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt; interface: When using the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;, one does not know what parameters to use in order to reproduce the results obtained with the LM-specific convergence check (i.e. how to reproduce the result from v2.1).&lt;br/&gt;
Unless I'm missing something, I think that there should be an LM-specific implementation of &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; that, when given the usual relative and absolute thresholds, can perform a check that will give the same result as the currently specific check (when the "checker" field is "null").&lt;/p&gt;, comments=[&lt;p&gt;The problem was identified and discussed as &lt;a href="https://issues.apache.org/jira/browse/MATH-362" title="LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it"&gt;&lt;del&gt;MATH-362&lt;/del&gt;&lt;/a&gt;. It was decided to let both convergence methods available.&lt;/p&gt;

&lt;p&gt;The reason there are two different way is that the Levenberg-Marquardt implementation originally came from Netlib and I kept the way it behaved. I think the general interface with the new generic convergence was set up later and at that time I forgot to implement it properly, so the settings were ignored.&lt;/p&gt;

&lt;p&gt;Reporter of issue 362 explicitly asked to keep the ortho-tolerance setting and this setting does not fit with the general scheme.&lt;/p&gt;
, &lt;p&gt;Sorry I hadn't followed that other report.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was decided to let both convergence methods available. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is &lt;tt&gt;null&lt;/tt&gt; or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;

&lt;p&gt;As explained above, from an OOP point-of-view, it is surprising that a class completely circumvents its base class interface.&lt;br/&gt;
At least one of the following is wrong:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; has a second interface for convergence checking&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; defines the interface for  convergence checking&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; does not fit with the general scheme.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;br/&gt;
Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;

&lt;p&gt;If it is really impossible to fit LM within the hierarchy it currently belongs to, then it should not belong to it, since one cannot leverage the advantages of "interface programming" anyways.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is null or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or LevenbergMarquardtOptimizer needs to be changed and the orthogonality concept be finally discarded.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I know, and I am not happy with this. However, I don't want LevenbergMarquardtOptimizer to be special. It &lt;em&gt;must&lt;/em&gt; fit. We can take the opportunity of a 3.0 major release to fix this problem too, with some incompatible changes. What would you propose for this ?&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;What would you propose for this ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don't know.&lt;/p&gt;

&lt;p&gt;However, it seems that this "non-fitting checker" case is not isolated. I wanted to replace the original check in "BrentOptimizer" (package "optimization.univariate") by a call to an appropriate subclass of "RealConvergenceChecker", but here too there are more values to be considered than those stored in a pair of "RealPointValuePair". The check needs&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the "current" point&lt;/li&gt;
	&lt;li&gt;the points at both interval ends&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;but it does not use the "previous" point.&lt;/p&gt;

&lt;p&gt;So it seems that this also does not fit with the "converged" method of the "RealConvergenceChecker" interface.&lt;/p&gt;

&lt;p&gt;At first sight, I'd say that there should be a more general "ConvergenceChecker" (not existing yet) interface. Maybe using generics...&lt;/p&gt;
, &lt;p&gt;I'm trying to define a more general "ConvergenceChecker" interface. This is an incompatible change.&lt;/p&gt;
, &lt;p&gt;Final resolution is delegated to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-413"&gt;MATH-413&lt;/a&gt;.&lt;/p&gt;
], resolution=Unknown, reporter=erans, assignees=[erans], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-395
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-395, created=Sun Jul 25 23:26:33 CEST 2010, updated=Wed Mar 23 21:14:58 CET 2011, resolved=Wed Jul 28 14:11:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Bugs in "BrentOptimizer", link=https://issues.apache.org/jira/browse/MATH-395, description=&lt;p&gt;I apologize for having provided a buggy implementation of Brent's optimization algorithm (class "BrentOptimizer" in package "optimization.univariate").&lt;br/&gt;
The unit tests didn't show that there was something wrong, although (from the "changes.xml" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.&lt;br/&gt;
Comparing with an implementation in Python, I could figure out the fixes. I'll modify "BrentOptimizer" and add a test. I also propose to change the name of the unit test class from "BrentMinimizerTest" to "BrentOptimizerTest".&lt;/p&gt;, comments=[&lt;p&gt;Bugs corrected in revision 979257.&lt;br/&gt;
Not resolving yet because the implementation still does not behave as the Python one. I've added a unit test that indicates the discrepancies (with "XXX" markers).&lt;/p&gt;
, &lt;p&gt;Last bug fixed in revision 980032.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;This revision also contains the modifications due to the changes in &amp;quot;AbstractUnivariateRealOptimizer&amp;quot;.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The test comparing with Python has been removed because a tracing of the execution paths (in Python and Java) showed that the remaining discrepancies were due to different values being used for the "golden ratio" constant.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[erans], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-392
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-392, created=Wed Jul 21 20:43:10 CEST 2010, updated=Wed Mar 23 21:13:58 CET 2011, resolved=Sun Aug 22 15:16:29 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=calculateYVariance in OLS/GLSMultipleLinearRegression uses residuals not Y vars, link=https://issues.apache.org/jira/browse/MATH-392, description=&lt;p&gt;Implementation of OLS/GLSMultipleLinearRegression is:&lt;br/&gt;
@Override&lt;br/&gt;
173        protected double calculateYVariance() {
174            RealVector residuals = calculateResiduals();
175            return residuals.dotProduct(residuals) /
176                   (X.getRowDimension() - X.getColumnDimension());
177        }&lt;/p&gt;

&lt;p&gt;This gives variance of residuals not variance of the dependent (Y) variable as the documentation suggests.&lt;/p&gt;, comments=[&lt;p&gt;Thank you for reporting this.  Patches welcome!&lt;/p&gt;
, &lt;p&gt;Can't test a patch as I'm not able to build current repository version:&lt;br/&gt;
math/src/test/java/org/apache/commons/math/optimization/univariate/BrentOptimizerTest.java:&lt;span class="error"&gt;&amp;#91;28,39&amp;#93;&lt;/span&gt; cannot find symbol&lt;br/&gt;
symbol  : class SincFunction&lt;/p&gt;

&lt;p&gt;Implementation for both GLS/OLS:&lt;/p&gt;

&lt;p&gt;protected double calculateYVariance() {
    return new Variance().evaluate(Y);
}&lt;/p&gt;
, &lt;p&gt;There was an error in a file committed this afternoon. It should be OK now.&lt;/p&gt;
, &lt;p&gt;corrected implementations of calculateYVariance() for OLS/GLSMultipleRegression&lt;/p&gt;

&lt;p&gt;added unit tests for both calculateYVariance implementations&lt;/p&gt;

&lt;p&gt;fixed AbstractMultipleRegression.estimateRegressionParametersStandardErrors() to use residuals &lt;/p&gt;
, &lt;p&gt;Fixed in 987897.   I added calcluate/estimateErrorVariance methods to return what was previously incorrectly reported as "Y variance."&lt;br/&gt;
Thanks for the patch!&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=markdevaney, assignees=[], commentAuthors=[psteitz, markdevaney, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-391
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-391, created=Wed Jul 21 10:57:46 CEST 2010, updated=Wed Mar 23 21:13:27 CET 2011, resolved=Sun Oct 03 18:43:11 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Inconsistent behaviour of constructors in ArrayRealVector class, link=https://issues.apache.org/jira/browse/MATH-391, description=&lt;p&gt;ArrayRealVector(double[] d) allows to construct a zero-length vector, but ArrayRealVector(double[] d, boolean copyArray) doesn't. Both should allow this as zero-length vectors are mathematically well-defined objects and they are useful boundary cases in many algorithms.&lt;/p&gt;

&lt;p&gt;This breaks some arithmetic operators (addition) on zero-length real vectors which worked in 2.0 but don't work in 2.1&lt;/p&gt;, comments=[&lt;p&gt;I agree that the code should be consistent.  I agree as well that a zero-dimensional vector is legit.   Can anyone explain why ArrayRealVector(double[] d, boolean copyArray) requires positive length?&lt;/p&gt;
, &lt;p&gt;Most probably my bad ...&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1003993 for barnch 2.X and r1003994 for trunk.&lt;br/&gt;
Note that the same problem occurred also in ArrayFieldVector but the fix is different. For Field-based vectors, we need to get the field, so either we use a non-empty array and retrieve the field from the first array element or we add a parameter for the field and allow the array to be empty. The two choices are now possible, as new constructors have been added and the javadoc updated to explain this behavior.&lt;br/&gt;
Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-390
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-390, created=Wed Jul 21 00:47:21 CEST 2010, updated=Wed Jul 21 01:32:12 CEST 2010, resolved=Wed Jul 21 01:32:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Major, summary=Simplex Solver is very inaccurate on a large problem, even a very low value for epsilon, link=https://issues.apache.org/jira/browse/MATH-390, description=&lt;p&gt;I'm currently playing with a program for solving a rather simple chess puzzle. The goal is to place 12 knights on a 8x8 board, such that each field is either attacked by a knight, or contains a knight. To solve this problem (and different variants) I want to use a handcrafted Branch and Bound algorithm that uses Linear Programming to calculate an upperbound on the number of fields that can be covered by a certain amount of knights.&lt;/p&gt;

&lt;p&gt;The idea is to create variables for each field that has to be covered, and to create variables for each field to contain a knight. A cover variable can only become positive if a corresponding knight variable for an adjacent field is also positive, there is a limit to the amount of knights we may place (so the sum of all knight variables cannot be larger than 12) and the cover variables cannot be larger than one. Also, only the cover variables have a coefficient of one in the objective function, all other variables have zero. Because we want to cover the entire board our goal will be to maximize the objective function, since we want to maximize the number of fields that are covered.&lt;/p&gt;

&lt;p&gt;Since a basic chessboard has 64 fields and since it is possible to cover the chessboard with 12 knights, we know there is an integer solution that has value 64. Since we are solving a relaxed variant of the problem, the value should be at least 64. However, when I use the Simplex Solver, I get a value of around 58.6, which is much too low. Even when I relax the constraints in such a fashion that 64 knights may be placed on the board, the solution value remains the same. I've lowered the value of epsilon as much as I can and it still gives the incorrect value. What makes it worse is that the calculation is totally useless as an upperbound (if the value would have been around 70, it would have been an upperbound at least).&lt;/p&gt;

&lt;p&gt;I've heard that using the revised simplex method is a lot better with respect to stacked errors, so I am not sure this is really a bug, or just a problem that arises when the two phase simplex method is used for large problems.&lt;/p&gt;

&lt;p&gt;I will try to attach a code example that implements the problem (but possibly isn't that readable).&lt;/p&gt;, comments=[&lt;p&gt;Example of the 8x8 Knight covering Chess problem. The objective value should at least be 64, but it is around 59.&lt;/p&gt;
, &lt;p&gt;Hmm, it seems I made a programming mistake in the type of the relationship: I used an equality where I should have used a greater-equals. I created a much nicer version of the example, which actually works. Feel free to use it for an example or something.&lt;/p&gt;

&lt;p&gt;My bad, I will close the issue.&lt;/p&gt;
, &lt;p&gt;The correct and more readable example, which actually works.&lt;/p&gt;
, &lt;p&gt;It seems I made a programming error. I included a correct example to solve the problem.&lt;/p&gt;
], resolution=Fixed, reporter=pcbouman, assignees=[], commentAuthors=[pcbouman], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,714 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-380
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-380, created=Thu Jun 24 18:47:54 CEST 2010, updated=Sat Mar 24 17:16:33 CET 2012, resolved=Sat Oct 01 15:54:20 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Minor, summary=Need to (re)initialize dYdY0 for multiple integrate with FirstOrderIntegratorWithJacobians, link=https://issues.apache.org/jira/browse/MATH-380, description=&lt;p&gt;There is a lack in the method integrate of FirstOrderIntegratorWithJacobians. The jacobian DYDY0 can't be initialized by the user, unlike DFDP with DF0DP.&lt;br/&gt;
So, for several successive integrations, the matrix is reinitialized to identity and that is not what we might want.&lt;/p&gt;, comments=[&lt;p&gt;You are perfectly right.&lt;/p&gt;

&lt;p&gt;The FirstOrderIntegratorWithJacobians class is a brand new one and it clearly has some design flaws.&lt;br/&gt;
It will most probably be deprecated in its current form and replaced by a new mechanism, better integrated (sorry for the joke) with the standard ODE solvers.&lt;br/&gt;
The ability for user to set an initial value for dydy0 will be present in the new design, but will probably not be back-ported to the current one.&lt;br/&gt;
In the meantime, you can save the final value of the jacobian matrix dydy0 after first part of integration, which we could call dy1dy0 as it represents dy(t1)/dy(t0). Start the second part from t1 to t2 that will reset the initial matrix to identity and hence compute compute dy(t2)/dy(t1) and do the multiplication by yourself of the two matrices to really get what you need: dy(t2)/dy(t1) = dy(t2)/dy(t1) * dy(t1)/dy(t0).&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue &lt;/p&gt;
, &lt;p&gt;changing target fix version to 3.0.&lt;br/&gt;
Fixing this and several other problems requires a complete rewrite of the jacobians computation with ODE, and this rewrite implies user interfaces changes, so it cannot be fixed before 3.0.&lt;/p&gt;
, &lt;p&gt;A first attempt to implement Jacobians computation again in ODE has been committed in subversion repository as of r1175409.&lt;br/&gt;
This implementation still lacks the ability for step handlers to also retrieve the additional equations and their derivatives.&lt;br/&gt;
This implementation is based on the Orekit one described here: &lt;a href="https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf"&gt;https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1176745.&lt;/p&gt;
], resolution=Fixed, reporter=pparraud, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-377
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-377, created=Thu Jun 17 11:06:03 CEST 2010, updated=Wed Mar 23 21:08:36 CET 2011, resolved=Sun Jul 25 21:49:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=weight versus sigma in AbstractLeastSquares, link=https://issues.apache.org/jira/browse/MATH-377, description=&lt;p&gt;In AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.&lt;/p&gt;

&lt;p&gt; Once corrected, getRMS() can even reduce&lt;/p&gt;

&lt;p&gt; public double getRMS() {return Math.sqrt(getChiSquare()/rows);}&lt;/p&gt;, comments=[&lt;p&gt;It is not clear to me exactly what is being computed in getChiSquare.  Step 0 is to get an actual definition in the javadoc for what it is trying to compute.  I agree it seems odd to be dividing by residual weights; but I could be missing the intent.&lt;/p&gt;
, &lt;p&gt;OK, let us define ChiSquare as the sum of the weighted square of the residual in order to be consistent with the rest of the definitions in that class.  That would also be consistent with what users expect from a parameter labeled 'weight' rather than 'sigma'.  If we reach consensus on that definition, I can take care of that issue.&lt;/p&gt;
, &lt;p&gt;I could be missing something, but I see no reason that the weighted sum of squared residuals computed here (after the proposed change) should in general follow a chi-square distribution or be related to a chi-square test statistic of any kind.   Why is it called chi-square?  Sorry if I am missing something simple here.&lt;/p&gt;
, &lt;p&gt;I guess if you assume normalliy distributed errors, it makes sense, so drop the last comment and I am +1 for the change (with definition added to the javadoc).&lt;/p&gt;
, &lt;p&gt;Indeed, the confusion comes from the fact that, in some textbooks, each residual is divided by 'sigma_i' which leads to a weight of 1/(sigma_i^2).  In CM, we adopted the terminology 'weight' without reference to sigma.  I will change the javadoc accordingly.&lt;/p&gt;
, &lt;p&gt;Patch to correct issue &lt;a href="https://issues.apache.org/jira/browse/MATH-377" title="weight versus sigma in AbstractLeastSquares"&gt;&lt;del&gt;MATH-377&lt;/del&gt;&lt;/a&gt;.  The change in getChiSquare let to a tiny update in one of Levenberg-Marquardt unit tests.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[psteitz, dimpbx, luc], timeEstimate=1, timeSpent=null]
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-373
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-373, created=Mon Jun 07 16:54:00 CEST 2010, updated=Sat Mar 24 17:16:56 CET 2012, resolved=Thu Sep 02 06:52:33 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=StatUtils.sum returns NaN for zero-length arrays, link=https://issues.apache.org/jira/browse/MATH-373, description=&lt;p&gt;StatUtils.sum returns NaN for zero-length arrays, which is:&lt;/p&gt;

&lt;p&gt;1. inconsistent with the mathematical notion of sum: in maths, sum_{i=0}^{N-1} a_i will be 0 for N=0. In particular, the identity&lt;br/&gt;
&lt;br/&gt;
sum_{i=0}^{k-1} a_i + sum_{i=k}^{N-1} = sum_{i=0}^{N-1}&lt;/p&gt;

&lt;p&gt;is broken for k = 0, since NaN + x = NaN, not x.&lt;/p&gt;

&lt;p&gt;2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition, as NaNs propagate silently and require manual tracing during the debugging)&lt;/p&gt;

&lt;p&gt;3. enforces "special case" handling when the user expects that the summed array can have a zero length.&lt;/p&gt;

&lt;p&gt;The correct behaviour is, in my opinion, to return 0.0, not NaN in the above case.&lt;/p&gt;, comments=[&lt;p&gt;I agree with the reasoning here, and we should do it this way in 3.0.  However it is an incompatible change to do in a point release, so I'm going to wait for more feed back from other developers before I make any changes to the current code.&lt;/p&gt;

&lt;p&gt;I'm thinking that adding a method to AbstractUnivariateStatistic that looks like:&lt;br/&gt;
   protected boolean test( final double[] values,  final int begin,   final int length, final boolean allowEmpty)&lt;/p&gt;

&lt;p&gt;that would have the test:&lt;br/&gt;
   if(length == 0 &amp;amp;&amp;amp; !allowEmpty)&lt;br/&gt;
        return false;&lt;/p&gt;

&lt;p&gt;The current test method can call the new one with allowEmpty=false for backwards compatibility.  Then we can decide on which statistics should have a zero value on the empty set.&lt;/p&gt;
, &lt;p&gt;The consensus of the commons-math developers is that, since the current behavior is documented in 2.x, that this will have to wait for 3.0.  Fixing this in 2.x would introduce a too large incompatibility change to include in 2.x.&lt;/p&gt;

&lt;p&gt;I can attach a patch against 2.x that fixes this, as long as anybody using the patch understands that it isn't supported.&lt;/p&gt;

, &lt;p&gt;Possibly crazy idea: &lt;/p&gt;

&lt;p&gt;if Math 3.0 is going to change package names (which may be necessary), one could introduce the fix using a math3 package name?&lt;/p&gt;
, &lt;p&gt;IIRC, changing the package name had been suggested and discussed for 2.0.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;One argument is that, to be consistent,  you&amp;#39;d have to change the name at every major release...&amp;#93;&lt;/span&gt;&lt;/p&gt;
, &lt;p&gt;Speaking as a maintainer of client code which uses ACM, I'd rather cope with occasional incompatibilities in the same packages, than have to change ALL my client code to keep up with the package name changes after every release. A reason to change the package name would be if you wanted to use the old and new version side by side, but that would not be a common usage pattern for ACM, I think.&lt;/p&gt;
, &lt;p&gt;As Gilles mentioned, changing the package name for commons-math was discussed and voted on for 2.x.  The result of the vote was to keep the package name, since commons-math won't usually be provided by a third party library.  Since nothing much has changed, I can't see that commons-math would change it's package for version 3.0.&lt;/p&gt;
, &lt;p&gt;This will be fixed in the 3.0 build.&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[billbarker, sebb@apache.org, erans, rwerp], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-369
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-369, created=Mon May 03 17:48:27 CEST 2010, updated=Wed Mar 23 21:05:06 CET 2011, resolved=Mon May 03 20:43:59 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Minor, summary=BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException, link=https://issues.apache.org/jira/browse/MATH-369, description=&lt;p&gt;Method &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  &lt;/p&gt;

&lt;p&gt;invokes &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(double min, double max) &lt;/p&gt;

&lt;p&gt;which throws NullPointerException, as member variable&lt;/p&gt;

&lt;p&gt;    UnivariateRealSolverImpl.f &lt;/p&gt;

&lt;p&gt;is null.&lt;/p&gt;

&lt;p&gt;Instead the method:&lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)&lt;/p&gt;

&lt;p&gt;should be called.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;/p&gt;

&lt;p&gt;invoke:&lt;/p&gt;

&lt;p&gt;     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);&lt;/p&gt;

&lt;p&gt;NullPointerException will be thrown.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository as of r940565.&lt;br/&gt;
Thanks for the report and for the fix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sasunpundev@abv.bg, assignees=[], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-368
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-368, created=Thu Apr 29 05:41:10 CEST 2010, updated=Wed Mar 23 21:04:17 CET 2011, resolved=Mon May 10 01:07:24 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=OpenMapRealVector.getSparcity should be getSparsity, link=https://issues.apache.org/jira/browse/MATH-368, description=&lt;p&gt;The term for describing the ratio of nonzero elements to zero elements in a matrix/vector is sparsity, not sparcity.  Suggest renaming getSparcity() to getSparsity()&lt;/p&gt;, comments=[&lt;p&gt;The policy of this project is to not remove methods from the public API in a point release.  However, the misspelled method has been deprecated and the correctly spelled method has been added.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-367
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-367, created=Thu Apr 22 20:31:06 CEST 2010, updated=Wed Mar 23 21:03:42 CET 2011, resolved=Mon May 10 03:17:14 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=AbstractRealVector.sparseIterator fails when vector has exactly one non-zero entry, link=https://issues.apache.org/jira/browse/MATH-367, description=&lt;p&gt;The following program:&lt;br/&gt;
===&lt;br/&gt;
import java.util.Iterator;&lt;br/&gt;
import org.apache.commons.math.linear.*;&lt;/p&gt;

&lt;p&gt;public class SparseIteratorTester&lt;br/&gt;
{&lt;br/&gt;
    public static void main(String[] args) {&lt;br/&gt;
        double vdata[] = { 0.0, 1.0, 0.0 };&lt;br/&gt;
        RealVector v = new ArrayRealVector(vdata);&lt;br/&gt;
        Iterator&amp;lt;RealVector.Entry&amp;gt; iter = v.sparseIterator();&lt;br/&gt;
        while(iter.hasNext()) {
            RealVector.Entry entry = iter.next();
            System.out.printf("%d: %f\n", entry.getIndex(), entry.getValue());
        }   &lt;br/&gt;
    }       &lt;br/&gt;
} &lt;br/&gt;
===&lt;br/&gt;
generates this output:&lt;/p&gt;

&lt;p&gt;1: 1.000000&lt;br/&gt;
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: -1&lt;br/&gt;
	at org.apache.commons.math.linear.ArrayRealVector.getEntry(ArrayRealVector.java:995)&lt;br/&gt;
	at org.apache.commons.math.linear.AbstractRealVector$EntryImpl.getValue(AbstractRealVector.java:850)&lt;br/&gt;
	at test.SparseIteratorTester.main(SparseIteratorTester.java:13)&lt;br/&gt;
===&lt;/p&gt;

&lt;p&gt;This patch fixes it, and simplifies AbstractRealVector.SparseEntryIterator  (sorry, i don't see any form entry for attaching a file)&lt;br/&gt;
===&lt;br/&gt;
Index: src/main/java/org/apache/commons/math/linear/AbstractRealVector.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(revision 936985)&lt;br/&gt;
+++ src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(working copy)&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.commons.math.linear;&lt;/p&gt;

&lt;p&gt; import java.util.Iterator;&lt;br/&gt;
+import java.util.NoSuchElementException;&lt;/p&gt;

&lt;p&gt; import org.apache.commons.math.FunctionEvaluationException;&lt;br/&gt;
 import org.apache.commons.math.MathRuntimeException;&lt;br/&gt;
@@ -875,40 +876,25 @@&lt;br/&gt;
         /** Dimension of the vector. */&lt;br/&gt;
         private final int dim;&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Temporary entry (reused on each call to {@link #next()}. */&lt;/li&gt;
	&lt;li&gt;private EntryImpl tmp = new EntryImpl();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;/** Current entry. */&lt;br/&gt;
+        /** Last entry returned by #next(). */&lt;br/&gt;
         private EntryImpl current;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Next entry. */&lt;br/&gt;
+        /** Next entry for #next() to return. */&lt;br/&gt;
         private EntryImpl next;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** Simple constructor. */&lt;br/&gt;
         protected SparseEntryIterator() {&lt;br/&gt;
             dim = getDimension();&lt;br/&gt;
             current = new EntryImpl();&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (current.getValue() == 0) {
-                advance(current);
-            }&lt;/li&gt;
	&lt;li&gt;if(current.getIndex() &amp;gt;= 0){
-                // There is at least one non-zero entry
-                next = new EntryImpl();
-                next.setIndex(current.getIndex());
+            next = new EntryImpl();
+            if(next.getValue() == 0)
                 advance(next);
-            } else {
-                // The vector consists of only zero entries, so deny having a next
-                current = null;
-            }&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Advance an entry up to the next non null one.&lt;br/&gt;
+        /** Advance an entry up to the next nonzero value.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param e entry to advance&lt;br/&gt;
          */&lt;br/&gt;
         protected void advance(EntryImpl e) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (e == null) {
-                return;
-            }&lt;br/&gt;
             do {
                 e.setIndex(e.getIndex() + 1);
             } while (e.getIndex() &amp;lt; dim &amp;amp;&amp;amp; e.getValue() == 0);&lt;br/&gt;
@@ -919,22 +905,17 @@&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;br/&gt;
         public boolean hasNext() {
-            return current != null;
+            return next.getIndex() &amp;gt;= 0;
         }&lt;br/&gt;
 &lt;br/&gt;
         /** {@inheritDoc} */&lt;br/&gt;
         public Entry next() {&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;tmp.setIndex(current.getIndex());&lt;/li&gt;
	&lt;li&gt;if (next != null) {&lt;/li&gt;
	&lt;li&gt;current.setIndex(next.getIndex());&lt;/li&gt;
	&lt;li&gt;advance(next);&lt;/li&gt;
	&lt;li&gt;if (next.getIndex() &amp;lt; 0) {
-                    next = null;
-                }&lt;/li&gt;
	&lt;li&gt;} else {
-                current = null;
-            }&lt;/li&gt;
	&lt;li&gt;return tmp;&lt;br/&gt;
+            int index = next.getIndex();&lt;br/&gt;
+            if(index &amp;lt; 0)&lt;br/&gt;
+                throw new NoSuchElementException();&lt;br/&gt;
+            current.setIndex(index);&lt;br/&gt;
+            advance(next);&lt;br/&gt;
+            return current;&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;/p&gt;, comments=[&lt;p&gt;patch fixing the bug&lt;/p&gt;
, &lt;p&gt;I've applied your patch (with a couple of style tweaks).  It should be available in the next release of commons-math.&lt;/p&gt;

&lt;p&gt;Thank you for your contribution.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[ashuang, billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-365
2016-01-13 22:04:32,730 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-365, created=Tue Apr 20 16:21:20 CEST 2010, updated=Wed Mar 23 21:02:52 CET 2011, resolved=Wed Apr 21 16:35:53 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=Issue with "SmoothingBicubicSplineInterpolator", link=https://issues.apache.org/jira/browse/MATH-365, description=&lt;p&gt;I figured out that the name of this class is misleading as the implementation doesn't perform the intended smoothing.&lt;/p&gt;

&lt;p&gt;In order to solve this issue, I propose to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;deprecate the "SmoothingBicubicSplineInterpolator" class&lt;/li&gt;
	&lt;li&gt;create a "BicubicSplineInterpolator" class (similar to the above class but with the useless code removed)&lt;/li&gt;
	&lt;li&gt;remove the "SmoothingBicubicSplineInterpolatorTest" class&lt;/li&gt;
	&lt;li&gt;add a "BicubicSplineInterpolatorTest" with essentially the same contents as the above one&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Then I would also add a new "SmoothingPolynomialBicubicSplineInterpolator" where I used the "PolynomialFitter" class to smooth the input data along both dimensions before the interpolating function is computed.&lt;/p&gt;

&lt;p&gt;Does someone object to these changes?&lt;/p&gt;, comments=[&lt;p&gt;removing the test class would badly impact test coverage, so it would be better to simply deprecae it also and to remove the library class and its associated test class together when releasing 3.0&lt;/p&gt;
, &lt;p&gt;revision 936295.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,745 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-362
2016-01-13 22:04:32,761 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-362, created=Tue Apr 06 13:38:46 CEST 2010, updated=Wed Mar 23 21:02:00 CET 2011, resolved=Sat May 29 20:16:50 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it, link=https://issues.apache.org/jira/browse/MATH-362, description=&lt;p&gt;LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.&lt;/p&gt;, comments=[&lt;p&gt;Ooops. You are right.&lt;br/&gt;
The Levenberg-Marquardt optimizer uses specific convergence parameters which can be set by   setInitialStepBoundFactor, setCostRelativeTolerance, setParRelativeTolerance and setOrthoTolerance.&lt;br/&gt;
The most important convergence tuning are either setCostRelativeTolerance for a convergence on the cost itself or setParRelativeTolerance for a convergence on the parameters.&lt;/p&gt;

&lt;p&gt;I'm not sure how to solve this. Do the existing tuning parameters fit your needs or not ? Some convergence criteria can be expressed with both methods, but not all. Should we keep both setting as alternate methods or should we remove one and rely on the remaining one ?&lt;/p&gt;
, &lt;p&gt;I would keep using orthoTolerance as it is used now:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;292                if (maxCosine &amp;lt;= orthoTolerance) {&lt;br/&gt;
293                    // convergence has been reached&lt;br/&gt;
294                    return new VectorialPointValuePair(point, objective);&lt;br/&gt;
295                }&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;and then use costRelativeTolerance &amp;amp; parRelativeTolerance if and only if the convergence checker is null, otherwise use the convergence checker and ignore {costRelativeTolerance, parRelativeTolerance}.&lt;/p&gt;

&lt;p&gt;What I am missing now is the ability to bail out if the absolute distance from the target falls below some value ("close enough").&lt;/p&gt;
, &lt;p&gt;I've spent that last few days trying to find a good curve fitting library for Java and got excited when I learned of Commons Math.  Unfortunately, its curve fitting is very unreliable.  I'm hoping that this bug is what is causing the problems that I'm seeing.  I'm comparing data from NIST and results from DataFitX and it is apparent that Commons Math is not yet up to the task.  My fingers are crossed that its quality in the curve fitting area will be improved in the near future.  Keep up the good work Apache.&lt;/p&gt;

&lt;p&gt;I've opened an issue about the problems I'm seeing, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Double check how you use it, Matt. I have succesfully used this curve fitting in production.&lt;/p&gt;
, &lt;p&gt;Matt, could you please describe the problem you encounter more precisely (i.e. with numerical examples) and preferably in a new JIRA issue ? We will check if the two problems are related and link the issues afterwards if it appears they are.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
, &lt;p&gt;It's good to see such quick responses.  I'll open a new JIRA issue and spend some time putting together code, data and a detailed description of the problem I'm seeing.  Thanks Apache for all your hard work.&lt;/p&gt;

&lt;p&gt;I've opened an issue regarding the problem, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r949433.&lt;br/&gt;
Thanks for reporting the issue&lt;/p&gt;
, &lt;p&gt;Thank you.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=roman.werpachowski, assignees=[], commentAuthors=[luc, roman.werpachowski, mprice], timeEstimate=null, timeSpent=null]
2016-01-13 22:04:32,761 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-288
2016-01-13 22:04:32,761 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-288, created=Tue Aug 25 00:31:11 CEST 2009, updated=Wed Apr 14 02:30:17 CEST 2010, resolved=Tue Aug 25 20:10:08 CEST 2009, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.1
], priority=Major, summary=SimplexSolver not working as expected 2, link=https://issues.apache.org/jira/browse/MATH-288, description=&lt;p&gt;SimplexSolver didn't find the optimal solution.&lt;/p&gt;

&lt;p&gt;Program for Lpsolve:&lt;br/&gt;
=====================&lt;br/&gt;
/* Objective function */&lt;br/&gt;
max: 7 a 3 b;&lt;/p&gt;

&lt;p&gt;/* Constraints */&lt;br/&gt;
R1: +3 a -5 c &amp;lt;= 0;&lt;br/&gt;
R2: +2 a -5 d &amp;lt;= 0;&lt;br/&gt;
R3: +2 b -5 c &amp;lt;= 0;&lt;br/&gt;
R4: +3 b -5 d &amp;lt;= 0;&lt;br/&gt;
R5: +3 a +2 b &amp;lt;= 5;&lt;br/&gt;
R6: +2 a +3 b &amp;lt;= 5;&lt;/p&gt;

&lt;p&gt;/* Variable bounds */&lt;br/&gt;
a &amp;lt;= 1;&lt;br/&gt;
b &amp;lt;= 1;&lt;br/&gt;
=====================&lt;br/&gt;
Results(correct): a = 1, b = 1, value = 10&lt;/p&gt;


&lt;p&gt;Program for SimplexSolve:&lt;br/&gt;
=====================&lt;br/&gt;
LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]{7, 3, 0, 0}, 0);&lt;br/&gt;
Collection&amp;lt;LinearConstraint&amp;gt; podmienky = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{1, 0, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 1, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 0, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 0, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 2, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 3, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 2, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 3, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
RealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);&lt;br/&gt;
=====================&lt;br/&gt;
Results(incorrect): a = 1, b = 0.5, value = 8.5&lt;/p&gt;

&lt;p&gt;P.S. I used the latest software from the repository (including &lt;a href="https://issues.apache.org/jira/browse/MATH-286" title="SimplexSolver not working as expected?"&gt;&lt;del&gt;MATH-286&lt;/del&gt;&lt;/a&gt; fix).&lt;/p&gt;, comments=[&lt;p&gt;Thanks for the bug report.  I've confirmed this is an issue.&lt;/p&gt;

&lt;p&gt;Here's a slightly smaller version of the problem that causes the same bug, which might be easier for debugging:&lt;/p&gt;

&lt;p&gt;MAX 7 a + 3 b&lt;br/&gt;
s.t.&lt;br/&gt;
3 a -5 c &amp;lt;= 0&lt;br/&gt;
2 a -5 d &amp;lt;= 0&lt;br/&gt;
3 b -5 d &amp;lt;= 0&lt;br/&gt;
a &amp;lt;= 1&lt;br/&gt;
b &amp;lt;= 1&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 7, 3, 0, 0 }, 0 );&lt;br/&gt;
        Collection&amp;lt;LinearConstraint&amp;gt; constraints = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 3, 0, -5, 0 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 2, 0, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 3, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0 }, Relationship.LEQ, 1.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 0 }, Relationship.LEQ, 1.0));&lt;/p&gt;

&lt;p&gt;        SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
        RealPointValuePair solution = solver.optimize(f, constraints, GoalType.MAXIMIZE, true);&lt;br/&gt;
        assertEquals(10.0, solution.getValue(), .0000001);&lt;/p&gt;
, &lt;p&gt;Patch attached.  It was a 1 character bug.  I was saying to only do the minimum ratio test if the entry is &amp;gt;= 0, but it should have been &amp;gt; 0 (dividing by 0 is never good :o)&lt;br/&gt;
Thanks again for the bug report.&lt;/p&gt;
, &lt;p&gt;resolved in subversion repository as of r807738&lt;br/&gt;
patch applied (except for debug print function)&lt;br/&gt;
thanks for the repoart and thanks for the patch&lt;/p&gt;
], resolution=Fixed, reporter=kefa, assignees=[], commentAuthors=[bmccann, luc], timeEstimate=480, timeSpent=null]
2016-01-13 22:04:32,776 : INFO  : KNIME-Worker-0 : ITSOfflineNodeModel : Jira Adapter (Offline) : 2:2 : Jira table created.
2016-01-13 22:04:32,776 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 End execute (2 secs)
2016-01-13 22:04:32,776 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 doBeforePostExecution
2016-01-13 22:04:32,776 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: POSTEXECUTE
2016-01-13 22:04:32,776 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 doAfterExecute - success
2016-01-13 22:04:32,776 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: EXECUTED
2016-01-13 22:04:32,776 : DEBUG : KNIME-Worker-0 : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:04:32,776 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : Table Difference Checker 2:3 has new state: CONFIGURED_QUEUED
2016-01-13 22:04:32,776 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 2:3 : Table Difference Checker 2:3 doBeforePreExecution
2016-01-13 22:04:32,776 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 2:3 : Table Difference Checker 2:3 has new state: PREEXECUTE
2016-01-13 22:04:32,776 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 2:3 : Table Difference Checker 2:3 doBeforeExecution
2016-01-13 22:04:32,792 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 2:3 : Table Difference Checker 2:3 has new state: EXECUTING
2016-01-13 22:04:32,792 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 2:3 : Adding handler 6b480ade-27e1-4667-9f0d-0066bbd497fd (Table Difference Checker 2:3: <no directory>) - 3 in total
2016-01-13 22:04:32,792 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : Table Difference Checker : 2:3 : Table Difference Checker 2:3 Start execute
2016-01-13 22:04:32,839 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : Table Difference Checker : 2:3 : Table Difference Checker 2:3 End execute (0 secs)
2016-01-13 22:04:32,839 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 2:3 : Table Difference Checker 2:3 doBeforePostExecution
2016-01-13 22:04:32,839 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 2:3 : Table Difference Checker 2:3 has new state: POSTEXECUTE
2016-01-13 22:04:32,839 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 2:3 : Table Difference Checker 2:3 doAfterExecute - success
2016-01-13 22:04:32,839 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 2:3 : Table Difference Checker 2:3 has new state: EXECUTED
2016-01-13 22:04:32,854 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 2:3 : JiraOfflineTest 2 has new state: EXECUTED
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test execute workflow -----------------
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test node messages -----------------
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test node messages -----------------
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test hilite rows -----------------
2016-01-13 22:04:32,870 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test hilite rows -----------------
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test close views -----------------
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test close views -----------------
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test log messages -----------------
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test log messages -----------------
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test uncaught exceptions -----------------
2016-01-13 22:04:32,870 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test uncaught exceptions -----------------
2016-01-13 22:04:33,837 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ===== Memory statistics: 995,500 MB max, 61,034 MB used, 934,466 MB free ====
2016-01-13 22:04:33,837 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ================= Finished testflow WorkflowTests\JiraOfflineTest =================
2016-01-13 22:04:33,868 : DEBUG : Service Thread : MemoryAlertSystem :  :  : Memory usage below threshold of 0.7125915080527087 after GC run
2016-01-13 22:04:34,305 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:04:34,305 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:04:34,336 : DEBUG : Worker-1 : WorkflowManager :  :  : Removing project "JiraOfflineTest 2"
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 2:3 : Removing handler 6b480ade-27e1-4667-9f0d-0066bbd497fd (Table Difference Checker 2:3: <no directory>) - 2 remaining
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : DifferenceCheckerNodeModel : Table Difference Checker : 2:3 : Removing all (0) views from model.
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 2:2 : Removing handler 6a192c76-8dd9-4f41-9136-c65816086d60 (Jira Adapter (Offline) 2:2: <no directory>) - 1 remaining
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : JiraAdapterNodeModel : Jira Adapter (Offline) : 2:2 : Removing all (0) views from model.
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : clean output ports.
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 2:1 : Removing handler fda7a8e9-a8e7-49a5-a12d-7ba8b43e663e (Jira Adapter (Offline) 2:1: <no directory>) - 0 remaining
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : JiraAdapterNodeModel : Jira Adapter (Offline) : 2:1 : Removing all (0) views from model.
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : clean output ports.
2016-01-13 22:04:34,399 : DEBUG : Worker-1 : WorkflowManager :  :  : Project "JiraOfflineTest 2" removed (2 remaining)
2016-01-13 22:05:04,700 : DEBUG : main : NodeContainerEditPart :  :  : Git SCM 0:1 (CONFIGURED)
2016-01-13 22:05:05,246 : DEBUG : main : NodeContainerEditPart :  :  : Git SCM 0:1 (CONFIGURED)
2016-01-13 22:06:49,172 : DEBUG : main : NodeContainerEditPart :  :  : Git SCM 0:1 (CONFIGURED)
2016-01-13 22:06:50,717 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:06:50,732 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:06:50,732 : DEBUG : main : ProjectWorkflowMap :  :  : unregistering org.knime.workbench.editor2.WorkflowEditor@36003e90 from file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/. 0 left.
2016-01-13 22:06:50,732 : DEBUG : main : ProjectWorkflowMap :  :  : Removing "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/" from project map (0 remaining)
2016-01-13 22:06:50,732 : DEBUG : main : WorkflowManager :  :  : Removing project "GitOfflineTest 0"
2016-01-13 22:06:50,764 : DEBUG : main : DifferenceCheckerNodeModel : Table Difference Checker : 0:3 : Removing all (0) views from model.
2016-01-13 22:06:50,764 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:06:50,764 : DEBUG : main : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Removing all (0) views from model.
2016-01-13 22:06:50,764 : DEBUG : main : Git SCM : Git SCM : 0:2 : clean output ports.
2016-01-13 22:06:50,764 : DEBUG : main : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Removing all (0) views from model.
2016-01-13 22:06:50,764 : DEBUG : main : Git SCM : Git SCM : 0:1 : clean output ports.
2016-01-13 22:06:50,764 : DEBUG : main : WorkflowManager :  :  : Project "GitOfflineTest 0" removed (1 remaining)
2016-01-13 22:06:54,367 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:06:54,367 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:06:54,414 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:06:54,414 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on workflow.knime
2016-01-13 22:06:54,414 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:06:54,414 : DEBUG : main : WorkflowEditor :  :  : Resource File's project: file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/
2016-01-13 22:06:54,508 : DEBUG : ModalContext : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:06:54,508 : DEBUG : ModalContext : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:06:54,554 : DEBUG : ModalContext : JiraAdapterNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:06:54,601 : DEBUG : ModalContext : JiraAdapterNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:06:54,617 : DEBUG : ModalContext : DifferenceCheckerNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:06:54,617 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:2(1) to node 0:3(2)
2016-01-13 22:06:54,617 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:3(1)
2016-01-13 22:06:54,617 : DEBUG : ModalContext : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:06:54,617 : DEBUG : ModalContext : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:06:54,617 : DEBUG : ModalContext : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:06:54,617 : DEBUG : ModalContext : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest"  with no errors
2016-01-13 22:06:54,648 : DEBUG : main : ProjectWorkflowMap :  :  : Adding "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/" to project map (1 in total)
2016-01-13 22:06:54,664 : DEBUG : main : ProjectWorkflowMap :  :  : registering org.knime.workbench.editor2.WorkflowEditor@49de1717 to file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/. 1 registered clients now.
2016-01-13 22:06:54,710 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:06:54,710 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:06:54,710 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:06:54,710 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 0:1 (CONFIGURED) )
2016-01-13 22:06:54,710 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:06:54,710 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:06:54,710 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 0:2 (CONFIGURED) )
2016-01-13 22:06:54,710 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:06:54,710 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:06:54,710 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:3 (CONFIGURED) )
2016-01-13 22:06:54,726 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:06:54,726 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:06:54,726 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:06:54,726 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:06:57,643 : DEBUG : main : NodeContainerEditPart :  :  : Table Difference Checker 0:3 (CONFIGURED)
2016-01-13 22:06:57,643 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 0:1 (CONFIGURED)
2016-01-13 22:07:17,554 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : reset
2016-01-13 22:07:17,554 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:07:17,554 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Setting dirty flag on Table Difference Checker 0:3
2016-01-13 22:07:17,554 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Setting dirty flag on JiraOfflineTest 0
2016-01-13 22:07:17,554 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Table Difference Checker 0:3 has new state: IDLE
2016-01-13 22:07:17,554 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : reset
2016-01-13 22:07:17,554 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : clean output ports.
2016-01-13 22:07:17,554 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Setting dirty flag on Jira Adapter (Offline) 0:1
2016-01-13 22:07:17,554 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: IDLE
2016-01-13 22:07:17,554 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=0;old=null;new=null;timestamp=2016-01-13 22:07:17]
2016-01-13 22:07:17,554 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:07:17,554 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: CONFIGURED
2016-01-13 22:07:17,554 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:07:17,554 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Table Difference Checker 0:3 has new state: CONFIGURED
2016-01-13 22:07:18,318 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : reset
2016-01-13 22:07:18,318 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:07:18,318 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Table Difference Checker 0:3 has new state: IDLE
2016-01-13 22:07:18,318 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : reset
2016-01-13 22:07:18,318 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : clean output ports.
2016-01-13 22:07:18,318 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: IDLE
2016-01-13 22:07:18,334 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:07:18,334 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: CONFIGURED
2016-01-13 22:07:18,334 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:07:18,334 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:1 : Table Difference Checker 0:3 has new state: CONFIGURED
2016-01-13 22:07:19,114 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 0:1 (CONFIGURED)
2016-01-13 22:07:19,114 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 0:2 (CONFIGURED)
2016-01-13 22:07:33,905 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : reset
2016-01-13 22:07:33,905 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:07:33,905 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:2 : Table Difference Checker 0:3 has new state: IDLE
2016-01-13 22:07:33,905 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : reset
2016-01-13 22:07:33,905 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : clean output ports.
2016-01-13 22:07:33,905 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:2 : Setting dirty flag on Jira Adapter (Offline) 0:2
2016-01-13 22:07:33,905 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: IDLE
2016-01-13 22:07:33,905 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:07:33,905 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: CONFIGURED
2016-01-13 22:07:33,905 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:07:33,905 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:2 : Table Difference Checker 0:3 has new state: CONFIGURED
2016-01-13 22:07:35,108 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : reset
2016-01-13 22:07:35,108 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:07:35,108 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:2 : Table Difference Checker 0:3 has new state: IDLE
2016-01-13 22:07:35,108 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : reset
2016-01-13 22:07:35,108 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : clean output ports.
2016-01-13 22:07:35,108 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: IDLE
2016-01-13 22:07:35,108 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:07:35,108 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: CONFIGURED
2016-01-13 22:07:35,108 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:07:35,108 : DEBUG : main : NodeContainer : Jira Adapter (Offline) : 0:2 : Table Difference Checker 0:3 has new state: CONFIGURED
2016-01-13 22:07:40,461 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 0:2 (CONFIGURED)
2016-01-13 22:07:40,913 : DEBUG : main : WorkflowEditor :  :  : Saving workflow JiraOfflineTest 0
2016-01-13 22:07:40,991 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Replaced node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest\Jira Adapter _Offline_ (#1)"
2016-01-13 22:07:41,007 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Replaced node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest\Jira Adapter _Offline_ (#2)"
2016-01-13 22:07:41,022 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Replaced node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest\Table Difference Checker (#3)"
2016-01-13 22:07:45,796 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:07:45,796 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:07:45,796 : DEBUG : main : ProjectWorkflowMap :  :  : unregistering org.knime.workbench.editor2.WorkflowEditor@49de1717 from file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/. 0 left.
2016-01-13 22:07:45,796 : DEBUG : main : ProjectWorkflowMap :  :  : Removing "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/" from project map (0 remaining)
2016-01-13 22:07:45,796 : DEBUG : main : WorkflowManager :  :  : Removing project "JiraOfflineTest 0"
2016-01-13 22:07:45,827 : DEBUG : main : DifferenceCheckerNodeModel : Table Difference Checker : 0:3 : Removing all (0) views from model.
2016-01-13 22:07:45,827 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:07:45,827 : DEBUG : main : JiraAdapterNodeModel : Jira Adapter (Offline) : 0:2 : Removing all (0) views from model.
2016-01-13 22:07:45,827 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : clean output ports.
2016-01-13 22:07:45,827 : DEBUG : main : JiraAdapterNodeModel : Jira Adapter (Offline) : 0:1 : Removing all (0) views from model.
2016-01-13 22:07:45,827 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : clean output ports.
2016-01-13 22:07:45,843 : DEBUG : main : WorkflowManager :  :  : Project "JiraOfflineTest 0" removed (1 remaining)
2016-01-13 22:07:45,843 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ================= Starting testflow WorkflowTests\JiraOfflineTest =================
2016-01-13 22:07:45,858 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ================= Average load: -1,00 =================
2016-01-13 22:07:45,858 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test load workflow -----------------
2016-01-13 22:07:45,858 : DEBUG : Worker-3 : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:07:45,874 : DEBUG : Worker-3 : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:07:45,890 : DEBUG : Worker-3 : JiraAdapterNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:07:45,905 : DEBUG : Worker-3 : JiraAdapterNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:07:45,921 : DEBUG : Worker-3 : DifferenceCheckerNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:07:45,921 : DEBUG : Worker-3 : WorkflowManager :  :  : Added new connection from node 0:2(1) to node 0:3(2)
2016-01-13 22:07:45,936 : DEBUG : Worker-3 : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:3(1)
2016-01-13 22:07:45,983 : DEBUG : Worker-3 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:07:45,999 : DEBUG : Worker-3 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:07:45,999 : DEBUG : Worker-3 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:07:45,999 : DEBUG : Worker-3 : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest"  with no errors
2016-01-13 22:07:46,061 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:07:46,061 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:07:46,092 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:07:46,092 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on 0 - JiraOfflineTest
2016-01-13 22:07:46,092 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:07:46,124 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:07:46,124 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:07:46,124 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:07:46,124 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 0:1 (CONFIGURED) )
2016-01-13 22:07:46,139 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:07:46,139 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:07:46,139 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 0:2 (CONFIGURED) )
2016-01-13 22:07:46,139 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:07:46,139 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:07:46,139 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:3 (CONFIGURED) )
2016-01-13 22:07:46,139 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:07:46,139 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:07:46,139 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:07:46,139 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:07:46,748 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test load workflow -----------------
2016-01-13 22:07:46,748 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test open views -----------------
2016-01-13 22:07:46,748 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test open views -----------------
2016-01-13 22:07:46,748 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test execute workflow -----------------
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : Setting dirty flag on Jira Adapter (Offline) 0:2
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : Setting dirty flag on JiraOfflineTest 0
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : Jira Adapter (Offline) 0:2 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : Jira Adapter (Offline) 0:2 has new state: CONFIGURED_QUEUED
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : Setting dirty flag on Jira Adapter (Offline) 0:1
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : Jira Adapter (Offline) 0:1 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : Jira Adapter (Offline) 0:1 has new state: CONFIGURED_QUEUED
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : Setting dirty flag on Table Difference Checker 0:3
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : Table Difference Checker 0:3 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : JiraOfflineTest 0 has new state: EXECUTING
2016-01-13 22:07:46,748 : DEBUG : Worker-3 : NodeContainer :  :  : ROOT  has new state: EXECUTING
2016-01-13 22:07:46,748 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=0;old=null;new=null;timestamp=2016-01-13 22:07:46]
2016-01-13 22:07:46,748 : DEBUG : KNIME-Worker-3 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doBeforePreExecution
2016-01-13 22:07:46,748 : DEBUG : KNIME-Worker-3 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: PREEXECUTE
2016-01-13 22:07:46,748 : DEBUG : KNIME-Worker-3 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doBeforeExecution
2016-01-13 22:07:46,748 : DEBUG : KNIME-Worker-3 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: EXECUTING
2016-01-13 22:07:46,748 : DEBUG : KNIME-Worker-3 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:1 : Adding handler 7d0206e3-fad3-4e9f-9cb9-e29447469731 (Jira Adapter (Offline) 0:1: <no directory>) - 1 in total
2016-01-13 22:07:46,748 : DEBUG : KNIME-Worker-3 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 Start execute
2016-01-13 22:07:46,748 : INFO  : KNIME-Worker-3 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:1 : Preparing to read jira entries.
2016-01-13 22:07:46,872 : DEBUG : KNIME-Worker-2 : WorkflowManager : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 doBeforePreExecution
2016-01-13 22:07:46,872 : DEBUG : KNIME-Worker-2 : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: PREEXECUTE
2016-01-13 22:07:46,872 : DEBUG : KNIME-Worker-2 : WorkflowManager : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 doBeforeExecution
2016-01-13 22:07:46,872 : DEBUG : KNIME-Worker-2 : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: EXECUTING
2016-01-13 22:07:46,872 : DEBUG : KNIME-Worker-2 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:2 : Adding handler 4e6e55cb-293e-4e69-97ac-aaaa330fede3 (Jira Adapter (Offline) 0:2: <no directory>) - 2 in total
2016-01-13 22:07:46,872 : DEBUG : KNIME-Worker-2 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 Start execute
2016-01-13 22:07:46,872 : INFO  : KNIME-Worker-2 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:2 : Preparing to read jira entries.
2016-01-13 22:07:48,417 : INFO  : KNIME-Worker-3 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:1 : Transforming to jira entries.
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-724
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-724, created=Mon Dec 12 16:03:41 CET 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Tue Dec 20 22:14:16 CET 2011, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=RandomDataImpl.nextInt does not distribute uniformly for negative lower bound, link=https://issues.apache.org/jira/browse/MATH-724, description=&lt;p&gt;When using the RandomDataImpl.nextInt function to get a uniform sample in a &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt; interval, when the lower value is less than zero, the output is not uniformly distributed, as the lowest value is practically never returned.&lt;/p&gt;

&lt;p&gt;See the attached NextIntUniformTest.java file. It uses a &lt;span class="error"&gt;&amp;#91;-3, 5&amp;#93;&lt;/span&gt; interval. For several values between 0 and 1, testNextIntUniform1 prints the return value of RandomDataImpl.nextInt (as double and as int). We see that -2 through 5 are returned several times. The -3 value however, is only returned for 0.0, and is thus under-respresented in the integer samples. The output of test method testNextIntUniform2 also clearly shows that value -3 is never sampled.&lt;/p&gt;, comments=[&lt;p&gt;NextIntUniformTest.java: see issue description&lt;/p&gt;
, &lt;p&gt;Thanks for reporting this. The problem is in the rounding, which does not work correctly for negative values.  My first inclination is to test for negative lower bound and just shift the interval in that case.  Any better ideas?&lt;/p&gt;
, &lt;p&gt;math-724.patch: it first scales the [0..1) interval to [0..length), then discretizes it, and finally shifts it to &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;It may be a good idea to also add some tests for cases such as &lt;span class="error"&gt;&amp;#91;0,3&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-5, -3&amp;#93;&lt;/span&gt;, and see if the distribution of sampled values is uniform. It seems RandomDataTest.testNextInt does this using chiSquare, but since I'm not familiar with that, I'm not sure how to add more tests for the other lower/upper bound pairs...&lt;/p&gt;
, &lt;p&gt;I just ran the unit tests with my patch applied, an the following test, in RandomDataTest:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;@Test
    &lt;span class="code-keyword"&gt;public&lt;/span&gt; void testNextIntExtremeValues() {
        &lt;span class="code-object"&gt;int&lt;/span&gt; x = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        &lt;span class="code-object"&gt;int&lt;/span&gt; y = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        Assert.assertFalse(x == y);
    }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails, as does testNextLongExtremeValues. Both x and y become equal to Integer.MIN_VALUE, making x == y to become true, causing the assertion to fail...&lt;/p&gt;
, &lt;p&gt;Also note that RandomDataImpl.nextUniform uses a similar scale/shift method to transform the range. It may thus suffer from the same failure in case of extreme values...&lt;/p&gt;
, &lt;p&gt;math-724-v2.patch: 2nd patch.&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;I think all unit tests work now, including the ones for the Integer.MIN_VALUE to Integer.MAX_VALUE interval.&lt;/li&gt;
	&lt;li&gt;The original problem was that negative values were rounded up by the conversion from double to int, while positive numbers were rounded down. By using floor, we first round the numbers down, and then convert to integer, thus ensuring a proper uniform distribution.&lt;/li&gt;
	&lt;li&gt;Test cases for negative values are still missing... Could someone else add them?&lt;/li&gt;
	&lt;li&gt;RandomDataImpl.nextUniform: I haven't changed this, as the change that I used for integers does not have the desired effect for doubles... This may be caused by the fact that Double.MIN_VALUE is more negative than Double.MAX_VALUE is positive, but I'm not really sure. Maybe it is not even an issue for the nextUniform method?&lt;/li&gt;
&lt;/ul&gt;

, &lt;blockquote&gt;&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; the fact that Double.MIN_VALUE is more negative &lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="http://docs.oracle.com/javase/6/docs/api/java/lang/Double.html#MIN_VALUE"&gt;Double.Min_VALUE&lt;/a&gt; is a &lt;em&gt;positive&lt;/em&gt; number.&lt;/p&gt;
, &lt;blockquote&gt;&lt;p&gt;Double.Min_VALUE is a positive number.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops...&lt;/p&gt;

&lt;p&gt;OK, I uploaded a third version of the patch (math-724-v3.patch), which also applies the new formula for nextUniform. I included two test files (NextUniformTest3.java and NextIntTest3.java), that show the results for nextInt and nextUniform, for both the old and new formulas. As for as I can see, the new formula works equally well or better in all cases. Also, all existing unit tests pass.&lt;/p&gt;
, &lt;p&gt;Thanks for reporting and diagnosing this, Dennis.&lt;/p&gt;

&lt;p&gt;Slightly modified version of the third patch (just removing unecessary parens), along with tests, committed in r1221490.  The "negativeToPositiveRange" tests fail before the fix.  The change to nextUniform is also needed to prevent overflows. I changed the relevant test cases to use the TestUtils chisquare test, which is more straightforward and has better output.  This was added after the original versions of these tests were written.  Others in this class should be similarly updated.  Patches welcome to further tidy the tests, but this issue can be resolved.&lt;/p&gt;
], resolution=Fixed, reporter=dhendriks, assignees=[], commentAuthors=[dhendriks, psteitz, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-723
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-723, created=Sun Dec 11 22:03:37 CET 2011, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Sun Dec 11 22:59:41 CET 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=BitStreamGenerators (MersenneTwister, Well generators) do not clear normal deviate cache on setSeed, link=https://issues.apache.org/jira/browse/MATH-723, description=&lt;p&gt;The BitStream generators generate normal deviates (for nextGaussian) in pairs, caching the last value generated. When reseeded, the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1213087.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-719
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-719, created=Tue Dec 06 18:07:24 CET 2011, updated=Sat Mar 24 17:16:38 CET 2012, resolved=Mon Jan 23 12:28:07 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[], priority=Minor, summary=Strange deprecations in API, link=https://issues.apache.org/jira/browse/MATH-719, description=&lt;p&gt;Sorry if this doesn't belong here. I couldn't find any sort of mailing list or other feedback mechanism on the website.&lt;/p&gt;

&lt;p&gt;RealMatrix has some very odd deprecations. In particular inverse(), getDeterminant() and isSingular(). The last has the message:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Deprecated. as of release 2.0, replaced by the boolean negation of new LUDecompositionImpl(m).getSolver().isNonSingular()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's an implementation, not an interface. The whole point of having an interface is that &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I can query whether a matrix is singular withou having to know about LUDecompositions&lt;/li&gt;
	&lt;li&gt;You guys can change the implementation of isSingular() if something better pops up without us guys having to change our code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I'm not using these methods now, because they're deprecated, but I've basically recreated them in as static methods in a utility class. Wouldn't it be much better to just put code from the deprecation message into the method and remove the deprecation?&lt;/p&gt;, comments=[&lt;blockquote&gt;&lt;p&gt;Sorry if this doesn't belong here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Indeed, you'd better bring this kind of issue to the "dev" ML. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
The more so that there have been recent discussions about changing the matrix API and decisions ought to be made quite soon now.&lt;/p&gt;
, &lt;p&gt;Ah, so there is a mailing list. I guess I should have looked a little harder. I'll bring it up there.&lt;/p&gt;
, &lt;p&gt;It is unlikely that we can come up with a new design before the release of v3.0.&lt;br/&gt;
This must be thoroughly discussed first on the "dev" ML, together with other matrix interface issues.&lt;/p&gt;
], resolution=Unknown, reporter=pbloem, assignees=[], commentAuthors=[erans, pbloem], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-692
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-692, created=Tue Oct 18 20:01:57 CEST 2011, updated=Sat Mar 24 17:16:26 CET 2012, resolved=Thu Feb 02 07:45:59 CET 2012, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 1.3
, 2.0
, 2.1
, 2.2
, 2.2.1
, 3.0
], fixVersion=[3.0
], priority=Minor, summary=Cumulative probability and inverse cumulative probability inconsistencies, link=https://issues.apache.org/jira/browse/MATH-692, description=&lt;p&gt;There are some inconsistencies in the documentation and implementation of functions regarding cumulative probabilities and inverse cumulative probabilities. More precisely, '&amp;lt;' and '&amp;lt;=' are not used in a consistent way.&lt;/p&gt;

&lt;p&gt;Besides I would move the function inverseCumulativeProbability(double) to the interface Distribution. A true inverse of the distribution function does neither exist for Distribution nor for ContinuosDistribution. Thus we need to define the inverse in terms of quantiles anyway, and this can already be done for Distribution.&lt;/p&gt;

&lt;p&gt;On the whole I would declare the (inverse) cumulative probability functions in the basic distribution interfaces as follows:&lt;/p&gt;

&lt;p&gt;Distribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(double x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(double x0, double x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1)&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;inverseCumulativeProbability(double p):&lt;br/&gt;
  returns the quantile function inf{x in R | P(X&amp;lt;=x) &amp;gt;= p} &lt;span class="error"&gt;&amp;#91;see also 2), 3), and 4)&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1) An aternative definition could be P(x0 &amp;lt;= X &amp;lt;= x1). But this requires to put the function probability(double x) or another cumulative probability function into the interface Distribution in order be able to calculate P(x0 &amp;lt;= X &amp;lt;= x1) in AbstractDistribution.&lt;br/&gt;
2) This definition is stricter than the definition in ContinuousDistribution, because the definition there does not specify what to do if there are multiple x satisfying P(X&amp;lt;=x) = p.&lt;br/&gt;
3) A modification could be defined for p=0: Returning sup{x in R | P(X&amp;lt;=x) = 0} would yield the infimum of the distribution's support instead of a mandatory -infinity.&lt;br/&gt;
4) This affects issue &lt;a href="https://issues.apache.org/jira/browse/MATH-540" title="AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug"&gt;&lt;del&gt;MATH-540&lt;/del&gt;&lt;/a&gt;. I'd prefere the definition from above for the following reasons:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;This definition simplifies inverse transform sampling (as mentioned in the other issue).&lt;/li&gt;
	&lt;li&gt;It is the standard textbook definition for the quantile function.&lt;/li&gt;
	&lt;li&gt;For integer distributions it has the advantage that the result doesn't change when switching to "x in Z", i.e. the result is independent of considering the intergers as sole set or as part of the reals.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ContinuousDistribution:&lt;br/&gt;
nothing to be added regarding (inverse) cumulative probability functions&lt;/p&gt;

&lt;p&gt;IntegerDistribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(int x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(int x0, int x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1) above&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;, comments=[&lt;p&gt;Thanks for raising this issue, Christian - especially now as we finalize the 3.0 API.&lt;/p&gt;

&lt;p&gt;I am +1 for these changes.  I agree that the inf-based definition of inverse cum is more standard and we are in a position now make the change, so I say lets do it.  I am also +1 on the move of this up to the distribution interface.  The reason we did not include it there originally was that we thought we might implement distributions for which we could not define inverses.  That has not happened in the last 8 years, so I think its safe enough to push it up.&lt;/p&gt;

&lt;p&gt;The code, test, user guide and doc changes for this have to be done carefully.  Patches most welcome.&lt;/p&gt;

&lt;p&gt;Is everyone else OK with this change?&lt;/p&gt;
, &lt;p&gt;I have neither used nor developed this part of CM, so my view on this is of but little value. Having said that, anything improving consistency can only be desirable, especially at this stage. So I'm all for it, and will be soon available (when I'm done on SYMMLQ) for an (novice on these issues) help.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;+1&lt;/p&gt;
, &lt;p&gt;Thanks for the feedback to all. Sbastien, thanks for offering your help. If you like and find time for it, you could implement AbstractDistribution.inverseCumulativeProbability(double p).&lt;/p&gt;

&lt;p&gt;I will provide some patches next week, but adjusting AbstractContinuousDistribution.inverseCumulativeProbability(double p) will take some more time.&lt;/p&gt;

&lt;p&gt;After thinking a little more about the structure of the interfaces, I'd like to put the function probability(double x) to Distribution anyway (independently of the thought in point 1) above).&lt;/p&gt;

&lt;p&gt;Are there any preferences on P(x0 &amp;lt;= X &amp;lt;= x1) or P(x0 &amp;lt; X &amp;lt;= x1) for cumulativeProbability(double x0, double x1)?&lt;/p&gt;
, &lt;p&gt;I am not sure it is really makes sense to add probability(double x) to the Distribution interface.  It would have to be defined as density (referring to the distribution function) to make sense in the continuous case, since defined as p(X = x) it would in most cases be identically 0 for continuous distributions.&lt;/p&gt;

&lt;p&gt;Regarding the cum definition, I am fine with P(x0 &amp;lt; X &amp;lt;= x1).&lt;/p&gt;
, &lt;p&gt;Happy to help on the inverse cumulative probability. You will have to be patient and forgieving with me, though, as I discover this part of CM.&lt;/p&gt;

&lt;p&gt;As for the definition, I think that one of the bounds should be excluded, so that these cumulative probabilities can be summed&lt;br/&gt;
P(a &amp;lt; X &amp;lt;= c) = P(a &amp;lt; X &amp;lt;= b) + P(b &amp;lt; X &amp;lt;= c),&lt;br/&gt;
even in the case of discrete PDFs.&lt;/p&gt;

&lt;p&gt;Whether the lower or upper bound should be excluded is another matter. I usually work with continuous pdfs, so I don't know if there is a common practice in the probability community. If there is none, I would tend to chose the following definition&lt;br/&gt;
P(x0 &amp;lt;= X &amp;lt; x1)&lt;br/&gt;
(sorry Phil!), because it would be consistent with the way things are usually indexed in java (a&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;.. a&lt;span class="error"&gt;&amp;#91;a.length-1&amp;#93;&lt;/span&gt;). See also &lt;tt&gt;org.apache.commons.math.util.MultidimensionalCounter&lt;/tt&gt;. Although this type of consistency is not an absolute requirement, I think it is nice for the user to have such simple principle: "lower bound always included, upper bound always excluded". Appart from this small point, I really have no objection to any choice.&lt;/p&gt;
, &lt;p&gt;Have a look at the default implementation of cum(x0,x1) now in AbstractDistribution.  I think the incorrectness in the documentation there may have been what triggered Christian to raise this issue.  The equation cum(a,b) = F(b) - F(a) where F is the distribution function is natural and what the impl there is trying to do.  In the discrete case, this equation fails, however, unless you define the cum to exclude the &lt;b&gt;lower&lt;/b&gt; endpoint.  That's why P(x0 &amp;lt; X &amp;lt;= x1) is a better definition.&lt;/p&gt;
, &lt;p&gt;OK, Phil, it makes perfect sense.&lt;/p&gt;
, &lt;p&gt;Good, the definition of cum(x0,x1) will be P(x0 &amp;lt; X &amp;lt;= x1). Phil, you are right: cum(x0,x1) in AbstractDistribution was a reason for raising this issue. Another reason was cum(int x0, int x1) in AbstractIntegerDistribution.&lt;/p&gt;

&lt;p&gt;The idea behind probability(double x) is in fact to define it as p(X = x) and to return 0 for continuous distributions. This function would be useful for discrete distributions not inheriting from IntergerDistribution and for distributions being composed of discrete and continuous parts.&lt;/p&gt;
, &lt;p&gt;I guess I am OK with pushing p&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/error.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt; up.  See related post to follow in commons-dev. &lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
I've started looking into this issue. As I said, you will have to be patient with me &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;.&lt;br/&gt;
I can see there already is a default implementation of &lt;tt&gt;AbstractContinuousDistribution.inverseCumulativeProbability&lt;/tt&gt;. So what exactly would you like me to do? Is this implementation fragile? Would you like me to improve robustness? Provide full testing?&lt;/p&gt;

&lt;p&gt;I think there might be issues when the PDF falls down to zero in a range (in which case the cum exhibits a plateau). The returned value might differ from the mathematical definition you proposed. Is this what you want me to work on? Have you already identified other issues?&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;

&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;

&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;

&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;
, &lt;p&gt;Another point for discussion:&lt;br/&gt;
I'd like to introduce&lt;br/&gt;
getDomainBracket(double p): returns double[]&lt;br/&gt;
to AbstractDistribution as helper function for inverseCumulativeProbability. This allows to avoid searching a bracket where a bracket can be specified directly.&lt;br/&gt;
The function getDomainBracket could be made abstract (which means to remove getInitialDomain, getDomainLowerBound, and getDomainUpperBound as these functions aren't needed any more), or it could have a default implementation (according to the corresponding part of the current implementation of inverseCumulativeProbability) which uses getInitialDomain, getDomainLowerBound, and getDomainUpperBound. However, getInitialDomain, getDomainLowerBound, and getDomainUpperBound should not be abstract in the latter case. Otherwise a derived class would be forced to implement something it potentially doesn't use. Thus the functions getInitialDomain, getDomainLowerBound, and getDomainUpperBound should have default implementations which either return default values (0, -infinity, +infinity) or throw an exception saying something like "has to be implemented".&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I'm working on it...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, for now, I'm concentrating on making the current impl in &lt;tt&gt;AbstractContinuousDistribution&lt;/tt&gt; more robust. The other impl should be easier.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current implementation uses a Brent solver. I think the solver itself is only one side of the issue. The other point is the algorithm used to bracket the solution, in order to ensure that the result is consistent with the definition of the cumprob. As for the &lt;tt&gt;DifferentiableUnivariateRealSolver&lt;/tt&gt;, I'm not too sure. I guess it depends on what is meant by "continuous distribution". For me, it means that the random variable takes values in a continuous set, and possibly its distribution is defined by a density. However, in my view, nothing prevents occurences of Dirac functions, in which case the cum sum is only piecewise C1. It's all a matter of definition, of course, and I'll ask the question on the forum to check whether or not people want to allow for such a situation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I'm very interested.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Please note that &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt; has been created specifically to handle plateaux.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;Here is the first patch for this issue (unfortunately with some delay). It adjusts the distributions with real domain to the definitions in this issue, and it mainly changes documentations.&lt;/p&gt;

&lt;p&gt;I could not move inverseCumulativeProbability(double) up to Distribution because there would be a conflict with IntegerDistribution.inverseCumulativeProbability(double): This method returns int. This problem will be removed by solving issue &lt;a href="https://issues.apache.org/jira/browse/MATH-703" title="Splitting up the distribution hierarchy"&gt;&lt;del&gt;MATH-703&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The implementation of inverseCumulativeProbability(double) is not changed as Sbastien is working on this.&lt;/p&gt;

&lt;p&gt;I will provide the patch for the integer distributions as soon as I have adjusted the test data to the new inequalities and reverified the adjusted test data.&lt;/p&gt;
, &lt;p&gt;All,&lt;br/&gt;
since I'm already working on this package, I'm happy to commit the patch on behalf of Christian. However, since I'm a relatively new committer, I would feel more confident if one of the "old, wise committers" could double check the svn log afterwards.&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hey, that's how it always works &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;  &lt;/p&gt;

&lt;p&gt;I don't know about "wise" but I certainly qualify as "old" by any standard, so will have a look once you have reviewed and committed.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
, &lt;p&gt;Patch &lt;tt&gt;Math-692_realDomain_patch1.patch&lt;/tt&gt; (20111108) applied in rev 1200179, with minor modifications (mostly checkstyle fixes).&lt;br/&gt;
Thanks Christian!&lt;/p&gt;
, &lt;p&gt;As mentioned by Sbastien in &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt;, the implementation of &lt;tt&gt;IntegerDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; can benefit from the ideas which came up for &lt;tt&gt;RealDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; in that thread.&lt;/p&gt;

&lt;p&gt;Thus I will remove &lt;tt&gt;getDomainLowerBound(double p)&lt;/tt&gt; and &lt;tt&gt;getDomainUpperBound(double p)&lt;/tt&gt; from the integer distributions. I checked that all current implementations of the lower/upper bound methods provide the whole support of the distribution as starting bracket. This means that using &lt;tt&gt;getSupportLowerBound()&lt;/tt&gt; and &lt;tt&gt;getSupportUpperBound()&lt;/tt&gt; for the starting bracket won't degrade the performance of the current distribution implementations. However, a user might want the improve the performance of his distribution implementations by providing a more targeted starting bracket for probability &lt;tt&gt;p&lt;/tt&gt;. Thus I will swap the solving step to a protected function &lt;tt&gt;solveInverseCumulativeProbability(double p, int lower, int upper)&lt;/tt&gt;, so that it gets easy to override &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; with an implementation which finds a better starting bracket.&lt;/p&gt;

&lt;p&gt;Furthermore, Phil's idea with Chebyshev's inequality can be applied to the generic implementation of &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; in order to get a better starting bracket.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
If you agree with that, I suggest that you also take care of &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;, as the two issues seem to be very much connected.&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;my changes in the integer distributions don't solve &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;. Instead I found a probably related problem with the Pascal distribution.&lt;/p&gt;

&lt;p&gt;The integer distribution patch for this issue still isn't ready. I will provide it next week.&lt;/p&gt;

&lt;p&gt;Christian&lt;/p&gt;
, &lt;p&gt;This is the patch which adjusts the integer distributions to the agreements above.&lt;/p&gt;

&lt;p&gt;The changes to the test cases for the random generators may be unexpected. But these changes initially were triggered by adjusting &lt;tt&gt;RandomDataTest.checkNextPoissonConsistency(double)&lt;/tt&gt; to the new contract for integer distributions. Then some random generator tests failed due to chance. While adjusting their seeds, I found some other tests with a high failure probability. Thus I also set some failure probabilities to 0.01 in order to find suitable seeds more quickly.&lt;/p&gt;

&lt;p&gt;My next task on this issue is to adjust the user guid.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
thanks for this contribution. I am away for a few days, but am very happy to commit this patch as soon as I am back, if you are not in too much of a hurry.&lt;br/&gt;
Thanks again,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Well, we've recently run into some troubles with SVN, but it seems everything is working fine again. Patch {{&lt;a href="https://issues.apache.org/jira/browse/MATH-692" title="Cumulative probability and inverse cumulative probability inconsistencies"&gt;&lt;del&gt;MATH-692&lt;/del&gt;&lt;/a&gt;_integerDomain_patch1.patch}} (with minor checkstyle changes) committed in revision &lt;tt&gt;1226041&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Please do not forget to run &lt;tt&gt;mvn clean; mvn site:site&lt;/tt&gt; and check the reports (in particular, &lt;tt&gt;checkstyle&lt;/tt&gt;) prior to submitting a patch!&lt;/p&gt;

&lt;p&gt;Thanks for this contribution.&lt;/p&gt;
, &lt;p&gt;The committed patch actually causes failure of &lt;tt&gt;Well1024Test&lt;/tt&gt; in &lt;tt&gt;o.a.c.m.random&lt;/tt&gt;.&lt;/p&gt;
, &lt;p&gt;Thanks for committing the patch, Sbastien. I see you already changed the seed in &lt;tt&gt;Well1024aTest&lt;/tt&gt;. This hopefully removes the failure.&lt;/p&gt;

&lt;p&gt;I'll have a look into Maven to prepare a better patch next time. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;I see you already changed the seed in Well1024aTest.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I did, but is this really how we want &lt;tt&gt;Well2004aTest&lt;/tt&gt; to pass?&lt;/p&gt;
, &lt;p&gt;I guess there is no alternative to this way of making probabilistic test cases pass. However, I understand your bad feeling with this kind of failure fixing. The problem is that probabilistic tests are quiet fuzzy: Neither a passed test nor a failed test provides a clear answer whether something is right or wrong in the implementation. There is just a high chance to pass such a test with a correct implementation. The chance for failure increases with an erroneous implementation due to systematic deviations in the generated data. These chances tell whether it is easy to find a seed which passes the tests or not. Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's exactly the point I've raised on the mailing-list: out of three seeds (100, 1000 and 1001), only one works. Of course, I would not dare to call that representative statistics, but I'm wondering whether or not we should be worried...&lt;/p&gt;
, &lt;p&gt;The issue about selection of an appropriate seed has been raised elsewhere. No definitive answer has been provided so far, so I suggest we consider this issue as solved for the time being.&lt;/p&gt;
], resolution=Fixed, reporter=cwinter, assignees=[], commentAuthors=[psteitz, celestin, mikl, cwinter], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-654
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-654, created=Tue Aug 30 19:23:19 CEST 2011, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Thu Sep 01 02:14:02 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=ValueServer not deterministic for a fixed random number seed, link=https://issues.apache.org/jira/browse/MATH-654, description=&lt;p&gt;I have built an agent-based model using the Apache Commons Math library, which has come in handy.&lt;/p&gt;

&lt;p&gt;The ValueServer seemed particularly helpful, as explained at:&lt;br/&gt;
&lt;a href="http://commons.apache.org/math/userguide/random.html"&gt;http://commons.apache.org/math/userguide/random.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My simulation needs repeatable randomness, so I used this form of the ValueServer constructor:&lt;/p&gt;

&lt;p&gt;    ValueServer(RandomData randomData) &lt;br/&gt;
    Construct a ValueServer instance using a RandomData as its source of random data.&lt;br/&gt;
    // &lt;a href="http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html"&gt;http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, in my simulation, I found that the ValueServer did not act deterministically if I supplied the same random number seed.&lt;/p&gt;

&lt;p&gt;I have not inspected the source code, but I suspect that the ValueServer is not using the `randomData` generator correctly. If it was, then it should be deterministic.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  I assume you are using DIGEST_MODE.  If this is the case and you are comfortable compiling the code in trunk, the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-634" title="EmpiricalDistributionImpl should use a pluggable RandomGenerator"&gt;&lt;del&gt;MATH-634&lt;/del&gt;&lt;/a&gt; enables a workaround for this.  Using the reseed method added to EmpiricalDistributionImpl in trunk, you can use ValueServer's getEmpiricalDistribution to get the distribution and then invoke reseed.  Unfortunately, this method does not exist in any released version yet.&lt;/p&gt;

&lt;p&gt;The problem is that ValueServer#getNextDigest (what it does for getNext in DIGEST_MODE) delegates to EmpiricalDistributionImpl#getNextValue.  EmpiricalDistributionImpl has its own RandomData instance.  To fix this issue, EmpiricalDistirbutionImpl should add a constructor taking a RandomData and ValueServer should provide this.&lt;/p&gt;
, &lt;p&gt;Fixed in r1163875. ValueServer now exposes a reSeed method that when supplied a fixed seed will generate a fixed sequence in any stochastic mode. The RandomDataImpl that it uses internally is passed to the EmpiricalDistributionImpl it creates when used in DIGEST_MODE.  The changes for this issue include an incompatible (vs. 2.x) change: the constructor for EmpiricalDistributionImpl that previously took a RandomData now takes a RandomDataImpl.  The plan for 3.0 is to merge these.&lt;/p&gt;
], resolution=Fixed, reporter=d.james, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-640
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-640, created=Tue Aug 02 21:06:35 CEST 2011, updated=Sat Mar 24 17:16:52 CET 2012, resolved=Wed Aug 03 06:17:43 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=AbstractRandomGenerator nextInt() and nextLong() default implementations generate only positive values, link=https://issues.apache.org/jira/browse/MATH-640, description=&lt;p&gt;The javadoc for these methods (and what is specified in the RandomGenerator interface) says that all int / long values should be in the range of these methods.  The default implementations provided in this class do not generate negative values.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1153338&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-618
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-618, created=Wed Jul 13 22:23:43 CEST 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Thu Jul 14 08:08:54 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same, link=https://issues.apache.org/jira/browse/MATH-618, description=&lt;p&gt;For both Complex add and subtract, the javadoc states that&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;* If either &lt;span class="code-keyword"&gt;this&lt;/span&gt; or &amp;lt;code&amp;gt;rhs&amp;lt;/code&amp;gt; has a NaN value in either part,
     * {@link #NaN} is returned; otherwise Inifinite and NaN values are
     * returned in the parts of the result according to the rules &lt;span class="code-keyword"&gt;for&lt;/span&gt;
     * {@link java.lang.&lt;span class="code-object"&gt;Double&lt;/span&gt;} arithmetic&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1146573&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-588
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-588, created=Sun Jun 12 20:19:07 CEST 2011, updated=Sat Mar 24 17:16:31 CET 2012, resolved=Sun Feb 05 20:54:50 CET 2012, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Weighted Mean evaluation may not have optimal numerics, link=https://issues.apache.org/jira/browse/MATH-588, description=&lt;p&gt;I recently got this in a test run&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;testWeightedConsistency(org.apache.commons.math.stat.descriptive.moment.MeanTest)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;0.002282165958997601&amp;gt; but was:&amp;lt;0.002282165958997157&amp;gt;
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:441)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:178)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:153)
	at org.apache.commons.math.stat.descriptive.UnivariateStatisticAbstractTest.testWeightedConsistency(UnivariateStatisticAbstractTest.java:170)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The correction formula used to compute the unweighted mean may not be appropriate or optimal in the presence of weights:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// Compute initial estimate using definitional formula
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; sumw = sum.evaluate(weights,begin,length);
&lt;span class="code-object"&gt;double&lt;/span&gt; xbarw = sum.evaluate(values, weights, begin, length) / sumw;

&lt;span class="code-comment"&gt;// Compute correction factor in second pass
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; correction = 0;
&lt;span class="code-keyword"&gt;for&lt;/span&gt; (&lt;span class="code-object"&gt;int&lt;/span&gt; i = begin; i &amp;lt; begin + length; i++) {
  correction += weights[i] * (values[i] - xbarw);
}
&lt;span class="code-keyword"&gt;return&lt;/span&gt; xbarw + (correction/sumw);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;, comments=[&lt;p&gt;Fixed it in r1240790.&lt;/p&gt;

&lt;p&gt;There was a too strict equality test using an relative error of 10-14 which resulted in certain unforunate cases of an absolute error of 10-18.&lt;/p&gt;
, &lt;p&gt;Corrected the equality test in r1240795 as it was leading to failure. In fact the test can range from very small to very large values which really requires a relative error estimate.&lt;/p&gt;

&lt;p&gt;The test is problematic in general, as it may contain values from very different scales (due to its random nature), leading to unavoidable precision errors in the above formula.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[tn], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-575
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-575, created=Sat May 14 18:40:34 CEST 2011, updated=Sat Mar 24 17:16:54 CET 2012, resolved=Thu Feb 02 12:12:52 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=Exceptions in genetics package or not consistent with the rest of [math], link=https://issues.apache.org/jira/browse/MATH-575, description=&lt;p&gt;InvalidRepresentationException is checked and non-localized.  This exception should be placed in the &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; hierarchy.  The AbstractListChromosome constructor also throws a non-localised IAE, which should be replaced by an appropriate &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; exception.&lt;/p&gt;, comments=[&lt;p&gt;Phil started to work on this issue in r1135025.&lt;/p&gt;

&lt;p&gt;In r1235038 additional cleanups have been performed:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;add localized messages for all exceptions&lt;/li&gt;
	&lt;li&gt;add @throws to javadoc where appropriate&lt;/li&gt;
	&lt;li&gt;add final to method parameters&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What is missing:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;Phil mentioned that InvalidRepresentationException should be placed into &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, although I am not sure why, as it is not used outside the genetics package&lt;/li&gt;
	&lt;li&gt;add more custom exception classes specific to the genetics package (optional). By now mostly MathIllegalArgumentException or other appropriate ones have been used.&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;Thanks for working on this, but before you do start to make modifications, please assign the issue to yourself!&lt;/p&gt;

&lt;p&gt;For the changes themselves, I don't agree with the creation of those many localized messages: We have been trying to rationalize and reduce the number of those, by removing duplicates and combining several ones to convey the full explanation of the problem. See my reply to the commit message.&lt;/p&gt;
, &lt;p&gt;Fixed in r1235197.&lt;/p&gt;

&lt;p&gt;Thanks for your suggestions!&lt;/p&gt;
, &lt;p&gt;Thomas,&lt;br/&gt;
Could please check whether this issue is resolved? And if it is, mark it so? Thanks.&lt;/p&gt;
, &lt;p&gt;As from the original issue description, Phil intended to move the InvalidRepresentationException to the general o.a.c.m.exceptions package. I am not sure about this, that's why I kept it aside for the time being. If we agree on keeping it in the genetics package we can resolve this issue.&lt;/p&gt;
, &lt;p&gt;Phil had always been opposed to having all exceptions grouped in their own package; so I doubt that he meant to move that one over there... &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
Here, the description just indicates that the exception should become &lt;em&gt;unchecked&lt;/em&gt; and that the "detailed message" should be an element from the "LocalizedFormats" enum (i.e. derive from one of the base CM exceptions).&lt;/p&gt;
, &lt;p&gt;Ah ok, that makes it clear. When reading hierarchy I was just thinking in terms of packages rather than class hierarchy.&lt;/p&gt;

&lt;p&gt;Thus, I resolve this issue.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[tn], commentAuthors=[tn, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-555
2016-01-13 22:07:48,542 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-555, created=Mon Apr 04 06:13:04 CEST 2011, updated=Sat Mar 24 17:16:43 CET 2012, resolved=Mon Apr 04 06:53:13 CEST 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=MathUtils round method should propagate rather than wrap Runitme exceptions, link=https://issues.apache.org/jira/browse/MATH-555, description=&lt;p&gt;MathUtils.round(double, int, int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException, the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in trunk in r1088473&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,620 : INFO  : KNIME-Worker-2 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:2 : Transforming to jira entries.
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-724
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-724, created=Mon Dec 12 16:03:41 CET 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Tue Dec 20 22:14:16 CET 2011, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=RandomDataImpl.nextInt does not distribute uniformly for negative lower bound, link=https://issues.apache.org/jira/browse/MATH-724, description=&lt;p&gt;When using the RandomDataImpl.nextInt function to get a uniform sample in a &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt; interval, when the lower value is less than zero, the output is not uniformly distributed, as the lowest value is practically never returned.&lt;/p&gt;

&lt;p&gt;See the attached NextIntUniformTest.java file. It uses a &lt;span class="error"&gt;&amp;#91;-3, 5&amp;#93;&lt;/span&gt; interval. For several values between 0 and 1, testNextIntUniform1 prints the return value of RandomDataImpl.nextInt (as double and as int). We see that -2 through 5 are returned several times. The -3 value however, is only returned for 0.0, and is thus under-respresented in the integer samples. The output of test method testNextIntUniform2 also clearly shows that value -3 is never sampled.&lt;/p&gt;, comments=[&lt;p&gt;NextIntUniformTest.java: see issue description&lt;/p&gt;
, &lt;p&gt;Thanks for reporting this. The problem is in the rounding, which does not work correctly for negative values.  My first inclination is to test for negative lower bound and just shift the interval in that case.  Any better ideas?&lt;/p&gt;
, &lt;p&gt;math-724.patch: it first scales the [0..1) interval to [0..length), then discretizes it, and finally shifts it to &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;It may be a good idea to also add some tests for cases such as &lt;span class="error"&gt;&amp;#91;0,3&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-5, -3&amp;#93;&lt;/span&gt;, and see if the distribution of sampled values is uniform. It seems RandomDataTest.testNextInt does this using chiSquare, but since I'm not familiar with that, I'm not sure how to add more tests for the other lower/upper bound pairs...&lt;/p&gt;
, &lt;p&gt;I just ran the unit tests with my patch applied, an the following test, in RandomDataTest:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;@Test
    &lt;span class="code-keyword"&gt;public&lt;/span&gt; void testNextIntExtremeValues() {
        &lt;span class="code-object"&gt;int&lt;/span&gt; x = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        &lt;span class="code-object"&gt;int&lt;/span&gt; y = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        Assert.assertFalse(x == y);
    }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails, as does testNextLongExtremeValues. Both x and y become equal to Integer.MIN_VALUE, making x == y to become true, causing the assertion to fail...&lt;/p&gt;
, &lt;p&gt;Also note that RandomDataImpl.nextUniform uses a similar scale/shift method to transform the range. It may thus suffer from the same failure in case of extreme values...&lt;/p&gt;
, &lt;p&gt;math-724-v2.patch: 2nd patch.&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;I think all unit tests work now, including the ones for the Integer.MIN_VALUE to Integer.MAX_VALUE interval.&lt;/li&gt;
	&lt;li&gt;The original problem was that negative values were rounded up by the conversion from double to int, while positive numbers were rounded down. By using floor, we first round the numbers down, and then convert to integer, thus ensuring a proper uniform distribution.&lt;/li&gt;
	&lt;li&gt;Test cases for negative values are still missing... Could someone else add them?&lt;/li&gt;
	&lt;li&gt;RandomDataImpl.nextUniform: I haven't changed this, as the change that I used for integers does not have the desired effect for doubles... This may be caused by the fact that Double.MIN_VALUE is more negative than Double.MAX_VALUE is positive, but I'm not really sure. Maybe it is not even an issue for the nextUniform method?&lt;/li&gt;
&lt;/ul&gt;

, &lt;blockquote&gt;&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; the fact that Double.MIN_VALUE is more negative &lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="http://docs.oracle.com/javase/6/docs/api/java/lang/Double.html#MIN_VALUE"&gt;Double.Min_VALUE&lt;/a&gt; is a &lt;em&gt;positive&lt;/em&gt; number.&lt;/p&gt;
, &lt;blockquote&gt;&lt;p&gt;Double.Min_VALUE is a positive number.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops...&lt;/p&gt;

&lt;p&gt;OK, I uploaded a third version of the patch (math-724-v3.patch), which also applies the new formula for nextUniform. I included two test files (NextUniformTest3.java and NextIntTest3.java), that show the results for nextInt and nextUniform, for both the old and new formulas. As for as I can see, the new formula works equally well or better in all cases. Also, all existing unit tests pass.&lt;/p&gt;
, &lt;p&gt;Thanks for reporting and diagnosing this, Dennis.&lt;/p&gt;

&lt;p&gt;Slightly modified version of the third patch (just removing unecessary parens), along with tests, committed in r1221490.  The "negativeToPositiveRange" tests fail before the fix.  The change to nextUniform is also needed to prevent overflows. I changed the relevant test cases to use the TestUtils chisquare test, which is more straightforward and has better output.  This was added after the original versions of these tests were written.  Others in this class should be similarly updated.  Patches welcome to further tidy the tests, but this issue can be resolved.&lt;/p&gt;
], resolution=Fixed, reporter=dhendriks, assignees=[], commentAuthors=[dhendriks, psteitz, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-723
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-723, created=Sun Dec 11 22:03:37 CET 2011, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Sun Dec 11 22:59:41 CET 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=BitStreamGenerators (MersenneTwister, Well generators) do not clear normal deviate cache on setSeed, link=https://issues.apache.org/jira/browse/MATH-723, description=&lt;p&gt;The BitStream generators generate normal deviates (for nextGaussian) in pairs, caching the last value generated. When reseeded, the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1213087.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-719
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-719, created=Tue Dec 06 18:07:24 CET 2011, updated=Sat Mar 24 17:16:38 CET 2012, resolved=Mon Jan 23 12:28:07 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[], priority=Minor, summary=Strange deprecations in API, link=https://issues.apache.org/jira/browse/MATH-719, description=&lt;p&gt;Sorry if this doesn't belong here. I couldn't find any sort of mailing list or other feedback mechanism on the website.&lt;/p&gt;

&lt;p&gt;RealMatrix has some very odd deprecations. In particular inverse(), getDeterminant() and isSingular(). The last has the message:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Deprecated. as of release 2.0, replaced by the boolean negation of new LUDecompositionImpl(m).getSolver().isNonSingular()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's an implementation, not an interface. The whole point of having an interface is that &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I can query whether a matrix is singular withou having to know about LUDecompositions&lt;/li&gt;
	&lt;li&gt;You guys can change the implementation of isSingular() if something better pops up without us guys having to change our code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I'm not using these methods now, because they're deprecated, but I've basically recreated them in as static methods in a utility class. Wouldn't it be much better to just put code from the deprecation message into the method and remove the deprecation?&lt;/p&gt;, comments=[&lt;blockquote&gt;&lt;p&gt;Sorry if this doesn't belong here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Indeed, you'd better bring this kind of issue to the "dev" ML. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
The more so that there have been recent discussions about changing the matrix API and decisions ought to be made quite soon now.&lt;/p&gt;
, &lt;p&gt;Ah, so there is a mailing list. I guess I should have looked a little harder. I'll bring it up there.&lt;/p&gt;
, &lt;p&gt;It is unlikely that we can come up with a new design before the release of v3.0.&lt;br/&gt;
This must be thoroughly discussed first on the "dev" ML, together with other matrix interface issues.&lt;/p&gt;
], resolution=Unknown, reporter=pbloem, assignees=[], commentAuthors=[erans, pbloem], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-692
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-692, created=Tue Oct 18 20:01:57 CEST 2011, updated=Sat Mar 24 17:16:26 CET 2012, resolved=Thu Feb 02 07:45:59 CET 2012, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 1.3
, 2.0
, 2.1
, 2.2
, 2.2.1
, 3.0
], fixVersion=[3.0
], priority=Minor, summary=Cumulative probability and inverse cumulative probability inconsistencies, link=https://issues.apache.org/jira/browse/MATH-692, description=&lt;p&gt;There are some inconsistencies in the documentation and implementation of functions regarding cumulative probabilities and inverse cumulative probabilities. More precisely, '&amp;lt;' and '&amp;lt;=' are not used in a consistent way.&lt;/p&gt;

&lt;p&gt;Besides I would move the function inverseCumulativeProbability(double) to the interface Distribution. A true inverse of the distribution function does neither exist for Distribution nor for ContinuosDistribution. Thus we need to define the inverse in terms of quantiles anyway, and this can already be done for Distribution.&lt;/p&gt;

&lt;p&gt;On the whole I would declare the (inverse) cumulative probability functions in the basic distribution interfaces as follows:&lt;/p&gt;

&lt;p&gt;Distribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(double x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(double x0, double x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1)&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;inverseCumulativeProbability(double p):&lt;br/&gt;
  returns the quantile function inf{x in R | P(X&amp;lt;=x) &amp;gt;= p} &lt;span class="error"&gt;&amp;#91;see also 2), 3), and 4)&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1) An aternative definition could be P(x0 &amp;lt;= X &amp;lt;= x1). But this requires to put the function probability(double x) or another cumulative probability function into the interface Distribution in order be able to calculate P(x0 &amp;lt;= X &amp;lt;= x1) in AbstractDistribution.&lt;br/&gt;
2) This definition is stricter than the definition in ContinuousDistribution, because the definition there does not specify what to do if there are multiple x satisfying P(X&amp;lt;=x) = p.&lt;br/&gt;
3) A modification could be defined for p=0: Returning sup{x in R | P(X&amp;lt;=x) = 0} would yield the infimum of the distribution's support instead of a mandatory -infinity.&lt;br/&gt;
4) This affects issue &lt;a href="https://issues.apache.org/jira/browse/MATH-540" title="AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug"&gt;&lt;del&gt;MATH-540&lt;/del&gt;&lt;/a&gt;. I'd prefere the definition from above for the following reasons:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;This definition simplifies inverse transform sampling (as mentioned in the other issue).&lt;/li&gt;
	&lt;li&gt;It is the standard textbook definition for the quantile function.&lt;/li&gt;
	&lt;li&gt;For integer distributions it has the advantage that the result doesn't change when switching to "x in Z", i.e. the result is independent of considering the intergers as sole set or as part of the reals.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ContinuousDistribution:&lt;br/&gt;
nothing to be added regarding (inverse) cumulative probability functions&lt;/p&gt;

&lt;p&gt;IntegerDistribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(int x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(int x0, int x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1) above&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;, comments=[&lt;p&gt;Thanks for raising this issue, Christian - especially now as we finalize the 3.0 API.&lt;/p&gt;

&lt;p&gt;I am +1 for these changes.  I agree that the inf-based definition of inverse cum is more standard and we are in a position now make the change, so I say lets do it.  I am also +1 on the move of this up to the distribution interface.  The reason we did not include it there originally was that we thought we might implement distributions for which we could not define inverses.  That has not happened in the last 8 years, so I think its safe enough to push it up.&lt;/p&gt;

&lt;p&gt;The code, test, user guide and doc changes for this have to be done carefully.  Patches most welcome.&lt;/p&gt;

&lt;p&gt;Is everyone else OK with this change?&lt;/p&gt;
, &lt;p&gt;I have neither used nor developed this part of CM, so my view on this is of but little value. Having said that, anything improving consistency can only be desirable, especially at this stage. So I'm all for it, and will be soon available (when I'm done on SYMMLQ) for an (novice on these issues) help.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;+1&lt;/p&gt;
, &lt;p&gt;Thanks for the feedback to all. Sbastien, thanks for offering your help. If you like and find time for it, you could implement AbstractDistribution.inverseCumulativeProbability(double p).&lt;/p&gt;

&lt;p&gt;I will provide some patches next week, but adjusting AbstractContinuousDistribution.inverseCumulativeProbability(double p) will take some more time.&lt;/p&gt;

&lt;p&gt;After thinking a little more about the structure of the interfaces, I'd like to put the function probability(double x) to Distribution anyway (independently of the thought in point 1) above).&lt;/p&gt;

&lt;p&gt;Are there any preferences on P(x0 &amp;lt;= X &amp;lt;= x1) or P(x0 &amp;lt; X &amp;lt;= x1) for cumulativeProbability(double x0, double x1)?&lt;/p&gt;
, &lt;p&gt;I am not sure it is really makes sense to add probability(double x) to the Distribution interface.  It would have to be defined as density (referring to the distribution function) to make sense in the continuous case, since defined as p(X = x) it would in most cases be identically 0 for continuous distributions.&lt;/p&gt;

&lt;p&gt;Regarding the cum definition, I am fine with P(x0 &amp;lt; X &amp;lt;= x1).&lt;/p&gt;
, &lt;p&gt;Happy to help on the inverse cumulative probability. You will have to be patient and forgieving with me, though, as I discover this part of CM.&lt;/p&gt;

&lt;p&gt;As for the definition, I think that one of the bounds should be excluded, so that these cumulative probabilities can be summed&lt;br/&gt;
P(a &amp;lt; X &amp;lt;= c) = P(a &amp;lt; X &amp;lt;= b) + P(b &amp;lt; X &amp;lt;= c),&lt;br/&gt;
even in the case of discrete PDFs.&lt;/p&gt;

&lt;p&gt;Whether the lower or upper bound should be excluded is another matter. I usually work with continuous pdfs, so I don't know if there is a common practice in the probability community. If there is none, I would tend to chose the following definition&lt;br/&gt;
P(x0 &amp;lt;= X &amp;lt; x1)&lt;br/&gt;
(sorry Phil!), because it would be consistent with the way things are usually indexed in java (a&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;.. a&lt;span class="error"&gt;&amp;#91;a.length-1&amp;#93;&lt;/span&gt;). See also &lt;tt&gt;org.apache.commons.math.util.MultidimensionalCounter&lt;/tt&gt;. Although this type of consistency is not an absolute requirement, I think it is nice for the user to have such simple principle: "lower bound always included, upper bound always excluded". Appart from this small point, I really have no objection to any choice.&lt;/p&gt;
, &lt;p&gt;Have a look at the default implementation of cum(x0,x1) now in AbstractDistribution.  I think the incorrectness in the documentation there may have been what triggered Christian to raise this issue.  The equation cum(a,b) = F(b) - F(a) where F is the distribution function is natural and what the impl there is trying to do.  In the discrete case, this equation fails, however, unless you define the cum to exclude the &lt;b&gt;lower&lt;/b&gt; endpoint.  That's why P(x0 &amp;lt; X &amp;lt;= x1) is a better definition.&lt;/p&gt;
, &lt;p&gt;OK, Phil, it makes perfect sense.&lt;/p&gt;
, &lt;p&gt;Good, the definition of cum(x0,x1) will be P(x0 &amp;lt; X &amp;lt;= x1). Phil, you are right: cum(x0,x1) in AbstractDistribution was a reason for raising this issue. Another reason was cum(int x0, int x1) in AbstractIntegerDistribution.&lt;/p&gt;

&lt;p&gt;The idea behind probability(double x) is in fact to define it as p(X = x) and to return 0 for continuous distributions. This function would be useful for discrete distributions not inheriting from IntergerDistribution and for distributions being composed of discrete and continuous parts.&lt;/p&gt;
, &lt;p&gt;I guess I am OK with pushing p&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/error.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt; up.  See related post to follow in commons-dev. &lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
I've started looking into this issue. As I said, you will have to be patient with me &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;.&lt;br/&gt;
I can see there already is a default implementation of &lt;tt&gt;AbstractContinuousDistribution.inverseCumulativeProbability&lt;/tt&gt;. So what exactly would you like me to do? Is this implementation fragile? Would you like me to improve robustness? Provide full testing?&lt;/p&gt;

&lt;p&gt;I think there might be issues when the PDF falls down to zero in a range (in which case the cum exhibits a plateau). The returned value might differ from the mathematical definition you proposed. Is this what you want me to work on? Have you already identified other issues?&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;

&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;

&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;

&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;
, &lt;p&gt;Another point for discussion:&lt;br/&gt;
I'd like to introduce&lt;br/&gt;
getDomainBracket(double p): returns double[]&lt;br/&gt;
to AbstractDistribution as helper function for inverseCumulativeProbability. This allows to avoid searching a bracket where a bracket can be specified directly.&lt;br/&gt;
The function getDomainBracket could be made abstract (which means to remove getInitialDomain, getDomainLowerBound, and getDomainUpperBound as these functions aren't needed any more), or it could have a default implementation (according to the corresponding part of the current implementation of inverseCumulativeProbability) which uses getInitialDomain, getDomainLowerBound, and getDomainUpperBound. However, getInitialDomain, getDomainLowerBound, and getDomainUpperBound should not be abstract in the latter case. Otherwise a derived class would be forced to implement something it potentially doesn't use. Thus the functions getInitialDomain, getDomainLowerBound, and getDomainUpperBound should have default implementations which either return default values (0, -infinity, +infinity) or throw an exception saying something like "has to be implemented".&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I'm working on it...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, for now, I'm concentrating on making the current impl in &lt;tt&gt;AbstractContinuousDistribution&lt;/tt&gt; more robust. The other impl should be easier.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current implementation uses a Brent solver. I think the solver itself is only one side of the issue. The other point is the algorithm used to bracket the solution, in order to ensure that the result is consistent with the definition of the cumprob. As for the &lt;tt&gt;DifferentiableUnivariateRealSolver&lt;/tt&gt;, I'm not too sure. I guess it depends on what is meant by "continuous distribution". For me, it means that the random variable takes values in a continuous set, and possibly its distribution is defined by a density. However, in my view, nothing prevents occurences of Dirac functions, in which case the cum sum is only piecewise C1. It's all a matter of definition, of course, and I'll ask the question on the forum to check whether or not people want to allow for such a situation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I'm very interested.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Please note that &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt; has been created specifically to handle plateaux.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;Here is the first patch for this issue (unfortunately with some delay). It adjusts the distributions with real domain to the definitions in this issue, and it mainly changes documentations.&lt;/p&gt;

&lt;p&gt;I could not move inverseCumulativeProbability(double) up to Distribution because there would be a conflict with IntegerDistribution.inverseCumulativeProbability(double): This method returns int. This problem will be removed by solving issue &lt;a href="https://issues.apache.org/jira/browse/MATH-703" title="Splitting up the distribution hierarchy"&gt;&lt;del&gt;MATH-703&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The implementation of inverseCumulativeProbability(double) is not changed as Sbastien is working on this.&lt;/p&gt;

&lt;p&gt;I will provide the patch for the integer distributions as soon as I have adjusted the test data to the new inequalities and reverified the adjusted test data.&lt;/p&gt;
, &lt;p&gt;All,&lt;br/&gt;
since I'm already working on this package, I'm happy to commit the patch on behalf of Christian. However, since I'm a relatively new committer, I would feel more confident if one of the "old, wise committers" could double check the svn log afterwards.&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hey, that's how it always works &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;  &lt;/p&gt;

&lt;p&gt;I don't know about "wise" but I certainly qualify as "old" by any standard, so will have a look once you have reviewed and committed.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
, &lt;p&gt;Patch &lt;tt&gt;Math-692_realDomain_patch1.patch&lt;/tt&gt; (20111108) applied in rev 1200179, with minor modifications (mostly checkstyle fixes).&lt;br/&gt;
Thanks Christian!&lt;/p&gt;
, &lt;p&gt;As mentioned by Sbastien in &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt;, the implementation of &lt;tt&gt;IntegerDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; can benefit from the ideas which came up for &lt;tt&gt;RealDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; in that thread.&lt;/p&gt;

&lt;p&gt;Thus I will remove &lt;tt&gt;getDomainLowerBound(double p)&lt;/tt&gt; and &lt;tt&gt;getDomainUpperBound(double p)&lt;/tt&gt; from the integer distributions. I checked that all current implementations of the lower/upper bound methods provide the whole support of the distribution as starting bracket. This means that using &lt;tt&gt;getSupportLowerBound()&lt;/tt&gt; and &lt;tt&gt;getSupportUpperBound()&lt;/tt&gt; for the starting bracket won't degrade the performance of the current distribution implementations. However, a user might want the improve the performance of his distribution implementations by providing a more targeted starting bracket for probability &lt;tt&gt;p&lt;/tt&gt;. Thus I will swap the solving step to a protected function &lt;tt&gt;solveInverseCumulativeProbability(double p, int lower, int upper)&lt;/tt&gt;, so that it gets easy to override &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; with an implementation which finds a better starting bracket.&lt;/p&gt;

&lt;p&gt;Furthermore, Phil's idea with Chebyshev's inequality can be applied to the generic implementation of &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; in order to get a better starting bracket.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
If you agree with that, I suggest that you also take care of &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;, as the two issues seem to be very much connected.&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;my changes in the integer distributions don't solve &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;. Instead I found a probably related problem with the Pascal distribution.&lt;/p&gt;

&lt;p&gt;The integer distribution patch for this issue still isn't ready. I will provide it next week.&lt;/p&gt;

&lt;p&gt;Christian&lt;/p&gt;
, &lt;p&gt;This is the patch which adjusts the integer distributions to the agreements above.&lt;/p&gt;

&lt;p&gt;The changes to the test cases for the random generators may be unexpected. But these changes initially were triggered by adjusting &lt;tt&gt;RandomDataTest.checkNextPoissonConsistency(double)&lt;/tt&gt; to the new contract for integer distributions. Then some random generator tests failed due to chance. While adjusting their seeds, I found some other tests with a high failure probability. Thus I also set some failure probabilities to 0.01 in order to find suitable seeds more quickly.&lt;/p&gt;

&lt;p&gt;My next task on this issue is to adjust the user guid.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
thanks for this contribution. I am away for a few days, but am very happy to commit this patch as soon as I am back, if you are not in too much of a hurry.&lt;br/&gt;
Thanks again,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Well, we've recently run into some troubles with SVN, but it seems everything is working fine again. Patch {{&lt;a href="https://issues.apache.org/jira/browse/MATH-692" title="Cumulative probability and inverse cumulative probability inconsistencies"&gt;&lt;del&gt;MATH-692&lt;/del&gt;&lt;/a&gt;_integerDomain_patch1.patch}} (with minor checkstyle changes) committed in revision &lt;tt&gt;1226041&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Please do not forget to run &lt;tt&gt;mvn clean; mvn site:site&lt;/tt&gt; and check the reports (in particular, &lt;tt&gt;checkstyle&lt;/tt&gt;) prior to submitting a patch!&lt;/p&gt;

&lt;p&gt;Thanks for this contribution.&lt;/p&gt;
, &lt;p&gt;The committed patch actually causes failure of &lt;tt&gt;Well1024Test&lt;/tt&gt; in &lt;tt&gt;o.a.c.m.random&lt;/tt&gt;.&lt;/p&gt;
, &lt;p&gt;Thanks for committing the patch, Sbastien. I see you already changed the seed in &lt;tt&gt;Well1024aTest&lt;/tt&gt;. This hopefully removes the failure.&lt;/p&gt;

&lt;p&gt;I'll have a look into Maven to prepare a better patch next time. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;I see you already changed the seed in Well1024aTest.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I did, but is this really how we want &lt;tt&gt;Well2004aTest&lt;/tt&gt; to pass?&lt;/p&gt;
, &lt;p&gt;I guess there is no alternative to this way of making probabilistic test cases pass. However, I understand your bad feeling with this kind of failure fixing. The problem is that probabilistic tests are quiet fuzzy: Neither a passed test nor a failed test provides a clear answer whether something is right or wrong in the implementation. There is just a high chance to pass such a test with a correct implementation. The chance for failure increases with an erroneous implementation due to systematic deviations in the generated data. These chances tell whether it is easy to find a seed which passes the tests or not. Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's exactly the point I've raised on the mailing-list: out of three seeds (100, 1000 and 1001), only one works. Of course, I would not dare to call that representative statistics, but I'm wondering whether or not we should be worried...&lt;/p&gt;
, &lt;p&gt;The issue about selection of an appropriate seed has been raised elsewhere. No definitive answer has been provided so far, so I suggest we consider this issue as solved for the time being.&lt;/p&gt;
], resolution=Fixed, reporter=cwinter, assignees=[], commentAuthors=[psteitz, celestin, mikl, cwinter], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-654
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-654, created=Tue Aug 30 19:23:19 CEST 2011, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Thu Sep 01 02:14:02 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=ValueServer not deterministic for a fixed random number seed, link=https://issues.apache.org/jira/browse/MATH-654, description=&lt;p&gt;I have built an agent-based model using the Apache Commons Math library, which has come in handy.&lt;/p&gt;

&lt;p&gt;The ValueServer seemed particularly helpful, as explained at:&lt;br/&gt;
&lt;a href="http://commons.apache.org/math/userguide/random.html"&gt;http://commons.apache.org/math/userguide/random.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My simulation needs repeatable randomness, so I used this form of the ValueServer constructor:&lt;/p&gt;

&lt;p&gt;    ValueServer(RandomData randomData) &lt;br/&gt;
    Construct a ValueServer instance using a RandomData as its source of random data.&lt;br/&gt;
    // &lt;a href="http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html"&gt;http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, in my simulation, I found that the ValueServer did not act deterministically if I supplied the same random number seed.&lt;/p&gt;

&lt;p&gt;I have not inspected the source code, but I suspect that the ValueServer is not using the `randomData` generator correctly. If it was, then it should be deterministic.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  I assume you are using DIGEST_MODE.  If this is the case and you are comfortable compiling the code in trunk, the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-634" title="EmpiricalDistributionImpl should use a pluggable RandomGenerator"&gt;&lt;del&gt;MATH-634&lt;/del&gt;&lt;/a&gt; enables a workaround for this.  Using the reseed method added to EmpiricalDistributionImpl in trunk, you can use ValueServer's getEmpiricalDistribution to get the distribution and then invoke reseed.  Unfortunately, this method does not exist in any released version yet.&lt;/p&gt;

&lt;p&gt;The problem is that ValueServer#getNextDigest (what it does for getNext in DIGEST_MODE) delegates to EmpiricalDistributionImpl#getNextValue.  EmpiricalDistributionImpl has its own RandomData instance.  To fix this issue, EmpiricalDistirbutionImpl should add a constructor taking a RandomData and ValueServer should provide this.&lt;/p&gt;
, &lt;p&gt;Fixed in r1163875. ValueServer now exposes a reSeed method that when supplied a fixed seed will generate a fixed sequence in any stochastic mode. The RandomDataImpl that it uses internally is passed to the EmpiricalDistributionImpl it creates when used in DIGEST_MODE.  The changes for this issue include an incompatible (vs. 2.x) change: the constructor for EmpiricalDistributionImpl that previously took a RandomData now takes a RandomDataImpl.  The plan for 3.0 is to merge these.&lt;/p&gt;
], resolution=Fixed, reporter=d.james, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-640
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-640, created=Tue Aug 02 21:06:35 CEST 2011, updated=Sat Mar 24 17:16:52 CET 2012, resolved=Wed Aug 03 06:17:43 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=AbstractRandomGenerator nextInt() and nextLong() default implementations generate only positive values, link=https://issues.apache.org/jira/browse/MATH-640, description=&lt;p&gt;The javadoc for these methods (and what is specified in the RandomGenerator interface) says that all int / long values should be in the range of these methods.  The default implementations provided in this class do not generate negative values.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1153338&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-618
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-618, created=Wed Jul 13 22:23:43 CEST 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Thu Jul 14 08:08:54 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same, link=https://issues.apache.org/jira/browse/MATH-618, description=&lt;p&gt;For both Complex add and subtract, the javadoc states that&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;* If either &lt;span class="code-keyword"&gt;this&lt;/span&gt; or &amp;lt;code&amp;gt;rhs&amp;lt;/code&amp;gt; has a NaN value in either part,
     * {@link #NaN} is returned; otherwise Inifinite and NaN values are
     * returned in the parts of the result according to the rules &lt;span class="code-keyword"&gt;for&lt;/span&gt;
     * {@link java.lang.&lt;span class="code-object"&gt;Double&lt;/span&gt;} arithmetic&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1146573&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-588
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-588, created=Sun Jun 12 20:19:07 CEST 2011, updated=Sat Mar 24 17:16:31 CET 2012, resolved=Sun Feb 05 20:54:50 CET 2012, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Weighted Mean evaluation may not have optimal numerics, link=https://issues.apache.org/jira/browse/MATH-588, description=&lt;p&gt;I recently got this in a test run&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;testWeightedConsistency(org.apache.commons.math.stat.descriptive.moment.MeanTest)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;0.002282165958997601&amp;gt; but was:&amp;lt;0.002282165958997157&amp;gt;
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:441)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:178)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:153)
	at org.apache.commons.math.stat.descriptive.UnivariateStatisticAbstractTest.testWeightedConsistency(UnivariateStatisticAbstractTest.java:170)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The correction formula used to compute the unweighted mean may not be appropriate or optimal in the presence of weights:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// Compute initial estimate using definitional formula
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; sumw = sum.evaluate(weights,begin,length);
&lt;span class="code-object"&gt;double&lt;/span&gt; xbarw = sum.evaluate(values, weights, begin, length) / sumw;

&lt;span class="code-comment"&gt;// Compute correction factor in second pass
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; correction = 0;
&lt;span class="code-keyword"&gt;for&lt;/span&gt; (&lt;span class="code-object"&gt;int&lt;/span&gt; i = begin; i &amp;lt; begin + length; i++) {
  correction += weights[i] * (values[i] - xbarw);
}
&lt;span class="code-keyword"&gt;return&lt;/span&gt; xbarw + (correction/sumw);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;, comments=[&lt;p&gt;Fixed it in r1240790.&lt;/p&gt;

&lt;p&gt;There was a too strict equality test using an relative error of 10-14 which resulted in certain unforunate cases of an absolute error of 10-18.&lt;/p&gt;
, &lt;p&gt;Corrected the equality test in r1240795 as it was leading to failure. In fact the test can range from very small to very large values which really requires a relative error estimate.&lt;/p&gt;

&lt;p&gt;The test is problematic in general, as it may contain values from very different scales (due to its random nature), leading to unavoidable precision errors in the above formula.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[tn], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-575
2016-01-13 22:07:48,635 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-575, created=Sat May 14 18:40:34 CEST 2011, updated=Sat Mar 24 17:16:54 CET 2012, resolved=Thu Feb 02 12:12:52 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=Exceptions in genetics package or not consistent with the rest of [math], link=https://issues.apache.org/jira/browse/MATH-575, description=&lt;p&gt;InvalidRepresentationException is checked and non-localized.  This exception should be placed in the &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; hierarchy.  The AbstractListChromosome constructor also throws a non-localised IAE, which should be replaced by an appropriate &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; exception.&lt;/p&gt;, comments=[&lt;p&gt;Phil started to work on this issue in r1135025.&lt;/p&gt;

&lt;p&gt;In r1235038 additional cleanups have been performed:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;add localized messages for all exceptions&lt;/li&gt;
	&lt;li&gt;add @throws to javadoc where appropriate&lt;/li&gt;
	&lt;li&gt;add final to method parameters&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What is missing:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;Phil mentioned that InvalidRepresentationException should be placed into &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, although I am not sure why, as it is not used outside the genetics package&lt;/li&gt;
	&lt;li&gt;add more custom exception classes specific to the genetics package (optional). By now mostly MathIllegalArgumentException or other appropriate ones have been used.&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;Thanks for working on this, but before you do start to make modifications, please assign the issue to yourself!&lt;/p&gt;

&lt;p&gt;For the changes themselves, I don't agree with the creation of those many localized messages: We have been trying to rationalize and reduce the number of those, by removing duplicates and combining several ones to convey the full explanation of the problem. See my reply to the commit message.&lt;/p&gt;
, &lt;p&gt;Fixed in r1235197.&lt;/p&gt;

&lt;p&gt;Thanks for your suggestions!&lt;/p&gt;
, &lt;p&gt;Thomas,&lt;br/&gt;
Could please check whether this issue is resolved? And if it is, mark it so? Thanks.&lt;/p&gt;
, &lt;p&gt;As from the original issue description, Phil intended to move the InvalidRepresentationException to the general o.a.c.m.exceptions package. I am not sure about this, that's why I kept it aside for the time being. If we agree on keeping it in the genetics package we can resolve this issue.&lt;/p&gt;
, &lt;p&gt;Phil had always been opposed to having all exceptions grouped in their own package; so I doubt that he meant to move that one over there... &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
Here, the description just indicates that the exception should become &lt;em&gt;unchecked&lt;/em&gt; and that the "detailed message" should be an element from the "LocalizedFormats" enum (i.e. derive from one of the base CM exceptions).&lt;/p&gt;
, &lt;p&gt;Ah ok, that makes it clear. When reading hierarchy I was just thinking in terms of packages rather than class hierarchy.&lt;/p&gt;

&lt;p&gt;Thus, I resolve this issue.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[tn], commentAuthors=[tn, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,651 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-555
2016-01-13 22:07:48,651 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-555, created=Mon Apr 04 06:13:04 CEST 2011, updated=Sat Mar 24 17:16:43 CET 2012, resolved=Mon Apr 04 06:53:13 CEST 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=MathUtils round method should propagate rather than wrap Runitme exceptions, link=https://issues.apache.org/jira/browse/MATH-555, description=&lt;p&gt;MathUtils.round(double, int, int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException, the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in trunk in r1088473&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,651 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-540
2016-01-13 22:07:48,682 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-540, created=Sun Mar 06 01:43:45 CET 2011, updated=Sat Mar 24 17:16:36 CET 2012, resolved=Sun Jun 12 07:58:50 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug, link=https://issues.apache.org/jira/browse/MATH-540, description=&lt;p&gt;The AbstractIntegerDistribution.inverseCumulativeProbability(...) function attempts to decrement the lower bound of discrete distributions to values that go below the lower bound.&lt;/p&gt;, comments=[&lt;p&gt;I don't think this is a bug.  Per the javadoc, the contract for inverse cum is&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/**
 * For a random variable {@code X} whose values are distributed according
 * to &lt;span class="code-keyword"&gt;this&lt;/span&gt; distribution, &lt;span class="code-keyword"&gt;this&lt;/span&gt; method returns the largest {@code x}, such
 * that {@code P(X &amp;lt; x) &amp;lt; p}.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This implies that if the first non-zero mass point has probability greater than p, the right value to return is one less than that value, which is whet the method will do.  Your example distribution throws NPE when trying to compute probabilities outside of its domain of support. &lt;/p&gt;
, &lt;p&gt;I'm looking at it like this.  I have very simple distribution like the one provided (Four sided dice).  I'm trying to write a simulation that draws values of x for a a set of uniform 0-1 probabilities.  So I'm expecting:&lt;/p&gt;

&lt;p&gt;0 When p is less than or equal to 0.25&lt;br/&gt;
1 When p is greater than 0.25 but less than or equal to 0.50&lt;br/&gt;
2 When p is greater than 0.50 but less than or equal to 0.75&lt;br/&gt;
3 When p is greater than 0.75 but less than or equal to 1.0&lt;/p&gt;

&lt;p&gt;So for the line &lt;/p&gt;

&lt;p&gt;int neverSucceeds = d.inverseCumulativeProbability(0.0001);&lt;/p&gt;

&lt;p&gt;I'm really expecting 0 to be returned.&lt;/p&gt;

&lt;p&gt;Make sense?&lt;/p&gt;
, &lt;p&gt;I see now that there actually does appear to be an error in the javadoc.  The implementation really returns the largest x such that p(X &amp;lt;= x) &amp;lt;= p.  In the discrete case, &amp;lt;= matters and I think both inequalities in the javadoc should be changed.&lt;/p&gt;

&lt;p&gt;In your example, if the probability distribution vanishes outside 0, 1, 2, 3 and puts .25 mass on each of these values, the inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;

&lt;p&gt;If you fix your distribution so that both probability and cumulativeProbability return correct values (rather than throwing NPEs) outside of the mass values, you should get -1 returned.&lt;/p&gt;
, &lt;p&gt;Reading your last comment a little more carefully, it looks like what you are trying to do is implement sampling.  IIUC, something like what you are suggesting should work - you just have an off-by-one problem vis-s-vis the contract of inverse cumulative probabilities as we define them.  I would be +1 for adding direct support for sampling from discrete distributions, but we should open a separate ticket for that.&lt;/p&gt;
, &lt;p&gt;OK - I'll close this one and open a separate ticket.&lt;/p&gt;
, &lt;p&gt;There is a javadoc bug that needs to be fixed here&lt;/p&gt;
, &lt;p&gt;Ooops - Thanks.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;...inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems to me that users would be better served if it returned 0 and that it is also correct to do so.&lt;/p&gt;

&lt;p&gt;In the definition we say "For a random variables X whose values are distributed according to this distribution...".&lt;/p&gt;

&lt;p&gt;Suppose the distribution was for a six sided dice.  One could assert that the distribution is only defined for the values 1,2,3,4,5,6.  In this case the inverseCumulativeDistribution returns 0, but that does not have any meaning.  So now developers are forced to define the meaning of 0 for a six sided dice implementation.  &lt;/p&gt;

&lt;p&gt;In Grad school we were taught the the inverse cumulative distribution is for sampling.  So for a six sided dice uniform probabilities less than 1/6 would return 1, less than 2/6 would return 2, etc.&lt;/p&gt;

&lt;p&gt;With the current implementation for values less than 1/6 we get 0 which is meaningless, and the only time we get 6 is when the uniform probability argument is 1.&lt;/p&gt;

&lt;p&gt;So if someone mistakenly tries to use the inverseCumulativeProbability function for sampling the results are going to be wacked.  What is the use case for the inverseCumulativeProbability the way it is right now?&lt;/p&gt;
, &lt;p&gt;You have a choice in defining the inverse cum whether to define it the way we have or to use and inf rather than a sup.  We can implement sampling using the current impl.  We just need to take into account the way the inverse cum is defined in AbstractIntegerDistribution.  &lt;/p&gt;
, &lt;p&gt;OK - I think it's starting to make more sense to me now.  So when implementing sampling we just add one to the value returned by inverseCumulativeDistribution, unless the uniform probability argument is 1?&lt;/p&gt;
, &lt;p&gt;I am sorry.  I forgot that we had in fact already implemented this in version 2.2. See AbstractIntegerDistribution#sample.  The base class implementation delegates to RandomDataImpl#nextInversionDeviate (adding one per the last comment).&lt;/p&gt;
, &lt;p&gt;Sorry for the noise. I closed the wrong ticket.  Still need to fix the javadoc to match behavior and user guide.&lt;/p&gt;
, &lt;p&gt;Javadoc fixed in trunk r1134866&lt;/p&gt;
], resolution=Fixed, reporter=ole, assignees=[], commentAuthors=[psteitz, ole], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,682 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-506
2016-01-13 22:07:48,682 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-506, created=Tue Feb 01 19:38:01 CET 2011, updated=Sat Mar 24 17:16:41 CET 2012, resolved=Sat Aug 20 23:14:57 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=The static field ChiSquareTestImpl.distribution serves no purpose, link=https://issues.apache.org/jira/browse/MATH-506, description=&lt;p&gt;The static field ChiSquareTestImpl.distribution serves no purpose.&lt;/p&gt;

&lt;p&gt;There is a setter for it, but in every case where the field is used, it is first overwritten with a new value.&lt;/p&gt;

&lt;p&gt;The field and the setter should be removed, and the methods that create a new instance should create a local variable instead.&lt;/p&gt;

&lt;p&gt;For Math 2.1, the field can be removed and the setter deprecated.&lt;/p&gt;, comments=[&lt;p&gt;Agreed.  Since the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; this instance field is unnecessary.&lt;/p&gt;
, &lt;p&gt;See the discussion in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; where it was decided to remove the distribution pluggability in 3.0.  In 2.x, the distribution is pluggable and the instance field is useful.  The 3.0 code in trunk removes the pluggability and makes the field useless.&lt;/p&gt;
, &lt;p&gt;Sorry - I thought I had checked the 2.x implementation as well, but obviously not, as it does use the field.&lt;/p&gt;

&lt;p&gt;However, we should still deprecate the setter in 2.2, as it is removed in 3.0 - OK?&lt;/p&gt;
, &lt;p&gt;Just tried removing the field and setter in 3.0, and found that the constructors rely on the setter (which is a separate bug, as the setter is not final - but easily fixable if required).&lt;/p&gt;

&lt;p&gt;The fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; merely removed deprecated code.&lt;/p&gt;

&lt;p&gt;It replaced "distribution.setDegreesOfFreedom(dof)" with "distribution = new ChiSquaredDistributionImpl(dof)" which is how the field became useless.&lt;/p&gt;

&lt;p&gt;There are two constructors which still create values for the distribution field.&lt;/p&gt;

&lt;p&gt;I don't know enough about the Math to know whether there would be any use cases for having additional methods that used a distribution provided by the class instance, rather than calculated by the individual methods (as at present).&lt;/p&gt;

&lt;p&gt;If there is no need for external provision of the distribution degree of freedom, then the constructor with parameter can be dropped.&lt;/p&gt;

&lt;p&gt;Otherwise, we need to add some methods that can use the provided distribution (which should be a final instance field).&lt;/p&gt;

&lt;p&gt;In any case, I think the setter needs to be dropped from 3.x&lt;/p&gt;
, &lt;p&gt;The instance field was there originally so that different ChiSquareDistribution implementations could be provided at construction time or via a setter (making the underlying ChiSquareDistribution pluggable).  &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; pointed to a different problem related to mutability of implementation instances.  The simplest solution to both problems is to eliminate the pluggability, which the change in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; does for this class.  The degrees of freedom are always computed from the data, so there is no need for the constructor that takes a distribution instance as argument.  Both the constructor and setter can be deprecated in 2.2 and removed in 3.0 unless we want to keep pluggability, which would require&lt;/p&gt;

&lt;p&gt;1) making the distribution field final (so removing the setter)&lt;br/&gt;
2) copying, rather than referencing the actual parameter provided to the constructor&lt;/p&gt;

&lt;p&gt;I am on the fence on this.  Maybe others can chime in (next week &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;p&gt;OK, I see now, thanks!&lt;/p&gt;
, &lt;p&gt;I removed the field (hence eliminating pluggability) in r1159916.  As of 3.0, the distribution classes are immutable, so to support pluggability a factory or class name rather than a distribution instance would have to be provided.  There is only one implementation provided by &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, so I do not see this as worth the effort and complexity to retain.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[psteitz], commentAuthors=[psteitz, sebb@apache.org], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,682 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-505
2016-01-13 22:07:48,682 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-505, created=Tue Feb 01 01:28:56 CET 2011, updated=Sat Mar 24 17:16:40 CET 2012, resolved=Tue Feb 01 19:58:30 CET 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
], fixVersion=[3.0
], priority=Major, summary=TestUtils is thread-hostile, link=https://issues.apache.org/jira/browse/MATH-505, description=&lt;p&gt;TestUtils has several mutable static fields which are not synchronised, or volatile.&lt;/p&gt;

&lt;p&gt;If one of the fields is updated by thread A, there is no guarantee that thread B will see the full update - it may see a partially updated object.&lt;/p&gt;

&lt;p&gt;Furthermore, at least some of the static fields reference a mutable object, which can be changed whilst another thread is using it.&lt;/p&gt;

&lt;p&gt;As far as I can tell, this class must only ever be used by a single thread otherwise the results will be unpredictable.&lt;/p&gt;, comments=[&lt;p&gt;What fields, exactly?&lt;/p&gt;
, &lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/** Singleton TTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; TTest tTest = &lt;span class="code-keyword"&gt;new&lt;/span&gt; TTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; ChiSquareTest chiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; UnknownDistributionChiSquareTest unknownDistributionChiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton OneWayAnova instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; OneWayAnova oneWayAnova =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; OneWayAnovaImpl();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of the above may be changed by set methods. There is no synch.&lt;/p&gt;
, &lt;p&gt;OK, I was looking at the wrong TestUtils &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;

&lt;p&gt;The reason for this strange-looking setup is to allow the implementations to be pluggable at runtime.  "Hostile" is a harsh word, but this class is certainly &lt;b&gt;not&lt;/b&gt; threadsafe.  Ideas / patches to achieve the design goal with less "hostility" would be appreciated.&lt;/p&gt;

&lt;p&gt;I would have to double-check, but I don't think that there is any test instance state used by the methods in this class. &lt;/p&gt;
, &lt;p&gt;By thread-hostile, I mean that it is not possible in general for two different threads to use the class safely.&lt;br/&gt;
If one thread changes any of the static fields, there is no way of knowing how the methods called by the other thread will behave. This is partly because the values are not safely published currently, but even if they were, the threads don't know what settings will be used as they can be changed at any time by another thread.&lt;/p&gt;

&lt;p&gt;In general, any class which relies on mutable static state for its behaviour is thread-hostile.&lt;br/&gt;
The shared state cannot simultaneously satisfy two threads needing different behaviour.&lt;/p&gt;

&lt;p&gt;I think the only safe way for two threads to use the class as it stands is if they both synchronize on the class.&lt;br/&gt;
This will ensure safe publication of any field changes, and enforce serial usage which can guarantee the setting that will be used (but the lock will have to be held for the set call as well).&lt;/p&gt;

&lt;p&gt;ChiSquareTestImpl has a non-final instance field which means its value won't necessarily be safely published.&lt;br/&gt;
The field also has a setter which could be invoked by one thread while another was using it.&lt;/p&gt;

&lt;p&gt;TTestImpl is immutable (has no fields), and OneWayAnovaImpl can be made immutable, but other implementations of the interfaces might exist which are not immutable.&lt;/p&gt;

&lt;p&gt;The simplest way to make the class thread-safe would be to convert all the methods and fields from static to instance, but I don't know if that is acceptable.&lt;/p&gt;
, &lt;p&gt;Making the methods instance sort of defeats the purpose of the class.  None of the instance data in any of the static singletons is actually used or depended on by the methods of this class.  You are correct though that if one thread changes the impl for one of the singletons while another is using the class, the other could see a different than expected impl.  I think the practical likelihood of this is pretty much nil, as it is hard to imagine an application supplying two different implementations for the tests and wanting different threads to use different impls.  Personally, I would be happy just documenting the fact that the class is not threadsafe and if concurrent threads want to plug in different implementations, they need to synchronize on the class.  If this is not acceptable, my next preference would be to remove the pluggability - i.e., make the singletons final or get rid of them altogether, creating instances as needed for static method calls.  There is no initialization overhead creating the test classes.&lt;/p&gt;
, &lt;p&gt;@Phil: Please also keep in mind that M3 supports now (currently optional) parallel execution and it might be no longer a proper assumption that all tests are executed serially.&lt;/p&gt;
, &lt;p&gt;There is another possible option, which would be to fix the default implementations, and create new static methods that took an extra parameter for the implementation to be used.&lt;/p&gt;

&lt;p&gt;At present, changes to the static fields are not guaranteed to be published correctly. Making them volatile would fix this, but would not help with concurrent access.&lt;/p&gt;
, &lt;p&gt;Thanks, Joerg.  There should be no problems with the unit tests unless and until we introduce different tests that actually test the pluggability.  &lt;/p&gt;

&lt;p&gt;I thought about the additional parameter option, Sebb; but that again defeats the purpose of this "convenience class" - you might as well just instantiate the implementation and use it.&lt;/p&gt;

&lt;p&gt;I think the best solution is to just make the fields final and drop the getters and setters.  This is consistent with StatUtils.  So we should document the "hostility" issues in 2.2 and deprecate there and drop in 3.0.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[sebb@apache.org], commentAuthors=[psteitz, sebb@apache.org, joehni], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,682 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-484
2016-01-13 22:07:48,682 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-484, created=Tue Jan 18 21:49:51 CET 2011, updated=Wed Mar 23 21:35:01 CET 2011, resolved=Mon Feb 14 15:20:29 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=events detection in ODE solvers is too complex and not robust, link=https://issues.apache.org/jira/browse/MATH-484, description=&lt;p&gt;All ODE solvers support multiple events detection since a long time. Events are specified by users by implementing the EventHandler interface. Events occur when the g(t, y) function evaluates to 0. When an event occurs, the solver step is shortened to make sure the event is located at the end of the step, and the event is triggered by calling the eventOccurred method in the user defined implementation class. Depending on the return value of this method, integration can continue, it can be stopped, or the state vector can be reset.&lt;/p&gt;

&lt;p&gt;Some ODE solvers are adaptive step size solvers. They can modify step size to match an integration error setting, increasing step size when error is low (thus reducing computing costs) or reducing step size when error is high (thus fulfilling accuracy requirements).&lt;/p&gt;

&lt;p&gt;The step adaptations due to events on one side and due to adaptive step size solvers are quite intricate by now, due to numerous fixes (&lt;a href="https://issues.apache.org/jira/browse/MATH-161" title="patch for Mantissa"&gt;&lt;del&gt;MATH-161&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-213" title="FirstOrderIntegrator.integrate does not give back integration stop time when an event handler stops integration"&gt;&lt;del&gt;MATH-213&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-358" title="ODE integrator goes past specified end of integration range"&gt;&lt;del&gt;MATH-358&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-421" title="restarting an ODE solver that has been stopped by an event doesn&amp;#39;t work"&gt;&lt;del&gt;MATH-421&lt;/del&gt;&lt;/a&gt; and also during standard maintenance - see for example r781157). The code is very difficult to maintain. It seems each bug fix introduces new bugs (r781157/&lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;) or tighten the link between adaptive step size and event detection (&lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;/r927202).&lt;/p&gt;

&lt;p&gt;A new bug discovered recently on an external library using a slightly modified version of this code could not be retroffitted into commons-math, despite the same problem is present. At the beginning of EventState.evaluateStep, the initial step may be exactly 0 thus preventing root solving, but preventing this size to drop to 0 would reopen &lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;. I could not fix both bugs at the same time.&lt;/p&gt;

&lt;p&gt;So it is now time to untangle events detection and adaptive step size, simplify code, and remove some inefficiency (event root solving is always done twice, once before step truncation and another time after truncation, of course with slightly different results, events shortened steps induce high computation load until the integrator recovers its optimal pace again, steps are rejected even when the event does not requires it ...).&lt;/p&gt;, comments=[&lt;p&gt;fixed in subversion repository as of r1061507 for branch 2.X and as of r1061508 for trunk&lt;/p&gt;
, &lt;p&gt;The fix introduced in r1061507 fails in several cases. If several events of the same type occur within a single long step, only the first one is triggered. If several events of different types occur during a backward integration, they are triggered in the wrong order (i.e. they are triggered in forward occurrence time order instead of backward).&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1070498 for branch 2.X and r1070499 for trunk&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-481
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-481, created=Mon Jan 17 18:15:41 CET 2011, updated=Wed Mar 23 21:33:40 CET 2011, resolved=Mon Jan 17 23:39:52 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=MathUtils.equals(double x, double y) disagrees with Javadoc, link=https://issues.apache.org/jira/browse/MATH-481, description=&lt;p&gt;MathUtils.equals(double x, double y) disagrees with Javadoc.&lt;/p&gt;

&lt;p&gt;The Javadoc says:&lt;/p&gt;

&lt;p&gt;Returns true iff they are equal as defined by  {@link #equals(double,double,int)}&lt;/p&gt;

&lt;p&gt;However, the code actually uses == and checks for NaN:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; &lt;span class="code-object"&gt;boolean&lt;/span&gt; equals(&lt;span class="code-object"&gt;double&lt;/span&gt; x, &lt;span class="code-object"&gt;double&lt;/span&gt; y) {
    &lt;span class="code-keyword"&gt;return&lt;/span&gt; (&lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(x) &amp;amp;&amp;amp; &lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(y)) || x == y;
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The method is deprecated, but it should probably still be consistent with its documentation.&lt;/p&gt;, comments=[&lt;p&gt;Corrected Javadoc in revision 1060117.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-465
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-465, created=Wed Jan 05 18:34:41 CET 2011, updated=Sat Mar 24 17:17:03 CET 2012, resolved=Wed Jul 20 14:20:51 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Incorrect matrix rank via SVD, link=https://issues.apache.org/jira/browse/MATH-465, description=&lt;p&gt;The getRank() function of SingularValueDecompositionImpl does not work properly. This problem is probably related to the numerical stability problems mentioned in &lt;a href="https://issues.apache.org/jira/browse/MATH-327"&gt;MATH-327&lt;/a&gt; and &lt;a href="https://issues.apache.org/jira/browse/MATH-320"&gt;MATH-320&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Example call with the standard matrix from R (rank 2):&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeHeader panelHeader" style="border-bottom-width: 1px;"&gt;&lt;b&gt;TestSVDRank.java&lt;/b&gt;&lt;/div&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.Array2DRowRealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.RealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecomposition;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecompositionImpl;

&lt;span class="code-keyword"&gt;public&lt;/span&gt; class TestSVDRank {
	&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; void main(&lt;span class="code-object"&gt;String&lt;/span&gt;[] args) {
		&lt;span class="code-object"&gt;double&lt;/span&gt;[][] d = { { 1, 1, 1 }, { 0, 0, 0 }, { 1, 2, 3 } };
		RealMatrix m = &lt;span class="code-keyword"&gt;new&lt;/span&gt; Array2DRowRealMatrix(d);
		SingularValueDecomposition svd = &lt;span class="code-keyword"&gt;new&lt;/span&gt; SingularValueDecompositionImpl(m);
		&lt;span class="code-object"&gt;int&lt;/span&gt; r = svd.getRank();
		&lt;span class="code-object"&gt;System&lt;/span&gt;.out.println(&lt;span class="code-quote"&gt;"Rank: "&lt;/span&gt;+r);
	}
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;The rank is computed as 3. This problem also occurs for larger matrices. I discovered the problem when trying to replace the corresponding JAMA method.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  Looks like it could as you suggest be related to &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt;.  &lt;/p&gt;
, &lt;p&gt;For now, pushing to 3.0.  If we get a fix for this and &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt; before 3.0 is ready, I may propose a 2.2.1 to include it.&lt;/p&gt;
, &lt;p&gt;My apologies if I am missing something, but here is what I noticed about the SVD. &lt;/p&gt;

&lt;p&gt;On lines 124-127 of SingularValueDecompositionImpl we have:&lt;/p&gt;

&lt;p&gt;        for (int i = 0; i &amp;lt; p; i++) {
            singularValues[i] = FastMath.sqrt(FastMath.abs(singularValues[i]));
        }&lt;/p&gt;

&lt;p&gt;This is potentially the offending line. First is the problem of negative eigenvalues. Negative variance in the principal components should probably be dealt with explicitly? Perhaps by throwing a MathException? Second, and the issue which this bug report deals with, is taking a square root of a very small number (&amp;lt;1) will return a larger number. If you apply the threshold test in getRank() (final double threshold = FastMath.max(m, n) * FastMath.ulp(singularValues&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;) )  prior to taking the square root, I believe this problem would be resolved. More importantly, philosophically, you test for zero variance. This is the appropriate test.&lt;/p&gt;

&lt;p&gt;Also, rank could be precalculated in the above loop. &lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1148714.&lt;/p&gt;

&lt;p&gt;This issue was fixed by changing SVD implementation according to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-611" title="A fast and stable SVD implementation from JAMA"&gt;&lt;del&gt;MATH-611&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
], resolution=Fixed, reporter=marisa, assignees=[], commentAuthors=[psteitz, gsteri1, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-464
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-464, created=Fri Dec 31 08:00:42 CET 2010, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Wed Aug 24 00:37:41 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Critical, summary=LegendreGaussIntegrator ignores defaultMaximalIterationCount and does 38 million iterations, link=https://issues.apache.org/jira/browse/MATH-464, description=&lt;p&gt;The following code results in count = 37801710 which is effectively an infinite loop for typical functions we are using&lt;br/&gt;
(in GeoGebra)&lt;/p&gt;

&lt;p&gt;The argument defaultMaximalIterationCount = 100 is being ignored&lt;/p&gt;

&lt;p&gt;This is the version we are using:&lt;br/&gt;
&lt;a href="http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java"&gt;http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    	LegendreGaussIntegrator gauss = new LegendreGaussIntegrator(5, 100);&lt;/p&gt;

&lt;p&gt;	try {
		double result = gauss.integrate(new testFun(), -10, 0.32462367623786328);
	} catch (Exception ee) {
		ee.printStackTrace();
	}&lt;/p&gt;



&lt;p&gt;class testFun implements UnivariateRealFunction {&lt;/p&gt;

&lt;p&gt;    public double value(double x) throws FunctionEvaluationException {
    	count ++;
        if (x&amp;gt;=0 &amp;amp;&amp;amp; x&amp;lt;=5) return 0.2; else return 0;
    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.&lt;/p&gt;

&lt;p&gt;The problem here is not with the iteration count.  In the example above, only 26 iterations are executed and the method returns the correct value.  What is causing the number of function evaluations to be so large is that each iteration involves multiple function evaluations.   I need to dig more deeply into the algorithm to determine what (if anything) the problem is, but what is causing the high number of function evaluations is the following&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// prepare next iteration
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; ratio = FastMath.min(4, FastMath.pow(delta / limit, 0.5 / abscissas.length));
n = FastMath.max((&lt;span class="code-object"&gt;int&lt;/span&gt;) (ratio * n), n + 1);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the example, delta / limit becomes large, causing n to increase rapidly.  As n increases, the number of function evaluations increases.&lt;/p&gt;
, &lt;p&gt;I am now thinking that this is not a bug, but a consequence of the fact that the integrand in the example is not at all well-approximated by a polynomial.  With a small-enough stepsize, the algorithm does converge, but requiring the large number of function evaluations above.  Here are some stepsize values for the example and the associated absolute error:&lt;/p&gt;

&lt;p&gt;n 8 error 0.05738431110184819&lt;br/&gt;
n 28 error 0.027423287634332688&lt;br/&gt;
n 100 error 8.62162720248888E-5&lt;br/&gt;
n 249 error 5.308122631570711E-4&lt;br/&gt;
n 650 error 4.3582615516528367E-4&lt;br/&gt;
n 1641 error 2.519984967931377E-4&lt;br/&gt;
n 3829 error 5.838605030586419E-5&lt;br/&gt;
...&lt;br/&gt;
 n 1102593 error 6.71416523906343E-8&lt;/p&gt;

&lt;p&gt;The last entry is from the last (26th) iteration.  I haven't verified the rationale for the updating formula for n above, but it does appear warranted in this case to increase n quickly as large n (= small stepsize) is required to get a decent estimate of the integral using Gaussian quadrature.&lt;/p&gt;
, &lt;p&gt;Perhaps we should also provide higher order formulas, using either a fixed set of precomputed constants or a way to compute the coefficients for any order.&lt;/p&gt;
, &lt;p&gt;Moving to 3.0.  I don't think this is a bug, but points to a couple of possible enhancements:&lt;/p&gt;

&lt;p&gt;1) higher order formulas (+0 on this suggestion from Luc - IMO the example and others like it are not suitable for Legendre-Gauss)&lt;br/&gt;
2) bound on the number of function evaluations (I vaguely recall us talking about this elsewhere, but can't find the reference.  If anyone else can, pls add.)&lt;/p&gt;
, &lt;p&gt;We restarted a thread about this a few days after the previous comment on this issue.&lt;br/&gt;
The thread can be read here: &lt;a href="http://markmail.org/thread/rnazrggnnuehz4qv"&gt;http://markmail.org/thread/rnazrggnnuehz4qv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think adding maxEvaluations while still preserving the existing maxIterations would be fine.&lt;/p&gt;
, &lt;p&gt;Coming back to this issue.&lt;/p&gt;

&lt;p&gt;I would propose to follow the same pattern we used for root solvers: adding a maxEval parameter in the top level integrate interface declaration. So we would have the same kind of configuration, with tolerances set at integrator/solver level and maxEval and function pointer passed at integrate/solve method call.&lt;/p&gt;

&lt;p&gt;Since we are just in the phase we change interfaces, this would be a good time to add this parameter.&lt;/p&gt;

&lt;p&gt;Does this seems reasonable ?&lt;/p&gt;
, &lt;p&gt;+1 for your suggestion, Luc.  Lets try to get this into 3.0.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1160914.&lt;/p&gt;

&lt;p&gt;The API of the integrators has been changed for consistency with solvers API. Now the main convergence parameters are set in the constructor and remain fixed, but a maximal number of function evaluation must be provided at each call to the integration method.&lt;/p&gt;

&lt;p&gt;Thanks for the report&lt;/p&gt;
], resolution=Fixed, reporter=murkle, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=180, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-453
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-453, created=Mon Dec 06 03:01:08 CET 2010, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Mon Dec 06 13:53:56 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function, link=https://issues.apache.org/jira/browse/MATH-453, description=&lt;p&gt;RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function.&lt;/p&gt;

&lt;p&gt;As this explains how to recode deprecated method calls, it ought to be corrected before release.&lt;/p&gt;, comments=[&lt;p&gt;Removed references to the &lt;tt&gt;analysis.function&lt;/tt&gt; package (revision 1042610).&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[erans], commentAuthors=[erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-434
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-434, created=Sun Nov 07 04:55:32 CET 2010, updated=Sat Mar 24 17:16:29 CET 2012, resolved=Sat Apr 09 21:21:59 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=SimplexSolver returns unfeasible solution, link=https://issues.apache.org/jira/browse/MATH-434, description=&lt;p&gt;The SimplexSolver is returning an unfeasible solution:&lt;/p&gt;

&lt;p&gt;import java.util.ArrayList;&lt;br/&gt;
import java.text.DecimalFormat;&lt;br/&gt;
import org.apache.commons.math.linear.ArrayRealVector;&lt;br/&gt;
import org.apache.commons.math.optimization.GoalType;&lt;br/&gt;
import org.apache.commons.math.optimization.OptimizationException;&lt;br/&gt;
import org.apache.commons.math.optimization.linear.*;&lt;/p&gt;

&lt;p&gt;public class SimplexSolverBug {&lt;/p&gt;

&lt;p&gt;    public static void main(String[] args) throws OptimizationException {&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction c = new LinearObjectiveFunction(new double[]{0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d}, 0.0d);&lt;/p&gt;

&lt;p&gt;        ArrayList&amp;lt;LinearConstraint&amp;gt; cnsts = new ArrayList&amp;lt;LinearConstraint&amp;gt;(5);&lt;br/&gt;
        LinearConstraint cnst;&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, -0.1d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.EQ, -0.1d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, -1e-18d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 1.0d, 0.0d, -0.0128588d, 1e-5d}, Relationship.EQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 0.0d, 1.0d, 1e-5d, -0.0128586d}, Relationship.EQ, 1e-10d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, -1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, -1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, 1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;/p&gt;

&lt;p&gt;        DecimalFormat df = new java.text.DecimalFormat("0.#####E0");&lt;/p&gt;

&lt;p&gt;        System.out.println("Constraints:");&lt;br/&gt;
        for(LinearConstraint con : cnsts) {
            for (int i = 0; i &amp;lt; con.getCoefficients().getDimension(); ++i)
                System.out.print(df.format(con.getCoefficients().getData()[i]) + " ");
            System.out.println(con.getRelationship() + " " + con.getValue());
        }&lt;/p&gt;

&lt;p&gt;        SimplexSolver simplex = new SimplexSolver(1e-7);&lt;br/&gt;
        double[] sol = simplex.optimize(c, cnsts, GoalType.MINIMIZE, false).getPointRef();&lt;br/&gt;
        System.out.println("Solution:\n" + new ArrayRealVector(sol));&lt;br/&gt;
        System.out.println("Second constraint is violated!");&lt;br/&gt;
    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;It's an odd problem, but something I ran across.  I tracked the problem to the getPivotRow routine in SimplexSolver.  It was choosing a pivot that resulted in a negative right-hand-side.  I recommend a fix by replacing&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
                ...&lt;br/&gt;
with&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;br/&gt;
                ...&lt;/p&gt;

&lt;p&gt;I believe this would be more appropriate (and at least resolves this particular problem).&lt;/p&gt;

&lt;p&gt;Also, you may want to consider making a change in getPivotColumn to replace&lt;br/&gt;
            ...&lt;br/&gt;
            if (MathUtils.compareTo(tableau.getEntry(0, i), minValue, epsilon) &amp;lt; 0) {&lt;br/&gt;
            ...&lt;br/&gt;
with&lt;br/&gt;
            ...&lt;br/&gt;
            if (tableau.getEntry(0, i) &amp;lt; minValue) &lt;br/&gt;
            ...&lt;br/&gt;
because I don't see the point of biasing earlier columns when multiple entries are within epsilon of each other.  Why not pick the absolute smallest.  I don't know that any problem can result from doing it the other way, but the latter may be a safer bet.&lt;/p&gt;

&lt;p&gt;VERY IMPORTANT: I discovered another bug that occurs when not restricting to non-negatives.  In SimplexTableu::getSolution(), &lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) &lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = 0;&lt;br/&gt;
          ...&lt;br/&gt;
should be&lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) {&lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = (restrictToNonNegative ? 0 : -mostNegative);&lt;br/&gt;
          ...&lt;br/&gt;
If necessary, I can give an example of where this bug causes a problem, but it should be fairly obvious why this was wrong.&lt;/p&gt;, comments=[&lt;p&gt;My original suggested fix had a potential for overflow errors (since minRatio is initialized to Double.MAX_VALUE).  Also, I added another suggestion and pointed out another bug which leads to invalid solutions.&lt;/p&gt;
, &lt;p&gt;Could you attach unit tests that demonstrate each problem?  Thank you.&lt;/p&gt;
, &lt;p&gt;I'll try to send some examples soon.  I'm noticing more problems with the right-hand-side going negative and want to cover all bases (as much as possible).&lt;/p&gt;
, &lt;p&gt;Code, and resulting output, that illustrates issues with the SimplexSolver.&lt;/p&gt;
, &lt;p&gt;Pushing out to 3.0.&lt;/p&gt;
, &lt;p&gt;Hey, sorry I took so long to look at this.  I've had very little time and am not working on this stuff anymore.  I'm honestly not going to be able to look at this stuff much moving forward, so hopefully there's a Commons Math contributor that can act as a reviewer.&lt;/p&gt;

&lt;p&gt;When you say it's choosing a pivot with a negative RHS, I'm assuming that means it's not within the epsilon?&lt;br/&gt;
Why would it be more appropriate to divide by the entry?  I'm not sure I see why you'd want to use a bigger epsilon when the entry is 0.1 and a smaller epsilon when the entry is 10.  Maybe we should just make the default epsilon smaller?  I'm no expert with floating point math so I'm not real sure how to set the epsilon and just made up a value.&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
...&lt;br/&gt;
with&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;/p&gt;
, &lt;p&gt;Attached a patch for the reported problems.&lt;br/&gt;
The problems can be split into two groups:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;wrong solution calculation with negative&lt;br/&gt;
   variables&lt;/li&gt;
	&lt;li&gt;failing to select an appropriate pivot&lt;br/&gt;
   row when values are below a given &lt;br/&gt;
   epsilon&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch addresses both problems:&lt;/p&gt;

&lt;p&gt; 1. fix in SimplexTableau.getSolution()&lt;br/&gt;
 2. use BigReal for arbitrary precision  &lt;br/&gt;
    support when selecting the pivot row&lt;/p&gt;

&lt;p&gt;Additionally, 4 test cases are included, as well as a minor typo fix for a method name.&lt;/p&gt;

&lt;p&gt;The fixed epsilon is also used in some other places of the code, this may also create problems under certain circumstances. So if this patch is accepted, the other places could also be adapted.&lt;/p&gt;
, &lt;p&gt;Thanks Thomas.&lt;/p&gt;

&lt;p&gt;I had a look at the patch. I'm not a big fan of using BigReal, mainly when we don't specify a scale and we don't link it to the choice for epsilon. Also reading back Ben comments, I wonder if we should not replace epsilon by an integer number of ulps with a default set to a very small value (say something like 10 ulps).&lt;/p&gt;

&lt;p&gt;What problem did you see in the accuracy of the variables to use BigReal ?&lt;/p&gt;
, &lt;p&gt;Hi Luc,&lt;/p&gt;

&lt;p&gt;my initial idea was to use an epsilon that is adjusted to the magnitude of the respective value used for comparison. To be honest, I was not aware of &lt;span class="error"&gt;&amp;#91;Math,FastMath&amp;#93;&lt;/span&gt;.ulp, therefore I went with BigReal/BigDecimal to circumvent the problem in another way (by using an arbitrary precision datatype). After reading your comment, I investigated more into the problem, e.g. using &lt;a href="http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm"&gt;http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm&lt;/a&gt;, and addressed it (hopefully correct) in the way you proposed.&lt;/p&gt;

&lt;p&gt;Though, I had to split up the epsilon test into two categories:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;general comparison of floating-point values: using ulp, as values can be arbitrarily small&lt;/li&gt;
	&lt;li&gt;algorithm convergence check: using a standard epsilon, as the algorithm may not converge due to limited precision of&lt;br/&gt;
    the double datatype otherwise&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Please find attached my updated patch, any comments are welcome (e.g. I was unsure whether to expose the maxUlps parameter in the constructor, or to use a generic comparison epsilon, e.g. using FastMath.ulp(1d) instead of one adjusted to the current value in question).&lt;/p&gt;
, &lt;p&gt;updated patch, incorporating comments from luc&lt;/p&gt;
, &lt;p&gt;&lt;span class="error"&gt;&amp;#91;Pardon the possibly nave questions.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In "SimplexTableau":&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Why not use directly "equals(double, double, int)" from "MathUtils" instead of computing an epsilon with "getEpsilon"?&lt;/li&gt;
	&lt;li&gt;Why is the "isOptimal" method not using the adjusted "epsilon" (at line 385)?&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;hmm, I feel a bit stupid now, as I have re-implemented MathUtils.equals(double, double, int) but in a mediocre way. So all calls to getEpsilon should be replaced with the equivalent MathUtils.equals.&lt;/p&gt;

&lt;p&gt;for the isOptimal:&lt;/p&gt;

&lt;p&gt;the idea was to have a user-defined threshold for the convergence criteria, which defaults to the original value of 1e-6. Using the same adjusted epsilon would possibly lead to more iterations as before. As the feasibility check in SimplexSolver.solvePhase1 has to use a static epsilon for convergence reasons, I thought to use the same epsilon in isOptimal makes sense for symmetry reasons (use the same epsilon to check for convergence /feasibility).&lt;/p&gt;

&lt;p&gt;But it's good that you raise these points, because I was hesitating myself what is the best way to go forward, as I am also not considering myself a floating-point expert. I am mainly interested in the simplex algorithm, that's why I have chosen to provide a patch for this (very nice) implementation of it.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1090656.&lt;br/&gt;
Path applied with a very small change: adding the maxUlps parameter to the detailed constructor.&lt;/p&gt;

&lt;p&gt;Thanks for the report and thanks for the patch.&lt;/p&gt;
, &lt;p&gt;Thanks for accepting the patch. The comparison using maxUlps has already been adapted according to &lt;a href="https://issues.apache.org/jira/browse/MATH-557" title="add a compareTo method to MathUtils that use a number of ulps for equality tolerance"&gt;&lt;del&gt;MATH-557&lt;/del&gt;&lt;/a&gt;, but it was missing for SimplexTableau. The cleanup patch fixes this and also renames the test names for similarity.&lt;/p&gt;
, &lt;p&gt;Cleanup patch applied.&lt;/p&gt;

&lt;p&gt;thanks again&lt;/p&gt;
], resolution=Fixed, reporter=wmwitzel, assignees=[], commentAuthors=[wmwitzel, erans, psteitz, bmccann, tn, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-429
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-429, created=Fri Oct 22 10:01:54 CEST 2010, updated=Wed Mar 23 21:25:46 CET 2011, resolved=Sat Oct 23 21:35:26 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Blocker, summary=KMeansPlusPlusClusterer breaks by division by zero, link=https://issues.apache.org/jira/browse/MATH-429, description=&lt;p&gt;For a certain space, KMeansPlusPlusClusterer  breaks. This is a blocker because this space occurs in our domain. &lt;/p&gt;, comments=[&lt;p&gt;The testcase which breaks KMeansPlusPlusClusterer&lt;/p&gt;
, &lt;p&gt;You have encountered one classical problem with k-means: at some stage (here at the first iteration), one of the clusters becomes empty.&lt;br/&gt;
This case is currently no handled by commons-math (which is a bug, so we have to fix it).&lt;br/&gt;
When a cluster is empty, a new centroid must be defined from the other clusters. There are different strategies:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;take the point farthest from any cluster&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest distance variance&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest number of points&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;My prefered choice would be 2, what do other people think ?&lt;/p&gt;
, &lt;p&gt;How about make it configurable?  Take a look at how the Mallet project did it:&lt;/p&gt;

&lt;p&gt;&lt;a href="http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html"&gt;http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By the way, I have suggested that they try to enter the Incubator here at the ASF and they seem somewhat receptive to the idea!&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1026666 for branche 2.X and as of r1026667 for trunk.&lt;br/&gt;
Users can now choose among four different strategies to deal with empty clusters:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;split the cluster with largest distance variance,&lt;/li&gt;
	&lt;li&gt;split the cluster with largest number of points,&lt;/li&gt;
	&lt;li&gt;create a cluster around the point farthest from its centroid,&lt;/li&gt;
	&lt;li&gt;generate an error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The default is to split according to largest variance.&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erikvaningen, assignees=[], commentAuthors=[erikvaningen, luc, jwcarman], timeEstimate=180, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-421
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-421, created=Wed Sep 29 20:24:56 CEST 2010, updated=Wed Mar 23 21:23:12 CET 2011, resolved=Wed Sep 29 21:51:49 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=restarting an ODE solver that has been stopped by an event doesn't work, link=https://issues.apache.org/jira/browse/MATH-421, description=&lt;p&gt;If an ODE solver is setup with an EventHandler that return STOP when the even is triggered, the integrators stops (which is exactly the expected behavior).&lt;br/&gt;
If however the user want to restart the solver from the final state reached at the event with the same configuration (expecting the event to be triggered again at a later time), then the integrator may fail to start. It can get stuck at the previous event.&lt;/p&gt;

&lt;p&gt;The occurrence of the bug depends on the residual sign of the g function which is not exactly 0, it depends on the convergence of the first event.&lt;/p&gt;

&lt;p&gt;As this use case is fairly general, event occurring less than epsilon after the solver start in the first step should be ignored, where epsilon is the convergence threshold of the event. The sign of the g function should be evaluated after this initial ignore zone, not exactly at beginning (if there are no event at the very beginning g(t0) and g(t0+epsilon) have the same sign, so this does not hurt ; if there is an event at the very beginning, g(t0) and g(t0+epsilon) have opposite signs and we want to start with the second one. Of course, the sign of epsilon depend on the integration direction (forward or backward).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository, as of r1002827 for branch 2.X and 1002829 for trunk (3.0)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-414
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-414, created=Tue Aug 31 13:01:44 CEST 2010, updated=Wed Mar 23 21:20:43 CET 2011, resolved=Tue Nov 30 12:57:23 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=ConvergenceException in NormalDistributionImpl.cumulativeProbability(), link=https://issues.apache.org/jira/browse/MATH-414, description=&lt;p&gt;I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.&lt;br/&gt;
For instance in the following code:&lt;/p&gt;

&lt;p&gt;	@Test&lt;br/&gt;
	public void testCumulative() {&lt;br/&gt;
		final NormalDistribution nd = new NormalDistributionImpl();&lt;br/&gt;
		for (int i = 0; i &amp;lt; 500; i++) {&lt;br/&gt;
			final double val = Math.exp&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/information.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt;;&lt;br/&gt;
			try {
				System.out.println("val = " + val + " cumulative = " + nd.cumulativeProbability(val));
			} catch (MathException e) {
				e.printStackTrace();
				fail();
			}&lt;br/&gt;
		}&lt;br/&gt;
	}&lt;/p&gt;

&lt;p&gt;In version 2.0, I get no exception. &lt;/p&gt;

&lt;p&gt;My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.&lt;/p&gt;, comments=[&lt;p&gt;The difference between 2.0 and 2.1 is due to the changes in ContinuedFraction included in the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-282" title="ChiSquaredDistributionImpl.cumulativeProbability &amp;gt; 1"&gt;&lt;del&gt;MATH-282&lt;/del&gt;&lt;/a&gt;.  For very large values, continued fractions are diverging to NaN. The suggested fix will work, but at this point, I wonder if we should just move the top-coding out of the catch - i.e., test the arguments and return 0 or 1 for extreme values without attempting the approximation.&lt;/p&gt;
, &lt;p&gt;I am leaning toward adding top-coding outside of the catch.  Based on the inequality p(Z &amp;gt; t) &amp;lt; exp(-t^2/2) derived in &lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; and Double.MIN_VALUE  = 2^-1074, I get that tail probabilities are not distinguishable from 0 for |t| &amp;gt; 39, so I propose that we top-code at 40 outside the catch.  Appreciate others checking my arithmetic.&lt;/p&gt;

&lt;p&gt;&lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href="http://www.johndcook.com/normalbounds.pdf"&gt;http://www.johndcook.com/normalbounds.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Your suggestion seems good to me.&lt;br/&gt;
I've check exp(-t^2/2) becomes lower than Double.MIN_VALUE/2 (i.e. rounds to 0) when |t|&amp;gt; 38.604&lt;/p&gt;
, &lt;p&gt;Fixed in r1040471&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=gustav.ryd, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=120, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-411
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-411, created=Sun Aug 29 00:14:32 CEST 2010, updated=Wed Mar 23 21:20:06 CET 2011, resolved=Mon Sep 13 04:04:01 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression newSampleData methods inconsistently create / omit intercepts, link=https://issues.apache.org/jira/browse/MATH-411, description=&lt;p&gt;The newSampleData(double[], nrows, ncols) method used in the unit tests adds a unitary column to the design matrix, resulting in an intercept term being estimated among the regression parameters.  The other newSampleData methods do not do this, forcing users to add the column of "1"s to estimate models with intercept.  Behavior should be consistent and users should not have to add the column.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r993574.  Modified multiple regression newSample methods to ensure that by default in all cases, regression models are estimated with intercept terms.  Prior to the fix for this issue,  newXSampleData(double[][]), newSampleData(double[], double[][]) and newSampleData(double[], double[][], double[][]) all required columns of "1's  to be inserted into the x[][] arrays to create a model with an intercept term;while newSampleData(double[], int, int) created a model including an intercept term without requiring the unitary column.  All methods have  been changed to eliminate the need for users to add unitary columns to specify regression models.&lt;/p&gt;

&lt;p&gt;Leaving open until &lt;a href="https://issues.apache.org/jira/browse/MATH-409" title="Multiple Regression API should allow specification of whether or not to estimate intercept term"&gt;&lt;del&gt;MATH-409&lt;/del&gt;&lt;/a&gt; is resolved. &lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-409
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-409, created=Tue Aug 24 11:55:32 CEST 2010, updated=Wed Mar 23 21:19:13 CET 2011, resolved=Mon Sep 13 04:02:43 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression API should allow specification of whether or not to estimate intercept term, link=https://issues.apache.org/jira/browse/MATH-409, description=&lt;p&gt;The OLS and GLS regression APIs should support estimating models including intercepts using design matrices including only variable data.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r996404 (both trunk and 2.x branch)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,698 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-408
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-408, created=Mon Aug 23 05:11:23 CEST 2010, updated=Wed Mar 23 21:18:48 CET 2011, resolved=Sun Dec 12 22:49:44 CET 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=GLSMultipleLinearRegression has no nontrivial validation tests, link=https://issues.apache.org/jira/browse/MATH-408, description=&lt;p&gt;There are no non-trivial tests verifying the computations for GLSMultipleLinearRegression.  Tests verifying computations against analytically determined models, R or some other reference package / datasets should be added to ensure that the statistics reported by this class are valid.&lt;/p&gt;, comments=[&lt;p&gt;Added a non-trivial test in r1044935.  While still not really a full verification test, it does at least verify that the GLS impl provided does better than OLS for models with error structure conforming to its covariance matrix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-407
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-407, created=Mon Aug 23 05:07:08 CEST 2010, updated=Wed Mar 23 21:18:29 CET 2011, resolved=Mon Sep 20 03:57:59 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Documentation improvements for multiple regression classes, link=https://issues.apache.org/jira/browse/MATH-407, description=&lt;p&gt;The user guide examples showing how to set up and estimate linear models using OLS and GLS multiple regression need to be updated to reflect changes in the API.  The javadoc for these classes and user guide descriptions also need to be improved to make it clear how to estimate a model with an intercept term.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r998761&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-406
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-406, created=Sat Aug 14 23:57:56 CEST 2010, updated=Wed Mar 23 21:18:04 CET 2011, resolved=Sun Aug 15 00:02:03 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Wrong weight handling in Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-406, description=&lt;p&gt;A comparison with a Fortran version of Levenberg-Marquardt reveals that when observations have different weights, the 2.1 version reaches a value of the function which does not necessary correspond to the minimum&lt;/p&gt;, comments=[&lt;p&gt;Correction patch.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-405
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-405, created=Wed Aug 11 15:24:39 CEST 2010, updated=Wed Mar 23 21:17:42 CET 2011, resolved=Wed Aug 11 15:46:55 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Inconsistent result from Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-405, description=&lt;p&gt;Levenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost&lt;/p&gt;, comments=[&lt;p&gt;Correction patch&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-404
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-404, created=Mon Aug 09 13:44:12 CEST 2010, updated=Sat Mar 24 17:17:04 CET 2012, resolved=Mon Aug 30 15:53:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Confusing interface for "LevenbergMarquardtOptimizer", link=https://issues.apache.org/jira/browse/MATH-404, description=&lt;p&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; which in turn implements &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt;. That interface mandates methods for setting and getting a &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;.&lt;br/&gt;
In v2.1, however, that checker is never used! The convergence check is performed using parameters specific to the Levenberg-Marquardt algorithm. Such circumvention of the superclass interface is confusing and leads to totally unexpected behaviour (such as changing the values of the thresholds of the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; being ineffective).&lt;br/&gt;
In the development version, the default constructor of &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; sets the the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; field to "null" and when such is the case, the behaviour is as in v2.1. Although it is documented, this is still confusing since it is impossible to use &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; through its &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt; interface: When using the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;, one does not know what parameters to use in order to reproduce the results obtained with the LM-specific convergence check (i.e. how to reproduce the result from v2.1).&lt;br/&gt;
Unless I'm missing something, I think that there should be an LM-specific implementation of &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; that, when given the usual relative and absolute thresholds, can perform a check that will give the same result as the currently specific check (when the "checker" field is "null").&lt;/p&gt;, comments=[&lt;p&gt;The problem was identified and discussed as &lt;a href="https://issues.apache.org/jira/browse/MATH-362" title="LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it"&gt;&lt;del&gt;MATH-362&lt;/del&gt;&lt;/a&gt;. It was decided to let both convergence methods available.&lt;/p&gt;

&lt;p&gt;The reason there are two different way is that the Levenberg-Marquardt implementation originally came from Netlib and I kept the way it behaved. I think the general interface with the new generic convergence was set up later and at that time I forgot to implement it properly, so the settings were ignored.&lt;/p&gt;

&lt;p&gt;Reporter of issue 362 explicitly asked to keep the ortho-tolerance setting and this setting does not fit with the general scheme.&lt;/p&gt;
, &lt;p&gt;Sorry I hadn't followed that other report.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was decided to let both convergence methods available. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is &lt;tt&gt;null&lt;/tt&gt; or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;

&lt;p&gt;As explained above, from an OOP point-of-view, it is surprising that a class completely circumvents its base class interface.&lt;br/&gt;
At least one of the following is wrong:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; has a second interface for convergence checking&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; defines the interface for  convergence checking&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; does not fit with the general scheme.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;br/&gt;
Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;

&lt;p&gt;If it is really impossible to fit LM within the hierarchy it currently belongs to, then it should not belong to it, since one cannot leverage the advantages of "interface programming" anyways.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is null or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or LevenbergMarquardtOptimizer needs to be changed and the orthogonality concept be finally discarded.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I know, and I am not happy with this. However, I don't want LevenbergMarquardtOptimizer to be special. It &lt;em&gt;must&lt;/em&gt; fit. We can take the opportunity of a 3.0 major release to fix this problem too, with some incompatible changes. What would you propose for this ?&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;What would you propose for this ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don't know.&lt;/p&gt;

&lt;p&gt;However, it seems that this "non-fitting checker" case is not isolated. I wanted to replace the original check in "BrentOptimizer" (package "optimization.univariate") by a call to an appropriate subclass of "RealConvergenceChecker", but here too there are more values to be considered than those stored in a pair of "RealPointValuePair". The check needs&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the "current" point&lt;/li&gt;
	&lt;li&gt;the points at both interval ends&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;but it does not use the "previous" point.&lt;/p&gt;

&lt;p&gt;So it seems that this also does not fit with the "converged" method of the "RealConvergenceChecker" interface.&lt;/p&gt;

&lt;p&gt;At first sight, I'd say that there should be a more general "ConvergenceChecker" (not existing yet) interface. Maybe using generics...&lt;/p&gt;
, &lt;p&gt;I'm trying to define a more general "ConvergenceChecker" interface. This is an incompatible change.&lt;/p&gt;
, &lt;p&gt;Final resolution is delegated to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-413"&gt;MATH-413&lt;/a&gt;.&lt;/p&gt;
], resolution=Unknown, reporter=erans, assignees=[erans], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-395
2016-01-13 22:07:48,713 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-395, created=Sun Jul 25 23:26:33 CEST 2010, updated=Wed Mar 23 21:14:58 CET 2011, resolved=Wed Jul 28 14:11:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Bugs in "BrentOptimizer", link=https://issues.apache.org/jira/browse/MATH-395, description=&lt;p&gt;I apologize for having provided a buggy implementation of Brent's optimization algorithm (class "BrentOptimizer" in package "optimization.univariate").&lt;br/&gt;
The unit tests didn't show that there was something wrong, although (from the "changes.xml" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.&lt;br/&gt;
Comparing with an implementation in Python, I could figure out the fixes. I'll modify "BrentOptimizer" and add a test. I also propose to change the name of the unit test class from "BrentMinimizerTest" to "BrentOptimizerTest".&lt;/p&gt;, comments=[&lt;p&gt;Bugs corrected in revision 979257.&lt;br/&gt;
Not resolving yet because the implementation still does not behave as the Python one. I've added a unit test that indicates the discrepancies (with "XXX" markers).&lt;/p&gt;
, &lt;p&gt;Last bug fixed in revision 980032.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;This revision also contains the modifications due to the changes in &amp;quot;AbstractUnivariateRealOptimizer&amp;quot;.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The test comparing with Python has been removed because a tracing of the execution paths (in Python and Java) showed that the remaining discrepancies were due to different values being used for the "golden ratio" constant.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[erans], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,682 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-540
2016-01-13 22:07:48,729 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-540, created=Sun Mar 06 01:43:45 CET 2011, updated=Sat Mar 24 17:16:36 CET 2012, resolved=Sun Jun 12 07:58:50 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug, link=https://issues.apache.org/jira/browse/MATH-540, description=&lt;p&gt;The AbstractIntegerDistribution.inverseCumulativeProbability(...) function attempts to decrement the lower bound of discrete distributions to values that go below the lower bound.&lt;/p&gt;, comments=[&lt;p&gt;I don't think this is a bug.  Per the javadoc, the contract for inverse cum is&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/**
 * For a random variable {@code X} whose values are distributed according
 * to &lt;span class="code-keyword"&gt;this&lt;/span&gt; distribution, &lt;span class="code-keyword"&gt;this&lt;/span&gt; method returns the largest {@code x}, such
 * that {@code P(X &amp;lt; x) &amp;lt; p}.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This implies that if the first non-zero mass point has probability greater than p, the right value to return is one less than that value, which is whet the method will do.  Your example distribution throws NPE when trying to compute probabilities outside of its domain of support. &lt;/p&gt;
, &lt;p&gt;I'm looking at it like this.  I have very simple distribution like the one provided (Four sided dice).  I'm trying to write a simulation that draws values of x for a a set of uniform 0-1 probabilities.  So I'm expecting:&lt;/p&gt;

&lt;p&gt;0 When p is less than or equal to 0.25&lt;br/&gt;
1 When p is greater than 0.25 but less than or equal to 0.50&lt;br/&gt;
2 When p is greater than 0.50 but less than or equal to 0.75&lt;br/&gt;
3 When p is greater than 0.75 but less than or equal to 1.0&lt;/p&gt;

&lt;p&gt;So for the line &lt;/p&gt;

&lt;p&gt;int neverSucceeds = d.inverseCumulativeProbability(0.0001);&lt;/p&gt;

&lt;p&gt;I'm really expecting 0 to be returned.&lt;/p&gt;

&lt;p&gt;Make sense?&lt;/p&gt;
, &lt;p&gt;I see now that there actually does appear to be an error in the javadoc.  The implementation really returns the largest x such that p(X &amp;lt;= x) &amp;lt;= p.  In the discrete case, &amp;lt;= matters and I think both inequalities in the javadoc should be changed.&lt;/p&gt;

&lt;p&gt;In your example, if the probability distribution vanishes outside 0, 1, 2, 3 and puts .25 mass on each of these values, the inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;

&lt;p&gt;If you fix your distribution so that both probability and cumulativeProbability return correct values (rather than throwing NPEs) outside of the mass values, you should get -1 returned.&lt;/p&gt;
, &lt;p&gt;Reading your last comment a little more carefully, it looks like what you are trying to do is implement sampling.  IIUC, something like what you are suggesting should work - you just have an off-by-one problem vis-s-vis the contract of inverse cumulative probabilities as we define them.  I would be +1 for adding direct support for sampling from discrete distributions, but we should open a separate ticket for that.&lt;/p&gt;
, &lt;p&gt;OK - I'll close this one and open a separate ticket.&lt;/p&gt;
, &lt;p&gt;There is a javadoc bug that needs to be fixed here&lt;/p&gt;
, &lt;p&gt;Ooops - Thanks.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;...inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems to me that users would be better served if it returned 0 and that it is also correct to do so.&lt;/p&gt;

&lt;p&gt;In the definition we say "For a random variables X whose values are distributed according to this distribution...".&lt;/p&gt;

&lt;p&gt;Suppose the distribution was for a six sided dice.  One could assert that the distribution is only defined for the values 1,2,3,4,5,6.  In this case the inverseCumulativeDistribution returns 0, but that does not have any meaning.  So now developers are forced to define the meaning of 0 for a six sided dice implementation.  &lt;/p&gt;

&lt;p&gt;In Grad school we were taught the the inverse cumulative distribution is for sampling.  So for a six sided dice uniform probabilities less than 1/6 would return 1, less than 2/6 would return 2, etc.&lt;/p&gt;

&lt;p&gt;With the current implementation for values less than 1/6 we get 0 which is meaningless, and the only time we get 6 is when the uniform probability argument is 1.&lt;/p&gt;

&lt;p&gt;So if someone mistakenly tries to use the inverseCumulativeProbability function for sampling the results are going to be wacked.  What is the use case for the inverseCumulativeProbability the way it is right now?&lt;/p&gt;
, &lt;p&gt;You have a choice in defining the inverse cum whether to define it the way we have or to use and inf rather than a sup.  We can implement sampling using the current impl.  We just need to take into account the way the inverse cum is defined in AbstractIntegerDistribution.  &lt;/p&gt;
, &lt;p&gt;OK - I think it's starting to make more sense to me now.  So when implementing sampling we just add one to the value returned by inverseCumulativeDistribution, unless the uniform probability argument is 1?&lt;/p&gt;
, &lt;p&gt;I am sorry.  I forgot that we had in fact already implemented this in version 2.2. See AbstractIntegerDistribution#sample.  The base class implementation delegates to RandomDataImpl#nextInversionDeviate (adding one per the last comment).&lt;/p&gt;
, &lt;p&gt;Sorry for the noise. I closed the wrong ticket.  Still need to fix the javadoc to match behavior and user guide.&lt;/p&gt;
, &lt;p&gt;Javadoc fixed in trunk r1134866&lt;/p&gt;
], resolution=Fixed, reporter=ole, assignees=[], commentAuthors=[psteitz, ole], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,729 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-506
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-506, created=Tue Feb 01 19:38:01 CET 2011, updated=Sat Mar 24 17:16:41 CET 2012, resolved=Sat Aug 20 23:14:57 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=The static field ChiSquareTestImpl.distribution serves no purpose, link=https://issues.apache.org/jira/browse/MATH-506, description=&lt;p&gt;The static field ChiSquareTestImpl.distribution serves no purpose.&lt;/p&gt;

&lt;p&gt;There is a setter for it, but in every case where the field is used, it is first overwritten with a new value.&lt;/p&gt;

&lt;p&gt;The field and the setter should be removed, and the methods that create a new instance should create a local variable instead.&lt;/p&gt;

&lt;p&gt;For Math 2.1, the field can be removed and the setter deprecated.&lt;/p&gt;, comments=[&lt;p&gt;Agreed.  Since the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; this instance field is unnecessary.&lt;/p&gt;
, &lt;p&gt;See the discussion in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; where it was decided to remove the distribution pluggability in 3.0.  In 2.x, the distribution is pluggable and the instance field is useful.  The 3.0 code in trunk removes the pluggability and makes the field useless.&lt;/p&gt;
, &lt;p&gt;Sorry - I thought I had checked the 2.x implementation as well, but obviously not, as it does use the field.&lt;/p&gt;

&lt;p&gt;However, we should still deprecate the setter in 2.2, as it is removed in 3.0 - OK?&lt;/p&gt;
, &lt;p&gt;Just tried removing the field and setter in 3.0, and found that the constructors rely on the setter (which is a separate bug, as the setter is not final - but easily fixable if required).&lt;/p&gt;

&lt;p&gt;The fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; merely removed deprecated code.&lt;/p&gt;

&lt;p&gt;It replaced "distribution.setDegreesOfFreedom(dof)" with "distribution = new ChiSquaredDistributionImpl(dof)" which is how the field became useless.&lt;/p&gt;

&lt;p&gt;There are two constructors which still create values for the distribution field.&lt;/p&gt;

&lt;p&gt;I don't know enough about the Math to know whether there would be any use cases for having additional methods that used a distribution provided by the class instance, rather than calculated by the individual methods (as at present).&lt;/p&gt;

&lt;p&gt;If there is no need for external provision of the distribution degree of freedom, then the constructor with parameter can be dropped.&lt;/p&gt;

&lt;p&gt;Otherwise, we need to add some methods that can use the provided distribution (which should be a final instance field).&lt;/p&gt;

&lt;p&gt;In any case, I think the setter needs to be dropped from 3.x&lt;/p&gt;
, &lt;p&gt;The instance field was there originally so that different ChiSquareDistribution implementations could be provided at construction time or via a setter (making the underlying ChiSquareDistribution pluggable).  &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; pointed to a different problem related to mutability of implementation instances.  The simplest solution to both problems is to eliminate the pluggability, which the change in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; does for this class.  The degrees of freedom are always computed from the data, so there is no need for the constructor that takes a distribution instance as argument.  Both the constructor and setter can be deprecated in 2.2 and removed in 3.0 unless we want to keep pluggability, which would require&lt;/p&gt;

&lt;p&gt;1) making the distribution field final (so removing the setter)&lt;br/&gt;
2) copying, rather than referencing the actual parameter provided to the constructor&lt;/p&gt;

&lt;p&gt;I am on the fence on this.  Maybe others can chime in (next week &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;p&gt;OK, I see now, thanks!&lt;/p&gt;
, &lt;p&gt;I removed the field (hence eliminating pluggability) in r1159916.  As of 3.0, the distribution classes are immutable, so to support pluggability a factory or class name rather than a distribution instance would have to be provided.  There is only one implementation provided by &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, so I do not see this as worth the effort and complexity to retain.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[psteitz], commentAuthors=[psteitz, sebb@apache.org], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-505
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-505, created=Tue Feb 01 01:28:56 CET 2011, updated=Sat Mar 24 17:16:40 CET 2012, resolved=Tue Feb 01 19:58:30 CET 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
], fixVersion=[3.0
], priority=Major, summary=TestUtils is thread-hostile, link=https://issues.apache.org/jira/browse/MATH-505, description=&lt;p&gt;TestUtils has several mutable static fields which are not synchronised, or volatile.&lt;/p&gt;

&lt;p&gt;If one of the fields is updated by thread A, there is no guarantee that thread B will see the full update - it may see a partially updated object.&lt;/p&gt;

&lt;p&gt;Furthermore, at least some of the static fields reference a mutable object, which can be changed whilst another thread is using it.&lt;/p&gt;

&lt;p&gt;As far as I can tell, this class must only ever be used by a single thread otherwise the results will be unpredictable.&lt;/p&gt;, comments=[&lt;p&gt;What fields, exactly?&lt;/p&gt;
, &lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/** Singleton TTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; TTest tTest = &lt;span class="code-keyword"&gt;new&lt;/span&gt; TTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; ChiSquareTest chiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; UnknownDistributionChiSquareTest unknownDistributionChiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton OneWayAnova instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; OneWayAnova oneWayAnova =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; OneWayAnovaImpl();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of the above may be changed by set methods. There is no synch.&lt;/p&gt;
, &lt;p&gt;OK, I was looking at the wrong TestUtils &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;

&lt;p&gt;The reason for this strange-looking setup is to allow the implementations to be pluggable at runtime.  "Hostile" is a harsh word, but this class is certainly &lt;b&gt;not&lt;/b&gt; threadsafe.  Ideas / patches to achieve the design goal with less "hostility" would be appreciated.&lt;/p&gt;

&lt;p&gt;I would have to double-check, but I don't think that there is any test instance state used by the methods in this class. &lt;/p&gt;
, &lt;p&gt;By thread-hostile, I mean that it is not possible in general for two different threads to use the class safely.&lt;br/&gt;
If one thread changes any of the static fields, there is no way of knowing how the methods called by the other thread will behave. This is partly because the values are not safely published currently, but even if they were, the threads don't know what settings will be used as they can be changed at any time by another thread.&lt;/p&gt;

&lt;p&gt;In general, any class which relies on mutable static state for its behaviour is thread-hostile.&lt;br/&gt;
The shared state cannot simultaneously satisfy two threads needing different behaviour.&lt;/p&gt;

&lt;p&gt;I think the only safe way for two threads to use the class as it stands is if they both synchronize on the class.&lt;br/&gt;
This will ensure safe publication of any field changes, and enforce serial usage which can guarantee the setting that will be used (but the lock will have to be held for the set call as well).&lt;/p&gt;

&lt;p&gt;ChiSquareTestImpl has a non-final instance field which means its value won't necessarily be safely published.&lt;br/&gt;
The field also has a setter which could be invoked by one thread while another was using it.&lt;/p&gt;

&lt;p&gt;TTestImpl is immutable (has no fields), and OneWayAnovaImpl can be made immutable, but other implementations of the interfaces might exist which are not immutable.&lt;/p&gt;

&lt;p&gt;The simplest way to make the class thread-safe would be to convert all the methods and fields from static to instance, but I don't know if that is acceptable.&lt;/p&gt;
, &lt;p&gt;Making the methods instance sort of defeats the purpose of the class.  None of the instance data in any of the static singletons is actually used or depended on by the methods of this class.  You are correct though that if one thread changes the impl for one of the singletons while another is using the class, the other could see a different than expected impl.  I think the practical likelihood of this is pretty much nil, as it is hard to imagine an application supplying two different implementations for the tests and wanting different threads to use different impls.  Personally, I would be happy just documenting the fact that the class is not threadsafe and if concurrent threads want to plug in different implementations, they need to synchronize on the class.  If this is not acceptable, my next preference would be to remove the pluggability - i.e., make the singletons final or get rid of them altogether, creating instances as needed for static method calls.  There is no initialization overhead creating the test classes.&lt;/p&gt;
, &lt;p&gt;@Phil: Please also keep in mind that M3 supports now (currently optional) parallel execution and it might be no longer a proper assumption that all tests are executed serially.&lt;/p&gt;
, &lt;p&gt;There is another possible option, which would be to fix the default implementations, and create new static methods that took an extra parameter for the implementation to be used.&lt;/p&gt;

&lt;p&gt;At present, changes to the static fields are not guaranteed to be published correctly. Making them volatile would fix this, but would not help with concurrent access.&lt;/p&gt;
, &lt;p&gt;Thanks, Joerg.  There should be no problems with the unit tests unless and until we introduce different tests that actually test the pluggability.  &lt;/p&gt;

&lt;p&gt;I thought about the additional parameter option, Sebb; but that again defeats the purpose of this "convenience class" - you might as well just instantiate the implementation and use it.&lt;/p&gt;

&lt;p&gt;I think the best solution is to just make the fields final and drop the getters and setters.  This is consistent with StatUtils.  So we should document the "hostility" issues in 2.2 and deprecate there and drop in 3.0.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[sebb@apache.org], commentAuthors=[psteitz, sebb@apache.org, joehni], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-484
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-484, created=Tue Jan 18 21:49:51 CET 2011, updated=Wed Mar 23 21:35:01 CET 2011, resolved=Mon Feb 14 15:20:29 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=events detection in ODE solvers is too complex and not robust, link=https://issues.apache.org/jira/browse/MATH-484, description=&lt;p&gt;All ODE solvers support multiple events detection since a long time. Events are specified by users by implementing the EventHandler interface. Events occur when the g(t, y) function evaluates to 0. When an event occurs, the solver step is shortened to make sure the event is located at the end of the step, and the event is triggered by calling the eventOccurred method in the user defined implementation class. Depending on the return value of this method, integration can continue, it can be stopped, or the state vector can be reset.&lt;/p&gt;

&lt;p&gt;Some ODE solvers are adaptive step size solvers. They can modify step size to match an integration error setting, increasing step size when error is low (thus reducing computing costs) or reducing step size when error is high (thus fulfilling accuracy requirements).&lt;/p&gt;

&lt;p&gt;The step adaptations due to events on one side and due to adaptive step size solvers are quite intricate by now, due to numerous fixes (&lt;a href="https://issues.apache.org/jira/browse/MATH-161" title="patch for Mantissa"&gt;&lt;del&gt;MATH-161&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-213" title="FirstOrderIntegrator.integrate does not give back integration stop time when an event handler stops integration"&gt;&lt;del&gt;MATH-213&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-358" title="ODE integrator goes past specified end of integration range"&gt;&lt;del&gt;MATH-358&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-421" title="restarting an ODE solver that has been stopped by an event doesn&amp;#39;t work"&gt;&lt;del&gt;MATH-421&lt;/del&gt;&lt;/a&gt; and also during standard maintenance - see for example r781157). The code is very difficult to maintain. It seems each bug fix introduces new bugs (r781157/&lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;) or tighten the link between adaptive step size and event detection (&lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;/r927202).&lt;/p&gt;

&lt;p&gt;A new bug discovered recently on an external library using a slightly modified version of this code could not be retroffitted into commons-math, despite the same problem is present. At the beginning of EventState.evaluateStep, the initial step may be exactly 0 thus preventing root solving, but preventing this size to drop to 0 would reopen &lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;. I could not fix both bugs at the same time.&lt;/p&gt;

&lt;p&gt;So it is now time to untangle events detection and adaptive step size, simplify code, and remove some inefficiency (event root solving is always done twice, once before step truncation and another time after truncation, of course with slightly different results, events shortened steps induce high computation load until the integrator recovers its optimal pace again, steps are rejected even when the event does not requires it ...).&lt;/p&gt;, comments=[&lt;p&gt;fixed in subversion repository as of r1061507 for branch 2.X and as of r1061508 for trunk&lt;/p&gt;
, &lt;p&gt;The fix introduced in r1061507 fails in several cases. If several events of the same type occur within a single long step, only the first one is triggered. If several events of different types occur during a backward integration, they are triggered in the wrong order (i.e. they are triggered in forward occurrence time order instead of backward).&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1070498 for branch 2.X and r1070499 for trunk&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-481
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-481, created=Mon Jan 17 18:15:41 CET 2011, updated=Wed Mar 23 21:33:40 CET 2011, resolved=Mon Jan 17 23:39:52 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=MathUtils.equals(double x, double y) disagrees with Javadoc, link=https://issues.apache.org/jira/browse/MATH-481, description=&lt;p&gt;MathUtils.equals(double x, double y) disagrees with Javadoc.&lt;/p&gt;

&lt;p&gt;The Javadoc says:&lt;/p&gt;

&lt;p&gt;Returns true iff they are equal as defined by  {@link #equals(double,double,int)}&lt;/p&gt;

&lt;p&gt;However, the code actually uses == and checks for NaN:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; &lt;span class="code-object"&gt;boolean&lt;/span&gt; equals(&lt;span class="code-object"&gt;double&lt;/span&gt; x, &lt;span class="code-object"&gt;double&lt;/span&gt; y) {
    &lt;span class="code-keyword"&gt;return&lt;/span&gt; (&lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(x) &amp;amp;&amp;amp; &lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(y)) || x == y;
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The method is deprecated, but it should probably still be consistent with its documentation.&lt;/p&gt;, comments=[&lt;p&gt;Corrected Javadoc in revision 1060117.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-465
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-465, created=Wed Jan 05 18:34:41 CET 2011, updated=Sat Mar 24 17:17:03 CET 2012, resolved=Wed Jul 20 14:20:51 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Incorrect matrix rank via SVD, link=https://issues.apache.org/jira/browse/MATH-465, description=&lt;p&gt;The getRank() function of SingularValueDecompositionImpl does not work properly. This problem is probably related to the numerical stability problems mentioned in &lt;a href="https://issues.apache.org/jira/browse/MATH-327"&gt;MATH-327&lt;/a&gt; and &lt;a href="https://issues.apache.org/jira/browse/MATH-320"&gt;MATH-320&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Example call with the standard matrix from R (rank 2):&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeHeader panelHeader" style="border-bottom-width: 1px;"&gt;&lt;b&gt;TestSVDRank.java&lt;/b&gt;&lt;/div&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.Array2DRowRealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.RealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecomposition;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecompositionImpl;

&lt;span class="code-keyword"&gt;public&lt;/span&gt; class TestSVDRank {
	&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; void main(&lt;span class="code-object"&gt;String&lt;/span&gt;[] args) {
		&lt;span class="code-object"&gt;double&lt;/span&gt;[][] d = { { 1, 1, 1 }, { 0, 0, 0 }, { 1, 2, 3 } };
		RealMatrix m = &lt;span class="code-keyword"&gt;new&lt;/span&gt; Array2DRowRealMatrix(d);
		SingularValueDecomposition svd = &lt;span class="code-keyword"&gt;new&lt;/span&gt; SingularValueDecompositionImpl(m);
		&lt;span class="code-object"&gt;int&lt;/span&gt; r = svd.getRank();
		&lt;span class="code-object"&gt;System&lt;/span&gt;.out.println(&lt;span class="code-quote"&gt;"Rank: "&lt;/span&gt;+r);
	}
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;The rank is computed as 3. This problem also occurs for larger matrices. I discovered the problem when trying to replace the corresponding JAMA method.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  Looks like it could as you suggest be related to &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt;.  &lt;/p&gt;
, &lt;p&gt;For now, pushing to 3.0.  If we get a fix for this and &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt; before 3.0 is ready, I may propose a 2.2.1 to include it.&lt;/p&gt;
, &lt;p&gt;My apologies if I am missing something, but here is what I noticed about the SVD. &lt;/p&gt;

&lt;p&gt;On lines 124-127 of SingularValueDecompositionImpl we have:&lt;/p&gt;

&lt;p&gt;        for (int i = 0; i &amp;lt; p; i++) {
            singularValues[i] = FastMath.sqrt(FastMath.abs(singularValues[i]));
        }&lt;/p&gt;

&lt;p&gt;This is potentially the offending line. First is the problem of negative eigenvalues. Negative variance in the principal components should probably be dealt with explicitly? Perhaps by throwing a MathException? Second, and the issue which this bug report deals with, is taking a square root of a very small number (&amp;lt;1) will return a larger number. If you apply the threshold test in getRank() (final double threshold = FastMath.max(m, n) * FastMath.ulp(singularValues&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;) )  prior to taking the square root, I believe this problem would be resolved. More importantly, philosophically, you test for zero variance. This is the appropriate test.&lt;/p&gt;

&lt;p&gt;Also, rank could be precalculated in the above loop. &lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1148714.&lt;/p&gt;

&lt;p&gt;This issue was fixed by changing SVD implementation according to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-611" title="A fast and stable SVD implementation from JAMA"&gt;&lt;del&gt;MATH-611&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
], resolution=Fixed, reporter=marisa, assignees=[], commentAuthors=[psteitz, gsteri1, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-464
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-464, created=Fri Dec 31 08:00:42 CET 2010, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Wed Aug 24 00:37:41 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Critical, summary=LegendreGaussIntegrator ignores defaultMaximalIterationCount and does 38 million iterations, link=https://issues.apache.org/jira/browse/MATH-464, description=&lt;p&gt;The following code results in count = 37801710 which is effectively an infinite loop for typical functions we are using&lt;br/&gt;
(in GeoGebra)&lt;/p&gt;

&lt;p&gt;The argument defaultMaximalIterationCount = 100 is being ignored&lt;/p&gt;

&lt;p&gt;This is the version we are using:&lt;br/&gt;
&lt;a href="http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java"&gt;http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    	LegendreGaussIntegrator gauss = new LegendreGaussIntegrator(5, 100);&lt;/p&gt;

&lt;p&gt;	try {
		double result = gauss.integrate(new testFun(), -10, 0.32462367623786328);
	} catch (Exception ee) {
		ee.printStackTrace();
	}&lt;/p&gt;



&lt;p&gt;class testFun implements UnivariateRealFunction {&lt;/p&gt;

&lt;p&gt;    public double value(double x) throws FunctionEvaluationException {
    	count ++;
        if (x&amp;gt;=0 &amp;amp;&amp;amp; x&amp;lt;=5) return 0.2; else return 0;
    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.&lt;/p&gt;

&lt;p&gt;The problem here is not with the iteration count.  In the example above, only 26 iterations are executed and the method returns the correct value.  What is causing the number of function evaluations to be so large is that each iteration involves multiple function evaluations.   I need to dig more deeply into the algorithm to determine what (if anything) the problem is, but what is causing the high number of function evaluations is the following&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// prepare next iteration
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; ratio = FastMath.min(4, FastMath.pow(delta / limit, 0.5 / abscissas.length));
n = FastMath.max((&lt;span class="code-object"&gt;int&lt;/span&gt;) (ratio * n), n + 1);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the example, delta / limit becomes large, causing n to increase rapidly.  As n increases, the number of function evaluations increases.&lt;/p&gt;
, &lt;p&gt;I am now thinking that this is not a bug, but a consequence of the fact that the integrand in the example is not at all well-approximated by a polynomial.  With a small-enough stepsize, the algorithm does converge, but requiring the large number of function evaluations above.  Here are some stepsize values for the example and the associated absolute error:&lt;/p&gt;

&lt;p&gt;n 8 error 0.05738431110184819&lt;br/&gt;
n 28 error 0.027423287634332688&lt;br/&gt;
n 100 error 8.62162720248888E-5&lt;br/&gt;
n 249 error 5.308122631570711E-4&lt;br/&gt;
n 650 error 4.3582615516528367E-4&lt;br/&gt;
n 1641 error 2.519984967931377E-4&lt;br/&gt;
n 3829 error 5.838605030586419E-5&lt;br/&gt;
...&lt;br/&gt;
 n 1102593 error 6.71416523906343E-8&lt;/p&gt;

&lt;p&gt;The last entry is from the last (26th) iteration.  I haven't verified the rationale for the updating formula for n above, but it does appear warranted in this case to increase n quickly as large n (= small stepsize) is required to get a decent estimate of the integral using Gaussian quadrature.&lt;/p&gt;
, &lt;p&gt;Perhaps we should also provide higher order formulas, using either a fixed set of precomputed constants or a way to compute the coefficients for any order.&lt;/p&gt;
, &lt;p&gt;Moving to 3.0.  I don't think this is a bug, but points to a couple of possible enhancements:&lt;/p&gt;

&lt;p&gt;1) higher order formulas (+0 on this suggestion from Luc - IMO the example and others like it are not suitable for Legendre-Gauss)&lt;br/&gt;
2) bound on the number of function evaluations (I vaguely recall us talking about this elsewhere, but can't find the reference.  If anyone else can, pls add.)&lt;/p&gt;
, &lt;p&gt;We restarted a thread about this a few days after the previous comment on this issue.&lt;br/&gt;
The thread can be read here: &lt;a href="http://markmail.org/thread/rnazrggnnuehz4qv"&gt;http://markmail.org/thread/rnazrggnnuehz4qv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think adding maxEvaluations while still preserving the existing maxIterations would be fine.&lt;/p&gt;
, &lt;p&gt;Coming back to this issue.&lt;/p&gt;

&lt;p&gt;I would propose to follow the same pattern we used for root solvers: adding a maxEval parameter in the top level integrate interface declaration. So we would have the same kind of configuration, with tolerances set at integrator/solver level and maxEval and function pointer passed at integrate/solve method call.&lt;/p&gt;

&lt;p&gt;Since we are just in the phase we change interfaces, this would be a good time to add this parameter.&lt;/p&gt;

&lt;p&gt;Does this seems reasonable ?&lt;/p&gt;
, &lt;p&gt;+1 for your suggestion, Luc.  Lets try to get this into 3.0.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1160914.&lt;/p&gt;

&lt;p&gt;The API of the integrators has been changed for consistency with solvers API. Now the main convergence parameters are set in the constructor and remain fixed, but a maximal number of function evaluation must be provided at each call to the integration method.&lt;/p&gt;

&lt;p&gt;Thanks for the report&lt;/p&gt;
], resolution=Fixed, reporter=murkle, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=180, timeSpent=null]
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-453
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-453, created=Mon Dec 06 03:01:08 CET 2010, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Mon Dec 06 13:53:56 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function, link=https://issues.apache.org/jira/browse/MATH-453, description=&lt;p&gt;RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function.&lt;/p&gt;

&lt;p&gt;As this explains how to recode deprecated method calls, it ought to be corrected before release.&lt;/p&gt;, comments=[&lt;p&gt;Removed references to the &lt;tt&gt;analysis.function&lt;/tt&gt; package (revision 1042610).&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[erans], commentAuthors=[erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,744 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-434
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-434, created=Sun Nov 07 04:55:32 CET 2010, updated=Sat Mar 24 17:16:29 CET 2012, resolved=Sat Apr 09 21:21:59 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=SimplexSolver returns unfeasible solution, link=https://issues.apache.org/jira/browse/MATH-434, description=&lt;p&gt;The SimplexSolver is returning an unfeasible solution:&lt;/p&gt;

&lt;p&gt;import java.util.ArrayList;&lt;br/&gt;
import java.text.DecimalFormat;&lt;br/&gt;
import org.apache.commons.math.linear.ArrayRealVector;&lt;br/&gt;
import org.apache.commons.math.optimization.GoalType;&lt;br/&gt;
import org.apache.commons.math.optimization.OptimizationException;&lt;br/&gt;
import org.apache.commons.math.optimization.linear.*;&lt;/p&gt;

&lt;p&gt;public class SimplexSolverBug {&lt;/p&gt;

&lt;p&gt;    public static void main(String[] args) throws OptimizationException {&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction c = new LinearObjectiveFunction(new double[]{0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d}, 0.0d);&lt;/p&gt;

&lt;p&gt;        ArrayList&amp;lt;LinearConstraint&amp;gt; cnsts = new ArrayList&amp;lt;LinearConstraint&amp;gt;(5);&lt;br/&gt;
        LinearConstraint cnst;&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, -0.1d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.EQ, -0.1d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, -1e-18d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 1.0d, 0.0d, -0.0128588d, 1e-5d}, Relationship.EQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 0.0d, 1.0d, 1e-5d, -0.0128586d}, Relationship.EQ, 1e-10d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, -1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, -1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, 1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;/p&gt;

&lt;p&gt;        DecimalFormat df = new java.text.DecimalFormat("0.#####E0");&lt;/p&gt;

&lt;p&gt;        System.out.println("Constraints:");&lt;br/&gt;
        for(LinearConstraint con : cnsts) {
            for (int i = 0; i &amp;lt; con.getCoefficients().getDimension(); ++i)
                System.out.print(df.format(con.getCoefficients().getData()[i]) + " ");
            System.out.println(con.getRelationship() + " " + con.getValue());
        }&lt;/p&gt;

&lt;p&gt;        SimplexSolver simplex = new SimplexSolver(1e-7);&lt;br/&gt;
        double[] sol = simplex.optimize(c, cnsts, GoalType.MINIMIZE, false).getPointRef();&lt;br/&gt;
        System.out.println("Solution:\n" + new ArrayRealVector(sol));&lt;br/&gt;
        System.out.println("Second constraint is violated!");&lt;br/&gt;
    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;It's an odd problem, but something I ran across.  I tracked the problem to the getPivotRow routine in SimplexSolver.  It was choosing a pivot that resulted in a negative right-hand-side.  I recommend a fix by replacing&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
                ...&lt;br/&gt;
with&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;br/&gt;
                ...&lt;/p&gt;

&lt;p&gt;I believe this would be more appropriate (and at least resolves this particular problem).&lt;/p&gt;

&lt;p&gt;Also, you may want to consider making a change in getPivotColumn to replace&lt;br/&gt;
            ...&lt;br/&gt;
            if (MathUtils.compareTo(tableau.getEntry(0, i), minValue, epsilon) &amp;lt; 0) {&lt;br/&gt;
            ...&lt;br/&gt;
with&lt;br/&gt;
            ...&lt;br/&gt;
            if (tableau.getEntry(0, i) &amp;lt; minValue) &lt;br/&gt;
            ...&lt;br/&gt;
because I don't see the point of biasing earlier columns when multiple entries are within epsilon of each other.  Why not pick the absolute smallest.  I don't know that any problem can result from doing it the other way, but the latter may be a safer bet.&lt;/p&gt;

&lt;p&gt;VERY IMPORTANT: I discovered another bug that occurs when not restricting to non-negatives.  In SimplexTableu::getSolution(), &lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) &lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = 0;&lt;br/&gt;
          ...&lt;br/&gt;
should be&lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) {&lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = (restrictToNonNegative ? 0 : -mostNegative);&lt;br/&gt;
          ...&lt;br/&gt;
If necessary, I can give an example of where this bug causes a problem, but it should be fairly obvious why this was wrong.&lt;/p&gt;, comments=[&lt;p&gt;My original suggested fix had a potential for overflow errors (since minRatio is initialized to Double.MAX_VALUE).  Also, I added another suggestion and pointed out another bug which leads to invalid solutions.&lt;/p&gt;
, &lt;p&gt;Could you attach unit tests that demonstrate each problem?  Thank you.&lt;/p&gt;
, &lt;p&gt;I'll try to send some examples soon.  I'm noticing more problems with the right-hand-side going negative and want to cover all bases (as much as possible).&lt;/p&gt;
, &lt;p&gt;Code, and resulting output, that illustrates issues with the SimplexSolver.&lt;/p&gt;
, &lt;p&gt;Pushing out to 3.0.&lt;/p&gt;
, &lt;p&gt;Hey, sorry I took so long to look at this.  I've had very little time and am not working on this stuff anymore.  I'm honestly not going to be able to look at this stuff much moving forward, so hopefully there's a Commons Math contributor that can act as a reviewer.&lt;/p&gt;

&lt;p&gt;When you say it's choosing a pivot with a negative RHS, I'm assuming that means it's not within the epsilon?&lt;br/&gt;
Why would it be more appropriate to divide by the entry?  I'm not sure I see why you'd want to use a bigger epsilon when the entry is 0.1 and a smaller epsilon when the entry is 10.  Maybe we should just make the default epsilon smaller?  I'm no expert with floating point math so I'm not real sure how to set the epsilon and just made up a value.&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
...&lt;br/&gt;
with&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;/p&gt;
, &lt;p&gt;Attached a patch for the reported problems.&lt;br/&gt;
The problems can be split into two groups:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;wrong solution calculation with negative&lt;br/&gt;
   variables&lt;/li&gt;
	&lt;li&gt;failing to select an appropriate pivot&lt;br/&gt;
   row when values are below a given &lt;br/&gt;
   epsilon&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch addresses both problems:&lt;/p&gt;

&lt;p&gt; 1. fix in SimplexTableau.getSolution()&lt;br/&gt;
 2. use BigReal for arbitrary precision  &lt;br/&gt;
    support when selecting the pivot row&lt;/p&gt;

&lt;p&gt;Additionally, 4 test cases are included, as well as a minor typo fix for a method name.&lt;/p&gt;

&lt;p&gt;The fixed epsilon is also used in some other places of the code, this may also create problems under certain circumstances. So if this patch is accepted, the other places could also be adapted.&lt;/p&gt;
, &lt;p&gt;Thanks Thomas.&lt;/p&gt;

&lt;p&gt;I had a look at the patch. I'm not a big fan of using BigReal, mainly when we don't specify a scale and we don't link it to the choice for epsilon. Also reading back Ben comments, I wonder if we should not replace epsilon by an integer number of ulps with a default set to a very small value (say something like 10 ulps).&lt;/p&gt;

&lt;p&gt;What problem did you see in the accuracy of the variables to use BigReal ?&lt;/p&gt;
, &lt;p&gt;Hi Luc,&lt;/p&gt;

&lt;p&gt;my initial idea was to use an epsilon that is adjusted to the magnitude of the respective value used for comparison. To be honest, I was not aware of &lt;span class="error"&gt;&amp;#91;Math,FastMath&amp;#93;&lt;/span&gt;.ulp, therefore I went with BigReal/BigDecimal to circumvent the problem in another way (by using an arbitrary precision datatype). After reading your comment, I investigated more into the problem, e.g. using &lt;a href="http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm"&gt;http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm&lt;/a&gt;, and addressed it (hopefully correct) in the way you proposed.&lt;/p&gt;

&lt;p&gt;Though, I had to split up the epsilon test into two categories:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;general comparison of floating-point values: using ulp, as values can be arbitrarily small&lt;/li&gt;
	&lt;li&gt;algorithm convergence check: using a standard epsilon, as the algorithm may not converge due to limited precision of&lt;br/&gt;
    the double datatype otherwise&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Please find attached my updated patch, any comments are welcome (e.g. I was unsure whether to expose the maxUlps parameter in the constructor, or to use a generic comparison epsilon, e.g. using FastMath.ulp(1d) instead of one adjusted to the current value in question).&lt;/p&gt;
, &lt;p&gt;updated patch, incorporating comments from luc&lt;/p&gt;
, &lt;p&gt;&lt;span class="error"&gt;&amp;#91;Pardon the possibly nave questions.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In "SimplexTableau":&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Why not use directly "equals(double, double, int)" from "MathUtils" instead of computing an epsilon with "getEpsilon"?&lt;/li&gt;
	&lt;li&gt;Why is the "isOptimal" method not using the adjusted "epsilon" (at line 385)?&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;hmm, I feel a bit stupid now, as I have re-implemented MathUtils.equals(double, double, int) but in a mediocre way. So all calls to getEpsilon should be replaced with the equivalent MathUtils.equals.&lt;/p&gt;

&lt;p&gt;for the isOptimal:&lt;/p&gt;

&lt;p&gt;the idea was to have a user-defined threshold for the convergence criteria, which defaults to the original value of 1e-6. Using the same adjusted epsilon would possibly lead to more iterations as before. As the feasibility check in SimplexSolver.solvePhase1 has to use a static epsilon for convergence reasons, I thought to use the same epsilon in isOptimal makes sense for symmetry reasons (use the same epsilon to check for convergence /feasibility).&lt;/p&gt;

&lt;p&gt;But it's good that you raise these points, because I was hesitating myself what is the best way to go forward, as I am also not considering myself a floating-point expert. I am mainly interested in the simplex algorithm, that's why I have chosen to provide a patch for this (very nice) implementation of it.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1090656.&lt;br/&gt;
Path applied with a very small change: adding the maxUlps parameter to the detailed constructor.&lt;/p&gt;

&lt;p&gt;Thanks for the report and thanks for the patch.&lt;/p&gt;
, &lt;p&gt;Thanks for accepting the patch. The comparison using maxUlps has already been adapted according to &lt;a href="https://issues.apache.org/jira/browse/MATH-557" title="add a compareTo method to MathUtils that use a number of ulps for equality tolerance"&gt;&lt;del&gt;MATH-557&lt;/del&gt;&lt;/a&gt;, but it was missing for SimplexTableau. The cleanup patch fixes this and also renames the test names for similarity.&lt;/p&gt;
, &lt;p&gt;Cleanup patch applied.&lt;/p&gt;

&lt;p&gt;thanks again&lt;/p&gt;
], resolution=Fixed, reporter=wmwitzel, assignees=[], commentAuthors=[wmwitzel, erans, psteitz, bmccann, tn, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-429
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-429, created=Fri Oct 22 10:01:54 CEST 2010, updated=Wed Mar 23 21:25:46 CET 2011, resolved=Sat Oct 23 21:35:26 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Blocker, summary=KMeansPlusPlusClusterer breaks by division by zero, link=https://issues.apache.org/jira/browse/MATH-429, description=&lt;p&gt;For a certain space, KMeansPlusPlusClusterer  breaks. This is a blocker because this space occurs in our domain. &lt;/p&gt;, comments=[&lt;p&gt;The testcase which breaks KMeansPlusPlusClusterer&lt;/p&gt;
, &lt;p&gt;You have encountered one classical problem with k-means: at some stage (here at the first iteration), one of the clusters becomes empty.&lt;br/&gt;
This case is currently no handled by commons-math (which is a bug, so we have to fix it).&lt;br/&gt;
When a cluster is empty, a new centroid must be defined from the other clusters. There are different strategies:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;take the point farthest from any cluster&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest distance variance&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest number of points&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;My prefered choice would be 2, what do other people think ?&lt;/p&gt;
, &lt;p&gt;How about make it configurable?  Take a look at how the Mallet project did it:&lt;/p&gt;

&lt;p&gt;&lt;a href="http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html"&gt;http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By the way, I have suggested that they try to enter the Incubator here at the ASF and they seem somewhat receptive to the idea!&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1026666 for branche 2.X and as of r1026667 for trunk.&lt;br/&gt;
Users can now choose among four different strategies to deal with empty clusters:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;split the cluster with largest distance variance,&lt;/li&gt;
	&lt;li&gt;split the cluster with largest number of points,&lt;/li&gt;
	&lt;li&gt;create a cluster around the point farthest from its centroid,&lt;/li&gt;
	&lt;li&gt;generate an error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The default is to split according to largest variance.&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erikvaningen, assignees=[], commentAuthors=[erikvaningen, luc, jwcarman], timeEstimate=180, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-421
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-421, created=Wed Sep 29 20:24:56 CEST 2010, updated=Wed Mar 23 21:23:12 CET 2011, resolved=Wed Sep 29 21:51:49 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=restarting an ODE solver that has been stopped by an event doesn't work, link=https://issues.apache.org/jira/browse/MATH-421, description=&lt;p&gt;If an ODE solver is setup with an EventHandler that return STOP when the even is triggered, the integrators stops (which is exactly the expected behavior).&lt;br/&gt;
If however the user want to restart the solver from the final state reached at the event with the same configuration (expecting the event to be triggered again at a later time), then the integrator may fail to start. It can get stuck at the previous event.&lt;/p&gt;

&lt;p&gt;The occurrence of the bug depends on the residual sign of the g function which is not exactly 0, it depends on the convergence of the first event.&lt;/p&gt;

&lt;p&gt;As this use case is fairly general, event occurring less than epsilon after the solver start in the first step should be ignored, where epsilon is the convergence threshold of the event. The sign of the g function should be evaluated after this initial ignore zone, not exactly at beginning (if there are no event at the very beginning g(t0) and g(t0+epsilon) have the same sign, so this does not hurt ; if there is an event at the very beginning, g(t0) and g(t0+epsilon) have opposite signs and we want to start with the second one. Of course, the sign of epsilon depend on the integration direction (forward or backward).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository, as of r1002827 for branch 2.X and 1002829 for trunk (3.0)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-414
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-414, created=Tue Aug 31 13:01:44 CEST 2010, updated=Wed Mar 23 21:20:43 CET 2011, resolved=Tue Nov 30 12:57:23 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=ConvergenceException in NormalDistributionImpl.cumulativeProbability(), link=https://issues.apache.org/jira/browse/MATH-414, description=&lt;p&gt;I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.&lt;br/&gt;
For instance in the following code:&lt;/p&gt;

&lt;p&gt;	@Test&lt;br/&gt;
	public void testCumulative() {&lt;br/&gt;
		final NormalDistribution nd = new NormalDistributionImpl();&lt;br/&gt;
		for (int i = 0; i &amp;lt; 500; i++) {&lt;br/&gt;
			final double val = Math.exp&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/information.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt;;&lt;br/&gt;
			try {
				System.out.println("val = " + val + " cumulative = " + nd.cumulativeProbability(val));
			} catch (MathException e) {
				e.printStackTrace();
				fail();
			}&lt;br/&gt;
		}&lt;br/&gt;
	}&lt;/p&gt;

&lt;p&gt;In version 2.0, I get no exception. &lt;/p&gt;

&lt;p&gt;My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.&lt;/p&gt;, comments=[&lt;p&gt;The difference between 2.0 and 2.1 is due to the changes in ContinuedFraction included in the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-282" title="ChiSquaredDistributionImpl.cumulativeProbability &amp;gt; 1"&gt;&lt;del&gt;MATH-282&lt;/del&gt;&lt;/a&gt;.  For very large values, continued fractions are diverging to NaN. The suggested fix will work, but at this point, I wonder if we should just move the top-coding out of the catch - i.e., test the arguments and return 0 or 1 for extreme values without attempting the approximation.&lt;/p&gt;
, &lt;p&gt;I am leaning toward adding top-coding outside of the catch.  Based on the inequality p(Z &amp;gt; t) &amp;lt; exp(-t^2/2) derived in &lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; and Double.MIN_VALUE  = 2^-1074, I get that tail probabilities are not distinguishable from 0 for |t| &amp;gt; 39, so I propose that we top-code at 40 outside the catch.  Appreciate others checking my arithmetic.&lt;/p&gt;

&lt;p&gt;&lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href="http://www.johndcook.com/normalbounds.pdf"&gt;http://www.johndcook.com/normalbounds.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Your suggestion seems good to me.&lt;br/&gt;
I've check exp(-t^2/2) becomes lower than Double.MIN_VALUE/2 (i.e. rounds to 0) when |t|&amp;gt; 38.604&lt;/p&gt;
, &lt;p&gt;Fixed in r1040471&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=gustav.ryd, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=120, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-411
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-411, created=Sun Aug 29 00:14:32 CEST 2010, updated=Wed Mar 23 21:20:06 CET 2011, resolved=Mon Sep 13 04:04:01 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression newSampleData methods inconsistently create / omit intercepts, link=https://issues.apache.org/jira/browse/MATH-411, description=&lt;p&gt;The newSampleData(double[], nrows, ncols) method used in the unit tests adds a unitary column to the design matrix, resulting in an intercept term being estimated among the regression parameters.  The other newSampleData methods do not do this, forcing users to add the column of "1"s to estimate models with intercept.  Behavior should be consistent and users should not have to add the column.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r993574.  Modified multiple regression newSample methods to ensure that by default in all cases, regression models are estimated with intercept terms.  Prior to the fix for this issue,  newXSampleData(double[][]), newSampleData(double[], double[][]) and newSampleData(double[], double[][], double[][]) all required columns of "1's  to be inserted into the x[][] arrays to create a model with an intercept term;while newSampleData(double[], int, int) created a model including an intercept term without requiring the unitary column.  All methods have  been changed to eliminate the need for users to add unitary columns to specify regression models.&lt;/p&gt;

&lt;p&gt;Leaving open until &lt;a href="https://issues.apache.org/jira/browse/MATH-409" title="Multiple Regression API should allow specification of whether or not to estimate intercept term"&gt;&lt;del&gt;MATH-409&lt;/del&gt;&lt;/a&gt; is resolved. &lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-409
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-409, created=Tue Aug 24 11:55:32 CEST 2010, updated=Wed Mar 23 21:19:13 CET 2011, resolved=Mon Sep 13 04:02:43 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression API should allow specification of whether or not to estimate intercept term, link=https://issues.apache.org/jira/browse/MATH-409, description=&lt;p&gt;The OLS and GLS regression APIs should support estimating models including intercepts using design matrices including only variable data.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r996404 (both trunk and 2.x branch)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-408
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-408, created=Mon Aug 23 05:11:23 CEST 2010, updated=Wed Mar 23 21:18:48 CET 2011, resolved=Sun Dec 12 22:49:44 CET 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=GLSMultipleLinearRegression has no nontrivial validation tests, link=https://issues.apache.org/jira/browse/MATH-408, description=&lt;p&gt;There are no non-trivial tests verifying the computations for GLSMultipleLinearRegression.  Tests verifying computations against analytically determined models, R or some other reference package / datasets should be added to ensure that the statistics reported by this class are valid.&lt;/p&gt;, comments=[&lt;p&gt;Added a non-trivial test in r1044935.  While still not really a full verification test, it does at least verify that the GLS impl provided does better than OLS for models with error structure conforming to its covariance matrix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-407
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-407, created=Mon Aug 23 05:07:08 CEST 2010, updated=Wed Mar 23 21:18:29 CET 2011, resolved=Mon Sep 20 03:57:59 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Documentation improvements for multiple regression classes, link=https://issues.apache.org/jira/browse/MATH-407, description=&lt;p&gt;The user guide examples showing how to set up and estimate linear models using OLS and GLS multiple regression need to be updated to reflect changes in the API.  The javadoc for these classes and user guide descriptions also need to be improved to make it clear how to estimate a model with an intercept term.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r998761&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-406
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-406, created=Sat Aug 14 23:57:56 CEST 2010, updated=Wed Mar 23 21:18:04 CET 2011, resolved=Sun Aug 15 00:02:03 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Wrong weight handling in Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-406, description=&lt;p&gt;A comparison with a Fortran version of Levenberg-Marquardt reveals that when observations have different weights, the 2.1 version reaches a value of the function which does not necessary correspond to the minimum&lt;/p&gt;, comments=[&lt;p&gt;Correction patch.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-405
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-405, created=Wed Aug 11 15:24:39 CEST 2010, updated=Wed Mar 23 21:17:42 CET 2011, resolved=Wed Aug 11 15:46:55 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Inconsistent result from Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-405, description=&lt;p&gt;Levenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost&lt;/p&gt;, comments=[&lt;p&gt;Correction patch&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-404
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-404, created=Mon Aug 09 13:44:12 CEST 2010, updated=Sat Mar 24 17:17:04 CET 2012, resolved=Mon Aug 30 15:53:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Confusing interface for "LevenbergMarquardtOptimizer", link=https://issues.apache.org/jira/browse/MATH-404, description=&lt;p&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; which in turn implements &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt;. That interface mandates methods for setting and getting a &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;.&lt;br/&gt;
In v2.1, however, that checker is never used! The convergence check is performed using parameters specific to the Levenberg-Marquardt algorithm. Such circumvention of the superclass interface is confusing and leads to totally unexpected behaviour (such as changing the values of the thresholds of the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; being ineffective).&lt;br/&gt;
In the development version, the default constructor of &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; sets the the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; field to "null" and when such is the case, the behaviour is as in v2.1. Although it is documented, this is still confusing since it is impossible to use &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; through its &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt; interface: When using the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;, one does not know what parameters to use in order to reproduce the results obtained with the LM-specific convergence check (i.e. how to reproduce the result from v2.1).&lt;br/&gt;
Unless I'm missing something, I think that there should be an LM-specific implementation of &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; that, when given the usual relative and absolute thresholds, can perform a check that will give the same result as the currently specific check (when the "checker" field is "null").&lt;/p&gt;, comments=[&lt;p&gt;The problem was identified and discussed as &lt;a href="https://issues.apache.org/jira/browse/MATH-362" title="LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it"&gt;&lt;del&gt;MATH-362&lt;/del&gt;&lt;/a&gt;. It was decided to let both convergence methods available.&lt;/p&gt;

&lt;p&gt;The reason there are two different way is that the Levenberg-Marquardt implementation originally came from Netlib and I kept the way it behaved. I think the general interface with the new generic convergence was set up later and at that time I forgot to implement it properly, so the settings were ignored.&lt;/p&gt;

&lt;p&gt;Reporter of issue 362 explicitly asked to keep the ortho-tolerance setting and this setting does not fit with the general scheme.&lt;/p&gt;
, &lt;p&gt;Sorry I hadn't followed that other report.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was decided to let both convergence methods available. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is &lt;tt&gt;null&lt;/tt&gt; or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;

&lt;p&gt;As explained above, from an OOP point-of-view, it is surprising that a class completely circumvents its base class interface.&lt;br/&gt;
At least one of the following is wrong:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; has a second interface for convergence checking&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; defines the interface for  convergence checking&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; does not fit with the general scheme.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;br/&gt;
Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;

&lt;p&gt;If it is really impossible to fit LM within the hierarchy it currently belongs to, then it should not belong to it, since one cannot leverage the advantages of "interface programming" anyways.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is null or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or LevenbergMarquardtOptimizer needs to be changed and the orthogonality concept be finally discarded.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I know, and I am not happy with this. However, I don't want LevenbergMarquardtOptimizer to be special. It &lt;em&gt;must&lt;/em&gt; fit. We can take the opportunity of a 3.0 major release to fix this problem too, with some incompatible changes. What would you propose for this ?&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;What would you propose for this ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don't know.&lt;/p&gt;

&lt;p&gt;However, it seems that this "non-fitting checker" case is not isolated. I wanted to replace the original check in "BrentOptimizer" (package "optimization.univariate") by a call to an appropriate subclass of "RealConvergenceChecker", but here too there are more values to be considered than those stored in a pair of "RealPointValuePair". The check needs&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the "current" point&lt;/li&gt;
	&lt;li&gt;the points at both interval ends&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;but it does not use the "previous" point.&lt;/p&gt;

&lt;p&gt;So it seems that this also does not fit with the "converged" method of the "RealConvergenceChecker" interface.&lt;/p&gt;

&lt;p&gt;At first sight, I'd say that there should be a more general "ConvergenceChecker" (not existing yet) interface. Maybe using generics...&lt;/p&gt;
, &lt;p&gt;I'm trying to define a more general "ConvergenceChecker" interface. This is an incompatible change.&lt;/p&gt;
, &lt;p&gt;Final resolution is delegated to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-413"&gt;MATH-413&lt;/a&gt;.&lt;/p&gt;
], resolution=Unknown, reporter=erans, assignees=[erans], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-395
2016-01-13 22:07:48,760 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-395, created=Sun Jul 25 23:26:33 CEST 2010, updated=Wed Mar 23 21:14:58 CET 2011, resolved=Wed Jul 28 14:11:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Bugs in "BrentOptimizer", link=https://issues.apache.org/jira/browse/MATH-395, description=&lt;p&gt;I apologize for having provided a buggy implementation of Brent's optimization algorithm (class "BrentOptimizer" in package "optimization.univariate").&lt;br/&gt;
The unit tests didn't show that there was something wrong, although (from the "changes.xml" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.&lt;br/&gt;
Comparing with an implementation in Python, I could figure out the fixes. I'll modify "BrentOptimizer" and add a test. I also propose to change the name of the unit test class from "BrentMinimizerTest" to "BrentOptimizerTest".&lt;/p&gt;, comments=[&lt;p&gt;Bugs corrected in revision 979257.&lt;br/&gt;
Not resolving yet because the implementation still does not behave as the Python one. I've added a unit test that indicates the discrepancies (with "XXX" markers).&lt;/p&gt;
, &lt;p&gt;Last bug fixed in revision 980032.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;This revision also contains the modifications due to the changes in &amp;quot;AbstractUnivariateRealOptimizer&amp;quot;.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The test comparing with Python has been removed because a tracing of the execution paths (in Python and Java) showed that the remaining discrepancies were due to different values being used for the "golden ratio" constant.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[erans], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,776 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-392
2016-01-13 22:07:48,776 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-392, created=Wed Jul 21 20:43:10 CEST 2010, updated=Wed Mar 23 21:13:58 CET 2011, resolved=Sun Aug 22 15:16:29 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=calculateYVariance in OLS/GLSMultipleLinearRegression uses residuals not Y vars, link=https://issues.apache.org/jira/browse/MATH-392, description=&lt;p&gt;Implementation of OLS/GLSMultipleLinearRegression is:&lt;br/&gt;
@Override&lt;br/&gt;
173        protected double calculateYVariance() {
174            RealVector residuals = calculateResiduals();
175            return residuals.dotProduct(residuals) /
176                   (X.getRowDimension() - X.getColumnDimension());
177        }&lt;/p&gt;

&lt;p&gt;This gives variance of residuals not variance of the dependent (Y) variable as the documentation suggests.&lt;/p&gt;, comments=[&lt;p&gt;Thank you for reporting this.  Patches welcome!&lt;/p&gt;
, &lt;p&gt;Can't test a patch as I'm not able to build current repository version:&lt;br/&gt;
math/src/test/java/org/apache/commons/math/optimization/univariate/BrentOptimizerTest.java:&lt;span class="error"&gt;&amp;#91;28,39&amp;#93;&lt;/span&gt; cannot find symbol&lt;br/&gt;
symbol  : class SincFunction&lt;/p&gt;

&lt;p&gt;Implementation for both GLS/OLS:&lt;/p&gt;

&lt;p&gt;protected double calculateYVariance() {
    return new Variance().evaluate(Y);
}&lt;/p&gt;
, &lt;p&gt;There was an error in a file committed this afternoon. It should be OK now.&lt;/p&gt;
, &lt;p&gt;corrected implementations of calculateYVariance() for OLS/GLSMultipleRegression&lt;/p&gt;

&lt;p&gt;added unit tests for both calculateYVariance implementations&lt;/p&gt;

&lt;p&gt;fixed AbstractMultipleRegression.estimateRegressionParametersStandardErrors() to use residuals &lt;/p&gt;
, &lt;p&gt;Fixed in 987897.   I added calcluate/estimateErrorVariance methods to return what was previously incorrectly reported as "Y variance."&lt;br/&gt;
Thanks for the patch!&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=markdevaney, assignees=[], commentAuthors=[psteitz, markdevaney, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,776 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-391
2016-01-13 22:07:48,776 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-391, created=Wed Jul 21 10:57:46 CEST 2010, updated=Wed Mar 23 21:13:27 CET 2011, resolved=Sun Oct 03 18:43:11 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Inconsistent behaviour of constructors in ArrayRealVector class, link=https://issues.apache.org/jira/browse/MATH-391, description=&lt;p&gt;ArrayRealVector(double[] d) allows to construct a zero-length vector, but ArrayRealVector(double[] d, boolean copyArray) doesn't. Both should allow this as zero-length vectors are mathematically well-defined objects and they are useful boundary cases in many algorithms.&lt;/p&gt;

&lt;p&gt;This breaks some arithmetic operators (addition) on zero-length real vectors which worked in 2.0 but don't work in 2.1&lt;/p&gt;, comments=[&lt;p&gt;I agree that the code should be consistent.  I agree as well that a zero-dimensional vector is legit.   Can anyone explain why ArrayRealVector(double[] d, boolean copyArray) requires positive length?&lt;/p&gt;
, &lt;p&gt;Most probably my bad ...&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1003993 for barnch 2.X and r1003994 for trunk.&lt;br/&gt;
Note that the same problem occurred also in ArrayFieldVector but the fix is different. For Field-based vectors, we need to get the field, so either we use a non-empty array and retrieve the field from the first array element or we add a parameter for the field and allow the array to be empty. The two choices are now possible, as new constructors have been added and the javadoc updated to explain this behavior.&lt;br/&gt;
Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,776 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-390
2016-01-13 22:07:48,776 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-390, created=Wed Jul 21 00:47:21 CEST 2010, updated=Wed Jul 21 01:32:12 CEST 2010, resolved=Wed Jul 21 01:32:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Major, summary=Simplex Solver is very inaccurate on a large problem, even a very low value for epsilon, link=https://issues.apache.org/jira/browse/MATH-390, description=&lt;p&gt;I'm currently playing with a program for solving a rather simple chess puzzle. The goal is to place 12 knights on a 8x8 board, such that each field is either attacked by a knight, or contains a knight. To solve this problem (and different variants) I want to use a handcrafted Branch and Bound algorithm that uses Linear Programming to calculate an upperbound on the number of fields that can be covered by a certain amount of knights.&lt;/p&gt;

&lt;p&gt;The idea is to create variables for each field that has to be covered, and to create variables for each field to contain a knight. A cover variable can only become positive if a corresponding knight variable for an adjacent field is also positive, there is a limit to the amount of knights we may place (so the sum of all knight variables cannot be larger than 12) and the cover variables cannot be larger than one. Also, only the cover variables have a coefficient of one in the objective function, all other variables have zero. Because we want to cover the entire board our goal will be to maximize the objective function, since we want to maximize the number of fields that are covered.&lt;/p&gt;

&lt;p&gt;Since a basic chessboard has 64 fields and since it is possible to cover the chessboard with 12 knights, we know there is an integer solution that has value 64. Since we are solving a relaxed variant of the problem, the value should be at least 64. However, when I use the Simplex Solver, I get a value of around 58.6, which is much too low. Even when I relax the constraints in such a fashion that 64 knights may be placed on the board, the solution value remains the same. I've lowered the value of epsilon as much as I can and it still gives the incorrect value. What makes it worse is that the calculation is totally useless as an upperbound (if the value would have been around 70, it would have been an upperbound at least).&lt;/p&gt;

&lt;p&gt;I've heard that using the revised simplex method is a lot better with respect to stacked errors, so I am not sure this is really a bug, or just a problem that arises when the two phase simplex method is used for large problems.&lt;/p&gt;

&lt;p&gt;I will try to attach a code example that implements the problem (but possibly isn't that readable).&lt;/p&gt;, comments=[&lt;p&gt;Example of the 8x8 Knight covering Chess problem. The objective value should at least be 64, but it is around 59.&lt;/p&gt;
, &lt;p&gt;Hmm, it seems I made a programming mistake in the type of the relationship: I used an equality where I should have used a greater-equals. I created a much nicer version of the example, which actually works. Feel free to use it for an example or something.&lt;/p&gt;

&lt;p&gt;My bad, I will close the issue.&lt;/p&gt;
, &lt;p&gt;The correct and more readable example, which actually works.&lt;/p&gt;
, &lt;p&gt;It seems I made a programming error. I included a correct example to solve the problem.&lt;/p&gt;
], resolution=Fixed, reporter=pcbouman, assignees=[], commentAuthors=[pcbouman], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,776 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-380
2016-01-13 22:07:48,776 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-380, created=Thu Jun 24 18:47:54 CEST 2010, updated=Sat Mar 24 17:16:33 CET 2012, resolved=Sat Oct 01 15:54:20 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Minor, summary=Need to (re)initialize dYdY0 for multiple integrate with FirstOrderIntegratorWithJacobians, link=https://issues.apache.org/jira/browse/MATH-380, description=&lt;p&gt;There is a lack in the method integrate of FirstOrderIntegratorWithJacobians. The jacobian DYDY0 can't be initialized by the user, unlike DFDP with DF0DP.&lt;br/&gt;
So, for several successive integrations, the matrix is reinitialized to identity and that is not what we might want.&lt;/p&gt;, comments=[&lt;p&gt;You are perfectly right.&lt;/p&gt;

&lt;p&gt;The FirstOrderIntegratorWithJacobians class is a brand new one and it clearly has some design flaws.&lt;br/&gt;
It will most probably be deprecated in its current form and replaced by a new mechanism, better integrated (sorry for the joke) with the standard ODE solvers.&lt;br/&gt;
The ability for user to set an initial value for dydy0 will be present in the new design, but will probably not be back-ported to the current one.&lt;br/&gt;
In the meantime, you can save the final value of the jacobian matrix dydy0 after first part of integration, which we could call dy1dy0 as it represents dy(t1)/dy(t0). Start the second part from t1 to t2 that will reset the initial matrix to identity and hence compute compute dy(t2)/dy(t1) and do the multiplication by yourself of the two matrices to really get what you need: dy(t2)/dy(t1) = dy(t2)/dy(t1) * dy(t1)/dy(t0).&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue &lt;/p&gt;
, &lt;p&gt;changing target fix version to 3.0.&lt;br/&gt;
Fixing this and several other problems requires a complete rewrite of the jacobians computation with ODE, and this rewrite implies user interfaces changes, so it cannot be fixed before 3.0.&lt;/p&gt;
, &lt;p&gt;A first attempt to implement Jacobians computation again in ODE has been committed in subversion repository as of r1175409.&lt;br/&gt;
This implementation still lacks the ability for step handlers to also retrieve the additional equations and their derivatives.&lt;br/&gt;
This implementation is based on the Orekit one described here: &lt;a href="https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf"&gt;https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1176745.&lt;/p&gt;
], resolution=Fixed, reporter=pparraud, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-377
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-377, created=Thu Jun 17 11:06:03 CEST 2010, updated=Wed Mar 23 21:08:36 CET 2011, resolved=Sun Jul 25 21:49:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=weight versus sigma in AbstractLeastSquares, link=https://issues.apache.org/jira/browse/MATH-377, description=&lt;p&gt;In AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.&lt;/p&gt;

&lt;p&gt; Once corrected, getRMS() can even reduce&lt;/p&gt;

&lt;p&gt; public double getRMS() {return Math.sqrt(getChiSquare()/rows);}&lt;/p&gt;, comments=[&lt;p&gt;It is not clear to me exactly what is being computed in getChiSquare.  Step 0 is to get an actual definition in the javadoc for what it is trying to compute.  I agree it seems odd to be dividing by residual weights; but I could be missing the intent.&lt;/p&gt;
, &lt;p&gt;OK, let us define ChiSquare as the sum of the weighted square of the residual in order to be consistent with the rest of the definitions in that class.  That would also be consistent with what users expect from a parameter labeled 'weight' rather than 'sigma'.  If we reach consensus on that definition, I can take care of that issue.&lt;/p&gt;
, &lt;p&gt;I could be missing something, but I see no reason that the weighted sum of squared residuals computed here (after the proposed change) should in general follow a chi-square distribution or be related to a chi-square test statistic of any kind.   Why is it called chi-square?  Sorry if I am missing something simple here.&lt;/p&gt;
, &lt;p&gt;I guess if you assume normalliy distributed errors, it makes sense, so drop the last comment and I am +1 for the change (with definition added to the javadoc).&lt;/p&gt;
, &lt;p&gt;Indeed, the confusion comes from the fact that, in some textbooks, each residual is divided by 'sigma_i' which leads to a weight of 1/(sigma_i^2).  In CM, we adopted the terminology 'weight' without reference to sigma.  I will change the javadoc accordingly.&lt;/p&gt;
, &lt;p&gt;Patch to correct issue &lt;a href="https://issues.apache.org/jira/browse/MATH-377" title="weight versus sigma in AbstractLeastSquares"&gt;&lt;del&gt;MATH-377&lt;/del&gt;&lt;/a&gt;.  The change in getChiSquare let to a tiny update in one of Levenberg-Marquardt unit tests.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[psteitz, dimpbx, luc], timeEstimate=1, timeSpent=null]
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-373
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-373, created=Mon Jun 07 16:54:00 CEST 2010, updated=Sat Mar 24 17:16:56 CET 2012, resolved=Thu Sep 02 06:52:33 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=StatUtils.sum returns NaN for zero-length arrays, link=https://issues.apache.org/jira/browse/MATH-373, description=&lt;p&gt;StatUtils.sum returns NaN for zero-length arrays, which is:&lt;/p&gt;

&lt;p&gt;1. inconsistent with the mathematical notion of sum: in maths, sum_{i=0}^{N-1} a_i will be 0 for N=0. In particular, the identity&lt;br/&gt;
&lt;br/&gt;
sum_{i=0}^{k-1} a_i + sum_{i=k}^{N-1} = sum_{i=0}^{N-1}&lt;/p&gt;

&lt;p&gt;is broken for k = 0, since NaN + x = NaN, not x.&lt;/p&gt;

&lt;p&gt;2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition, as NaNs propagate silently and require manual tracing during the debugging)&lt;/p&gt;

&lt;p&gt;3. enforces "special case" handling when the user expects that the summed array can have a zero length.&lt;/p&gt;

&lt;p&gt;The correct behaviour is, in my opinion, to return 0.0, not NaN in the above case.&lt;/p&gt;, comments=[&lt;p&gt;I agree with the reasoning here, and we should do it this way in 3.0.  However it is an incompatible change to do in a point release, so I'm going to wait for more feed back from other developers before I make any changes to the current code.&lt;/p&gt;

&lt;p&gt;I'm thinking that adding a method to AbstractUnivariateStatistic that looks like:&lt;br/&gt;
   protected boolean test( final double[] values,  final int begin,   final int length, final boolean allowEmpty)&lt;/p&gt;

&lt;p&gt;that would have the test:&lt;br/&gt;
   if(length == 0 &amp;amp;&amp;amp; !allowEmpty)&lt;br/&gt;
        return false;&lt;/p&gt;

&lt;p&gt;The current test method can call the new one with allowEmpty=false for backwards compatibility.  Then we can decide on which statistics should have a zero value on the empty set.&lt;/p&gt;
, &lt;p&gt;The consensus of the commons-math developers is that, since the current behavior is documented in 2.x, that this will have to wait for 3.0.  Fixing this in 2.x would introduce a too large incompatibility change to include in 2.x.&lt;/p&gt;

&lt;p&gt;I can attach a patch against 2.x that fixes this, as long as anybody using the patch understands that it isn't supported.&lt;/p&gt;

, &lt;p&gt;Possibly crazy idea: &lt;/p&gt;

&lt;p&gt;if Math 3.0 is going to change package names (which may be necessary), one could introduce the fix using a math3 package name?&lt;/p&gt;
, &lt;p&gt;IIRC, changing the package name had been suggested and discussed for 2.0.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;One argument is that, to be consistent,  you&amp;#39;d have to change the name at every major release...&amp;#93;&lt;/span&gt;&lt;/p&gt;
, &lt;p&gt;Speaking as a maintainer of client code which uses ACM, I'd rather cope with occasional incompatibilities in the same packages, than have to change ALL my client code to keep up with the package name changes after every release. A reason to change the package name would be if you wanted to use the old and new version side by side, but that would not be a common usage pattern for ACM, I think.&lt;/p&gt;
, &lt;p&gt;As Gilles mentioned, changing the package name for commons-math was discussed and voted on for 2.x.  The result of the vote was to keep the package name, since commons-math won't usually be provided by a third party library.  Since nothing much has changed, I can't see that commons-math would change it's package for version 3.0.&lt;/p&gt;
, &lt;p&gt;This will be fixed in the 3.0 build.&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[billbarker, sebb@apache.org, erans, rwerp], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-369
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-369, created=Mon May 03 17:48:27 CEST 2010, updated=Wed Mar 23 21:05:06 CET 2011, resolved=Mon May 03 20:43:59 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Minor, summary=BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException, link=https://issues.apache.org/jira/browse/MATH-369, description=&lt;p&gt;Method &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  &lt;/p&gt;

&lt;p&gt;invokes &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(double min, double max) &lt;/p&gt;

&lt;p&gt;which throws NullPointerException, as member variable&lt;/p&gt;

&lt;p&gt;    UnivariateRealSolverImpl.f &lt;/p&gt;

&lt;p&gt;is null.&lt;/p&gt;

&lt;p&gt;Instead the method:&lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)&lt;/p&gt;

&lt;p&gt;should be called.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;/p&gt;

&lt;p&gt;invoke:&lt;/p&gt;

&lt;p&gt;     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);&lt;/p&gt;

&lt;p&gt;NullPointerException will be thrown.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository as of r940565.&lt;br/&gt;
Thanks for the report and for the fix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sasunpundev@abv.bg, assignees=[], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-368
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-368, created=Thu Apr 29 05:41:10 CEST 2010, updated=Wed Mar 23 21:04:17 CET 2011, resolved=Mon May 10 01:07:24 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=OpenMapRealVector.getSparcity should be getSparsity, link=https://issues.apache.org/jira/browse/MATH-368, description=&lt;p&gt;The term for describing the ratio of nonzero elements to zero elements in a matrix/vector is sparsity, not sparcity.  Suggest renaming getSparcity() to getSparsity()&lt;/p&gt;, comments=[&lt;p&gt;The policy of this project is to not remove methods from the public API in a point release.  However, the misspelled method has been deprecated and the correctly spelled method has been added.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-367
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-367, created=Thu Apr 22 20:31:06 CEST 2010, updated=Wed Mar 23 21:03:42 CET 2011, resolved=Mon May 10 03:17:14 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=AbstractRealVector.sparseIterator fails when vector has exactly one non-zero entry, link=https://issues.apache.org/jira/browse/MATH-367, description=&lt;p&gt;The following program:&lt;br/&gt;
===&lt;br/&gt;
import java.util.Iterator;&lt;br/&gt;
import org.apache.commons.math.linear.*;&lt;/p&gt;

&lt;p&gt;public class SparseIteratorTester&lt;br/&gt;
{&lt;br/&gt;
    public static void main(String[] args) {&lt;br/&gt;
        double vdata[] = { 0.0, 1.0, 0.0 };&lt;br/&gt;
        RealVector v = new ArrayRealVector(vdata);&lt;br/&gt;
        Iterator&amp;lt;RealVector.Entry&amp;gt; iter = v.sparseIterator();&lt;br/&gt;
        while(iter.hasNext()) {
            RealVector.Entry entry = iter.next();
            System.out.printf("%d: %f\n", entry.getIndex(), entry.getValue());
        }   &lt;br/&gt;
    }       &lt;br/&gt;
} &lt;br/&gt;
===&lt;br/&gt;
generates this output:&lt;/p&gt;

&lt;p&gt;1: 1.000000&lt;br/&gt;
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: -1&lt;br/&gt;
	at org.apache.commons.math.linear.ArrayRealVector.getEntry(ArrayRealVector.java:995)&lt;br/&gt;
	at org.apache.commons.math.linear.AbstractRealVector$EntryImpl.getValue(AbstractRealVector.java:850)&lt;br/&gt;
	at test.SparseIteratorTester.main(SparseIteratorTester.java:13)&lt;br/&gt;
===&lt;/p&gt;

&lt;p&gt;This patch fixes it, and simplifies AbstractRealVector.SparseEntryIterator  (sorry, i don't see any form entry for attaching a file)&lt;br/&gt;
===&lt;br/&gt;
Index: src/main/java/org/apache/commons/math/linear/AbstractRealVector.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(revision 936985)&lt;br/&gt;
+++ src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(working copy)&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.commons.math.linear;&lt;/p&gt;

&lt;p&gt; import java.util.Iterator;&lt;br/&gt;
+import java.util.NoSuchElementException;&lt;/p&gt;

&lt;p&gt; import org.apache.commons.math.FunctionEvaluationException;&lt;br/&gt;
 import org.apache.commons.math.MathRuntimeException;&lt;br/&gt;
@@ -875,40 +876,25 @@&lt;br/&gt;
         /** Dimension of the vector. */&lt;br/&gt;
         private final int dim;&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Temporary entry (reused on each call to {@link #next()}. */&lt;/li&gt;
	&lt;li&gt;private EntryImpl tmp = new EntryImpl();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;/** Current entry. */&lt;br/&gt;
+        /** Last entry returned by #next(). */&lt;br/&gt;
         private EntryImpl current;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Next entry. */&lt;br/&gt;
+        /** Next entry for #next() to return. */&lt;br/&gt;
         private EntryImpl next;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** Simple constructor. */&lt;br/&gt;
         protected SparseEntryIterator() {&lt;br/&gt;
             dim = getDimension();&lt;br/&gt;
             current = new EntryImpl();&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (current.getValue() == 0) {
-                advance(current);
-            }&lt;/li&gt;
	&lt;li&gt;if(current.getIndex() &amp;gt;= 0){
-                // There is at least one non-zero entry
-                next = new EntryImpl();
-                next.setIndex(current.getIndex());
+            next = new EntryImpl();
+            if(next.getValue() == 0)
                 advance(next);
-            } else {
-                // The vector consists of only zero entries, so deny having a next
-                current = null;
-            }&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Advance an entry up to the next non null one.&lt;br/&gt;
+        /** Advance an entry up to the next nonzero value.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param e entry to advance&lt;br/&gt;
          */&lt;br/&gt;
         protected void advance(EntryImpl e) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (e == null) {
-                return;
-            }&lt;br/&gt;
             do {
                 e.setIndex(e.getIndex() + 1);
             } while (e.getIndex() &amp;lt; dim &amp;amp;&amp;amp; e.getValue() == 0);&lt;br/&gt;
@@ -919,22 +905,17 @@&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;br/&gt;
         public boolean hasNext() {
-            return current != null;
+            return next.getIndex() &amp;gt;= 0;
         }&lt;br/&gt;
 &lt;br/&gt;
         /** {@inheritDoc} */&lt;br/&gt;
         public Entry next() {&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;tmp.setIndex(current.getIndex());&lt;/li&gt;
	&lt;li&gt;if (next != null) {&lt;/li&gt;
	&lt;li&gt;current.setIndex(next.getIndex());&lt;/li&gt;
	&lt;li&gt;advance(next);&lt;/li&gt;
	&lt;li&gt;if (next.getIndex() &amp;lt; 0) {
-                    next = null;
-                }&lt;/li&gt;
	&lt;li&gt;} else {
-                current = null;
-            }&lt;/li&gt;
	&lt;li&gt;return tmp;&lt;br/&gt;
+            int index = next.getIndex();&lt;br/&gt;
+            if(index &amp;lt; 0)&lt;br/&gt;
+                throw new NoSuchElementException();&lt;br/&gt;
+            current.setIndex(index);&lt;br/&gt;
+            advance(next);&lt;br/&gt;
+            return current;&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;/p&gt;, comments=[&lt;p&gt;patch fixing the bug&lt;/p&gt;
, &lt;p&gt;I've applied your patch (with a couple of style tweaks).  It should be available in the next release of commons-math.&lt;/p&gt;

&lt;p&gt;Thank you for your contribution.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[ashuang, billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-365
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-365, created=Tue Apr 20 16:21:20 CEST 2010, updated=Wed Mar 23 21:02:52 CET 2011, resolved=Wed Apr 21 16:35:53 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=Issue with "SmoothingBicubicSplineInterpolator", link=https://issues.apache.org/jira/browse/MATH-365, description=&lt;p&gt;I figured out that the name of this class is misleading as the implementation doesn't perform the intended smoothing.&lt;/p&gt;

&lt;p&gt;In order to solve this issue, I propose to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;deprecate the "SmoothingBicubicSplineInterpolator" class&lt;/li&gt;
	&lt;li&gt;create a "BicubicSplineInterpolator" class (similar to the above class but with the useless code removed)&lt;/li&gt;
	&lt;li&gt;remove the "SmoothingBicubicSplineInterpolatorTest" class&lt;/li&gt;
	&lt;li&gt;add a "BicubicSplineInterpolatorTest" with essentially the same contents as the above one&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Then I would also add a new "SmoothingPolynomialBicubicSplineInterpolator" where I used the "PolynomialFitter" class to smooth the input data along both dimensions before the interpolating function is computed.&lt;/p&gt;

&lt;p&gt;Does someone object to these changes?&lt;/p&gt;, comments=[&lt;p&gt;removing the test class would badly impact test coverage, so it would be better to simply deprecae it also and to remove the library class and its associated test class together when releasing 3.0&lt;/p&gt;
, &lt;p&gt;revision 936295.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-362
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-362, created=Tue Apr 06 13:38:46 CEST 2010, updated=Wed Mar 23 21:02:00 CET 2011, resolved=Sat May 29 20:16:50 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it, link=https://issues.apache.org/jira/browse/MATH-362, description=&lt;p&gt;LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.&lt;/p&gt;, comments=[&lt;p&gt;Ooops. You are right.&lt;br/&gt;
The Levenberg-Marquardt optimizer uses specific convergence parameters which can be set by   setInitialStepBoundFactor, setCostRelativeTolerance, setParRelativeTolerance and setOrthoTolerance.&lt;br/&gt;
The most important convergence tuning are either setCostRelativeTolerance for a convergence on the cost itself or setParRelativeTolerance for a convergence on the parameters.&lt;/p&gt;

&lt;p&gt;I'm not sure how to solve this. Do the existing tuning parameters fit your needs or not ? Some convergence criteria can be expressed with both methods, but not all. Should we keep both setting as alternate methods or should we remove one and rely on the remaining one ?&lt;/p&gt;
, &lt;p&gt;I would keep using orthoTolerance as it is used now:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;292                if (maxCosine &amp;lt;= orthoTolerance) {&lt;br/&gt;
293                    // convergence has been reached&lt;br/&gt;
294                    return new VectorialPointValuePair(point, objective);&lt;br/&gt;
295                }&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;and then use costRelativeTolerance &amp;amp; parRelativeTolerance if and only if the convergence checker is null, otherwise use the convergence checker and ignore {costRelativeTolerance, parRelativeTolerance}.&lt;/p&gt;

&lt;p&gt;What I am missing now is the ability to bail out if the absolute distance from the target falls below some value ("close enough").&lt;/p&gt;
, &lt;p&gt;I've spent that last few days trying to find a good curve fitting library for Java and got excited when I learned of Commons Math.  Unfortunately, its curve fitting is very unreliable.  I'm hoping that this bug is what is causing the problems that I'm seeing.  I'm comparing data from NIST and results from DataFitX and it is apparent that Commons Math is not yet up to the task.  My fingers are crossed that its quality in the curve fitting area will be improved in the near future.  Keep up the good work Apache.&lt;/p&gt;

&lt;p&gt;I've opened an issue about the problems I'm seeing, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Double check how you use it, Matt. I have succesfully used this curve fitting in production.&lt;/p&gt;
, &lt;p&gt;Matt, could you please describe the problem you encounter more precisely (i.e. with numerical examples) and preferably in a new JIRA issue ? We will check if the two problems are related and link the issues afterwards if it appears they are.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
, &lt;p&gt;It's good to see such quick responses.  I'll open a new JIRA issue and spend some time putting together code, data and a detailed description of the problem I'm seeing.  Thanks Apache for all your hard work.&lt;/p&gt;

&lt;p&gt;I've opened an issue regarding the problem, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r949433.&lt;br/&gt;
Thanks for reporting the issue&lt;/p&gt;
, &lt;p&gt;Thank you.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=roman.werpachowski, assignees=[], commentAuthors=[luc, roman.werpachowski, mprice], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-288
2016-01-13 22:07:48,791 : DEBUG : KNIME-Worker-3 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-288, created=Tue Aug 25 00:31:11 CEST 2009, updated=Wed Apr 14 02:30:17 CEST 2010, resolved=Tue Aug 25 20:10:08 CEST 2009, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.1
], priority=Major, summary=SimplexSolver not working as expected 2, link=https://issues.apache.org/jira/browse/MATH-288, description=&lt;p&gt;SimplexSolver didn't find the optimal solution.&lt;/p&gt;

&lt;p&gt;Program for Lpsolve:&lt;br/&gt;
=====================&lt;br/&gt;
/* Objective function */&lt;br/&gt;
max: 7 a 3 b;&lt;/p&gt;

&lt;p&gt;/* Constraints */&lt;br/&gt;
R1: +3 a -5 c &amp;lt;= 0;&lt;br/&gt;
R2: +2 a -5 d &amp;lt;= 0;&lt;br/&gt;
R3: +2 b -5 c &amp;lt;= 0;&lt;br/&gt;
R4: +3 b -5 d &amp;lt;= 0;&lt;br/&gt;
R5: +3 a +2 b &amp;lt;= 5;&lt;br/&gt;
R6: +2 a +3 b &amp;lt;= 5;&lt;/p&gt;

&lt;p&gt;/* Variable bounds */&lt;br/&gt;
a &amp;lt;= 1;&lt;br/&gt;
b &amp;lt;= 1;&lt;br/&gt;
=====================&lt;br/&gt;
Results(correct): a = 1, b = 1, value = 10&lt;/p&gt;


&lt;p&gt;Program for SimplexSolve:&lt;br/&gt;
=====================&lt;br/&gt;
LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]{7, 3, 0, 0}, 0);&lt;br/&gt;
Collection&amp;lt;LinearConstraint&amp;gt; podmienky = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{1, 0, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 1, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 0, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 0, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 2, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 3, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 2, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 3, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
RealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);&lt;br/&gt;
=====================&lt;br/&gt;
Results(incorrect): a = 1, b = 0.5, value = 8.5&lt;/p&gt;

&lt;p&gt;P.S. I used the latest software from the repository (including &lt;a href="https://issues.apache.org/jira/browse/MATH-286" title="SimplexSolver not working as expected?"&gt;&lt;del&gt;MATH-286&lt;/del&gt;&lt;/a&gt; fix).&lt;/p&gt;, comments=[&lt;p&gt;Thanks for the bug report.  I've confirmed this is an issue.&lt;/p&gt;

&lt;p&gt;Here's a slightly smaller version of the problem that causes the same bug, which might be easier for debugging:&lt;/p&gt;

&lt;p&gt;MAX 7 a + 3 b&lt;br/&gt;
s.t.&lt;br/&gt;
3 a -5 c &amp;lt;= 0&lt;br/&gt;
2 a -5 d &amp;lt;= 0&lt;br/&gt;
3 b -5 d &amp;lt;= 0&lt;br/&gt;
a &amp;lt;= 1&lt;br/&gt;
b &amp;lt;= 1&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 7, 3, 0, 0 }, 0 );&lt;br/&gt;
        Collection&amp;lt;LinearConstraint&amp;gt; constraints = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 3, 0, -5, 0 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 2, 0, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 3, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0 }, Relationship.LEQ, 1.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 0 }, Relationship.LEQ, 1.0));&lt;/p&gt;

&lt;p&gt;        SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
        RealPointValuePair solution = solver.optimize(f, constraints, GoalType.MAXIMIZE, true);&lt;br/&gt;
        assertEquals(10.0, solution.getValue(), .0000001);&lt;/p&gt;
, &lt;p&gt;Patch attached.  It was a 1 character bug.  I was saying to only do the minimum ratio test if the entry is &amp;gt;= 0, but it should have been &amp;gt; 0 (dividing by 0 is never good :o)&lt;br/&gt;
Thanks again for the bug report.&lt;/p&gt;
, &lt;p&gt;resolved in subversion repository as of r807738&lt;br/&gt;
patch applied (except for debug print function)&lt;br/&gt;
thanks for the repoart and thanks for the patch&lt;/p&gt;
], resolution=Fixed, reporter=kefa, assignees=[], commentAuthors=[bmccann, luc], timeEstimate=480, timeSpent=null]
2016-01-13 22:07:48,776 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-392
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-392, created=Wed Jul 21 20:43:10 CEST 2010, updated=Wed Mar 23 21:13:58 CET 2011, resolved=Sun Aug 22 15:16:29 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=calculateYVariance in OLS/GLSMultipleLinearRegression uses residuals not Y vars, link=https://issues.apache.org/jira/browse/MATH-392, description=&lt;p&gt;Implementation of OLS/GLSMultipleLinearRegression is:&lt;br/&gt;
@Override&lt;br/&gt;
173        protected double calculateYVariance() {
174            RealVector residuals = calculateResiduals();
175            return residuals.dotProduct(residuals) /
176                   (X.getRowDimension() - X.getColumnDimension());
177        }&lt;/p&gt;

&lt;p&gt;This gives variance of residuals not variance of the dependent (Y) variable as the documentation suggests.&lt;/p&gt;, comments=[&lt;p&gt;Thank you for reporting this.  Patches welcome!&lt;/p&gt;
, &lt;p&gt;Can't test a patch as I'm not able to build current repository version:&lt;br/&gt;
math/src/test/java/org/apache/commons/math/optimization/univariate/BrentOptimizerTest.java:&lt;span class="error"&gt;&amp;#91;28,39&amp;#93;&lt;/span&gt; cannot find symbol&lt;br/&gt;
symbol  : class SincFunction&lt;/p&gt;

&lt;p&gt;Implementation for both GLS/OLS:&lt;/p&gt;

&lt;p&gt;protected double calculateYVariance() {
    return new Variance().evaluate(Y);
}&lt;/p&gt;
, &lt;p&gt;There was an error in a file committed this afternoon. It should be OK now.&lt;/p&gt;
, &lt;p&gt;corrected implementations of calculateYVariance() for OLS/GLSMultipleRegression&lt;/p&gt;

&lt;p&gt;added unit tests for both calculateYVariance implementations&lt;/p&gt;

&lt;p&gt;fixed AbstractMultipleRegression.estimateRegressionParametersStandardErrors() to use residuals &lt;/p&gt;
, &lt;p&gt;Fixed in 987897.   I added calcluate/estimateErrorVariance methods to return what was previously incorrectly reported as "Y variance."&lt;br/&gt;
Thanks for the patch!&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=markdevaney, assignees=[], commentAuthors=[psteitz, markdevaney, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-391
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-391, created=Wed Jul 21 10:57:46 CEST 2010, updated=Wed Mar 23 21:13:27 CET 2011, resolved=Sun Oct 03 18:43:11 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Inconsistent behaviour of constructors in ArrayRealVector class, link=https://issues.apache.org/jira/browse/MATH-391, description=&lt;p&gt;ArrayRealVector(double[] d) allows to construct a zero-length vector, but ArrayRealVector(double[] d, boolean copyArray) doesn't. Both should allow this as zero-length vectors are mathematically well-defined objects and they are useful boundary cases in many algorithms.&lt;/p&gt;

&lt;p&gt;This breaks some arithmetic operators (addition) on zero-length real vectors which worked in 2.0 but don't work in 2.1&lt;/p&gt;, comments=[&lt;p&gt;I agree that the code should be consistent.  I agree as well that a zero-dimensional vector is legit.   Can anyone explain why ArrayRealVector(double[] d, boolean copyArray) requires positive length?&lt;/p&gt;
, &lt;p&gt;Most probably my bad ...&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1003993 for barnch 2.X and r1003994 for trunk.&lt;br/&gt;
Note that the same problem occurred also in ArrayFieldVector but the fix is different. For Field-based vectors, we need to get the field, so either we use a non-empty array and retrieve the field from the first array element or we add a parameter for the field and allow the array to be empty. The two choices are now possible, as new constructors have been added and the javadoc updated to explain this behavior.&lt;br/&gt;
Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-390
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-390, created=Wed Jul 21 00:47:21 CEST 2010, updated=Wed Jul 21 01:32:12 CEST 2010, resolved=Wed Jul 21 01:32:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Major, summary=Simplex Solver is very inaccurate on a large problem, even a very low value for epsilon, link=https://issues.apache.org/jira/browse/MATH-390, description=&lt;p&gt;I'm currently playing with a program for solving a rather simple chess puzzle. The goal is to place 12 knights on a 8x8 board, such that each field is either attacked by a knight, or contains a knight. To solve this problem (and different variants) I want to use a handcrafted Branch and Bound algorithm that uses Linear Programming to calculate an upperbound on the number of fields that can be covered by a certain amount of knights.&lt;/p&gt;

&lt;p&gt;The idea is to create variables for each field that has to be covered, and to create variables for each field to contain a knight. A cover variable can only become positive if a corresponding knight variable for an adjacent field is also positive, there is a limit to the amount of knights we may place (so the sum of all knight variables cannot be larger than 12) and the cover variables cannot be larger than one. Also, only the cover variables have a coefficient of one in the objective function, all other variables have zero. Because we want to cover the entire board our goal will be to maximize the objective function, since we want to maximize the number of fields that are covered.&lt;/p&gt;

&lt;p&gt;Since a basic chessboard has 64 fields and since it is possible to cover the chessboard with 12 knights, we know there is an integer solution that has value 64. Since we are solving a relaxed variant of the problem, the value should be at least 64. However, when I use the Simplex Solver, I get a value of around 58.6, which is much too low. Even when I relax the constraints in such a fashion that 64 knights may be placed on the board, the solution value remains the same. I've lowered the value of epsilon as much as I can and it still gives the incorrect value. What makes it worse is that the calculation is totally useless as an upperbound (if the value would have been around 70, it would have been an upperbound at least).&lt;/p&gt;

&lt;p&gt;I've heard that using the revised simplex method is a lot better with respect to stacked errors, so I am not sure this is really a bug, or just a problem that arises when the two phase simplex method is used for large problems.&lt;/p&gt;

&lt;p&gt;I will try to attach a code example that implements the problem (but possibly isn't that readable).&lt;/p&gt;, comments=[&lt;p&gt;Example of the 8x8 Knight covering Chess problem. The objective value should at least be 64, but it is around 59.&lt;/p&gt;
, &lt;p&gt;Hmm, it seems I made a programming mistake in the type of the relationship: I used an equality where I should have used a greater-equals. I created a much nicer version of the example, which actually works. Feel free to use it for an example or something.&lt;/p&gt;

&lt;p&gt;My bad, I will close the issue.&lt;/p&gt;
, &lt;p&gt;The correct and more readable example, which actually works.&lt;/p&gt;
, &lt;p&gt;It seems I made a programming error. I included a correct example to solve the problem.&lt;/p&gt;
], resolution=Fixed, reporter=pcbouman, assignees=[], commentAuthors=[pcbouman], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-380
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-380, created=Thu Jun 24 18:47:54 CEST 2010, updated=Sat Mar 24 17:16:33 CET 2012, resolved=Sat Oct 01 15:54:20 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Minor, summary=Need to (re)initialize dYdY0 for multiple integrate with FirstOrderIntegratorWithJacobians, link=https://issues.apache.org/jira/browse/MATH-380, description=&lt;p&gt;There is a lack in the method integrate of FirstOrderIntegratorWithJacobians. The jacobian DYDY0 can't be initialized by the user, unlike DFDP with DF0DP.&lt;br/&gt;
So, for several successive integrations, the matrix is reinitialized to identity and that is not what we might want.&lt;/p&gt;, comments=[&lt;p&gt;You are perfectly right.&lt;/p&gt;

&lt;p&gt;The FirstOrderIntegratorWithJacobians class is a brand new one and it clearly has some design flaws.&lt;br/&gt;
It will most probably be deprecated in its current form and replaced by a new mechanism, better integrated (sorry for the joke) with the standard ODE solvers.&lt;br/&gt;
The ability for user to set an initial value for dydy0 will be present in the new design, but will probably not be back-ported to the current one.&lt;br/&gt;
In the meantime, you can save the final value of the jacobian matrix dydy0 after first part of integration, which we could call dy1dy0 as it represents dy(t1)/dy(t0). Start the second part from t1 to t2 that will reset the initial matrix to identity and hence compute compute dy(t2)/dy(t1) and do the multiplication by yourself of the two matrices to really get what you need: dy(t2)/dy(t1) = dy(t2)/dy(t1) * dy(t1)/dy(t0).&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue &lt;/p&gt;
, &lt;p&gt;changing target fix version to 3.0.&lt;br/&gt;
Fixing this and several other problems requires a complete rewrite of the jacobians computation with ODE, and this rewrite implies user interfaces changes, so it cannot be fixed before 3.0.&lt;/p&gt;
, &lt;p&gt;A first attempt to implement Jacobians computation again in ODE has been committed in subversion repository as of r1175409.&lt;br/&gt;
This implementation still lacks the ability for step handlers to also retrieve the additional equations and their derivatives.&lt;br/&gt;
This implementation is based on the Orekit one described here: &lt;a href="https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf"&gt;https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1176745.&lt;/p&gt;
], resolution=Fixed, reporter=pparraud, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-377
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-377, created=Thu Jun 17 11:06:03 CEST 2010, updated=Wed Mar 23 21:08:36 CET 2011, resolved=Sun Jul 25 21:49:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=weight versus sigma in AbstractLeastSquares, link=https://issues.apache.org/jira/browse/MATH-377, description=&lt;p&gt;In AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.&lt;/p&gt;

&lt;p&gt; Once corrected, getRMS() can even reduce&lt;/p&gt;

&lt;p&gt; public double getRMS() {return Math.sqrt(getChiSquare()/rows);}&lt;/p&gt;, comments=[&lt;p&gt;It is not clear to me exactly what is being computed in getChiSquare.  Step 0 is to get an actual definition in the javadoc for what it is trying to compute.  I agree it seems odd to be dividing by residual weights; but I could be missing the intent.&lt;/p&gt;
, &lt;p&gt;OK, let us define ChiSquare as the sum of the weighted square of the residual in order to be consistent with the rest of the definitions in that class.  That would also be consistent with what users expect from a parameter labeled 'weight' rather than 'sigma'.  If we reach consensus on that definition, I can take care of that issue.&lt;/p&gt;
, &lt;p&gt;I could be missing something, but I see no reason that the weighted sum of squared residuals computed here (after the proposed change) should in general follow a chi-square distribution or be related to a chi-square test statistic of any kind.   Why is it called chi-square?  Sorry if I am missing something simple here.&lt;/p&gt;
, &lt;p&gt;I guess if you assume normalliy distributed errors, it makes sense, so drop the last comment and I am +1 for the change (with definition added to the javadoc).&lt;/p&gt;
, &lt;p&gt;Indeed, the confusion comes from the fact that, in some textbooks, each residual is divided by 'sigma_i' which leads to a weight of 1/(sigma_i^2).  In CM, we adopted the terminology 'weight' without reference to sigma.  I will change the javadoc accordingly.&lt;/p&gt;
, &lt;p&gt;Patch to correct issue &lt;a href="https://issues.apache.org/jira/browse/MATH-377" title="weight versus sigma in AbstractLeastSquares"&gt;&lt;del&gt;MATH-377&lt;/del&gt;&lt;/a&gt;.  The change in getChiSquare let to a tiny update in one of Levenberg-Marquardt unit tests.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[psteitz, dimpbx, luc], timeEstimate=1, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-373
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-373, created=Mon Jun 07 16:54:00 CEST 2010, updated=Sat Mar 24 17:16:56 CET 2012, resolved=Thu Sep 02 06:52:33 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=StatUtils.sum returns NaN for zero-length arrays, link=https://issues.apache.org/jira/browse/MATH-373, description=&lt;p&gt;StatUtils.sum returns NaN for zero-length arrays, which is:&lt;/p&gt;

&lt;p&gt;1. inconsistent with the mathematical notion of sum: in maths, sum_{i=0}^{N-1} a_i will be 0 for N=0. In particular, the identity&lt;br/&gt;
&lt;br/&gt;
sum_{i=0}^{k-1} a_i + sum_{i=k}^{N-1} = sum_{i=0}^{N-1}&lt;/p&gt;

&lt;p&gt;is broken for k = 0, since NaN + x = NaN, not x.&lt;/p&gt;

&lt;p&gt;2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition, as NaNs propagate silently and require manual tracing during the debugging)&lt;/p&gt;

&lt;p&gt;3. enforces "special case" handling when the user expects that the summed array can have a zero length.&lt;/p&gt;

&lt;p&gt;The correct behaviour is, in my opinion, to return 0.0, not NaN in the above case.&lt;/p&gt;, comments=[&lt;p&gt;I agree with the reasoning here, and we should do it this way in 3.0.  However it is an incompatible change to do in a point release, so I'm going to wait for more feed back from other developers before I make any changes to the current code.&lt;/p&gt;

&lt;p&gt;I'm thinking that adding a method to AbstractUnivariateStatistic that looks like:&lt;br/&gt;
   protected boolean test( final double[] values,  final int begin,   final int length, final boolean allowEmpty)&lt;/p&gt;

&lt;p&gt;that would have the test:&lt;br/&gt;
   if(length == 0 &amp;amp;&amp;amp; !allowEmpty)&lt;br/&gt;
        return false;&lt;/p&gt;

&lt;p&gt;The current test method can call the new one with allowEmpty=false for backwards compatibility.  Then we can decide on which statistics should have a zero value on the empty set.&lt;/p&gt;
, &lt;p&gt;The consensus of the commons-math developers is that, since the current behavior is documented in 2.x, that this will have to wait for 3.0.  Fixing this in 2.x would introduce a too large incompatibility change to include in 2.x.&lt;/p&gt;

&lt;p&gt;I can attach a patch against 2.x that fixes this, as long as anybody using the patch understands that it isn't supported.&lt;/p&gt;

, &lt;p&gt;Possibly crazy idea: &lt;/p&gt;

&lt;p&gt;if Math 3.0 is going to change package names (which may be necessary), one could introduce the fix using a math3 package name?&lt;/p&gt;
, &lt;p&gt;IIRC, changing the package name had been suggested and discussed for 2.0.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;One argument is that, to be consistent,  you&amp;#39;d have to change the name at every major release...&amp;#93;&lt;/span&gt;&lt;/p&gt;
, &lt;p&gt;Speaking as a maintainer of client code which uses ACM, I'd rather cope with occasional incompatibilities in the same packages, than have to change ALL my client code to keep up with the package name changes after every release. A reason to change the package name would be if you wanted to use the old and new version side by side, but that would not be a common usage pattern for ACM, I think.&lt;/p&gt;
, &lt;p&gt;As Gilles mentioned, changing the package name for commons-math was discussed and voted on for 2.x.  The result of the vote was to keep the package name, since commons-math won't usually be provided by a third party library.  Since nothing much has changed, I can't see that commons-math would change it's package for version 3.0.&lt;/p&gt;
, &lt;p&gt;This will be fixed in the 3.0 build.&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[billbarker, sebb@apache.org, erans, rwerp], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-369
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-369, created=Mon May 03 17:48:27 CEST 2010, updated=Wed Mar 23 21:05:06 CET 2011, resolved=Mon May 03 20:43:59 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Minor, summary=BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException, link=https://issues.apache.org/jira/browse/MATH-369, description=&lt;p&gt;Method &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  &lt;/p&gt;

&lt;p&gt;invokes &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(double min, double max) &lt;/p&gt;

&lt;p&gt;which throws NullPointerException, as member variable&lt;/p&gt;

&lt;p&gt;    UnivariateRealSolverImpl.f &lt;/p&gt;

&lt;p&gt;is null.&lt;/p&gt;

&lt;p&gt;Instead the method:&lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)&lt;/p&gt;

&lt;p&gt;should be called.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;/p&gt;

&lt;p&gt;invoke:&lt;/p&gt;

&lt;p&gt;     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);&lt;/p&gt;

&lt;p&gt;NullPointerException will be thrown.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository as of r940565.&lt;br/&gt;
Thanks for the report and for the fix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sasunpundev@abv.bg, assignees=[], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-368
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-368, created=Thu Apr 29 05:41:10 CEST 2010, updated=Wed Mar 23 21:04:17 CET 2011, resolved=Mon May 10 01:07:24 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=OpenMapRealVector.getSparcity should be getSparsity, link=https://issues.apache.org/jira/browse/MATH-368, description=&lt;p&gt;The term for describing the ratio of nonzero elements to zero elements in a matrix/vector is sparsity, not sparcity.  Suggest renaming getSparcity() to getSparsity()&lt;/p&gt;, comments=[&lt;p&gt;The policy of this project is to not remove methods from the public API in a point release.  However, the misspelled method has been deprecated and the correctly spelled method has been added.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-367
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-367, created=Thu Apr 22 20:31:06 CEST 2010, updated=Wed Mar 23 21:03:42 CET 2011, resolved=Mon May 10 03:17:14 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=AbstractRealVector.sparseIterator fails when vector has exactly one non-zero entry, link=https://issues.apache.org/jira/browse/MATH-367, description=&lt;p&gt;The following program:&lt;br/&gt;
===&lt;br/&gt;
import java.util.Iterator;&lt;br/&gt;
import org.apache.commons.math.linear.*;&lt;/p&gt;

&lt;p&gt;public class SparseIteratorTester&lt;br/&gt;
{&lt;br/&gt;
    public static void main(String[] args) {&lt;br/&gt;
        double vdata[] = { 0.0, 1.0, 0.0 };&lt;br/&gt;
        RealVector v = new ArrayRealVector(vdata);&lt;br/&gt;
        Iterator&amp;lt;RealVector.Entry&amp;gt; iter = v.sparseIterator();&lt;br/&gt;
        while(iter.hasNext()) {
            RealVector.Entry entry = iter.next();
            System.out.printf("%d: %f\n", entry.getIndex(), entry.getValue());
        }   &lt;br/&gt;
    }       &lt;br/&gt;
} &lt;br/&gt;
===&lt;br/&gt;
generates this output:&lt;/p&gt;

&lt;p&gt;1: 1.000000&lt;br/&gt;
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: -1&lt;br/&gt;
	at org.apache.commons.math.linear.ArrayRealVector.getEntry(ArrayRealVector.java:995)&lt;br/&gt;
	at org.apache.commons.math.linear.AbstractRealVector$EntryImpl.getValue(AbstractRealVector.java:850)&lt;br/&gt;
	at test.SparseIteratorTester.main(SparseIteratorTester.java:13)&lt;br/&gt;
===&lt;/p&gt;

&lt;p&gt;This patch fixes it, and simplifies AbstractRealVector.SparseEntryIterator  (sorry, i don't see any form entry for attaching a file)&lt;br/&gt;
===&lt;br/&gt;
Index: src/main/java/org/apache/commons/math/linear/AbstractRealVector.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(revision 936985)&lt;br/&gt;
+++ src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(working copy)&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.commons.math.linear;&lt;/p&gt;

&lt;p&gt; import java.util.Iterator;&lt;br/&gt;
+import java.util.NoSuchElementException;&lt;/p&gt;

&lt;p&gt; import org.apache.commons.math.FunctionEvaluationException;&lt;br/&gt;
 import org.apache.commons.math.MathRuntimeException;&lt;br/&gt;
@@ -875,40 +876,25 @@&lt;br/&gt;
         /** Dimension of the vector. */&lt;br/&gt;
         private final int dim;&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Temporary entry (reused on each call to {@link #next()}. */&lt;/li&gt;
	&lt;li&gt;private EntryImpl tmp = new EntryImpl();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;/** Current entry. */&lt;br/&gt;
+        /** Last entry returned by #next(). */&lt;br/&gt;
         private EntryImpl current;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Next entry. */&lt;br/&gt;
+        /** Next entry for #next() to return. */&lt;br/&gt;
         private EntryImpl next;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** Simple constructor. */&lt;br/&gt;
         protected SparseEntryIterator() {&lt;br/&gt;
             dim = getDimension();&lt;br/&gt;
             current = new EntryImpl();&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (current.getValue() == 0) {
-                advance(current);
-            }&lt;/li&gt;
	&lt;li&gt;if(current.getIndex() &amp;gt;= 0){
-                // There is at least one non-zero entry
-                next = new EntryImpl();
-                next.setIndex(current.getIndex());
+            next = new EntryImpl();
+            if(next.getValue() == 0)
                 advance(next);
-            } else {
-                // The vector consists of only zero entries, so deny having a next
-                current = null;
-            }&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Advance an entry up to the next non null one.&lt;br/&gt;
+        /** Advance an entry up to the next nonzero value.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param e entry to advance&lt;br/&gt;
          */&lt;br/&gt;
         protected void advance(EntryImpl e) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (e == null) {
-                return;
-            }&lt;br/&gt;
             do {
                 e.setIndex(e.getIndex() + 1);
             } while (e.getIndex() &amp;lt; dim &amp;amp;&amp;amp; e.getValue() == 0);&lt;br/&gt;
@@ -919,22 +905,17 @@&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;br/&gt;
         public boolean hasNext() {
-            return current != null;
+            return next.getIndex() &amp;gt;= 0;
         }&lt;br/&gt;
 &lt;br/&gt;
         /** {@inheritDoc} */&lt;br/&gt;
         public Entry next() {&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;tmp.setIndex(current.getIndex());&lt;/li&gt;
	&lt;li&gt;if (next != null) {&lt;/li&gt;
	&lt;li&gt;current.setIndex(next.getIndex());&lt;/li&gt;
	&lt;li&gt;advance(next);&lt;/li&gt;
	&lt;li&gt;if (next.getIndex() &amp;lt; 0) {
-                    next = null;
-                }&lt;/li&gt;
	&lt;li&gt;} else {
-                current = null;
-            }&lt;/li&gt;
	&lt;li&gt;return tmp;&lt;br/&gt;
+            int index = next.getIndex();&lt;br/&gt;
+            if(index &amp;lt; 0)&lt;br/&gt;
+                throw new NoSuchElementException();&lt;br/&gt;
+            current.setIndex(index);&lt;br/&gt;
+            advance(next);&lt;br/&gt;
+            return current;&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;/p&gt;, comments=[&lt;p&gt;patch fixing the bug&lt;/p&gt;
, &lt;p&gt;I've applied your patch (with a couple of style tweaks).  It should be available in the next release of commons-math.&lt;/p&gt;

&lt;p&gt;Thank you for your contribution.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[ashuang, billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-365
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-365, created=Tue Apr 20 16:21:20 CEST 2010, updated=Wed Mar 23 21:02:52 CET 2011, resolved=Wed Apr 21 16:35:53 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=Issue with "SmoothingBicubicSplineInterpolator", link=https://issues.apache.org/jira/browse/MATH-365, description=&lt;p&gt;I figured out that the name of this class is misleading as the implementation doesn't perform the intended smoothing.&lt;/p&gt;

&lt;p&gt;In order to solve this issue, I propose to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;deprecate the "SmoothingBicubicSplineInterpolator" class&lt;/li&gt;
	&lt;li&gt;create a "BicubicSplineInterpolator" class (similar to the above class but with the useless code removed)&lt;/li&gt;
	&lt;li&gt;remove the "SmoothingBicubicSplineInterpolatorTest" class&lt;/li&gt;
	&lt;li&gt;add a "BicubicSplineInterpolatorTest" with essentially the same contents as the above one&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Then I would also add a new "SmoothingPolynomialBicubicSplineInterpolator" where I used the "PolynomialFitter" class to smooth the input data along both dimensions before the interpolating function is computed.&lt;/p&gt;

&lt;p&gt;Does someone object to these changes?&lt;/p&gt;, comments=[&lt;p&gt;removing the test class would badly impact test coverage, so it would be better to simply deprecae it also and to remove the library class and its associated test class together when releasing 3.0&lt;/p&gt;
, &lt;p&gt;revision 936295.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,807 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-362
2016-01-13 22:07:48,822 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-362, created=Tue Apr 06 13:38:46 CEST 2010, updated=Wed Mar 23 21:02:00 CET 2011, resolved=Sat May 29 20:16:50 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it, link=https://issues.apache.org/jira/browse/MATH-362, description=&lt;p&gt;LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.&lt;/p&gt;, comments=[&lt;p&gt;Ooops. You are right.&lt;br/&gt;
The Levenberg-Marquardt optimizer uses specific convergence parameters which can be set by   setInitialStepBoundFactor, setCostRelativeTolerance, setParRelativeTolerance and setOrthoTolerance.&lt;br/&gt;
The most important convergence tuning are either setCostRelativeTolerance for a convergence on the cost itself or setParRelativeTolerance for a convergence on the parameters.&lt;/p&gt;

&lt;p&gt;I'm not sure how to solve this. Do the existing tuning parameters fit your needs or not ? Some convergence criteria can be expressed with both methods, but not all. Should we keep both setting as alternate methods or should we remove one and rely on the remaining one ?&lt;/p&gt;
, &lt;p&gt;I would keep using orthoTolerance as it is used now:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;292                if (maxCosine &amp;lt;= orthoTolerance) {&lt;br/&gt;
293                    // convergence has been reached&lt;br/&gt;
294                    return new VectorialPointValuePair(point, objective);&lt;br/&gt;
295                }&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;and then use costRelativeTolerance &amp;amp; parRelativeTolerance if and only if the convergence checker is null, otherwise use the convergence checker and ignore {costRelativeTolerance, parRelativeTolerance}.&lt;/p&gt;

&lt;p&gt;What I am missing now is the ability to bail out if the absolute distance from the target falls below some value ("close enough").&lt;/p&gt;
, &lt;p&gt;I've spent that last few days trying to find a good curve fitting library for Java and got excited when I learned of Commons Math.  Unfortunately, its curve fitting is very unreliable.  I'm hoping that this bug is what is causing the problems that I'm seeing.  I'm comparing data from NIST and results from DataFitX and it is apparent that Commons Math is not yet up to the task.  My fingers are crossed that its quality in the curve fitting area will be improved in the near future.  Keep up the good work Apache.&lt;/p&gt;

&lt;p&gt;I've opened an issue about the problems I'm seeing, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Double check how you use it, Matt. I have succesfully used this curve fitting in production.&lt;/p&gt;
, &lt;p&gt;Matt, could you please describe the problem you encounter more precisely (i.e. with numerical examples) and preferably in a new JIRA issue ? We will check if the two problems are related and link the issues afterwards if it appears they are.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
, &lt;p&gt;It's good to see such quick responses.  I'll open a new JIRA issue and spend some time putting together code, data and a detailed description of the problem I'm seeing.  Thanks Apache for all your hard work.&lt;/p&gt;

&lt;p&gt;I've opened an issue regarding the problem, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r949433.&lt;br/&gt;
Thanks for reporting the issue&lt;/p&gt;
, &lt;p&gt;Thank you.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=roman.werpachowski, assignees=[], commentAuthors=[luc, roman.werpachowski, mprice], timeEstimate=null, timeSpent=null]
2016-01-13 22:07:48,822 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-288
2016-01-13 22:07:48,822 : DEBUG : KNIME-Worker-2 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-288, created=Tue Aug 25 00:31:11 CEST 2009, updated=Wed Apr 14 02:30:17 CEST 2010, resolved=Tue Aug 25 20:10:08 CEST 2009, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.1
], priority=Major, summary=SimplexSolver not working as expected 2, link=https://issues.apache.org/jira/browse/MATH-288, description=&lt;p&gt;SimplexSolver didn't find the optimal solution.&lt;/p&gt;

&lt;p&gt;Program for Lpsolve:&lt;br/&gt;
=====================&lt;br/&gt;
/* Objective function */&lt;br/&gt;
max: 7 a 3 b;&lt;/p&gt;

&lt;p&gt;/* Constraints */&lt;br/&gt;
R1: +3 a -5 c &amp;lt;= 0;&lt;br/&gt;
R2: +2 a -5 d &amp;lt;= 0;&lt;br/&gt;
R3: +2 b -5 c &amp;lt;= 0;&lt;br/&gt;
R4: +3 b -5 d &amp;lt;= 0;&lt;br/&gt;
R5: +3 a +2 b &amp;lt;= 5;&lt;br/&gt;
R6: +2 a +3 b &amp;lt;= 5;&lt;/p&gt;

&lt;p&gt;/* Variable bounds */&lt;br/&gt;
a &amp;lt;= 1;&lt;br/&gt;
b &amp;lt;= 1;&lt;br/&gt;
=====================&lt;br/&gt;
Results(correct): a = 1, b = 1, value = 10&lt;/p&gt;


&lt;p&gt;Program for SimplexSolve:&lt;br/&gt;
=====================&lt;br/&gt;
LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]{7, 3, 0, 0}, 0);&lt;br/&gt;
Collection&amp;lt;LinearConstraint&amp;gt; podmienky = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{1, 0, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 1, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 0, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 0, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 2, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 3, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 2, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 3, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
RealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);&lt;br/&gt;
=====================&lt;br/&gt;
Results(incorrect): a = 1, b = 0.5, value = 8.5&lt;/p&gt;

&lt;p&gt;P.S. I used the latest software from the repository (including &lt;a href="https://issues.apache.org/jira/browse/MATH-286" title="SimplexSolver not working as expected?"&gt;&lt;del&gt;MATH-286&lt;/del&gt;&lt;/a&gt; fix).&lt;/p&gt;, comments=[&lt;p&gt;Thanks for the bug report.  I've confirmed this is an issue.&lt;/p&gt;

&lt;p&gt;Here's a slightly smaller version of the problem that causes the same bug, which might be easier for debugging:&lt;/p&gt;

&lt;p&gt;MAX 7 a + 3 b&lt;br/&gt;
s.t.&lt;br/&gt;
3 a -5 c &amp;lt;= 0&lt;br/&gt;
2 a -5 d &amp;lt;= 0&lt;br/&gt;
3 b -5 d &amp;lt;= 0&lt;br/&gt;
a &amp;lt;= 1&lt;br/&gt;
b &amp;lt;= 1&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 7, 3, 0, 0 }, 0 );&lt;br/&gt;
        Collection&amp;lt;LinearConstraint&amp;gt; constraints = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 3, 0, -5, 0 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 2, 0, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 3, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0 }, Relationship.LEQ, 1.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 0 }, Relationship.LEQ, 1.0));&lt;/p&gt;

&lt;p&gt;        SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
        RealPointValuePair solution = solver.optimize(f, constraints, GoalType.MAXIMIZE, true);&lt;br/&gt;
        assertEquals(10.0, solution.getValue(), .0000001);&lt;/p&gt;
, &lt;p&gt;Patch attached.  It was a 1 character bug.  I was saying to only do the minimum ratio test if the entry is &amp;gt;= 0, but it should have been &amp;gt; 0 (dividing by 0 is never good :o)&lt;br/&gt;
Thanks again for the bug report.&lt;/p&gt;
, &lt;p&gt;resolved in subversion repository as of r807738&lt;br/&gt;
patch applied (except for debug print function)&lt;br/&gt;
thanks for the repoart and thanks for the patch&lt;/p&gt;
], resolution=Fixed, reporter=kefa, assignees=[], commentAuthors=[bmccann, luc], timeEstimate=480, timeSpent=null]
2016-01-13 22:07:48,822 : INFO  : KNIME-Worker-3 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:1 : Jira table created.
2016-01-13 22:07:48,822 : INFO  : KNIME-Worker-3 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 End execute (2 secs)
2016-01-13 22:07:48,822 : DEBUG : KNIME-Worker-3 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doBeforePostExecution
2016-01-13 22:07:48,822 : DEBUG : KNIME-Worker-3 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: POSTEXECUTE
2016-01-13 22:07:48,822 : DEBUG : KNIME-Worker-3 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doAfterExecute - success
2016-01-13 22:07:48,822 : DEBUG : KNIME-Worker-3 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: EXECUTED
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-3 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:07:48,822 : INFO  : KNIME-Worker-2 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:2 : Jira table created.
2016-01-13 22:07:48,838 : INFO  : KNIME-Worker-2 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 End execute (1 sec)
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-2 : WorkflowManager : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 doBeforePostExecution
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-2 : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: POSTEXECUTE
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-2 : WorkflowManager : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 doAfterExecute - success
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-2 : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: EXECUTED
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-2 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-2 : NodeContainer : Jira Adapter (Offline) : 0:2 : Table Difference Checker 0:3 has new state: CONFIGURED_QUEUED
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-3 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePreExecution
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-3 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: PREEXECUTE
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-3 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforeExecution
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-3 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTING
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-3 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Adding handler e1f7d6e7-141d-4553-91f5-3f20a4188d79 (Table Difference Checker 0:3: <no directory>) - 3 in total
2016-01-13 22:07:48,838 : DEBUG : KNIME-Worker-3 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 Start execute
2016-01-13 22:07:48,869 : INFO  : KNIME-Worker-3 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 End execute (0 secs)
2016-01-13 22:07:48,869 : DEBUG : KNIME-Worker-3 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePostExecution
2016-01-13 22:07:48,869 : DEBUG : KNIME-Worker-3 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: POSTEXECUTE
2016-01-13 22:07:48,869 : DEBUG : KNIME-Worker-3 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doAfterExecute - success
2016-01-13 22:07:48,869 : DEBUG : KNIME-Worker-3 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTED
2016-01-13 22:07:48,869 : DEBUG : KNIME-Worker-3 : NodeContainer : Table Difference Checker : 0:3 : JiraOfflineTest 0 has new state: EXECUTED
2016-01-13 22:07:48,869 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test execute workflow -----------------
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test node messages -----------------
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test node messages -----------------
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test hilite rows -----------------
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test hilite rows -----------------
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test close views -----------------
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test close views -----------------
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test log messages -----------------
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test log messages -----------------
2016-01-13 22:07:48,869 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test uncaught exceptions -----------------
2016-01-13 22:07:48,978 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test uncaught exceptions -----------------
2016-01-13 22:07:50,273 : DEBUG : Service Thread : MemoryAlertSystem :  :  : Memory usage below threshold of 0.7125915080527087 after GC run
2016-01-13 22:07:50,273 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ===== Memory statistics: 996,000 MB max, 61,384 MB used, 934,616 MB free ====
2016-01-13 22:07:50,273 : INFO  : Worker-3 : GUIWorkflowTestSuite :  :  : ================= Finished testflow WorkflowTests\JiraOfflineTest =================
2016-01-13 22:07:50,398 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:07:50,398 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:07:50,414 : DEBUG : Worker-3 : WorkflowManager :  :  : Removing project "JiraOfflineTest 0"
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Removing handler e1f7d6e7-141d-4553-91f5-3f20a4188d79 (Table Difference Checker 0:3: <no directory>) - 2 remaining
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : DifferenceCheckerNodeModel : Table Difference Checker : 0:3 : Removing all (0) views from model.
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:2 : Removing handler 4e6e55cb-293e-4e69-97ac-aaaa330fede3 (Jira Adapter (Offline) 0:2: <no directory>) - 1 remaining
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : JiraAdapterNodeModel : Jira Adapter (Offline) : 0:2 : Removing all (0) views from model.
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : clean output ports.
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:1 : Removing handler 7d0206e3-fad3-4e9f-9cb9-e29447469731 (Jira Adapter (Offline) 0:1: <no directory>) - 0 remaining
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : JiraAdapterNodeModel : Jira Adapter (Offline) : 0:1 : Removing all (0) views from model.
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : clean output ports.
2016-01-13 22:07:50,507 : DEBUG : Worker-3 : WorkflowManager :  :  : Project "JiraOfflineTest 0" removed (1 remaining)
2016-01-13 22:08:20,356 : DEBUG : KNIME-Node-Usage-Writer : NodeTimer$GlobalNodeStats :  :  : Successfully wrote node usage stats to file: D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\nodeusage_3.0.json
2016-01-13 22:08:20,356 : DEBUG : KNIME-Node-Usage-Sender : NodeTimer$GlobalNodeStats :  :  : Sending of usage stats disabled.
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # Welcome to the KNIME Analytics Platform v3.1.0.v201512031304 (Build December 06, 2015 #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # Based on Eclipse, http://www.eclipse.org                                              #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # Copyright by KNIME GmbH, Konstanz, Germany and others.                                #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # Website: http://www.knime.org                                                         #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # E-mail: contact@knime.org                                                             #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # For more details see the KNIME log file:                                              #
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\knime.log
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : #---------------------------------------------------------------------------------------#
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # logging date=Wed Jan 13 22:09:09 CET 2016
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # java.version=1.8.0_60
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # java.vm.version=25.60-b23
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # java.vendor=Oracle Corporation
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # os.name=Windows 7
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # os.arch=amd64
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # number of CPUs=2
2016-01-13 22:09:09,682 : INFO  : main : NodeLogger :  :  : # assertions=off
2016-01-13 22:09:09,697 : INFO  : main : NodeLogger :  :  : # host=SONY-Komputer
2016-01-13 22:09:09,697 : INFO  : main : NodeLogger :  :  : # username=SONY
2016-01-13 22:09:09,697 : INFO  : main : NodeLogger :  :  : # max mem=910MB
2016-01-13 22:09:09,713 : INFO  : main : NodeLogger :  :  : # application=org.knime.product.KNIME_APPLICATION
2016-01-13 22:09:09,713 : INFO  : main : NodeLogger :  :  : # ID=01-9c587cb4eccee8b8
2016-01-13 22:09:09,713 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:09:17,287 : INFO  : main : StringHistory :  :  : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_database_drivers.txt' does not exist.
2016-01-13 22:09:17,287 : INFO  : main : StringHistory :  :  : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_database_urls.txt' does not exist.
2016-01-13 22:09:17,303 : DEBUG : main : DatabaseConnectionSettings :  :  : Settings database timeout to 15 seconds
2016-01-13 22:09:17,365 : DEBUG : main : DatabaseConnectionSettings :  :  : Database concurrency (sync via database connection) is true.
2016-01-13 22:09:17,365 : DEBUG : main : KNIMECorePlugin :  :  : Setting KNIME max thread count to 4
2016-01-13 22:09:17,365 : DEBUG : main : KNIMECorePlugin :  :  : Setting KNIME temp dir to "C:\Users\SONY\AppData\Local\Temp"
2016-01-13 22:09:17,474 : INFO  : main : KNIMECorePlugin :  :  : Setting console view log level to WARN
2016-01-13 22:09:17,755 : DEBUG : main : KnimeEncryption :  :  : Replacing current encryption key supplier "null" with this new one "org.knime.workbench.core.EclipseEncryptionKeySupplier@2c77344f".
2016-01-13 22:09:17,755 : DEBUG : main : DatabaseConnectionSettings :  :  : Settings database timeout to 15 seconds
2016-01-13 22:09:17,771 : DEBUG : main : KnimeEncryption :  :  : Replacing current encryption key supplier "org.knime.workbench.core.EclipseEncryptionKeySupplier@2c77344f" with this new one "org.knime.workbench.ui.masterkey.MasterKeyPreferencePage$1@7198ab9a".
2016-01-13 22:09:18,114 : DEBUG : main : SvgPluginActivator :  :  : Added SVG export option to node view class
2016-01-13 22:09:19,970 : DEBUG : main : KnimeEnterpriseFileSystemPlugin :  :  : Started KNIME Enterprise Remote File System plug-in
2016-01-13 22:09:20,033 : INFO  : main : ExplorerMountTable :  :  : Mounted Explorer Temp Space 'knime-temp-space' - com.knime.explorer.tempspace
2016-01-13 22:09:20,126 : DEBUG : main : UpdateManager :  :  : Updating registered ServerSpaces every 2000 msec.
2016-01-13 22:09:21,842 : DEBUG : main : NodeTimer$GlobalNodeStats :  :  : Successfully read node usage stats from file: D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\nodeusage_3.0.json
2016-01-13 22:09:21,905 : DEBUG : main : NodeContainer :  :  : ROOT  has new state: EXECUTED
2016-01-13 22:09:21,905 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 
2016-01-13 22:09:21,905 : DEBUG : main : NodeContainer :  :  : KNIME MetaNode Repository 1 has new state: EXECUTED
2016-01-13 22:09:21,905 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1
2016-01-13 22:09:21,905 : DEBUG : main : WorkflowManager :  :  : Added new subworkflow 1
2016-01-13 22:09:21,905 : DEBUG : main : WorkflowManager :  :  : Created project 1
2016-01-13 22:09:21,920 : DEBUG : main : RepositoryManager :  :  : Found category extension 'io' on path '/'
2016-01-13 22:09:21,920 : DEBUG : main : RepositoryManager :  :  : Found category extension 'manipulation' on path '/'
2016-01-13 22:09:21,920 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database' on path '/'
2016-01-13 22:09:21,920 : DEBUG : main : RepositoryManager :  :  : Found category extension 'view' on path '/'
2016-01-13 22:09:21,920 : DEBUG : main : RepositoryManager :  :  : Found category extension 'analytics' on path '/'
2016-01-13 22:09:21,936 : DEBUG : main : RepositoryManager :  :  : Found category extension 'toolintegration' on path '/'
2016-01-13 22:09:21,936 : DEBUG : main : RepositoryManager :  :  : Found category extension 'misc' on path '/'
2016-01-13 22:09:21,936 : DEBUG : main : RepositoryManager :  :  : Found category extension 'labs' on path '/'
2016-01-13 22:09:21,936 : DEBUG : main : RepositoryManager :  :  : Found category extension 'community' on path '/'
2016-01-13 22:09:21,952 : DEBUG : main : RepositoryManager :  :  : Found category extension 'social-media' on path '/'
2016-01-13 22:09:21,952 : DEBUG : main : RepositoryManager :  :  : Found category extension 'report' on path '/'
2016-01-13 22:09:21,952 : DEBUG : main : RepositoryManager :  :  : Found category extension 'chemistry' on path '/'
2016-01-13 22:09:21,952 : DEBUG : main : RepositoryManager :  :  : Found category extension 'applications' on path '/'
2016-01-13 22:09:21,952 : DEBUG : main : RepositoryManager :  :  : Found category extension 'struct-data' on path '/'
2016-01-13 22:09:21,967 : DEBUG : main : RepositoryManager :  :  : Found category extension 'scripting' on path '/'
2016-01-13 22:09:21,967 : DEBUG : main : RepositoryManager :  :  : Found category extension 'flowcontrol' on path '/'
2016-01-13 22:09:21,967 : DEBUG : main : RepositoryManager :  :  : Found category extension 'uncategorized' on path '/'
2016-01-13 22:09:21,967 : DEBUG : main : RepositoryManager :  :  : Found category extension 'testing' on path '/'
2016-01-13 22:09:21,983 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress' on path '/community'
2016-01-13 22:09:21,983 : DEBUG : main : RepositoryManager :  :  : Found category extension 'read' on path '/io'
2016-01-13 22:09:21,983 : DEBUG : main : RepositoryManager :  :  : Found category extension 'write' on path '/io'
2016-01-13 22:09:21,983 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column' on path '/manipulation'
2016-01-13 22:09:21,983 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row' on path '/manipulation'
2016-01-13 22:09:21,998 : DEBUG : main : RepositoryManager :  :  : Found category extension 'table' on path '/manipulation'
2016-01-13 22:09:21,998 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pmml' on path '/manipulation'
2016-01-13 22:09:21,998 : DEBUG : main : RepositoryManager :  :  : Found category extension 'property' on path '/view'
2016-01-13 22:09:21,998 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mining' on path '/analytics'
2016-01-13 22:09:21,998 : DEBUG : main : RepositoryManager :  :  : Found category extension 'statistics' on path '/analytics'
2016-01-13 22:09:21,998 : DEBUG : main : RepositoryManager :  :  : Found category extension 'io-other' on path '/io'
2016-01-13 22:09:22,014 : DEBUG : main : RepositoryManager :  :  : Found category extension 'java-snippet' on path '/scripting'
2016-01-13 22:09:22,014 : DEBUG : main : RepositoryManager :  :  : Found category extension 'view-util' on path '/view'
2016-01-13 22:09:22,014 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-io' on path '/database'
2016-01-13 22:09:22,014 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-manipulation' on path '/database'
2016-01-13 22:09:22,014 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-connector' on path '/database'
2016-01-13 22:09:22,014 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-utility' on path '/database'
2016-01-13 22:09:22,014 : DEBUG : main : RepositoryManager :  :  : Found category extension 'automation' on path '/flowcontrol'
2016-01-13 22:09:22,030 : DEBUG : main : RepositoryManager :  :  : Found category extension 'quickforms' on path '/flowcontrol'
2016-01-13 22:09:22,030 : DEBUG : main : RepositoryManager :  :  : Found category extension 'variables' on path '/flowcontrol'
2016-01-13 22:09:22,030 : DEBUG : main : RepositoryManager :  :  : Found category extension 'switches' on path '/flowcontrol'
2016-01-13 22:09:22,030 : DEBUG : main : RepositoryManager :  :  : Found category extension 'trycatch' on path '/flowcontrol'
2016-01-13 22:09:22,030 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/flowcontrol'
2016-01-13 22:09:22,030 : DEBUG : main : RepositoryManager :  :  : Found category extension 'filestore' on path '/testing'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'timeseries' on path '/applications'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress.scm' on path '/community/depress'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress.its' on path '/community/depress'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-other' on path '/manipulation/row'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-split+combine' on path '/manipulation/column'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-filter' on path '/manipulation/column'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-transform' on path '/manipulation/column'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'binning' on path '/manipulation/column'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-convert+replace' on path '/manipulation/column'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-filter' on path '/manipulation/row'
2016-01-13 22:09:22,045 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-transform' on path '/manipulation/row'
2016-01-13 22:09:22,061 : DEBUG : main : RepositoryManager :  :  : Found category extension 'clustering' on path '/analytics/mining'
2016-01-13 22:09:22,061 : DEBUG : main : RepositoryManager :  :  : Found category extension 'nn' on path '/analytics/mining'
2016-01-13 22:09:22,061 : DEBUG : main : RepositoryManager :  :  : Found category extension 'regression' on path '/analytics/statistics'
2016-01-13 22:09:22,061 : DEBUG : main : RepositoryManager :  :  : Found category extension 'rules' on path '/analytics/mining'
2016-01-13 22:09:22,061 : DEBUG : main : RepositoryManager :  :  : Found category extension 'dtree' on path '/analytics/mining'
2016-01-13 22:09:22,061 : DEBUG : main : RepositoryManager :  :  : Found category extension 'modeleval' on path '/analytics/mining'
2016-01-13 22:09:22,076 : DEBUG : main : RepositoryManager :  :  : Found category extension 'subgroup' on path '/analytics/mining'
2016-01-13 22:09:22,076 : DEBUG : main : RepositoryManager :  :  : Found category extension 'miscClass' on path '/analytics/mining'
2016-01-13 22:09:22,076 : DEBUG : main : RepositoryManager :  :  : Found category extension 'bayes' on path '/analytics/mining'
2016-01-13 22:09:22,076 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mds' on path '/analytics/mining'
2016-01-13 22:09:22,076 : DEBUG : main : RepositoryManager :  :  : Found category extension 'svm' on path '/analytics/mining'
2016-01-13 22:09:22,076 : DEBUG : main : RepositoryManager :  :  : Found category extension 'featureselection' on path '/analytics/mining'
2016-01-13 22:09:22,092 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pca' on path '/analytics/mining'
2016-01-13 22:09:22,092 : DEBUG : main : RepositoryManager :  :  : Found category extension 'weka' on path '/analytics/mining'
2016-01-13 22:09:22,092 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mining-pmml' on path '/analytics/mining'
2016-01-13 22:09:22,108 : DEBUG : main : RepositoryManager :  :  : Found category extension 'loopsupport' on path '/flowcontrol/'
2016-01-13 22:09:22,108 : DEBUG : main : RepositoryManager :  :  : Found category extension 'treeensemble' on path '/analytics/mining'
2016-01-13 22:09:22,108 : DEBUG : main : RepositoryManager :  :  : Found category extension 'regression' on path 'analytics/mining/treeensemble'
2016-01-13 22:09:22,108 : DEBUG : main : RepositoryManager :  :  : Found category extension 'ensembles' on path '/analytics/mining'
2016-01-13 22:09:22,108 : DEBUG : main : RepositoryManager :  :  : Found category extension 'hypothesis-testing' on path '/analytics/statistics'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/applications/timeseries'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'basisfunction' on path '/analytics/mining/rules'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mlp' on path '/analytics/mining/nn'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pnn' on path '/analytics/mining/nn'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/featureselection'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'crossvalidation' on path '/analytics/mining/modeleval'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/modeleval'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'classification' on path '/analytics/mining/treeensemble'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'ensembles-combine' on path '/analytics/mining/ensembles'
2016-01-13 22:09:22,123 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/ensembles'
2016-01-13 22:09:23,106 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.its.bugzilla': Bugzilla Adapter (Offline)
2016-01-13 22:09:23,137 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.its.jira': Jira Adapter (Offline)
2016-01-13 22:09:23,153 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.scm.gitoffline': Git SCM
2016-01-13 22:09:23,168 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.scm.svnoffline': SVN SCM
2016-01-13 22:09:23,184 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.smote.SmoteNodeFactory': SMOTE
2016-01-13 22:09:23,215 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.filereader.FileReaderNodeFactory': File Reader
2016-01-13 22:09:23,231 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.ColorManager2NodeFactory': Color Manager
2016-01-13 22:09:23,324 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.size.SizeManager2NodeFactory': Size Manager
2016-01-13 22:09:23,356 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.shape.ShapeManagerNodeFactory': Shape Manager
2016-01-13 22:09:23,387 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.ColorAppenderNodeFactory': Color Appender
2016-01-13 22:09:23,465 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.size.SizeAppenderNodeFactory': Size Appender
2016-01-13 22:09:23,527 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.shape.ShapeAppenderNodeFactory': Shape Appender
2016-01-13 22:09:23,543 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.table.TableNodeFactory': Interactive Table
2016-01-13 22:09:23,574 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.binner.BinnerNodeFactory': Numeric Binner
2016-01-13 22:09:23,621 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.binnerdictionary.BinByDictionaryNodeFactory': Binner (Dictionary)
2016-01-13 22:09:23,652 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.cache.CacheNodeFactory': Cache
2016-01-13 22:09:23,699 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.fuzzy.FuzzyBasisFunctionLearnerNodeFactory': Fuzzy Rule Learner
2016-01-13 22:09:25,306 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.fuzzy.FuzzyBasisFunctionPredictor2NodeFactory': Fuzzy Rule Predictor
2016-01-13 22:09:25,321 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.radial.RadialBasisFunctionLearnerNodeFactory': PNN Learner (DDA)
2016-01-13 22:09:25,337 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.radial.RadialBasisFunctionPredictor2NodeFactory': PNN Predictor
2016-01-13 22:09:25,384 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.csvwriter.CSVWriterNodeFactory': CSV Writer
2016-01-13 22:09:25,399 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.joiner.Joiner2NodeFactory': Joiner
2016-01-13 22:09:25,399 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.crossjoin.CrossJoinerNodeFactory': Cross Joiner
2016-01-13 22:09:25,415 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.split2.SplitNodeFactory2': Column Splitter
2016-01-13 22:09:25,430 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnappend.ColumnAppenderNodeFactory': Column Appender
2016-01-13 22:09:25,446 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.arffwriter.ARFFWriterNodeFactory': ARFF Writer
2016-01-13 22:09:25,446 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.sorter.SorterNodeFactory': Sorter
2016-01-13 22:09:25,462 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.arffreader.ARFFReaderNodeFactory': ARFF Reader
2016-01-13 22:09:25,477 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.csvreader.CSVReaderNodeFactory': CSV Reader
2016-01-13 22:09:25,493 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.linereader.LineReaderNodeFactory': Line Reader
2016-01-13 22:09:25,493 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.crosstable.CrosstabNodeFactory': Crosstab
2016-01-13 22:09:25,508 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.valcount.ValueCounterNodeFactory': Value Counter
2016-01-13 22:09:25,524 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize3.Normalize3NodeFactory': Normalizer
2016-01-13 22:09:25,540 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.PMMLNormalizerApplyNodeFactory': Normalizer Apply (PMML)
2016-01-13 22:09:25,571 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columnfilter.DataColumnSpecFilterPMMLNodeFactory': Column Filter (PMML)
2016-01-13 22:09:25,602 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.append.row.AppendedRowsNodeFactory': Concatenate
2016-01-13 22:09:25,618 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.append.row.AppendedRowsWithOptionalInNodeFactory': Concatenate (Optional in)
2016-01-13 22:09:25,633 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.row.RowFilterNodeFactory': Row Filter
2016-01-13 22:09:25,649 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.row.RowFilter2PortNodeFactory': Row Splitter
2016-01-13 22:09:25,664 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.shuffle.ShuffleNodeFactory': Shuffle
2016-01-13 22:09:25,680 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.sample.SamplingNodeFactory': Row Sampling
2016-01-13 22:09:25,696 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bootstrap.BootstrapNodeFactory': Bootstrap Sampling
2016-01-13 22:09:25,711 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.equalsizesampling.EqualSizeSamplingNodeFactory': Equal Size Sampling
2016-01-13 22:09:25,711 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.partition.PartitionNodeFactory': Partitioning
2016-01-13 22:09:25,727 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.fuzzycmeans.FuzzyClusterNodeFactory2': Fuzzy c-Means
2016-01-13 22:09:25,742 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.neural.mlp2.MLPPredictorNodeFactory': MultiLayerPerceptron Predictor
2016-01-13 22:09:25,774 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.predictor.PredictorReaderNodeFactory': Model Reader
2016-01-13 22:09:25,774 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.transpose.TransposeTableNodeFactory': Transpose
2016-01-13 22:09:25,789 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.extracttabledimension.ExtractTableDimensionNodeFactory': Extract Table Dimension
2016-01-13 22:09:25,789 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.extracttablespec.ExtractTableSpecNodeFactory': Extract Table Spec
2016-01-13 22:09:25,805 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.predictor2.DecTreePredictorNodeFactory': Decision Tree Predictor
2016-01-13 22:09:25,820 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.image.DecTreeToImageNodeFactory': Decision Tree To Image
2016-01-13 22:09:25,836 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.sota.SotaLearnerNodeFactory': SOTA Learner
2016-01-13 22:09:25,852 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rename.RenameNodeFactory': Column Rename
2016-01-13 22:09:25,852 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnrenameregex.ColumnRenameRegexNodeFactory': Column Rename (Regex)
2016-01-13 22:09:25,867 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.constantvalue.ConstantValueColumnNodeFactory': Constant Value Column
2016-01-13 22:09:25,883 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.create.CreateBitVectorNodeFactory': Create Bit Vector
2016-01-13 22:09:25,883 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.subgroupminer.SubgroupMinerFactory2': Association Rule Learner
2016-01-13 22:09:25,898 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.linear2.predict.GeneralRegressionPredictorNodeFactory': Regression Predictor
2016-01-13 22:09:25,898 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.table.read.ReadTableNodeFactory': Table Reader
2016-01-13 22:09:25,914 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.table.write.WriteTableNodeFactory': Table Writer
2016-01-13 22:09:25,914 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.create.CreateBitVectorNodeFactory': Create Bit Vector
2016-01-13 22:09:25,930 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.expand.ExpandBitVectorNodeFactory': Expand Bit Vector
2016-01-13 22:09:25,961 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.histogram.node.HistogramNodeFactory': Histogram (interactive)
2016-01-13 22:09:25,976 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.histogram.node.FixedColumnHistogramNodeFactory': Histogram
2016-01-13 22:09:25,976 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.NormalizeApplyNodeFactory': Normalizer (Apply)
2016-01-13 22:09:25,992 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.box.BoxPlotNodeFactory': Box Plot
2016-01-13 22:09:26,008 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.line.LinePlotterNodeFactory': Line Plot
2016-01-13 22:09:26,008 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.parcoord.ParallelCoordinateNodeFactory': Parallel Coordinates
2016-01-13 22:09:26,023 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.scatter.ScatterPlotterNodeFactory': Scatter Plot
2016-01-13 22:09:26,023 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.scattermatrix.ScatterMatrixNodeFactory': Scatter Matrix
2016-01-13 22:09:26,039 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.hilite': HiLite Row Splitter
2016-01-13 22:09:26,101 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.discretization.caim.modelcreator.CAIMDiscretizationNodeFactory': CAIM Binner
2016-01-13 22:09:26,148 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.discretization.caim.modelapply.DiscretizationApplyNodeFactory': CAIM Applier
2016-01-13 22:09:26,164 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rowkey2.RowKeyNodeFactory2': RowID
2016-01-13 22:09:26,195 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.knn.KnnNodeFactory': K Nearest Neighbor
2016-01-13 22:09:26,210 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.hierarchical.HierarchicalClusterNodeFactory': Hierarchical Clustering
2016-01-13 22:09:26,210 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.sota.predictor.SotaPredictorNodeFactory': SOTA Predictor
2016-01-13 22:09:26,226 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.pie.node.fixed.FixedPieNodeFactory': Pie chart
2016-01-13 22:09:26,242 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.pie.node.interactive.InteractivePieNodeFactory': Pie chart (interactive)
2016-01-13 22:09:26,242 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.groupby.GroupByNodeFactory': GroupBy
2016-01-13 22:09:26,257 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.ungroup.UngroupNodeFactory': Ungroup
2016-01-13 22:09:26,273 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pivot.Pivot2NodeFactory': Pivoting
2016-01-13 22:09:26,273 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bayes.naivebayes.predictor3.NaiveBayesPredictorNodeFactory2': Naive Bayes Predictor
2016-01-13 22:09:26,288 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.compute.CorrelationComputeNodeFactory': Linear Correlation
2016-01-13 22:09:26,288 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.compute.CorrelationComputeNodeFactory': Linear Correlation
2016-01-13 22:09:26,304 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.filter.CorrelationFilterNodeFactory': Correlation Filter
2016-01-13 22:09:26,304 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.lowvarfilter2.LowVarFilter2NodeFactory': Low Variance Filter
2016-01-13 22:09:26,320 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.mds.MDSNodeFactory': MDS
2016-01-13 22:09:26,335 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.mds.mdsprojection.MDSProjectionNodeFactory': MDS Projection
2016-01-13 22:09:26,335 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.svm.predictor2.SVMPredictorNodeFactory': SVM Predictor
2016-01-13 22:09:26,351 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colcompare.ColumnComparatorNodeFactory': Column Comparator
2016-01-13 22:09:26,351 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rowsplit.NumericRowSplitterNodeFactory': Numeric Row Splitter
2016-01-13 22:09:26,366 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringreplacer.StringReplacerNodeFactory': String Replacer
2016-01-13 22:09:26,366 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.dialog2.DomainNodeFactory': Domain Calculator
2016-01-13 22:09:26,382 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnumeric.EditNumericDomainNodeFactory': Edit Numeric Domain
2016-01-13 22:09:26,398 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnominal.dic.EditNominalDomainDicNodeFactory': Edit Nominal Domain (Dictionary)
2016-01-13 22:09:26,398 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnominal.EditNominalDomainNodeFactory': Edit Nominal Domain
2016-01-13 22:09:26,413 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.caseconvert.CaseConvertNodeFactory': Case Converter
2016-01-13 22:09:26,413 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringreplacer.dict.SearchReplaceDictNodeFactory': String Replace (Dictionary)
2016-01-13 22:09:26,429 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellsplit.CellSplitterNodeFactory': Cell Splitter
2016-01-13 22:09:26,444 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.numbertostring.NumberToStringNodeFactory': Number To String
2016-01-13 22:09:26,444 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.stringtonumber.StringToNumberNodeFactory': String To Number
2016-01-13 22:09:26,460 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntrans2.One2ManyCol2NodeFactory': One to Many
2016-01-13 22:09:26,460 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntrans2.Many2OneCol2NodeFactory': Many to One
2016-01-13 22:09:26,476 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colcombine2.ColCombine2NodeFactory': Column Combiner
2016-01-13 22:09:26,522 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnmerge.ColumnMergerNodeFactory': Column Merger
2016-01-13 22:09:26,538 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.assign.ClusterAssignerNodeFactory': Cluster Assigner
2016-01-13 22:09:26,569 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.accuracy.AccuracyScorerNodeFactory': Scorer
2016-01-13 22:09:26,663 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.numeric.NumericScorerNodeFactory': Numeric Scorer
2016-01-13 22:09:26,694 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.entrop.NewEntropyNodeFactory': Entropy Scorer
2016-01-13 22:09:26,710 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.roc.ROCNodeFactory': ROC Curve
2016-01-13 22:09:26,772 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.chem.node.viz.enrich2.EnrichmentPlotterFactory': Enrichment Plotter
2016-01-13 22:09:26,803 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBReaderNodeFactory': Database Reader
2016-01-13 22:09:26,850 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBReaderConnectionNodeFactory': Database Table Connector
2016-01-13 22:09:26,881 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DatabaseLoopingNodeFactory': Database Looping
2016-01-13 22:09:26,897 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBConnectionNodeFactory': Database Connection Table Reader
2016-01-13 22:09:26,897 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBRowFilterNodeFactory': Database Row Filter
2016-01-13 22:09:26,912 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBQueryNodeFactory2': Database Query
2016-01-13 22:09:26,912 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBColumnFilterNodeFactory': Database Column Filter
2016-01-13 22:09:26,944 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBSorterNodeFactory': Database Sorter
2016-01-13 22:09:26,975 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBGroupByNodeFactory': Database GroupBy
2016-01-13 22:09:27,022 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBJoinerNodeFactory': Database Joiner
2016-01-13 22:09:27,022 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBConnectionWriterNodeFactory': Database Connection Table Writer
2016-01-13 22:09:27,053 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBWriterNodeFactory': Database Writer
2016-01-13 22:09:27,084 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBUpdateNodeFactory': Database Update
2016-01-13 22:09:27,100 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBDeleteRowsNodeFactory': Database Delete
2016-01-13 22:09:27,131 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBSQLExecutorNodeFactory': Database SQL Executor
2016-01-13 22:09:27,146 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellsplitbypos.CellSplitterByPositionNodeFactory': Cell Splitter By Position
2016-01-13 22:09:27,162 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.condbox.ConditionalBoxPlotNodeFactory': Conditional Box Plot
2016-01-13 22:09:27,178 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnFilterRefNodeFactory': Reference Column Filter
2016-01-13 22:09:27,178 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.MissingValueColumnFilterNodeFactory': Missing Value Column Filter
2016-01-13 22:09:27,209 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowFilterRefNodeFactory': Reference Row Filter
2016-01-13 22:09:27,224 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.collection.list.create2.CollectionCreate2NodeFactory': Create Collection Column
2016-01-13 22:09:27,240 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.collection.list.split.CollectionSplitNodeFactory': Split Collection Column
2016-01-13 22:09:27,240 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.pmml.read.PMMLReaderNodeFactory': PMML Reader
2016-01-13 22:09:27,256 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.regexsplit.RegexSplitNodeFactory': Regex Split
2016-01-13 22:09:27,256 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.pmml.write.PMMLWriterNodeFactory': PMML Writer
2016-01-13 22:09:27,271 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.predictor.PredictorWriterNodeFactory': Model Writer
2016-01-13 22:09:27,302 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.writemage.WriteImageNodeFactory': Image Port Writer
2016-01-13 22:09:27,334 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.imagecolwriter.ImageColumnWriterNodeFactory': Image Column Writer
2016-01-13 22:09:27,349 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.liftchart.LiftChartNodeFactory': Lift Chart
2016-01-13 22:09:27,349 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.setoperator.SetOperatorNodeFactory': Set Operator
2016-01-13 22:09:27,365 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.xvalidation.XValidatePartitionerFactory': X-Partitioner
2016-01-13 22:09:27,380 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.xvalidation.AggregateOutputNodeFactory': X-Aggregator
2016-01-13 22:09:27,380 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopStartCountNodeFactory': Counting Loop Start
2016-01-13 22:09:27,427 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.chunk.LoopStartChunkNodeFactory': Chunk Loop Start
2016-01-13 22:09:27,427 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.columnlist2.ColumnListLoopStartNodeFactory': Column List Loop Start
2016-01-13 22:09:27,427 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.condition.LoopStartGenericNodeFactory': Generic Loop Start
2016-01-13 22:09:27,443 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.variableloophead.LoopStartVariableNodeFactory': Table Row To Variable Loop Start
2016-01-13 22:09:27,458 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopEndNodeFactory': Loop End
2016-01-13 22:09:27,458 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.condition.LoopEndConditionNodeFactory': Variable Condition Loop End
2016-01-13 22:09:27,474 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.extractvariables.ExtractVariablesNodeFactory': Extract Variables (Data)
2016-01-13 22:09:27,568 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.extractvariables.ExtractVariablesDBNodeFactory': Extract Variables (Database)
2016-01-13 22:09:27,583 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopStart1NodeFactory': Backward Feature Elimination Start (1:1)
2016-01-13 22:09:27,583 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopStart2NodeFactory': Backward Feature Elimination Start (2:2)
2016-01-13 22:09:27,599 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopEndNodeFactory': Backward Feature Elimination End
2016-01-13 22:09:27,599 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimFilterNodeFactory': Backward Feature Elimination Filter
2016-01-13 22:09:27,614 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.appendvariabletotable2.AppendVariableToTable2NodeFactory': Variable to Table Column
2016-01-13 22:09:27,614 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.variabletotablerow2.VariableToTable2NodeFactory': Variable to Table Row
2016-01-13 22:09:27,630 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.tablerowtovariable.TableToVariableNodeFactory': Table Row to Variable
2016-01-13 22:09:27,630 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.injectvariables.InjectVariablesNodeFactory': Inject Variables (Data)
2016-01-13 22:09:27,646 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.injectvariables.InjectVariablesDBNodeFactory': Inject Variables (Database)
2016-01-13 22:09:27,646 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.nominal.NominalValueRowFilterNodeFactory': Nominal Value Row Filter
2016-01-13 22:09:27,661 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopStartIntervalNodeFactory': Interval Loop Start
2016-01-13 22:09:27,661 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.breakpoint.BreakpointNodeFactory': Breakpoint
2016-01-13 22:09:27,677 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.unpivot2.Unpivot2NodeFactory': Unpivoting
2016-01-13 22:09:27,677 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCANodeFactory': PCA
2016-01-13 22:09:27,692 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAComputeNodeFactory': PCA Compute
2016-01-13 22:09:27,692 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAApplyNodeFactory': PCA Apply
2016-01-13 22:09:27,708 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAReverseNodeFactory': PCA Inversion
2016-01-13 22:09:27,708 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.double2int.DoubleToIntNodeFactory': Double To Int
2016-01-13 22:09:27,724 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.hilite.collector.InteractiveHiLiteCollectorNodeFactory': Interactive HiLite Collector
2016-01-13 22:09:27,739 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.exp.node.meta.looper.LoopEnd2NodeFactory': Loop End (2 ports)
2016-01-13 22:09:27,739 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.matcher.SubsetMatcherNodeFactory': Subset Matcher
2016-01-13 22:09:27,755 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.matcher.SubsetMatcherNodeFactory': Subset Matcher
2016-01-13 22:09:27,755 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.ImageToTableNodeFactory': Image To Table
2016-01-13 22:09:27,770 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.tablerowtoimage.TableRowToImageNodeFactory': Table To Image
2016-01-13 22:09:27,770 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.manualif.ManualIfNodeFactory': IF Switch
2016-01-13 22:09:27,786 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endif.EndifNodeFactory': End IF
2016-01-13 22:09:27,802 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.startcase.StartcaseNodeFactory': CASE Switch Data (Start)
2016-01-13 22:09:27,802 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endcase.EndcaseNodeFactory': CASE Switch Data (End)
2016-01-13 22:09:27,817 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.model.CaseStartModelNodeFactory': CASE Switch Model (Start)
2016-01-13 22:09:27,817 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endmodelcase.EndmodelcaseNodeFactory': CASE Switch Model (End)
2016-01-13 22:09:27,833 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.variable.CaseStartVariableNodeFactory': CASE Switch Variable (Start)
2016-01-13 22:09:27,848 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.variable.CaseEndVariableNodeFactory': CASE Switch Variable (End)
2016-01-13 22:09:27,864 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.emptytableswitch.EmptyTableSwitchNodeFactory': Empty Table Switch
2016-01-13 22:09:27,864 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntogrid2.ColumnToGrid2NodeFactory': Column to Grid
2016-01-13 22:09:27,880 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnheaderextract.ColumnHeaderExtractorNodeFactory': Extract Column Header
2016-01-13 22:09:27,895 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnheaderinsert.ColumnHeaderInsertNodeFactory': Insert Column Header
2016-01-13 22:09:27,895 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.addemptyrows.AddEmptyRowsNodeFactory': Add Empty Rows
2016-01-13 22:09:27,911 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellreplace.CellReplacerNodeFactory': Cell Replacer
2016-01-13 22:09:27,926 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.autobinner3.AutoBinnerLearnNodeFactory': Auto-Binner
2016-01-13 22:09:27,926 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.autobinner.apply.AutoBinnerApplyNodeFactory': Auto-Binner (Apply)
2016-01-13 22:09:27,942 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopEndJoin2NodeFactory': Loop End (Column Append)
2016-01-13 22:09:27,942 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.listfiles2.ListFilesNodeFactory': List Files
2016-01-13 22:09:27,973 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.tablecreator.TableCreator2NodeFactory': Table Creator
2016-01-13 22:09:28,004 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.sampledata.SampleDataNodeFactory': Data Generator
2016-01-13 22:09:28,004 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.createtablestructure.CreateTableStructureNodeFactory': Create Table Structure
2016-01-13 22:09:28,036 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.createtempdir.CreateTempDirectoryNodeFactory': Create Temp Dir
2016-01-13 22:09:28,036 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.sendmail.SendMailNodeFactory': Send Email
2016-01-13 22:09:28,051 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.extractsysprop.ReadSysPropertyNodeFactory': Extract System Properties
2016-01-13 22:09:28,067 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.extractcontextprop.ReadContextPropertyNodeFactory': Extract Context Properties
2016-01-13 22:09:28,082 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.PMMLNormalizerDeNodeFactory': Denormalizer (PMML)
2016-01-13 22:09:28,098 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.NormalizerDeNodeFactory': Denormalizer
2016-01-13 22:09:28,098 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.extract.ColorExtractNodeFactory': Extract Color
2016-01-13 22:09:28,114 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.categorytonumber2.CategoryToNumberNodeFactory2': Category To Number
2016-01-13 22:09:28,129 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.categorytonumber.CategoryToNumberApplyNodeFactory': Category To Number (Apply)
2016-01-13 22:09:28,129 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.column.DataColumnSpecFilterNodeFactory': Column Filter
2016-01-13 22:09:28,145 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rounddouble.RoundDoubleNodeFactory': Round Double
2016-01-13 22:09:28,160 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnresorter.ColumnResorterNodeFactory': Column Resorter
2016-01-13 22:09:28,192 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnlag.LagColumnNodeFactory': Lag Column
2016-01-13 22:09:28,238 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.datavalidator.DataValidatorNodeFactory': Table Validator
2016-01-13 22:09:28,270 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.datavalidator.DataValidatorSpecNodeFactory': Table Validator (Reference)
2016-01-13 22:09:28,270 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.mergevariables.MergeVariablesNodeFactory': Merge Variables
2016-01-13 22:09:28,285 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.group.GroupLoopStartNodeFactory': Group Loop Start
2016-01-13 22:09:28,301 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.variableloopend.VariableLoopEndNodeFactory': Variable Loop End
2016-01-13 22:09:28,301 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnaggregator.ColumnAggregatorNodeFactory': Column Aggregator
2016-01-13 22:09:28,316 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bytevector.create.CreateByteVectorNodeFactory': Create Byte Vector
2016-01-13 22:09:28,332 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bytevector.expand.ExpandByteVectorNodeFactory': Expand Byte Vector
2016-01-13 22:09:28,348 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.generictry.DataPortTryNodeFactory': Try (Data Ports)
2016-01-13 22:09:28,348 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.generictry.VariablePortTryNodeFactory': Try (Variable Ports)
2016-01-13 22:09:28,363 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.DataPortCatchNodeFactory': Catch Errors (Data Ports)
2016-01-13 22:09:28,379 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.VariablePortCatchNodeFactory': Catch Errors (Var Ports)
2016-01-13 22:09:28,379 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.DBPortCatchNodeFactory': Catch Errors (DB Ports)
2016-01-13 22:09:28,379 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.GenericPortCatchNodeFactory': Catch Errors (Generic Ports)
2016-01-13 22:09:28,394 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.inverter.ActiveBranchInverterNodeFactory': Active Branch Inverter
2016-01-13 22:09:28,394 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.tablecoltovariable.TableColumnToVariableNodeFactory': Table Column to Variable
2016-01-13 22:09:28,410 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.sleep.SleepNodeFactory': Wait...
2016-01-13 22:09:28,426 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.workflow.save.SaveWorkflowNodeFactory': Save Workflow
2016-01-13 22:09:28,426 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.timerinfo.TimerinfoNodeFactory': Timer Info
2016-01-13 22:09:28,441 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.globaltimerinfo.GlobalTimerinfoNodeFactory': Global Timer Info
2016-01-13 22:09:28,441 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopStartNodeFactory': Recursive Loop Start
2016-01-13 22:09:28,457 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopEndNodeFactory': Recursive Loop End
2016-01-13 22:09:28,457 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopStart2NodeFactory': Recursive Loop Start (2 ports)
2016-01-13 22:09:28,472 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopEnd2NodeFactory': Recursive Loop End (2 ports)
2016-01-13 22:09:28,472 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.xml2pmml.XML2PMMLNodeFactory': XML To PMML
2016-01-13 22:09:28,488 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.JDBCConnectorNodeFactory': Database Connector
2016-01-13 22:09:28,504 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.connection.DBTableSelectorNodeFactory': Database Table Selector
2016-01-13 22:09:28,504 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.SQLInjectNodeFactory': SQL Inject
2016-01-13 22:09:28,519 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.SQLExtractNodeFactory': SQL Extract
2016-01-13 22:09:28,519 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.drop.DBDropTableNodeFactory': Database Drop Table
2016-01-13 22:09:28,535 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.hilite.AutoHiLiteNodeFactory': HiLite Table
2016-01-13 22:09:28,550 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.coltypechanger.ColumnTypeChangerNodeFactory': Column Auto Type Cast
2016-01-13 22:09:28,550 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.fixedwidthfr.FixedWidthFRNodeFactory': Fixed Width File Reader
2016-01-13 22:09:28,566 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.targetshuffling.TargetShufflingNodeFactory': Target Shuffling
2016-01-13 22:09:28,628 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMeanMissingCellHandlerFactory
2016-01-13 22:09:28,800 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMeanMissingCellHandlerFactory
2016-01-13 22:09:28,831 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMovingAverageMissingCellHandlerFactory
2016-01-13 22:09:28,831 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMovingAverageMissingCellHandlerFactory
2016-01-13 22:09:28,847 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedDoubleValueMissingCellHandlerFactory
2016-01-13 22:09:28,862 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedDoubleValueMissingCellHandlerFactory
2016-01-13 22:09:28,878 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MaxMissingCellHandlerFactory
2016-01-13 22:09:28,894 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MaxMissingCellHandlerFactory
2016-01-13 22:09:28,925 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.IntegerMeanMissingCellHandlerFactory
2016-01-13 22:09:28,956 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.IntegerMeanMissingCellHandlerFactory
2016-01-13 22:09:28,956 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedIntegerValueMissingCellHandlerFactory
2016-01-13 22:09:28,972 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedIntegerValueMissingCellHandlerFactory
2016-01-13 22:09:29,003 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MinMissingCellHandlerFactory
2016-01-13 22:09:29,003 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MinMissingCellHandlerFactory
2016-01-13 22:09:29,018 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MostFrequentValueMissingCellHandlerFactory
2016-01-13 22:09:29,018 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MostFrequentValueMissingCellHandlerFactory
2016-01-13 22:09:29,034 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.NextMissingCellHandlerFactory
2016-01-13 22:09:29,050 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.NextMissingCellHandlerFactory
2016-01-13 22:09:29,050 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.RemoveRowMissingCellHandlerFactory
2016-01-13 22:09:29,050 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.RemoveRowMissingCellHandlerFactory
2016-01-13 22:09:29,065 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MedianNumberMissingCellHandlerFactory
2016-01-13 22:09:29,065 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MedianNumberMissingCellHandlerFactory
2016-01-13 22:09:29,065 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.PreviousMissingCellHandlerFactory
2016-01-13 22:09:29,065 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.PreviousMissingCellHandlerFactory
2016-01-13 22:09:29,081 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.LinearInterpolationMissingCellHandlerFactory
2016-01-13 22:09:29,081 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.LinearInterpolationMissingCellHandlerFactory
2016-01-13 22:09:29,096 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedStringValueMissingCellHandlerFactory
2016-01-13 22:09:29,096 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedStringValueMissingCellHandlerFactory
2016-01-13 22:09:29,112 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.AverageInterpolationMissingCellHandlerFactory
2016-01-13 22:09:29,206 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.AverageInterpolationMissingCellHandlerFactory
2016-01-13 22:09:29,206 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedLongValueMissingCellHandlerFactory
2016-01-13 22:09:29,206 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedLongValueMissingCellHandlerFactory
2016-01-13 22:09:29,268 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.missingval.compute.MissingValueHandlerNodeFactory': Missing Value
2016-01-13 22:09:29,268 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.missingval.apply.MissingValueApplyNodeFactory': Missing Value (Apply)
2016-01-13 22:09:29,284 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.numbertocategory.NumberToCategoryApplyNodeFactory': Number To Category (Apply)
2016-01-13 22:09:29,299 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.columnrename.DBColumnRenameNodeFactory': Database Column Rename
2016-01-13 22:09:29,299 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.normalize.NormalizerPMMLNodeFactory2': Normalizer (PMML)
2016-01-13 22:09:29,315 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.numbertostring.NumberToStringNodeFactory2': Number To String (PMML)
2016-01-13 22:09:29,330 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.stringtonumber.StringToNumberNodeFactory2': String To Number (PMML)
2016-01-13 22:09:29,330 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.binner.BinnerNodeFactory2': Numeric Binner (PMML)
2016-01-13 22:09:29,346 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columntrans2.One2ManyCol2PMMLNodeFactory2': One to Many (PMML)
2016-01-13 22:09:29,424 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columntrans2.Many2OneCol2PMMLNodeFactory2': Many to One (PMML)
2016-01-13 22:09:29,440 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.learner2.DecisionTreeLearnerNodeFactory3': Decision Tree Learner
2016-01-13 22:09:29,455 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.linear2.learner.LinReg2LearnerNodeFactory2': Linear Regression Learner
2016-01-13 22:09:29,455 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.polynomial.learner2.PolyRegLearnerNodeFactory2': Polynomial Regression Learner
2016-01-13 22:09:29,471 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.logistic.learner3.LogRegLearnerNodeFactory3': Logistic Regression Learner
2016-01-13 22:09:29,486 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.neural.rprop.RPropNodeFactory2': RProp MLP Learner
2016-01-13 22:09:29,486 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.svm.learner.SVMLearnerNodeFactory2': SVM Learner
2016-01-13 22:09:29,502 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bayes.naivebayes.learner2.NaiveBayesLearnerNodeFactory3': Naive Bayes Learner
2016-01-13 22:09:29,518 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.kmeans.ClusterNodeFactory': k-Means
2016-01-13 22:09:29,518 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.pivot.DBPivotNodeFactory': Database Pivot
2016-01-13 22:09:29,533 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.sampling.DBSamplingNodeFactory': Database Sampling
2016-01-13 22:09:29,533 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.auto.DBAutoBinnerNodeFactory': Database Auto-Binner
2016-01-13 22:09:29,549 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.numeric.DBNumericBinnerNodeFactory': Database Numeric-Binner
2016-01-13 22:09:29,549 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.apply.DBApplyBinnerNodeFactory': Database Apply-Binner
2016-01-13 22:09:29,564 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowSplitRefNodeFactory': Reference Row Splitter
2016-01-13 22:09:29,564 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnSplitRefNodeFactory': Reference Column Splitter
2016-01-13 22:09:29,580 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rank.RankNodeFactory': Rank
2016-01-13 22:09:29,580 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowSplitRefNodeFactory': Reference Row Splitter
2016-01-13 22:09:29,580 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnSplitRefNodeFactory': Reference Column Splitter
2016-01-13 22:09:29,580 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rank.RankNodeFactory': Rank
2016-01-13 22:09:29,596 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.learner.classification.TreeEnsembleClassificationLearnerNodeFactory': Tree Ensemble Learner
2016-01-13 22:09:29,611 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.predictor.classification.TreeEnsembleClassificationPredictorNodeFactory': Tree Ensemble Predictor
2016-01-13 22:09:29,611 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.modelextractor.TreeEnsembleModelExtractorNodeFactory': Tree Ensemble Model Extract
2016-01-13 22:09:29,627 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.learner.regression.TreeEnsembleRegressionLearnerNodeFactory': Tree Ensemble Learner (Regression)
2016-01-13 22:09:29,642 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.predictor.regression.TreeEnsembleRegressionPredictorNodeFactory': Tree Ensemble Predictor (Regression)
2016-01-13 22:09:29,642 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.learner.classification.RandomForestClassificationLearnerNodeFactory': Random Forest Learner
2016-01-13 22:09:29,658 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.learner.regression.RandomForestRegressionLearnerNodeFactory': Random Forest Learner (Regression)
2016-01-13 22:09:29,658 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.predictor.classification.RandomForestClassificationPredictorNodeFactory': Random Forest Predictor
2016-01-13 22:09:29,674 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.predictor.regression.RandomForestRegressionPredictorNodeFactory': Random Forest Predictor (Regression)
2016-01-13 22:09:29,674 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.regressiontree.learner.RegressionTreeLearnerNodeFactory': Simple Regression Tree Learner
2016-01-13 22:09:29,674 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.regressiontree.predictor.RegressionTreePredictorNodeFactory': Simple Regression Tree Predictor
2016-01-13 22:09:29,689 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.metalearning.pmmlporttocell.PMMLPortToCellNodeFactory': PMML To Cell
2016-01-13 22:09:29,705 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.modeltotable.ModelToTableNodeFactory': Model to Cell
2016-01-13 22:09:29,705 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.tabletomodel.TableToModelNodeFactory': Cell To Model
2016-01-13 22:09:29,705 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingLearnerLoopStartNodeFactory': Boosting Learner Loop Start
2016-01-13 22:09:29,720 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingLearnerLoopEndNodeFactory': Boosting Learner Loop End
2016-01-13 22:09:29,720 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingPredictorLoopStartNodeFactory': Boosting Predictor Loop Start
2016-01-13 22:09:29,736 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingPredictorLoopEndNodeFactory': Boosting Predictor Loop End
2016-01-13 22:09:29,736 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.bagging.ModelLoopStartNodeFactory': Model Loop Start
2016-01-13 22:09:29,752 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.bagging.ModelLoopEndNodeFactory': Model Loop End
2016-01-13 22:09:29,752 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.tabletopmmlport.TableToPMMLNodeFactory': Cell To PMML
2016-01-13 22:09:29,767 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.voting.VotingLoopEndNodeFactory': Voting Loop End
2016-01-13 22:09:29,767 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmmlpredict2.PMMLPredictor2NodeFactory': PMML Predictor
2016-01-13 22:09:29,783 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.combine.PMMLEnsembleNodeFactory': Table to PMML Ensemble
2016-01-13 22:09:29,783 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.totable.PMMLEnsemble2TableNodeFactory': PMML Ensemble to Table
2016-01-13 22:09:29,798 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.predictor2.PMMLEnsemblePredictor2NodeFactory': PMML Ensemble Predictor
2016-01-13 22:09:29,798 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.loopend.PMMLEnsembleLoopEndNodeFactory': PMML Ensemble Loop End
2016-01-13 22:09:29,814 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.predictionfusion.PredictionFusionNodeFactory': Prediction Fusion
2016-01-13 22:09:29,830 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.JavaScriptingNodeFactory': Java Snippet (simple)
2016-01-13 22:09:29,830 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.rowfilter.JavaRowFilterNodeFactory': Java Snippet Row Filter
2016-01-13 22:09:29,845 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.rowsplitter.JavaRowSplitterNodeFactory': Java Snippet Row Splitter
2016-01-13 22:09:29,845 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.editvar.JavaEditVariableNodeFactory': Java Edit Variable (simple)
2016-01-13 22:09:29,861 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.ifswitch.JavaIfSwitchNodeFactory': Java IF (Table)
2016-01-13 22:09:29,876 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.svg.node.sparklines.SparkLineNodeFactory': Spark Line Appender
2016-01-13 22:09:29,876 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.svg.node.radarplot.RadarplotAppenderFactory': Radar Plot Appender
2016-01-13 22:09:29,892 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.renderer2image.Renderer2ImageNodeFactory': Renderer to Image
2016-01-13 22:09:29,892 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.readimage.ReadImageFromUrlNodeFactory': Read Images
2016-01-13 22:09:29,908 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.stringtosvg.StringToSvgNodeFactory': String To SVG
2016-01-13 22:09:29,923 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.jsnippet.JavaSnippetNodeFactory': Java Snippet
2016-01-13 22:09:29,923 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.jsnippet.JavaEditVarNodeFactory': Java Edit Variable
2016-01-13 22:09:29,939 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineVariableNodeFactory': Rule Engine Variable
2016-01-13 22:09:29,954 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngineVariable2PortsNodeFactory': Rule Engine Variable (Dictionary)
2016-01-13 22:09:29,954 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringmanipulation.StringManipulationNodeFactory': String Manipulation
2016-01-13 22:09:29,970 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineNodeFactory': Rule Engine
2016-01-13 22:09:29,970 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineFilterNodeFactory': Rule-based Row Filter
2016-01-13 22:09:29,986 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineSplitterNodeFactory': Rule-based Row Splitter
2016-01-13 22:09:30,001 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngine2PortsNodeFactory': Rule Engine (Dictionary)
2016-01-13 22:09:30,001 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngineFilter2PortsNodeFactory': Rule-based Row Filter (Dictionary)
2016-01-13 22:09:30,017 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngine2PortsSplitterNodeFactory': Rule-based Row Splitter (Dictionary)
2016-01-13 22:09:30,017 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.pmml.PMMLRuleEditorNodeFactory': Ruleset Editor
2016-01-13 22:09:30,032 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.pmml.PMMLRuleSetPredictorNodeFactory': Ruleset Predictor
2016-01-13 22:09:30,032 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.totable.RulesToTableNodeFactory': Ruleset to Table
2016-01-13 22:09:30,048 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.decisiontree.FromDecisionTreeNodeFactory': Decision Tree to Ruleset
2016-01-13 22:09:30,048 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.OneSampleTTestNodeFactory': Single sample t-test
2016-01-13 22:09:30,064 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.TwoSampleTTestNodeFactory': Independent groups t-test
2016-01-13 22:09:30,064 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.PairedTTestNodeFactory': Paired t-test
2016-01-13 22:09:30,079 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.OneWayANOVANodeFactory': One-way ANOVA
2016-01-13 22:09:30,095 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.viz.extended.ExtendedStatisticsNodeFactory': Statistics
2016-01-13 22:09:30,095 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.disturber.DisturberNodeFactory': Disturber Node
2016-01-13 22:09:30,110 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.differModelContent.DiffModelContentFactory': Model Content Difference Checker
2016-01-13 22:09:30,110 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.blocking.BlockingNodeFactory': Block Programmatically
2016-01-13 22:09:30,110 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.failing.FailingNodeFactory': Fail in execution
2016-01-13 22:09:30,126 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.credentialsvalidate.CredentialsValidateNodeFactory': Credentials Validate Test
2016-01-13 22:09:30,126 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.datagenerator.TestDataNodeFactory': Test Data Generator
2016-01-13 22:09:30,142 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.executioncount.ExecutionCountNodeFactory': Count Execution Programmatically
2016-01-13 22:09:30,142 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.file.DifferFileNodeFactory': File Difference Checker
2016-01-13 22:09:30,157 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.imagecomp.ImageCompNodeFactory': Image Comparator (deprecated)
2016-01-13 22:09:30,157 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.differ.DifferenceCheckerNodeFactory': Table Difference Checker
2016-01-13 22:09:30,173 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.internal.nodes.image.ImageDifferNodeFactory': Image Difference Checker
2016-01-13 22:09:30,173 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.config.TestConfigNodeFactory': Testflow Configuration
2016-01-13 22:09:30,188 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.internal.nodes.pmml.PMMLDifferenceCheckerNodeFactory': PMML Difference Checker
2016-01-13 22:09:30,188 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.create.FileStoreCreateNodeFactory': Create FileStore Column
2016-01-13 22:09:30,204 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.check.FileStoreTestNodeFactory': Test FileStore Column
2016-01-13 22:09:30,204 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.createloopend.FileStoreCreateLoopEndNodeFactory': Create FileStore Column in LoopEnd
2016-01-13 22:09:30,204 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.fsloopend.LoopEndFileStorePortObjectTestNodeFactory': Test FileStore Port Object Loop End
2016-01-13 22:09:30,220 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.fsobject2cell.FileStoreObjectToCellNodeFactory': Test FileStore Port Object to Table
2016-01-13 22:09:30,220 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.logging.LoggerOptionNodeFactory': Logger Option
2016-01-13 22:09:30,235 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.filter.extract.ExtractFromToNodeFactory': Extract Time Window
2016-01-13 22:09:30,251 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.movavg.MovingAverageNodeFactory': Moving Average
2016-01-13 22:09:30,251 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.stringtotimestamp.String2DateNodeFactory': String to Date/Time
2016-01-13 22:09:30,266 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.diff.TimeDifferenceNodeFactory': Time Difference
2016-01-13 22:09:30,298 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.generator.DateGeneratorNodeFactory': Time Generator
2016-01-13 22:09:30,298 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.extract.TimeFieldExtractorNodeFactory': Time Field Extractor
2016-01-13 22:09:30,298 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.time2string.Time2StringNodeFactory': Time to String
2016-01-13 22:09:30,313 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.preset.TimePresetNodeFactory': Preset Date/Time
2016-01-13 22:09:30,313 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.mask.MaskTimeNodeFactory': Mask Date/Time
2016-01-13 22:09:30,329 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.extract.date.DateFieldExtractorNodeFactory': Date Field Extractor
2016-01-13 22:09:30,344 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.movagg.MovingAggregationNodeFactory': Moving Aggregation
2016-01-13 22:09:30,344 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.converter.DateShiftNodeFactory': Date/Time Shift 
2016-01-13 22:09:30,344 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Cross Validation/
2016-01-13 22:09:30,344 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Cross Validation
2016-01-13 22:09:30,391 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Cross Validation") is not locked
2016-01-13 22:09:30,391 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Cross Validation" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:30,422 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:0
2016-01-13 22:09:30,422 : DEBUG : main : NodeContainer :  :  : KNIME MetaNode Repository 1 has new state: IDLE
2016-01-13 22:09:30,454 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("X_Aggregator (#1)") is not locked
2016-01-13 22:09:30,454 : DEBUG : main : AggregateOutputNodeFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:30,688 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("X_Partitioner (#2)") is not locked
2016-01-13 22:09:30,703 : DEBUG : main : XValidatePartitionerFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:30,703 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("Decision Tree Learner (#14)") is not locked
2016-01-13 22:09:30,734 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:30,797 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("Decision Tree Predictor (#15)") is not locked
2016-01-13 22:09:30,812 : DEBUG : main : DecTreePredictorNodeFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:30,859 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:14(1) to node 1:0:15(1)
2016-01-13 22:09:30,875 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:2(1) to node 1:0:14(1)
2016-01-13 22:09:30,875 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:2(2) to node 1:0:15(2)
2016-01-13 22:09:30,875 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0(0) to node 1:0:2(1)
2016-01-13 22:09:30,875 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:1(2) to node 1:0(1)
2016-01-13 22:09:30,875 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:1(1) to node 1:0(0)
2016-01-13 22:09:30,875 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:15(1) to node 1:0:1(1)
2016-01-13 22:09:30,890 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Cross Validation"  with no errors
2016-01-13 22:09:30,906 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'cross_validation': Cross Validation
2016-01-13 22:09:30,906 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Feature Elimination/
2016-01-13 22:09:30,906 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Feature Elimination
2016-01-13 22:09:30,906 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Feature Elimination") is not locked
2016-01-13 22:09:30,906 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Feature Elimination" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:30,922 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:1
2016-01-13 22:09:30,922 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination Start _1_1_ (#1)") is not locked
2016-01-13 22:09:30,922 : DEBUG : main : BWElimLoopStart1NodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:30,922 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination Filter (#2)") is not locked
2016-01-13 22:09:30,937 : DEBUG : main : BWElimFilterNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:30,937 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination End (#3)") is not locked
2016-01-13 22:09:30,953 : DEBUG : main : BWElimLoopEndNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:30,953 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Partitioning (#7)") is not locked
2016-01-13 22:09:30,968 : DEBUG : main : PartitionNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:30,968 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Naive Bayes Learner (#8)") is not locked
2016-01-13 22:09:30,984 : DEBUG : main : NaiveBayesLearnerNodeFactory2 : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:30,984 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Naive Bayes Predictor (#9)") is not locked
2016-01-13 22:09:31,000 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:3(2) to node 1:1:2(1)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:8(1) to node 1:1:9(1)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:1(1) to node 1:1:7(1)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:9(1) to node 1:1:3(1)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:3(1) to node 1:1(0)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1(1) to node 1:1:2(2)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:2(1) to node 1:1(1)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:7(2) to node 1:1:9(2)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1(0) to node 1:1:1(1)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:7(1) to node 1:1:8(1)
2016-01-13 22:09:31,015 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Feature Elimination"  with no errors
2016-01-13 22:09:31,031 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'feature_elimination': Feature Elimination
2016-01-13 22:09:31,031 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Variables Loop (Data)/
2016-01-13 22:09:31,031 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Variables Loop (Data)
2016-01-13 22:09:31,031 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Variables Loop (Data)") is not locked
2016-01-13 22:09:31,031 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Data)" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,031 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:2
2016-01-13 22:09:31,031 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 22:09:31,046 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Row To Variable Loop Start (#3)") is not locked
2016-01-13 22:09:31,062 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Inject Variables _Data_ (#4)") is not locked
2016-01-13 22:09:31,062 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2:3(1) to node 1:2:4(2)
2016-01-13 22:09:31,078 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2(1) to node 1:2:3(1)
2016-01-13 22:09:31,078 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2(0) to node 1:2:4(1)
2016-01-13 22:09:31,078 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2:2(1) to node 1:2(0)
2016-01-13 22:09:31,078 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Data)"  with no errors
2016-01-13 22:09:31,078 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'variables_loop': Variables Loop (Data)
2016-01-13 22:09:31,078 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Variables Loop (Database)/
2016-01-13 22:09:31,078 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Variables Loop (Database)
2016-01-13 22:09:31,093 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Variables Loop (Database)") is not locked
2016-01-13 22:09:31,093 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Database)" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,093 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:3
2016-01-13 22:09:31,093 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 22:09:31,109 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Row To Variable Loop Start (#3)") is not locked
2016-01-13 22:09:31,109 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Inject Variables _Database_ (#4)") is not locked
2016-01-13 22:09:31,124 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3:3(1) to node 1:3:4(2)
2016-01-13 22:09:31,124 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3(1) to node 1:3:3(1)
2016-01-13 22:09:31,124 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3(0) to node 1:3:4(1)
2016-01-13 22:09:31,124 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3:2(1) to node 1:3(0)
2016-01-13 22:09:31,124 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Database)"  with no errors
2016-01-13 22:09:31,124 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'variables_loop_db': Variables Loop (Database)
2016-01-13 22:09:31,124 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Iterate list of files/
2016-01-13 22:09:31,124 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Iterate list of files
2016-01-13 22:09:31,140 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Iterate list of files") is not locked
2016-01-13 22:09:31,140 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Iterate list of files" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,140 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:4
2016-01-13 22:09:31,140 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("TableRow To Variable Loop Start (#2)") is not locked
2016-01-13 22:09:31,140 : DEBUG : main : LoopStartVariableNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,156 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("Loop End (#3)") is not locked
2016-01-13 22:09:31,156 : DEBUG : main : LoopEndNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,156 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("File Reader (#4)") is not locked
2016-01-13 22:09:31,171 : DEBUG : main : FileReaderNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,171 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:2(1) to node 1:4:4(0)
2016-01-13 22:09:31,171 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:4(1) to node 1:4:3(1)
2016-01-13 22:09:31,171 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:3(1) to node 1:4(0)
2016-01-13 22:09:31,171 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4(0) to node 1:4:2(1)
2016-01-13 22:09:31,234 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Iterate list of files"  with no errors
2016-01-13 22:09:31,234 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'iterate_list_of_files': Iterate List of Files
2016-01-13 22:09:31,234 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Looper/
2016-01-13 22:09:31,234 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Looper
2016-01-13 22:09:31,234 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Looper") is not locked
2016-01-13 22:09:31,234 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Looper" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,249 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:5
2016-01-13 22:09:31,249 : DEBUG : main : FileNodeContainerMetaPersistor : Loop x-times : 1:5 : Workflow being loaded ("Counting Loop Start (#1)") is not locked
2016-01-13 22:09:31,249 : DEBUG : main : FileNodeContainerMetaPersistor : Loop x-times : 1:5 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 22:09:31,265 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:5:2(1) to node 1:5(0)
2016-01-13 22:09:31,265 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:5(0) to node 1:5:1(1)
2016-01-13 22:09:31,265 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Looper"  with no errors
2016-01-13 22:09:31,280 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'looper': Loop x-times
2016-01-13 22:09:31,280 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Boosting Learner/
2016-01-13 22:09:31,280 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Boosting Learner
2016-01-13 22:09:31,280 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Boosting Learner") is not locked
2016-01-13 22:09:31,280 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Learner" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,296 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:6
2016-01-13 22:09:31,296 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Boosting Learner Loop Start (#1)") is not locked
2016-01-13 22:09:31,312 : DEBUG : main : BoostingLearnerLoopStartNodeFactory : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,312 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Boosting Learner Loop End (#4)") is not locked
2016-01-13 22:09:31,312 : DEBUG : main : BoostingLearnerLoopEndNodeFactory : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,327 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Naive Bayes Learner (#7)") is not locked
2016-01-13 22:09:31,327 : DEBUG : main : NaiveBayesLearnerNodeFactory2 : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,327 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Naive Bayes Predictor (#8)") is not locked
2016-01-13 22:09:31,343 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,343 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:7(1) to node 1:6:4(1)
2016-01-13 22:09:31,343 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:1(1) to node 1:6:7(1)
2016-01-13 22:09:31,343 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:1(2) to node 1:6:8(2)
2016-01-13 22:09:31,343 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:4(1) to node 1:6(0)
2016-01-13 22:09:31,343 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:8(1) to node 1:6:4(2)
2016-01-13 22:09:31,343 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6(0) to node 1:6:1(1)
2016-01-13 22:09:31,343 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:7(1) to node 1:6:8(1)
2016-01-13 22:09:31,343 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Learner"  with no errors
2016-01-13 22:09:31,343 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.boosting_learner': Boosting Learner
2016-01-13 22:09:31,343 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Boosting Predictor/
2016-01-13 22:09:31,358 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Boosting Predictor
2016-01-13 22:09:31,358 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Boosting Predictor") is not locked
2016-01-13 22:09:31,358 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Predictor" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,358 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:7
2016-01-13 22:09:31,358 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Boosting Predictor Loop Start (#1)") is not locked
2016-01-13 22:09:31,374 : DEBUG : main : BoostingPredictorLoopStartNodeFactory : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,374 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Boosting Predictor Loop End (#3)") is not locked
2016-01-13 22:09:31,390 : DEBUG : main : BoostingPredictorLoopEndNodeFactory : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,390 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Naive Bayes Predictor (#4)") is not locked
2016-01-13 22:09:31,390 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,405 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:1(1) to node 1:7:4(1)
2016-01-13 22:09:31,405 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:4(1) to node 1:7:3(1)
2016-01-13 22:09:31,405 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7(1) to node 1:7:4(2)
2016-01-13 22:09:31,405 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:3(1) to node 1:7(0)
2016-01-13 22:09:31,405 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7(0) to node 1:7:1(1)
2016-01-13 22:09:31,405 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Predictor"  with no errors
2016-01-13 22:09:31,405 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.boosting_predictor': Boosting Predictor
2016-01-13 22:09:31,405 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Delegating/
2016-01-13 22:09:31,405 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Delegating
2016-01-13 22:09:31,421 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Delegating") is not locked
2016-01-13 22:09:31,421 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Delegating" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,421 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:8
2016-01-13 22:09:31,421 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Filter well (#61)") is not locked
2016-01-13 22:09:31,421 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Decision Tree Learner (#62)") is not locked
2016-01-13 22:09:31,436 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,436 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Recursive Loop Start (#63)") is not locked
2016-01-13 22:09:31,452 : DEBUG : main : RecursiveLoopStartNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,452 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Recursive Loop End (#64)") is not locked
2016-01-13 22:09:31,452 : DEBUG : main : RecursiveLoopEndNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,452 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("PMML Predictor (#65)") is not locked
2016-01-13 22:09:31,468 : DEBUG : main : PMMLPredictor2NodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,468 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Reference Column Filter (#66)") is not locked
2016-01-13 22:09:31,483 : DEBUG : main : ColumnFilterRefNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,483 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("PMML To Cell (#67)") is not locked
2016-01-13 22:09:31,499 : DEBUG : main : PMMLPortToCellNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:8:61
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8(0) to node 1:8:63(1)
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:62(1)
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:66(1) to node 1:8:64(2)
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:67(1) to node 1:8:64(1)
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:65(1) to node 1:8:61(0)
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:62(1) to node 1:8:67(1)
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:66(2)
2016-01-13 22:09:31,499 : DEBUG : main : Workflow :  :  : Triggering graph analysis on 1:8:61
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:65(2)
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:66(1)
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:62(1) to node 1:8:65(1)
2016-01-13 22:09:31,499 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:64(1) to node 1:8(0)
2016-01-13 22:09:31,514 : DEBUG : main : FileNodeContainerMetaPersistor : Filter well predicted rows : 1:8:61 : Workflow being loaded ("Joiner (#61)") is not locked
2016-01-13 22:09:31,514 : DEBUG : main : Joiner2NodeFactory : Filter well predicted rows : 1:8:61 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,530 : DEBUG : main : FileNodeContainerMetaPersistor : Filter well predicted rows : 1:8:61 : Workflow being loaded ("Reference Row Filter (#62)") is not locked
2016-01-13 22:09:31,546 : DEBUG : main : RowFilterRefNodeFactory : Filter well predicted rows : 1:8:61 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,546 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61:62(1) to node 1:8:61(0)
2016-01-13 22:09:31,546 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:62(1)
2016-01-13 22:09:31,546 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:61(1)
2016-01-13 22:09:31,546 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:61(2)
2016-01-13 22:09:31,546 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61:61(1) to node 1:8:61:62(2)
2016-01-13 22:09:31,561 : DEBUG : main : Workflow :  :  : Triggering graph analysis on 1:8:61
2016-01-13 22:09:31,577 : DEBUG : main : NodeContainer :  :  : Recursive Loop Start 1:8:63 has new state: IDLE
2016-01-13 22:09:31,577 : DEBUG : main : NodeContainer :  :  : Decision Tree Learner (deprecated) 1:8:62 has new state: IDLE
2016-01-13 22:09:31,577 : DEBUG : main : NodeContainer :  :  : PMML Predictor 1:8:65 has new state: IDLE
2016-01-13 22:09:31,577 : DEBUG : main : NodeContainer :  :  : PMML To Cell 1:8:67 has new state: IDLE
2016-01-13 22:09:31,577 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Delegating"  with warnings
2016-01-13 22:09:31,577 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.delegated_learning': Delegating
2016-01-13 22:09:31,577 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Bagging/
2016-01-13 22:09:31,577 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Bagging
2016-01-13 22:09:31,592 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Bagging") is not locked
2016-01-13 22:09:31,592 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Bagging" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,592 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:9
2016-01-13 22:09:31,592 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Model Loop End (#7)") is not locked
2016-01-13 22:09:31,608 : DEBUG : main : ModelLoopEndNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,608 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Model Loop Start (#8)") is not locked
2016-01-13 22:09:31,624 : DEBUG : main : ModelLoopStartNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,624 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Voting Loop End (#9)") is not locked
2016-01-13 22:09:31,639 : DEBUG : main : VotingLoopEndNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,639 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Chunk Loop Start (#12)") is not locked
2016-01-13 22:09:31,655 : DEBUG : main : LoopStartChunkNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,655 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Shuffle (#13)") is not locked
2016-01-13 22:09:31,655 : DEBUG : main : ShuffleNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,655 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Decision Tree Learner (#14)") is not locked
2016-01-13 22:09:31,670 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,670 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Decision Tree Predictor (#15)") is not locked
2016-01-13 22:09:31,670 : DEBUG : main : DecTreePredictorNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,670 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9(1) to node 1:9:15(2)
2016-01-13 22:09:31,686 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:13(1) to node 1:9:12(1)
2016-01-13 22:09:31,686 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:12(1) to node 1:9:14(1)
2016-01-13 22:09:31,686 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9(0) to node 1:9:13(1)
2016-01-13 22:09:31,686 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:9(1) to node 1:9(0)
2016-01-13 22:09:31,686 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:15(1) to node 1:9:9(1)
2016-01-13 22:09:31,686 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:8(1) to node 1:9:15(1)
2016-01-13 22:09:31,686 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:14(1) to node 1:9:7(1)
2016-01-13 22:09:31,686 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:7(1) to node 1:9:8(1)
2016-01-13 22:09:31,686 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Bagging"  with no errors
2016-01-13 22:09:31,686 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.bagging': Bagging
2016-01-13 22:09:31,686 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Seasonality Correction/
2016-01-13 22:09:31,686 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Seasonality Correction
2016-01-13 22:09:31,702 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Seasonality Correction") is not locked
2016-01-13 22:09:31,702 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Seasonality Correction" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,702 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:10
2016-01-13 22:09:31,702 : DEBUG : main : FileNodeContainerMetaPersistor : Seasonality Correction : 1:10 : Workflow being loaded ("Lag Column (#24)") is not locked
2016-01-13 22:09:31,717 : DEBUG : main : LagColumnNodeFactory : Seasonality Correction : 1:10 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,717 : DEBUG : main : FileNodeContainerMetaPersistor : Seasonality Correction : 1:10 : Workflow being loaded ("Java Snippet _simple_ (#25)") is not locked
2016-01-13 22:09:31,733 : DEBUG : main : JavaScriptingNodeFactory : Seasonality Correction : 1:10 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,733 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10:24(1) to node 1:10:25(1)
2016-01-13 22:09:31,733 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10:25(1) to node 1:10(0)
2016-01-13 22:09:31,733 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10(0) to node 1:10:24(1)
2016-01-13 22:09:31,733 : DEBUG : main : NodeContainer :  :  : Lag Column 1:10:24 has new state: IDLE
2016-01-13 22:09:31,733 : DEBUG : main : NodeContainer :  :  : Java Snippet (simple) 1:10:25 has new state: IDLE
2016-01-13 22:09:31,733 : DEBUG : main : NodeContainer :  :  : Seasonality Correction 1:10 has new state: IDLE
2016-01-13 22:09:31,733 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Seasonality Correction"  with warnings
2016-01-13 22:09:31,733 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'SeasonalityCorrection': Seasonality Correction
2016-01-13 22:09:31,733 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Time Series Auto-Prediction Training/
2016-01-13 22:09:31,748 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Time Series Auto-Prediction Training
2016-01-13 22:09:31,748 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Time Series Auto-Prediction Training") is not locked
2016-01-13 22:09:31,748 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Training" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,748 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:11
2016-01-13 22:09:31,764 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Partitioning (#147)") is not locked
2016-01-13 22:09:31,764 : DEBUG : main : PartitionNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,764 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Lag Column (#216)") is not locked
2016-01-13 22:09:31,764 : DEBUG : main : LagColumnNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,780 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Linear Regression Learner (#234)") is not locked
2016-01-13 22:09:31,780 : DEBUG : main : LinReg2LearnerNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,795 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:234(1) to node 1:11(0)
2016-01-13 22:09:31,795 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:234(2) to node 1:11(1)
2016-01-13 22:09:31,811 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11(0) to node 1:11:216(1)
2016-01-13 22:09:31,811 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:147(1) to node 1:11:234(1)
2016-01-13 22:09:31,811 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:216(1) to node 1:11:147(1)
2016-01-13 22:09:31,811 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:147(2) to node 1:11(2)
2016-01-13 22:09:31,826 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Training"  with no errors
2016-01-13 22:09:31,826 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'Time-SeriesAuto-PredictionTraining': Time-Series Auto-Prediction Training
2016-01-13 22:09:31,826 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Time Series Auto-Prediction Predictor/
2016-01-13 22:09:31,826 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Time Series Auto-Prediction Predictor
2016-01-13 22:09:31,826 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Time Series Auto-Prediction Predictor") is not locked
2016-01-13 22:09:31,826 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Predictor" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:09:31,842 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:12
2016-01-13 22:09:31,842 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Predictor : 1:12 : Workflow being loaded ("Numeric Scorer (#176)") is not locked
2016-01-13 22:09:31,842 : DEBUG : main : NumericScorerNodeFactory : Time Series Auto-Prediction Predictor : 1:12 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,858 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Predictor : 1:12 : Workflow being loaded ("Regression Predictor (#237)") is not locked
2016-01-13 22:09:31,873 : DEBUG : main : RegressionPredictorNodeFactory : Time Series Auto-Prediction Predictor : 1:12 : Factory is already initialized. Nothing to do.
2016-01-13 22:09:31,873 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12(1) to node 1:12:237(2)
2016-01-13 22:09:31,873 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:237(1) to node 1:12(0)
2016-01-13 22:09:31,873 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12(0) to node 1:12:237(1)
2016-01-13 22:09:31,873 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:237(1) to node 1:12:176(1)
2016-01-13 22:09:31,873 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:176(1) to node 1:12(1)
2016-01-13 22:09:31,889 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Predictor"  with no errors
2016-01-13 22:09:31,889 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'Time-SeriesAuto-PredictionPredictor': Time-Series Auto-Prediction Predictor
2016-01-13 22:09:32,107 : DEBUG : main : KNIMEEditorPlugin :  :  : Workflow SVG export not available, unable to instantiate "org.knime.workbench.editor.svgexport.exportservice.WorkflowSVGExportImpl"
2016-01-13 22:09:35,399 : ERROR : main : CategorySorter :  :  : CODING PROBLEM	After-ID 'toolintegration' of [Id: community Name: Community Nodes After-id: toolintegration] does not exist - in plug-in org.knime.base
2016-01-13 22:09:59,729 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".all" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:09:59,729 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".csv" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:09:59,729 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".csv.gz" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:09:59,729 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".pmml" registered for Node Factory: PMMLReaderNodeFactory.
2016-01-13 22:09:59,729 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".table" registered for Node Factory: ReadTableNodeFactory.
2016-01-13 22:09:59,729 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".tsv" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:09:59,729 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".txt" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:09:59,729 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".txt.gz" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:10:03,614 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ================= Starting testflow WorkflowTests\GitOfflineTest =================
2016-01-13 22:10:03,629 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ================= Average load: -1,00 =================
2016-01-13 22:10:03,629 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test load workflow -----------------
2016-01-13 22:10:03,645 : DEBUG : Worker-1 : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:10:03,661 : DEBUG : Worker-1 : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:10:03,676 : DEBUG : Worker-1 : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:10:03,739 : DEBUG : Worker-1 : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:10:03,754 : DEBUG : Worker-1 : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:10:03,785 : DEBUG : Worker-1 : DifferenceCheckerNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:10:03,801 : DEBUG : Worker-1 : WorkflowManager :  :  : Added new connection from node 0:2(1) to node 0:3(2)
2016-01-13 22:10:03,801 : DEBUG : Worker-1 : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:3(1)
2016-01-13 22:10:03,957 : DEBUG : Worker-1 : Git SCM : Git SCM : 0:1 : Configure succeeded. (Git SCM)
2016-01-13 22:10:03,957 : DEBUG : Worker-1 : Git SCM : Git SCM : 0:2 : Configure succeeded. (Git SCM)
2016-01-13 22:10:03,988 : DEBUG : Worker-1 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:10:03,988 : DEBUG : Worker-1 : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest"  with no errors
2016-01-13 22:10:04,113 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:10:04,144 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:10:04,347 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:10:04,347 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on 0 - GitOfflineTest
2016-01-13 22:10:04,347 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:10:04,706 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:10:04,815 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:10:04,815 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:10:04,831 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:1 (CONFIGURED) )
2016-01-13 22:10:04,987 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:10:04,987 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:10:04,987 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:2 (CONFIGURED) )
2016-01-13 22:10:05,002 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:10:05,002 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:10:05,002 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:3 (CONFIGURED) )
2016-01-13 22:10:05,002 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:10:05,002 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:10:05,002 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:10:05,002 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:10:06,484 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test load workflow -----------------
2016-01-13 22:10:06,484 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test open views -----------------
2016-01-13 22:10:06,484 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test open views -----------------
2016-01-13 22:10:06,484 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test execute workflow -----------------
2016-01-13 22:10:06,484 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on Git SCM 0:2
2016-01-13 22:10:06,484 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on GitOfflineTest 0
2016-01-13 22:10:06,484 : DEBUG : Worker-1 : NodeContainer :  :  : Git SCM 0:2 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:10:06,484 : DEBUG : Worker-1 : NodeContainer :  :  : Git SCM 0:2 has new state: CONFIGURED_QUEUED
2016-01-13 22:10:06,796 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on Git SCM 0:1
2016-01-13 22:10:06,843 : DEBUG : Worker-1 : NodeContainer :  :  : Git SCM 0:1 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:10:06,859 : DEBUG : Worker-1 : NodeContainer :  :  : Git SCM 0:1 has new state: CONFIGURED_QUEUED
2016-01-13 22:10:06,859 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on Table Difference Checker 0:3
2016-01-13 22:10:06,859 : DEBUG : Worker-1 : NodeContainer :  :  : Table Difference Checker 0:3 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:10:06,859 : DEBUG : Worker-1 : NodeContainer :  :  : GitOfflineTest 0 has new state: EXECUTING
2016-01-13 22:10:06,859 : DEBUG : Worker-1 : NodeContainer :  :  : ROOT  has new state: EXECUTING
2016-01-13 22:10:06,859 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:2 : Git SCM 0:2 doBeforePreExecution
2016-01-13 22:10:06,796 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=0;old=null;new=null;timestamp=2016-01-13 22:10:06]
2016-01-13 22:10:06,859 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : Git SCM 0:2 has new state: PREEXECUTE
2016-01-13 22:10:06,874 : DEBUG : KNIME-Worker-1 : WorkflowManager : Git SCM : 0:1 : Git SCM 0:1 doBeforePreExecution
2016-01-13 22:10:06,874 : DEBUG : KNIME-Worker-1 : NodeContainer : Git SCM : 0:1 : Git SCM 0:1 has new state: PREEXECUTE
2016-01-13 22:10:06,874 : DEBUG : KNIME-Worker-1 : WorkflowManager : Git SCM : 0:1 : Git SCM 0:1 doBeforeExecution
2016-01-13 22:10:06,874 : DEBUG : KNIME-Worker-1 : NodeContainer : Git SCM : 0:1 : Git SCM 0:1 has new state: EXECUTING
2016-01-13 22:10:06,890 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : Git SCM : 0:1 : Adding handler 61414310-d7d2-4784-870f-1662285a3ea3 (Git SCM 0:1: <no directory>) - 1 in total
2016-01-13 22:10:06,890 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : Git SCM : 0:1 : Git SCM 0:1 Start execute
2016-01-13 22:10:06,905 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:2 : Git SCM 0:2 doBeforeExecution
2016-01-13 22:10:06,905 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : Git SCM 0:2 has new state: EXECUTING
2016-01-13 22:10:06,905 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Git SCM : 0:2 : Adding handler 36b46ae5-c528-4f86-bc04-e88988d11b26 (Git SCM 0:2: <no directory>) - 2 in total
2016-01-13 22:10:06,905 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Git SCM : 0:2 : Git SCM 0:2 Start execute
2016-01-13 22:10:06,937 : INFO  : KNIME-Worker-1 : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Reading git logs from file file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/Git%20SCM%20(%231)/drop/git-test-log.txt
2016-01-13 22:10:07,030 : INFO  : KNIME-Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Reading git logs from file file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/Git%20SCM%20(%232)/drop/git-test-log.txt
2016-01-13 22:10:07,108 : INFO  : KNIME-Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Reading git logs finished
2016-01-13 22:10:07,171 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:10:07,171 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:10:07,202 : INFO  : KNIME-Worker-1 : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Reading git logs finished
2016-01-13 22:10:07,249 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:10:07,249 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitTableFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitTableFactory.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:10:07,249 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.test.org.impressivecode.depress.scm.git.GitTableFactoryTest, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/test/org/impressivecode/depress/scm/git/GitTableFactoryTest.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommit, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommit.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommitFile, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommitFile.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommitFileOperation, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommitFileOperation.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-base/src/org/impressivecode/depress/its/ITSAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.its.ITSAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-base/test/org/impressivecode/depress/its/ITSAdapterTransformerTest.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,264 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitTableFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitTableFactory.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.test.org.impressivecode.depress.scm.git.GitTableFactoryTest, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/test/org/impressivecode/depress/scm/git/GitTableFactoryTest.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommit, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommit.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommitFile, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommitFile.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommitFileOperation, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommitFileOperation.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-base/src/org/impressivecode/depress/its/ITSAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,280 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.its.ITSAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-base/test/org/impressivecode/depress/its/ITSAdapterTransformerTest.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,295 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,373 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,389 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,389 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,389 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,389 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,389 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,389 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSAdapterTableFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSDataType, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSDataType.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSPriority, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSPriority.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,467 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,483 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSResolution, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSResolution.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,483 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,483 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSStatus, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSStatus.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,483 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,483 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSType, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSType.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,483 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,498 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.its.ITSAdapterTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/test/org/impressivecode/depress/its/ITSAdapterTableFactoryTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,498 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,498 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,498 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,498 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,498 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,498 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,436 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSAdapterTableFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSDataType, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSDataType.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSPriority, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSPriority.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,545 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,561 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSResolution, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSResolution.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,561 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,561 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSStatus, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSStatus.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,561 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,561 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSType, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSType.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,639 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,779 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.its.ITSAdapterTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/test/org/impressivecode/depress/its/ITSAdapterTableFactoryTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,795 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,810 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,826 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeDialog.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,826 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,841 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeFactory.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,841 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,841 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeModel.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,841 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,841 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,841 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeDialog.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeFactory.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeModel.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTableFactory.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformer.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParser.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntry, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntry.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.test.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/test/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformerTest.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.test.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/test/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParserTest.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeDataTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeDataTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:07,857 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberDataTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberDataTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeData, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeDataTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeDataTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetric, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetric.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricProcessor, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricProcessor.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,888 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,904 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,904 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,904 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberDataTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberDataTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,904 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,904 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,904 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:07,904 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.test.org.impressivecode.depress.metric.po.PeopleOrganizationMetricProcessorTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/test/org/impressivecode/depress/metric/po/PeopleOrganizationMetricProcessorTest.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,904 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:07,935 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:08,029 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTableFactory.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformer.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParser.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntry, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntry.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.test.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/test/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformerTest.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.test.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/test/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParserTest.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:10:08,060 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeDataTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeDataTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberDataTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberDataTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeData, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeDataTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeDataTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,075 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetric, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetric.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:07,966 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.PluginApp, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/PluginApp.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:10:08,200 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,231 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberTransformer.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 907348573f0b3f74a644e962128cc2c855610239
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitTableFactory, extension=java, author=Sawek Kaposki, operation=ADDED, message=#12 Added class GitTableFactory with Input tables creating method. Methods which will generate output table is not created yet, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitTableFactory.java, commitDate=Mon Mar 04 22:29:44 CET 2013, commitID=907348573f0b3f74a644e962128cc2c855610239]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-checkstyle.src.org.impressivecode.depress.metric.checkstyle.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-checkstyle/src/org/impressivecode/depress/metric/checkstyle/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-findbug.src.org.impressivecode.depress.metric.findbug.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-findbug/src/org/impressivecode/depress/metric/findbug/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-pmd.src.org.impressivecode.depress.metric.pmd.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-pmd/src/org/impressivecode/depress/metric/pmd/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-common.src.org.impressivecode.depress.scm.common.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-scm-common/src/org/impressivecode/depress/scm/common/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 added PO Metric plugin draft, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.scm.SCMAdapterTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 added PO Metric plugin draft, path=ic-depress-base/test/org/impressivecode/depress/scm/SCMAdapterTableFactoryTest.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:10:08,247 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 added PO Metric plugin draft, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterTableFactory.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapterTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapterTableFactoryPluginTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: ef1d2453bf8587aec197ebd60f8d5260f3b02692
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Sat Mar 02 22:05:28 CET 2013, commitID=ef1d2453bf8587aec197ebd60f8d5260f3b02692]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeDialog.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyXmlResult, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyXmlResult.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,263 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeDialog.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#4 added progress, added tests, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b70ca05b7f982cf43d3f86e8a169a5c35ce46eed
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=Test added, #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Tue Feb 26 23:27:48 CET 2013, commitID=b70ca05b7f982cf43d3f86e8a169a5c35ce46eed]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b70ca05b7f982cf43d3f86e8a169a5c35ce46eed
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Test added, #4, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Tue Feb 26 23:27:48 CET 2013, commitID=b70ca05b7f982cf43d3f86e8a169a5c35ce46eed]
2016-01-13 22:10:08,278 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeDialog.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeFactory.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyXmlResult, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyXmlResult.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-pitest.src.org.impressivecode.depress.metric.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-pitest/src/org/impressivecode/depress/metric/pitest/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-judy.src.org.impressivecode.depress.metrics.judy.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-judy/src/org/impressivecode/depress/metrics/judy/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-pitest.src.org.impressivecode.depress.metrics.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-pitest/src/org/impressivecode/depress/metrics/pitest/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-data-anonymisation.src.org.impressivecode.depress.data.anonymization.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-data-anonymisation/src/org/impressivecode/depress/data/anonymization/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-data-source.src.org.impressivecode.depress.data.source.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-data-source/src/org/impressivecode/depress/data/source/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-judy.src.org.impressivecode.depress.metrics.judy.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-judy/src/org/impressivecode/depress/metrics/judy/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-pitest.src.org.impressivecode.depress.metrics.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-pitest/src/org/impressivecode/depress/metrics/pitest/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-common.src.org.impressivecode.depress.scm.common.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-common/src/org/impressivecode/depress/scm/common/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,294 : DEBUG : KNIME-Worker-1 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-svn.src.org.impressivecode.depress.scm.svn.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-svn/src/org/impressivecode/depress/scm/svn/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,309 : INFO  : KNIME-Worker-1 : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Transforming git logs finished.
2016-01-13 22:10:08,309 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : Git SCM : 0:1 : Git SCM 0:1 End execute (1 sec)
2016-01-13 22:10:08,309 : DEBUG : KNIME-Worker-1 : WorkflowManager : Git SCM : 0:1 : Git SCM 0:1 doBeforePostExecution
2016-01-13 22:10:08,356 : DEBUG : KNIME-Worker-1 : NodeContainer : Git SCM : 0:1 : Git SCM 0:1 has new state: POSTEXECUTE
2016-01-13 22:10:08,356 : DEBUG : KNIME-Worker-1 : WorkflowManager : Git SCM : 0:1 : Git SCM 0:1 doAfterExecute - success
2016-01-13 22:10:08,387 : DEBUG : KNIME-Worker-1 : NodeContainer : Git SCM : 0:1 : Git SCM 0:1 has new state: EXECUTED
2016-01-13 22:10:08,387 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricProcessor, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricProcessor.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberDataTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberDataTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,434 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.test.org.impressivecode.depress.metric.po.PeopleOrganizationMetricProcessorTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/test/org/impressivecode/depress/metric/po/PeopleOrganizationMetricProcessorTest.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,450 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,465 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,465 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,465 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,465 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,465 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:10:08,481 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.PluginApp, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/PluginApp.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:10:08,481 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:10:08,481 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:10:08,481 : DEBUG : KNIME-Worker-1 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:10:08,512 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:10:08,512 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:10:08,512 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:10:08,512 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:10:08,512 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:10:08,512 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberTransformer.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:10:08,528 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 907348573f0b3f74a644e962128cc2c855610239
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitTableFactory, extension=java, author=Sawek Kaposki, operation=ADDED, message=#12 Added class GitTableFactory with Input tables creating method. Methods which will generate output table is not created yet, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitTableFactory.java, commitDate=Mon Mar 04 22:29:44 CET 2013, commitID=907348573f0b3f74a644e962128cc2c855610239]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-checkstyle.src.org.impressivecode.depress.metric.checkstyle.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-checkstyle/src/org/impressivecode/depress/metric/checkstyle/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-findbug.src.org.impressivecode.depress.metric.findbug.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-findbug/src/org/impressivecode/depress/metric/findbug/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-pmd.src.org.impressivecode.depress.metric.pmd.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-pmd/src/org/impressivecode/depress/metric/pmd/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-common.src.org.impressivecode.depress.scm.common.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-scm-common/src/org/impressivecode/depress/scm/common/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 added PO Metric plugin draft, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.scm.SCMAdapterTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 added PO Metric plugin draft, path=ic-depress-base/test/org/impressivecode/depress/scm/SCMAdapterTableFactoryTest.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 added PO Metric plugin draft, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterTableFactory.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapterTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapterTableFactoryPluginTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: ef1d2453bf8587aec197ebd60f8d5260f3b02692
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Sat Mar 02 22:05:28 CET 2013, commitID=ef1d2453bf8587aec197ebd60f8d5260f3b02692]
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,543 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,559 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,559 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,559 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,653 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,684 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,684 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeDialog.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,699 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,715 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,715 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,715 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,715 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,715 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,715 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,715 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyXmlResult, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyXmlResult.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,715 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,715 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeDialog.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#4 added progress, added tests, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b70ca05b7f982cf43d3f86e8a169a5c35ce46eed
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=Test added, #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Tue Feb 26 23:27:48 CET 2013, commitID=b70ca05b7f982cf43d3f86e8a169a5c35ce46eed]
2016-01-13 22:10:08,731 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b70ca05b7f982cf43d3f86e8a169a5c35ce46eed
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Test added, #4, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Tue Feb 26 23:27:48 CET 2013, commitID=b70ca05b7f982cf43d3f86e8a169a5c35ce46eed]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeDialog.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeFactory.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyXmlResult, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyXmlResult.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-pitest.src.org.impressivecode.depress.metric.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-pitest/src/org/impressivecode/depress/metric/pitest/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-judy.src.org.impressivecode.depress.metrics.judy.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-judy/src/org/impressivecode/depress/metrics/judy/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-pitest.src.org.impressivecode.depress.metrics.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-pitest/src/org/impressivecode/depress/metrics/pitest/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-data-anonymisation.src.org.impressivecode.depress.data.anonymization.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-data-anonymisation/src/org/impressivecode/depress/data/anonymization/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-data-source.src.org.impressivecode.depress.data.source.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-data-source/src/org/impressivecode/depress/data/source/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-judy.src.org.impressivecode.depress.metrics.judy.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-judy/src/org/impressivecode/depress/metrics/judy/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-pitest.src.org.impressivecode.depress.metrics.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-pitest/src/org/impressivecode/depress/metrics/pitest/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-common.src.org.impressivecode.depress.scm.common.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-common/src/org/impressivecode/depress/scm/common/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:10:08,746 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-svn.src.org.impressivecode.depress.scm.svn.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-svn/src/org/impressivecode/depress/scm/svn/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:10:08,762 : INFO  : KNIME-Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Transforming git logs finished.
2016-01-13 22:10:08,762 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Git SCM : 0:2 : Git SCM 0:2 End execute (1 sec)
2016-01-13 22:10:08,762 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:2 : Git SCM 0:2 doBeforePostExecution
2016-01-13 22:10:08,762 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : Git SCM 0:2 has new state: POSTEXECUTE
2016-01-13 22:10:08,762 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:2 : Git SCM 0:2 doAfterExecute - success
2016-01-13 22:10:08,762 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : Git SCM 0:2 has new state: EXECUTED
2016-01-13 22:10:08,793 : DEBUG : KNIME-Worker-0 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:10:08,793 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : Table Difference Checker 0:3 has new state: CONFIGURED_QUEUED
2016-01-13 22:10:08,793 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePreExecution
2016-01-13 22:10:08,793 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: PREEXECUTE
2016-01-13 22:10:08,793 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforeExecution
2016-01-13 22:10:08,793 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTING
2016-01-13 22:10:08,840 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Adding handler af1466b0-3c70-47c6-b3c2-3f3b42415912 (Table Difference Checker 0:3: <no directory>) - 3 in total
2016-01-13 22:10:08,855 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 Start execute
2016-01-13 22:10:08,949 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 End execute (0 secs)
2016-01-13 22:10:08,949 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePostExecution
2016-01-13 22:10:08,949 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: POSTEXECUTE
2016-01-13 22:10:08,949 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doAfterExecute - success
2016-01-13 22:10:08,949 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTED
2016-01-13 22:10:08,949 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : GitOfflineTest 0 has new state: EXECUTED
2016-01-13 22:10:08,949 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test execute workflow -----------------
2016-01-13 22:10:08,949 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test node messages -----------------
2016-01-13 22:10:08,949 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test node messages -----------------
2016-01-13 22:10:08,949 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test hilite rows -----------------
2016-01-13 22:10:08,965 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test hilite rows -----------------
2016-01-13 22:10:08,965 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test close views -----------------
2016-01-13 22:10:08,965 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test close views -----------------
2016-01-13 22:10:08,965 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test log messages -----------------
2016-01-13 22:10:08,980 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test log messages -----------------
2016-01-13 22:10:08,980 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test uncaught exceptions -----------------
2016-01-13 22:10:09,011 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test uncaught exceptions -----------------
2016-01-13 22:10:09,027 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:10:10,103 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ===== Memory statistics: 994,000 MB max, 55,233 MB used, 938,767 MB free ====
2016-01-13 22:10:10,103 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ================= Finished testflow WorkflowTests\GitOfflineTest =================
2016-01-13 22:10:10,119 : DEBUG : Service Thread : MemoryAlertSystem :  :  : Memory usage below threshold of 0.7125915080527087 after GC run
2016-01-13 22:10:10,653 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:10:10,669 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:10:10,700 : DEBUG : Worker-1 : WorkflowManager :  :  : Removing project "GitOfflineTest 0"
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Removing handler af1466b0-3c70-47c6-b3c2-3f3b42415912 (Table Difference Checker 0:3: <no directory>) - 2 remaining
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : DifferenceCheckerNodeModel : Table Difference Checker : 0:3 : Removing all (0) views from model.
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : WorkflowFileStoreHandlerRepository : Git SCM : 0:2 : Removing handler 36b46ae5-c528-4f86-bc04-e88988d11b26 (Git SCM 0:2: <no directory>) - 1 remaining
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Removing all (0) views from model.
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : Git SCM : Git SCM : 0:2 : clean output ports.
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : WorkflowFileStoreHandlerRepository : Git SCM : 0:1 : Removing handler 61414310-d7d2-4784-870f-1662285a3ea3 (Git SCM 0:1: <no directory>) - 0 remaining
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Removing all (0) views from model.
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : Git SCM : Git SCM : 0:1 : clean output ports.
2016-01-13 22:10:10,809 : DEBUG : Worker-1 : WorkflowManager :  :  : Project "GitOfflineTest 0" removed (1 remaining)
2016-01-13 22:10:10,809 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ================= Starting testflow WorkflowTests\JiraOfflineTest =================
2016-01-13 22:10:10,809 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ================= Average load: -1,00 =================
2016-01-13 22:10:10,825 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test load workflow -----------------
2016-01-13 22:10:10,825 : DEBUG : Worker-1 : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:10:10,856 : DEBUG : Worker-1 : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:10:10,872 : DEBUG : Worker-1 : JiraAdapterNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:10:10,887 : DEBUG : Worker-1 : JiraAdapterNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:10:10,903 : DEBUG : Worker-1 : DifferenceCheckerNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:10:10,903 : DEBUG : Worker-1 : WorkflowManager :  :  : Added new connection from node 0:2(1) to node 0:3(2)
2016-01-13 22:10:10,903 : DEBUG : Worker-1 : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:3(1)
2016-01-13 22:10:10,919 : DEBUG : Worker-1 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:10:10,919 : DEBUG : Worker-1 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:10:10,919 : DEBUG : Worker-1 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:10:10,919 : DEBUG : Worker-1 : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest"  with no errors
2016-01-13 22:10:10,981 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:10:10,981 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:10:11,028 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:10:11,028 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on 0 - JiraOfflineTest
2016-01-13 22:10:11,028 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:10:11,090 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:10:11,090 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:10:11,090 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:10:11,090 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 0:1 (CONFIGURED) )
2016-01-13 22:10:11,106 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:10:11,106 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:10:11,106 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 0:2 (CONFIGURED) )
2016-01-13 22:10:11,106 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:10:11,106 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:10:11,106 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:3 (CONFIGURED) )
2016-01-13 22:10:11,121 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:10:11,121 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:10:11,121 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:10:11,121 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:10:11,844 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test load workflow -----------------
2016-01-13 22:10:11,844 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test open views -----------------
2016-01-13 22:10:11,844 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test open views -----------------
2016-01-13 22:10:11,844 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test execute workflow -----------------
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on Jira Adapter (Offline) 0:2
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on JiraOfflineTest 0
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : Jira Adapter (Offline) 0:2 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : Jira Adapter (Offline) 0:2 has new state: CONFIGURED_QUEUED
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on Jira Adapter (Offline) 0:1
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : Jira Adapter (Offline) 0:1 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : Jira Adapter (Offline) 0:1 has new state: CONFIGURED_QUEUED
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : Setting dirty flag on Table Difference Checker 0:3
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : Table Difference Checker 0:3 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:10:11,844 : DEBUG : Worker-1 : NodeContainer :  :  : JiraOfflineTest 0 has new state: EXECUTING
2016-01-13 22:10:11,859 : DEBUG : Worker-1 : NodeContainer :  :  : ROOT  has new state: EXECUTING
2016-01-13 22:10:11,891 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 doBeforePreExecution
2016-01-13 22:10:11,891 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: PREEXECUTE
2016-01-13 22:10:11,891 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 doBeforeExecution
2016-01-13 22:10:12,000 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: EXECUTING
2016-01-13 22:10:12,031 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:2 : Adding handler 8c21a786-a673-485c-b8de-3becfc0a13c1 (Jira Adapter (Offline) 0:2: <no directory>) - 1 in total
2016-01-13 22:10:12,031 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 Start execute
2016-01-13 22:10:12,031 : INFO  : KNIME-Worker-1 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:2 : Preparing to read jira entries.
2016-01-13 22:10:12,047 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doBeforePreExecution
2016-01-13 22:10:12,047 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: PREEXECUTE
2016-01-13 22:10:12,062 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doBeforeExecution
2016-01-13 22:10:12,062 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: EXECUTING
2016-01-13 22:10:12,062 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:1 : Adding handler 93835152-8d52-4ae6-bc44-8e95dab6448a (Jira Adapter (Offline) 0:1: <no directory>) - 2 in total
2016-01-13 22:10:12,062 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 Start execute
2016-01-13 22:10:12,078 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=0;old=null;new=null;timestamp=2016-01-13 22:10:11]
2016-01-13 22:10:12,062 : INFO  : KNIME-Worker-0 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:1 : Preparing to read jira entries.
2016-01-13 22:10:13,809 : INFO  : KNIME-Worker-0 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:1 : Transforming to jira entries.
2016-01-13 22:10:13,809 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-724
2016-01-13 22:10:13,809 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-724, created=Mon Dec 12 16:03:41 CET 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Tue Dec 20 22:14:16 CET 2011, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=RandomDataImpl.nextInt does not distribute uniformly for negative lower bound, link=https://issues.apache.org/jira/browse/MATH-724, description=&lt;p&gt;When using the RandomDataImpl.nextInt function to get a uniform sample in a &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt; interval, when the lower value is less than zero, the output is not uniformly distributed, as the lowest value is practically never returned.&lt;/p&gt;

&lt;p&gt;See the attached NextIntUniformTest.java file. It uses a &lt;span class="error"&gt;&amp;#91;-3, 5&amp;#93;&lt;/span&gt; interval. For several values between 0 and 1, testNextIntUniform1 prints the return value of RandomDataImpl.nextInt (as double and as int). We see that -2 through 5 are returned several times. The -3 value however, is only returned for 0.0, and is thus under-respresented in the integer samples. The output of test method testNextIntUniform2 also clearly shows that value -3 is never sampled.&lt;/p&gt;, comments=[&lt;p&gt;NextIntUniformTest.java: see issue description&lt;/p&gt;
, &lt;p&gt;Thanks for reporting this. The problem is in the rounding, which does not work correctly for negative values.  My first inclination is to test for negative lower bound and just shift the interval in that case.  Any better ideas?&lt;/p&gt;
, &lt;p&gt;math-724.patch: it first scales the [0..1) interval to [0..length), then discretizes it, and finally shifts it to &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;It may be a good idea to also add some tests for cases such as &lt;span class="error"&gt;&amp;#91;0,3&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-5, -3&amp;#93;&lt;/span&gt;, and see if the distribution of sampled values is uniform. It seems RandomDataTest.testNextInt does this using chiSquare, but since I'm not familiar with that, I'm not sure how to add more tests for the other lower/upper bound pairs...&lt;/p&gt;
, &lt;p&gt;I just ran the unit tests with my patch applied, an the following test, in RandomDataTest:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;@Test
    &lt;span class="code-keyword"&gt;public&lt;/span&gt; void testNextIntExtremeValues() {
        &lt;span class="code-object"&gt;int&lt;/span&gt; x = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        &lt;span class="code-object"&gt;int&lt;/span&gt; y = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        Assert.assertFalse(x == y);
    }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails, as does testNextLongExtremeValues. Both x and y become equal to Integer.MIN_VALUE, making x == y to become true, causing the assertion to fail...&lt;/p&gt;
, &lt;p&gt;Also note that RandomDataImpl.nextUniform uses a similar scale/shift method to transform the range. It may thus suffer from the same failure in case of extreme values...&lt;/p&gt;
, &lt;p&gt;math-724-v2.patch: 2nd patch.&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;I think all unit tests work now, including the ones for the Integer.MIN_VALUE to Integer.MAX_VALUE interval.&lt;/li&gt;
	&lt;li&gt;The original problem was that negative values were rounded up by the conversion from double to int, while positive numbers were rounded down. By using floor, we first round the numbers down, and then convert to integer, thus ensuring a proper uniform distribution.&lt;/li&gt;
	&lt;li&gt;Test cases for negative values are still missing... Could someone else add them?&lt;/li&gt;
	&lt;li&gt;RandomDataImpl.nextUniform: I haven't changed this, as the change that I used for integers does not have the desired effect for doubles... This may be caused by the fact that Double.MIN_VALUE is more negative than Double.MAX_VALUE is positive, but I'm not really sure. Maybe it is not even an issue for the nextUniform method?&lt;/li&gt;
&lt;/ul&gt;

, &lt;blockquote&gt;&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; the fact that Double.MIN_VALUE is more negative &lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="http://docs.oracle.com/javase/6/docs/api/java/lang/Double.html#MIN_VALUE"&gt;Double.Min_VALUE&lt;/a&gt; is a &lt;em&gt;positive&lt;/em&gt; number.&lt;/p&gt;
, &lt;blockquote&gt;&lt;p&gt;Double.Min_VALUE is a positive number.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops...&lt;/p&gt;

&lt;p&gt;OK, I uploaded a third version of the patch (math-724-v3.patch), which also applies the new formula for nextUniform. I included two test files (NextUniformTest3.java and NextIntTest3.java), that show the results for nextInt and nextUniform, for both the old and new formulas. As for as I can see, the new formula works equally well or better in all cases. Also, all existing unit tests pass.&lt;/p&gt;
, &lt;p&gt;Thanks for reporting and diagnosing this, Dennis.&lt;/p&gt;

&lt;p&gt;Slightly modified version of the third patch (just removing unecessary parens), along with tests, committed in r1221490.  The "negativeToPositiveRange" tests fail before the fix.  The change to nextUniform is also needed to prevent overflows. I changed the relevant test cases to use the TestUtils chisquare test, which is more straightforward and has better output.  This was added after the original versions of these tests were written.  Others in this class should be similarly updated.  Patches welcome to further tidy the tests, but this issue can be resolved.&lt;/p&gt;
], resolution=Fixed, reporter=dhendriks, assignees=[], commentAuthors=[dhendriks, psteitz, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,887 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-723
2016-01-13 22:10:13,887 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-723, created=Sun Dec 11 22:03:37 CET 2011, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Sun Dec 11 22:59:41 CET 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=BitStreamGenerators (MersenneTwister, Well generators) do not clear normal deviate cache on setSeed, link=https://issues.apache.org/jira/browse/MATH-723, description=&lt;p&gt;The BitStream generators generate normal deviates (for nextGaussian) in pairs, caching the last value generated. When reseeded, the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1213087.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,903 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-719
2016-01-13 22:10:13,903 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-719, created=Tue Dec 06 18:07:24 CET 2011, updated=Sat Mar 24 17:16:38 CET 2012, resolved=Mon Jan 23 12:28:07 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[], priority=Minor, summary=Strange deprecations in API, link=https://issues.apache.org/jira/browse/MATH-719, description=&lt;p&gt;Sorry if this doesn't belong here. I couldn't find any sort of mailing list or other feedback mechanism on the website.&lt;/p&gt;

&lt;p&gt;RealMatrix has some very odd deprecations. In particular inverse(), getDeterminant() and isSingular(). The last has the message:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Deprecated. as of release 2.0, replaced by the boolean negation of new LUDecompositionImpl(m).getSolver().isNonSingular()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's an implementation, not an interface. The whole point of having an interface is that &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I can query whether a matrix is singular withou having to know about LUDecompositions&lt;/li&gt;
	&lt;li&gt;You guys can change the implementation of isSingular() if something better pops up without us guys having to change our code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I'm not using these methods now, because they're deprecated, but I've basically recreated them in as static methods in a utility class. Wouldn't it be much better to just put code from the deprecation message into the method and remove the deprecation?&lt;/p&gt;, comments=[&lt;blockquote&gt;&lt;p&gt;Sorry if this doesn't belong here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Indeed, you'd better bring this kind of issue to the "dev" ML. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
The more so that there have been recent discussions about changing the matrix API and decisions ought to be made quite soon now.&lt;/p&gt;
, &lt;p&gt;Ah, so there is a mailing list. I guess I should have looked a little harder. I'll bring it up there.&lt;/p&gt;
, &lt;p&gt;It is unlikely that we can come up with a new design before the release of v3.0.&lt;br/&gt;
This must be thoroughly discussed first on the "dev" ML, together with other matrix interface issues.&lt;/p&gt;
], resolution=Unknown, reporter=pbloem, assignees=[], commentAuthors=[erans, pbloem], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,903 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-692
2016-01-13 22:10:13,903 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-692, created=Tue Oct 18 20:01:57 CEST 2011, updated=Sat Mar 24 17:16:26 CET 2012, resolved=Thu Feb 02 07:45:59 CET 2012, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 1.3
, 2.0
, 2.1
, 2.2
, 2.2.1
, 3.0
], fixVersion=[3.0
], priority=Minor, summary=Cumulative probability and inverse cumulative probability inconsistencies, link=https://issues.apache.org/jira/browse/MATH-692, description=&lt;p&gt;There are some inconsistencies in the documentation and implementation of functions regarding cumulative probabilities and inverse cumulative probabilities. More precisely, '&amp;lt;' and '&amp;lt;=' are not used in a consistent way.&lt;/p&gt;

&lt;p&gt;Besides I would move the function inverseCumulativeProbability(double) to the interface Distribution. A true inverse of the distribution function does neither exist for Distribution nor for ContinuosDistribution. Thus we need to define the inverse in terms of quantiles anyway, and this can already be done for Distribution.&lt;/p&gt;

&lt;p&gt;On the whole I would declare the (inverse) cumulative probability functions in the basic distribution interfaces as follows:&lt;/p&gt;

&lt;p&gt;Distribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(double x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(double x0, double x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1)&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;inverseCumulativeProbability(double p):&lt;br/&gt;
  returns the quantile function inf{x in R | P(X&amp;lt;=x) &amp;gt;= p} &lt;span class="error"&gt;&amp;#91;see also 2), 3), and 4)&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1) An aternative definition could be P(x0 &amp;lt;= X &amp;lt;= x1). But this requires to put the function probability(double x) or another cumulative probability function into the interface Distribution in order be able to calculate P(x0 &amp;lt;= X &amp;lt;= x1) in AbstractDistribution.&lt;br/&gt;
2) This definition is stricter than the definition in ContinuousDistribution, because the definition there does not specify what to do if there are multiple x satisfying P(X&amp;lt;=x) = p.&lt;br/&gt;
3) A modification could be defined for p=0: Returning sup{x in R | P(X&amp;lt;=x) = 0} would yield the infimum of the distribution's support instead of a mandatory -infinity.&lt;br/&gt;
4) This affects issue &lt;a href="https://issues.apache.org/jira/browse/MATH-540" title="AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug"&gt;&lt;del&gt;MATH-540&lt;/del&gt;&lt;/a&gt;. I'd prefere the definition from above for the following reasons:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;This definition simplifies inverse transform sampling (as mentioned in the other issue).&lt;/li&gt;
	&lt;li&gt;It is the standard textbook definition for the quantile function.&lt;/li&gt;
	&lt;li&gt;For integer distributions it has the advantage that the result doesn't change when switching to "x in Z", i.e. the result is independent of considering the intergers as sole set or as part of the reals.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ContinuousDistribution:&lt;br/&gt;
nothing to be added regarding (inverse) cumulative probability functions&lt;/p&gt;

&lt;p&gt;IntegerDistribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(int x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(int x0, int x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1) above&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;, comments=[&lt;p&gt;Thanks for raising this issue, Christian - especially now as we finalize the 3.0 API.&lt;/p&gt;

&lt;p&gt;I am +1 for these changes.  I agree that the inf-based definition of inverse cum is more standard and we are in a position now make the change, so I say lets do it.  I am also +1 on the move of this up to the distribution interface.  The reason we did not include it there originally was that we thought we might implement distributions for which we could not define inverses.  That has not happened in the last 8 years, so I think its safe enough to push it up.&lt;/p&gt;

&lt;p&gt;The code, test, user guide and doc changes for this have to be done carefully.  Patches most welcome.&lt;/p&gt;

&lt;p&gt;Is everyone else OK with this change?&lt;/p&gt;
, &lt;p&gt;I have neither used nor developed this part of CM, so my view on this is of but little value. Having said that, anything improving consistency can only be desirable, especially at this stage. So I'm all for it, and will be soon available (when I'm done on SYMMLQ) for an (novice on these issues) help.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;+1&lt;/p&gt;
, &lt;p&gt;Thanks for the feedback to all. Sbastien, thanks for offering your help. If you like and find time for it, you could implement AbstractDistribution.inverseCumulativeProbability(double p).&lt;/p&gt;

&lt;p&gt;I will provide some patches next week, but adjusting AbstractContinuousDistribution.inverseCumulativeProbability(double p) will take some more time.&lt;/p&gt;

&lt;p&gt;After thinking a little more about the structure of the interfaces, I'd like to put the function probability(double x) to Distribution anyway (independently of the thought in point 1) above).&lt;/p&gt;

&lt;p&gt;Are there any preferences on P(x0 &amp;lt;= X &amp;lt;= x1) or P(x0 &amp;lt; X &amp;lt;= x1) for cumulativeProbability(double x0, double x1)?&lt;/p&gt;
, &lt;p&gt;I am not sure it is really makes sense to add probability(double x) to the Distribution interface.  It would have to be defined as density (referring to the distribution function) to make sense in the continuous case, since defined as p(X = x) it would in most cases be identically 0 for continuous distributions.&lt;/p&gt;

&lt;p&gt;Regarding the cum definition, I am fine with P(x0 &amp;lt; X &amp;lt;= x1).&lt;/p&gt;
, &lt;p&gt;Happy to help on the inverse cumulative probability. You will have to be patient and forgieving with me, though, as I discover this part of CM.&lt;/p&gt;

&lt;p&gt;As for the definition, I think that one of the bounds should be excluded, so that these cumulative probabilities can be summed&lt;br/&gt;
P(a &amp;lt; X &amp;lt;= c) = P(a &amp;lt; X &amp;lt;= b) + P(b &amp;lt; X &amp;lt;= c),&lt;br/&gt;
even in the case of discrete PDFs.&lt;/p&gt;

&lt;p&gt;Whether the lower or upper bound should be excluded is another matter. I usually work with continuous pdfs, so I don't know if there is a common practice in the probability community. If there is none, I would tend to chose the following definition&lt;br/&gt;
P(x0 &amp;lt;= X &amp;lt; x1)&lt;br/&gt;
(sorry Phil!), because it would be consistent with the way things are usually indexed in java (a&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;.. a&lt;span class="error"&gt;&amp;#91;a.length-1&amp;#93;&lt;/span&gt;). See also &lt;tt&gt;org.apache.commons.math.util.MultidimensionalCounter&lt;/tt&gt;. Although this type of consistency is not an absolute requirement, I think it is nice for the user to have such simple principle: "lower bound always included, upper bound always excluded". Appart from this small point, I really have no objection to any choice.&lt;/p&gt;
, &lt;p&gt;Have a look at the default implementation of cum(x0,x1) now in AbstractDistribution.  I think the incorrectness in the documentation there may have been what triggered Christian to raise this issue.  The equation cum(a,b) = F(b) - F(a) where F is the distribution function is natural and what the impl there is trying to do.  In the discrete case, this equation fails, however, unless you define the cum to exclude the &lt;b&gt;lower&lt;/b&gt; endpoint.  That's why P(x0 &amp;lt; X &amp;lt;= x1) is a better definition.&lt;/p&gt;
, &lt;p&gt;OK, Phil, it makes perfect sense.&lt;/p&gt;
, &lt;p&gt;Good, the definition of cum(x0,x1) will be P(x0 &amp;lt; X &amp;lt;= x1). Phil, you are right: cum(x0,x1) in AbstractDistribution was a reason for raising this issue. Another reason was cum(int x0, int x1) in AbstractIntegerDistribution.&lt;/p&gt;

&lt;p&gt;The idea behind probability(double x) is in fact to define it as p(X = x) and to return 0 for continuous distributions. This function would be useful for discrete distributions not inheriting from IntergerDistribution and for distributions being composed of discrete and continuous parts.&lt;/p&gt;
, &lt;p&gt;I guess I am OK with pushing p&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/error.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt; up.  See related post to follow in commons-dev. &lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
I've started looking into this issue. As I said, you will have to be patient with me &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;.&lt;br/&gt;
I can see there already is a default implementation of &lt;tt&gt;AbstractContinuousDistribution.inverseCumulativeProbability&lt;/tt&gt;. So what exactly would you like me to do? Is this implementation fragile? Would you like me to improve robustness? Provide full testing?&lt;/p&gt;

&lt;p&gt;I think there might be issues when the PDF falls down to zero in a range (in which case the cum exhibits a plateau). The returned value might differ from the mathematical definition you proposed. Is this what you want me to work on? Have you already identified other issues?&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;

&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;

&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;

&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;
, &lt;p&gt;Another point for discussion:&lt;br/&gt;
I'd like to introduce&lt;br/&gt;
getDomainBracket(double p): returns double[]&lt;br/&gt;
to AbstractDistribution as helper function for inverseCumulativeProbability. This allows to avoid searching a bracket where a bracket can be specified directly.&lt;br/&gt;
The function getDomainBracket could be made abstract (which means to remove getInitialDomain, getDomainLowerBound, and getDomainUpperBound as these functions aren't needed any more), or it could have a default implementation (according to the corresponding part of the current implementation of inverseCumulativeProbability) which uses getInitialDomain, getDomainLowerBound, and getDomainUpperBound. However, getInitialDomain, getDomainLowerBound, and getDomainUpperBound should not be abstract in the latter case. Otherwise a derived class would be forced to implement something it potentially doesn't use. Thus the functions getInitialDomain, getDomainLowerBound, and getDomainUpperBound should have default implementations which either return default values (0, -infinity, +infinity) or throw an exception saying something like "has to be implemented".&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I'm working on it...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, for now, I'm concentrating on making the current impl in &lt;tt&gt;AbstractContinuousDistribution&lt;/tt&gt; more robust. The other impl should be easier.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current implementation uses a Brent solver. I think the solver itself is only one side of the issue. The other point is the algorithm used to bracket the solution, in order to ensure that the result is consistent with the definition of the cumprob. As for the &lt;tt&gt;DifferentiableUnivariateRealSolver&lt;/tt&gt;, I'm not too sure. I guess it depends on what is meant by "continuous distribution". For me, it means that the random variable takes values in a continuous set, and possibly its distribution is defined by a density. However, in my view, nothing prevents occurences of Dirac functions, in which case the cum sum is only piecewise C1. It's all a matter of definition, of course, and I'll ask the question on the forum to check whether or not people want to allow for such a situation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I'm very interested.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Please note that &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt; has been created specifically to handle plateaux.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;Here is the first patch for this issue (unfortunately with some delay). It adjusts the distributions with real domain to the definitions in this issue, and it mainly changes documentations.&lt;/p&gt;

&lt;p&gt;I could not move inverseCumulativeProbability(double) up to Distribution because there would be a conflict with IntegerDistribution.inverseCumulativeProbability(double): This method returns int. This problem will be removed by solving issue &lt;a href="https://issues.apache.org/jira/browse/MATH-703" title="Splitting up the distribution hierarchy"&gt;&lt;del&gt;MATH-703&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The implementation of inverseCumulativeProbability(double) is not changed as Sbastien is working on this.&lt;/p&gt;

&lt;p&gt;I will provide the patch for the integer distributions as soon as I have adjusted the test data to the new inequalities and reverified the adjusted test data.&lt;/p&gt;
, &lt;p&gt;All,&lt;br/&gt;
since I'm already working on this package, I'm happy to commit the patch on behalf of Christian. However, since I'm a relatively new committer, I would feel more confident if one of the "old, wise committers" could double check the svn log afterwards.&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hey, that's how it always works &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;  &lt;/p&gt;

&lt;p&gt;I don't know about "wise" but I certainly qualify as "old" by any standard, so will have a look once you have reviewed and committed.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
, &lt;p&gt;Patch &lt;tt&gt;Math-692_realDomain_patch1.patch&lt;/tt&gt; (20111108) applied in rev 1200179, with minor modifications (mostly checkstyle fixes).&lt;br/&gt;
Thanks Christian!&lt;/p&gt;
, &lt;p&gt;As mentioned by Sbastien in &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt;, the implementation of &lt;tt&gt;IntegerDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; can benefit from the ideas which came up for &lt;tt&gt;RealDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; in that thread.&lt;/p&gt;

&lt;p&gt;Thus I will remove &lt;tt&gt;getDomainLowerBound(double p)&lt;/tt&gt; and &lt;tt&gt;getDomainUpperBound(double p)&lt;/tt&gt; from the integer distributions. I checked that all current implementations of the lower/upper bound methods provide the whole support of the distribution as starting bracket. This means that using &lt;tt&gt;getSupportLowerBound()&lt;/tt&gt; and &lt;tt&gt;getSupportUpperBound()&lt;/tt&gt; for the starting bracket won't degrade the performance of the current distribution implementations. However, a user might want the improve the performance of his distribution implementations by providing a more targeted starting bracket for probability &lt;tt&gt;p&lt;/tt&gt;. Thus I will swap the solving step to a protected function &lt;tt&gt;solveInverseCumulativeProbability(double p, int lower, int upper)&lt;/tt&gt;, so that it gets easy to override &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; with an implementation which finds a better starting bracket.&lt;/p&gt;

&lt;p&gt;Furthermore, Phil's idea with Chebyshev's inequality can be applied to the generic implementation of &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; in order to get a better starting bracket.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
If you agree with that, I suggest that you also take care of &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;, as the two issues seem to be very much connected.&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;my changes in the integer distributions don't solve &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;. Instead I found a probably related problem with the Pascal distribution.&lt;/p&gt;

&lt;p&gt;The integer distribution patch for this issue still isn't ready. I will provide it next week.&lt;/p&gt;

&lt;p&gt;Christian&lt;/p&gt;
, &lt;p&gt;This is the patch which adjusts the integer distributions to the agreements above.&lt;/p&gt;

&lt;p&gt;The changes to the test cases for the random generators may be unexpected. But these changes initially were triggered by adjusting &lt;tt&gt;RandomDataTest.checkNextPoissonConsistency(double)&lt;/tt&gt; to the new contract for integer distributions. Then some random generator tests failed due to chance. While adjusting their seeds, I found some other tests with a high failure probability. Thus I also set some failure probabilities to 0.01 in order to find suitable seeds more quickly.&lt;/p&gt;

&lt;p&gt;My next task on this issue is to adjust the user guid.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
thanks for this contribution. I am away for a few days, but am very happy to commit this patch as soon as I am back, if you are not in too much of a hurry.&lt;br/&gt;
Thanks again,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Well, we've recently run into some troubles with SVN, but it seems everything is working fine again. Patch {{&lt;a href="https://issues.apache.org/jira/browse/MATH-692" title="Cumulative probability and inverse cumulative probability inconsistencies"&gt;&lt;del&gt;MATH-692&lt;/del&gt;&lt;/a&gt;_integerDomain_patch1.patch}} (with minor checkstyle changes) committed in revision &lt;tt&gt;1226041&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Please do not forget to run &lt;tt&gt;mvn clean; mvn site:site&lt;/tt&gt; and check the reports (in particular, &lt;tt&gt;checkstyle&lt;/tt&gt;) prior to submitting a patch!&lt;/p&gt;

&lt;p&gt;Thanks for this contribution.&lt;/p&gt;
, &lt;p&gt;The committed patch actually causes failure of &lt;tt&gt;Well1024Test&lt;/tt&gt; in &lt;tt&gt;o.a.c.m.random&lt;/tt&gt;.&lt;/p&gt;
, &lt;p&gt;Thanks for committing the patch, Sbastien. I see you already changed the seed in &lt;tt&gt;Well1024aTest&lt;/tt&gt;. This hopefully removes the failure.&lt;/p&gt;

&lt;p&gt;I'll have a look into Maven to prepare a better patch next time. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;I see you already changed the seed in Well1024aTest.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I did, but is this really how we want &lt;tt&gt;Well2004aTest&lt;/tt&gt; to pass?&lt;/p&gt;
, &lt;p&gt;I guess there is no alternative to this way of making probabilistic test cases pass. However, I understand your bad feeling with this kind of failure fixing. The problem is that probabilistic tests are quiet fuzzy: Neither a passed test nor a failed test provides a clear answer whether something is right or wrong in the implementation. There is just a high chance to pass such a test with a correct implementation. The chance for failure increases with an erroneous implementation due to systematic deviations in the generated data. These chances tell whether it is easy to find a seed which passes the tests or not. Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's exactly the point I've raised on the mailing-list: out of three seeds (100, 1000 and 1001), only one works. Of course, I would not dare to call that representative statistics, but I'm wondering whether or not we should be worried...&lt;/p&gt;
, &lt;p&gt;The issue about selection of an appropriate seed has been raised elsewhere. No definitive answer has been provided so far, so I suggest we consider this issue as solved for the time being.&lt;/p&gt;
], resolution=Fixed, reporter=cwinter, assignees=[], commentAuthors=[psteitz, celestin, mikl, cwinter], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,919 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-654
2016-01-13 22:10:13,919 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-654, created=Tue Aug 30 19:23:19 CEST 2011, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Thu Sep 01 02:14:02 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=ValueServer not deterministic for a fixed random number seed, link=https://issues.apache.org/jira/browse/MATH-654, description=&lt;p&gt;I have built an agent-based model using the Apache Commons Math library, which has come in handy.&lt;/p&gt;

&lt;p&gt;The ValueServer seemed particularly helpful, as explained at:&lt;br/&gt;
&lt;a href="http://commons.apache.org/math/userguide/random.html"&gt;http://commons.apache.org/math/userguide/random.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My simulation needs repeatable randomness, so I used this form of the ValueServer constructor:&lt;/p&gt;

&lt;p&gt;    ValueServer(RandomData randomData) &lt;br/&gt;
    Construct a ValueServer instance using a RandomData as its source of random data.&lt;br/&gt;
    // &lt;a href="http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html"&gt;http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, in my simulation, I found that the ValueServer did not act deterministically if I supplied the same random number seed.&lt;/p&gt;

&lt;p&gt;I have not inspected the source code, but I suspect that the ValueServer is not using the `randomData` generator correctly. If it was, then it should be deterministic.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  I assume you are using DIGEST_MODE.  If this is the case and you are comfortable compiling the code in trunk, the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-634" title="EmpiricalDistributionImpl should use a pluggable RandomGenerator"&gt;&lt;del&gt;MATH-634&lt;/del&gt;&lt;/a&gt; enables a workaround for this.  Using the reseed method added to EmpiricalDistributionImpl in trunk, you can use ValueServer's getEmpiricalDistribution to get the distribution and then invoke reseed.  Unfortunately, this method does not exist in any released version yet.&lt;/p&gt;

&lt;p&gt;The problem is that ValueServer#getNextDigest (what it does for getNext in DIGEST_MODE) delegates to EmpiricalDistributionImpl#getNextValue.  EmpiricalDistributionImpl has its own RandomData instance.  To fix this issue, EmpiricalDistirbutionImpl should add a constructor taking a RandomData and ValueServer should provide this.&lt;/p&gt;
, &lt;p&gt;Fixed in r1163875. ValueServer now exposes a reSeed method that when supplied a fixed seed will generate a fixed sequence in any stochastic mode. The RandomDataImpl that it uses internally is passed to the EmpiricalDistributionImpl it creates when used in DIGEST_MODE.  The changes for this issue include an incompatible (vs. 2.x) change: the constructor for EmpiricalDistributionImpl that previously took a RandomData now takes a RandomDataImpl.  The plan for 3.0 is to merge these.&lt;/p&gt;
], resolution=Fixed, reporter=d.james, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-640
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-640, created=Tue Aug 02 21:06:35 CEST 2011, updated=Sat Mar 24 17:16:52 CET 2012, resolved=Wed Aug 03 06:17:43 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=AbstractRandomGenerator nextInt() and nextLong() default implementations generate only positive values, link=https://issues.apache.org/jira/browse/MATH-640, description=&lt;p&gt;The javadoc for these methods (and what is specified in the RandomGenerator interface) says that all int / long values should be in the range of these methods.  The default implementations provided in this class do not generate negative values.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1153338&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-618
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-618, created=Wed Jul 13 22:23:43 CEST 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Thu Jul 14 08:08:54 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same, link=https://issues.apache.org/jira/browse/MATH-618, description=&lt;p&gt;For both Complex add and subtract, the javadoc states that&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;* If either &lt;span class="code-keyword"&gt;this&lt;/span&gt; or &amp;lt;code&amp;gt;rhs&amp;lt;/code&amp;gt; has a NaN value in either part,
     * {@link #NaN} is returned; otherwise Inifinite and NaN values are
     * returned in the parts of the result according to the rules &lt;span class="code-keyword"&gt;for&lt;/span&gt;
     * {@link java.lang.&lt;span class="code-object"&gt;Double&lt;/span&gt;} arithmetic&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1146573&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-588
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-588, created=Sun Jun 12 20:19:07 CEST 2011, updated=Sat Mar 24 17:16:31 CET 2012, resolved=Sun Feb 05 20:54:50 CET 2012, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Weighted Mean evaluation may not have optimal numerics, link=https://issues.apache.org/jira/browse/MATH-588, description=&lt;p&gt;I recently got this in a test run&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;testWeightedConsistency(org.apache.commons.math.stat.descriptive.moment.MeanTest)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;0.002282165958997601&amp;gt; but was:&amp;lt;0.002282165958997157&amp;gt;
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:441)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:178)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:153)
	at org.apache.commons.math.stat.descriptive.UnivariateStatisticAbstractTest.testWeightedConsistency(UnivariateStatisticAbstractTest.java:170)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The correction formula used to compute the unweighted mean may not be appropriate or optimal in the presence of weights:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// Compute initial estimate using definitional formula
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; sumw = sum.evaluate(weights,begin,length);
&lt;span class="code-object"&gt;double&lt;/span&gt; xbarw = sum.evaluate(values, weights, begin, length) / sumw;

&lt;span class="code-comment"&gt;// Compute correction factor in second pass
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; correction = 0;
&lt;span class="code-keyword"&gt;for&lt;/span&gt; (&lt;span class="code-object"&gt;int&lt;/span&gt; i = begin; i &amp;lt; begin + length; i++) {
  correction += weights[i] * (values[i] - xbarw);
}
&lt;span class="code-keyword"&gt;return&lt;/span&gt; xbarw + (correction/sumw);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;, comments=[&lt;p&gt;Fixed it in r1240790.&lt;/p&gt;

&lt;p&gt;There was a too strict equality test using an relative error of 10-14 which resulted in certain unforunate cases of an absolute error of 10-18.&lt;/p&gt;
, &lt;p&gt;Corrected the equality test in r1240795 as it was leading to failure. In fact the test can range from very small to very large values which really requires a relative error estimate.&lt;/p&gt;

&lt;p&gt;The test is problematic in general, as it may contain values from very different scales (due to its random nature), leading to unavoidable precision errors in the above formula.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[tn], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-575
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-575, created=Sat May 14 18:40:34 CEST 2011, updated=Sat Mar 24 17:16:54 CET 2012, resolved=Thu Feb 02 12:12:52 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=Exceptions in genetics package or not consistent with the rest of [math], link=https://issues.apache.org/jira/browse/MATH-575, description=&lt;p&gt;InvalidRepresentationException is checked and non-localized.  This exception should be placed in the &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; hierarchy.  The AbstractListChromosome constructor also throws a non-localised IAE, which should be replaced by an appropriate &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; exception.&lt;/p&gt;, comments=[&lt;p&gt;Phil started to work on this issue in r1135025.&lt;/p&gt;

&lt;p&gt;In r1235038 additional cleanups have been performed:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;add localized messages for all exceptions&lt;/li&gt;
	&lt;li&gt;add @throws to javadoc where appropriate&lt;/li&gt;
	&lt;li&gt;add final to method parameters&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What is missing:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;Phil mentioned that InvalidRepresentationException should be placed into &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, although I am not sure why, as it is not used outside the genetics package&lt;/li&gt;
	&lt;li&gt;add more custom exception classes specific to the genetics package (optional). By now mostly MathIllegalArgumentException or other appropriate ones have been used.&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;Thanks for working on this, but before you do start to make modifications, please assign the issue to yourself!&lt;/p&gt;

&lt;p&gt;For the changes themselves, I don't agree with the creation of those many localized messages: We have been trying to rationalize and reduce the number of those, by removing duplicates and combining several ones to convey the full explanation of the problem. See my reply to the commit message.&lt;/p&gt;
, &lt;p&gt;Fixed in r1235197.&lt;/p&gt;

&lt;p&gt;Thanks for your suggestions!&lt;/p&gt;
, &lt;p&gt;Thomas,&lt;br/&gt;
Could please check whether this issue is resolved? And if it is, mark it so? Thanks.&lt;/p&gt;
, &lt;p&gt;As from the original issue description, Phil intended to move the InvalidRepresentationException to the general o.a.c.m.exceptions package. I am not sure about this, that's why I kept it aside for the time being. If we agree on keeping it in the genetics package we can resolve this issue.&lt;/p&gt;
, &lt;p&gt;Phil had always been opposed to having all exceptions grouped in their own package; so I doubt that he meant to move that one over there... &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
Here, the description just indicates that the exception should become &lt;em&gt;unchecked&lt;/em&gt; and that the "detailed message" should be an element from the "LocalizedFormats" enum (i.e. derive from one of the base CM exceptions).&lt;/p&gt;
, &lt;p&gt;Ah ok, that makes it clear. When reading hierarchy I was just thinking in terms of packages rather than class hierarchy.&lt;/p&gt;

&lt;p&gt;Thus, I resolve this issue.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[tn], commentAuthors=[tn, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-555
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-555, created=Mon Apr 04 06:13:04 CEST 2011, updated=Sat Mar 24 17:16:43 CET 2012, resolved=Mon Apr 04 06:53:13 CEST 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=MathUtils round method should propagate rather than wrap Runitme exceptions, link=https://issues.apache.org/jira/browse/MATH-555, description=&lt;p&gt;MathUtils.round(double, int, int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException, the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in trunk in r1088473&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-540
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-540, created=Sun Mar 06 01:43:45 CET 2011, updated=Sat Mar 24 17:16:36 CET 2012, resolved=Sun Jun 12 07:58:50 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug, link=https://issues.apache.org/jira/browse/MATH-540, description=&lt;p&gt;The AbstractIntegerDistribution.inverseCumulativeProbability(...) function attempts to decrement the lower bound of discrete distributions to values that go below the lower bound.&lt;/p&gt;, comments=[&lt;p&gt;I don't think this is a bug.  Per the javadoc, the contract for inverse cum is&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/**
 * For a random variable {@code X} whose values are distributed according
 * to &lt;span class="code-keyword"&gt;this&lt;/span&gt; distribution, &lt;span class="code-keyword"&gt;this&lt;/span&gt; method returns the largest {@code x}, such
 * that {@code P(X &amp;lt; x) &amp;lt; p}.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This implies that if the first non-zero mass point has probability greater than p, the right value to return is one less than that value, which is whet the method will do.  Your example distribution throws NPE when trying to compute probabilities outside of its domain of support. &lt;/p&gt;
, &lt;p&gt;I'm looking at it like this.  I have very simple distribution like the one provided (Four sided dice).  I'm trying to write a simulation that draws values of x for a a set of uniform 0-1 probabilities.  So I'm expecting:&lt;/p&gt;

&lt;p&gt;0 When p is less than or equal to 0.25&lt;br/&gt;
1 When p is greater than 0.25 but less than or equal to 0.50&lt;br/&gt;
2 When p is greater than 0.50 but less than or equal to 0.75&lt;br/&gt;
3 When p is greater than 0.75 but less than or equal to 1.0&lt;/p&gt;

&lt;p&gt;So for the line &lt;/p&gt;

&lt;p&gt;int neverSucceeds = d.inverseCumulativeProbability(0.0001);&lt;/p&gt;

&lt;p&gt;I'm really expecting 0 to be returned.&lt;/p&gt;

&lt;p&gt;Make sense?&lt;/p&gt;
, &lt;p&gt;I see now that there actually does appear to be an error in the javadoc.  The implementation really returns the largest x such that p(X &amp;lt;= x) &amp;lt;= p.  In the discrete case, &amp;lt;= matters and I think both inequalities in the javadoc should be changed.&lt;/p&gt;

&lt;p&gt;In your example, if the probability distribution vanishes outside 0, 1, 2, 3 and puts .25 mass on each of these values, the inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;

&lt;p&gt;If you fix your distribution so that both probability and cumulativeProbability return correct values (rather than throwing NPEs) outside of the mass values, you should get -1 returned.&lt;/p&gt;
, &lt;p&gt;Reading your last comment a little more carefully, it looks like what you are trying to do is implement sampling.  IIUC, something like what you are suggesting should work - you just have an off-by-one problem vis-s-vis the contract of inverse cumulative probabilities as we define them.  I would be +1 for adding direct support for sampling from discrete distributions, but we should open a separate ticket for that.&lt;/p&gt;
, &lt;p&gt;OK - I'll close this one and open a separate ticket.&lt;/p&gt;
, &lt;p&gt;There is a javadoc bug that needs to be fixed here&lt;/p&gt;
, &lt;p&gt;Ooops - Thanks.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;...inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems to me that users would be better served if it returned 0 and that it is also correct to do so.&lt;/p&gt;

&lt;p&gt;In the definition we say "For a random variables X whose values are distributed according to this distribution...".&lt;/p&gt;

&lt;p&gt;Suppose the distribution was for a six sided dice.  One could assert that the distribution is only defined for the values 1,2,3,4,5,6.  In this case the inverseCumulativeDistribution returns 0, but that does not have any meaning.  So now developers are forced to define the meaning of 0 for a six sided dice implementation.  &lt;/p&gt;

&lt;p&gt;In Grad school we were taught the the inverse cumulative distribution is for sampling.  So for a six sided dice uniform probabilities less than 1/6 would return 1, less than 2/6 would return 2, etc.&lt;/p&gt;

&lt;p&gt;With the current implementation for values less than 1/6 we get 0 which is meaningless, and the only time we get 6 is when the uniform probability argument is 1.&lt;/p&gt;

&lt;p&gt;So if someone mistakenly tries to use the inverseCumulativeProbability function for sampling the results are going to be wacked.  What is the use case for the inverseCumulativeProbability the way it is right now?&lt;/p&gt;
, &lt;p&gt;You have a choice in defining the inverse cum whether to define it the way we have or to use and inf rather than a sup.  We can implement sampling using the current impl.  We just need to take into account the way the inverse cum is defined in AbstractIntegerDistribution.  &lt;/p&gt;
, &lt;p&gt;OK - I think it's starting to make more sense to me now.  So when implementing sampling we just add one to the value returned by inverseCumulativeDistribution, unless the uniform probability argument is 1?&lt;/p&gt;
, &lt;p&gt;I am sorry.  I forgot that we had in fact already implemented this in version 2.2. See AbstractIntegerDistribution#sample.  The base class implementation delegates to RandomDataImpl#nextInversionDeviate (adding one per the last comment).&lt;/p&gt;
, &lt;p&gt;Sorry for the noise. I closed the wrong ticket.  Still need to fix the javadoc to match behavior and user guide.&lt;/p&gt;
, &lt;p&gt;Javadoc fixed in trunk r1134866&lt;/p&gt;
], resolution=Fixed, reporter=ole, assignees=[], commentAuthors=[psteitz, ole], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-506
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-506, created=Tue Feb 01 19:38:01 CET 2011, updated=Sat Mar 24 17:16:41 CET 2012, resolved=Sat Aug 20 23:14:57 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=The static field ChiSquareTestImpl.distribution serves no purpose, link=https://issues.apache.org/jira/browse/MATH-506, description=&lt;p&gt;The static field ChiSquareTestImpl.distribution serves no purpose.&lt;/p&gt;

&lt;p&gt;There is a setter for it, but in every case where the field is used, it is first overwritten with a new value.&lt;/p&gt;

&lt;p&gt;The field and the setter should be removed, and the methods that create a new instance should create a local variable instead.&lt;/p&gt;

&lt;p&gt;For Math 2.1, the field can be removed and the setter deprecated.&lt;/p&gt;, comments=[&lt;p&gt;Agreed.  Since the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; this instance field is unnecessary.&lt;/p&gt;
, &lt;p&gt;See the discussion in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; where it was decided to remove the distribution pluggability in 3.0.  In 2.x, the distribution is pluggable and the instance field is useful.  The 3.0 code in trunk removes the pluggability and makes the field useless.&lt;/p&gt;
, &lt;p&gt;Sorry - I thought I had checked the 2.x implementation as well, but obviously not, as it does use the field.&lt;/p&gt;

&lt;p&gt;However, we should still deprecate the setter in 2.2, as it is removed in 3.0 - OK?&lt;/p&gt;
, &lt;p&gt;Just tried removing the field and setter in 3.0, and found that the constructors rely on the setter (which is a separate bug, as the setter is not final - but easily fixable if required).&lt;/p&gt;

&lt;p&gt;The fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; merely removed deprecated code.&lt;/p&gt;

&lt;p&gt;It replaced "distribution.setDegreesOfFreedom(dof)" with "distribution = new ChiSquaredDistributionImpl(dof)" which is how the field became useless.&lt;/p&gt;

&lt;p&gt;There are two constructors which still create values for the distribution field.&lt;/p&gt;

&lt;p&gt;I don't know enough about the Math to know whether there would be any use cases for having additional methods that used a distribution provided by the class instance, rather than calculated by the individual methods (as at present).&lt;/p&gt;

&lt;p&gt;If there is no need for external provision of the distribution degree of freedom, then the constructor with parameter can be dropped.&lt;/p&gt;

&lt;p&gt;Otherwise, we need to add some methods that can use the provided distribution (which should be a final instance field).&lt;/p&gt;

&lt;p&gt;In any case, I think the setter needs to be dropped from 3.x&lt;/p&gt;
, &lt;p&gt;The instance field was there originally so that different ChiSquareDistribution implementations could be provided at construction time or via a setter (making the underlying ChiSquareDistribution pluggable).  &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; pointed to a different problem related to mutability of implementation instances.  The simplest solution to both problems is to eliminate the pluggability, which the change in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; does for this class.  The degrees of freedom are always computed from the data, so there is no need for the constructor that takes a distribution instance as argument.  Both the constructor and setter can be deprecated in 2.2 and removed in 3.0 unless we want to keep pluggability, which would require&lt;/p&gt;

&lt;p&gt;1) making the distribution field final (so removing the setter)&lt;br/&gt;
2) copying, rather than referencing the actual parameter provided to the constructor&lt;/p&gt;

&lt;p&gt;I am on the fence on this.  Maybe others can chime in (next week &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;p&gt;OK, I see now, thanks!&lt;/p&gt;
, &lt;p&gt;I removed the field (hence eliminating pluggability) in r1159916.  As of 3.0, the distribution classes are immutable, so to support pluggability a factory or class name rather than a distribution instance would have to be provided.  There is only one implementation provided by &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, so I do not see this as worth the effort and complexity to retain.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[psteitz], commentAuthors=[psteitz, sebb@apache.org], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,934 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-505
2016-01-13 22:10:13,950 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-505, created=Tue Feb 01 01:28:56 CET 2011, updated=Sat Mar 24 17:16:40 CET 2012, resolved=Tue Feb 01 19:58:30 CET 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
], fixVersion=[3.0
], priority=Major, summary=TestUtils is thread-hostile, link=https://issues.apache.org/jira/browse/MATH-505, description=&lt;p&gt;TestUtils has several mutable static fields which are not synchronised, or volatile.&lt;/p&gt;

&lt;p&gt;If one of the fields is updated by thread A, there is no guarantee that thread B will see the full update - it may see a partially updated object.&lt;/p&gt;

&lt;p&gt;Furthermore, at least some of the static fields reference a mutable object, which can be changed whilst another thread is using it.&lt;/p&gt;

&lt;p&gt;As far as I can tell, this class must only ever be used by a single thread otherwise the results will be unpredictable.&lt;/p&gt;, comments=[&lt;p&gt;What fields, exactly?&lt;/p&gt;
, &lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/** Singleton TTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; TTest tTest = &lt;span class="code-keyword"&gt;new&lt;/span&gt; TTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; ChiSquareTest chiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; UnknownDistributionChiSquareTest unknownDistributionChiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton OneWayAnova instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; OneWayAnova oneWayAnova =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; OneWayAnovaImpl();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of the above may be changed by set methods. There is no synch.&lt;/p&gt;
, &lt;p&gt;OK, I was looking at the wrong TestUtils &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;

&lt;p&gt;The reason for this strange-looking setup is to allow the implementations to be pluggable at runtime.  "Hostile" is a harsh word, but this class is certainly &lt;b&gt;not&lt;/b&gt; threadsafe.  Ideas / patches to achieve the design goal with less "hostility" would be appreciated.&lt;/p&gt;

&lt;p&gt;I would have to double-check, but I don't think that there is any test instance state used by the methods in this class. &lt;/p&gt;
, &lt;p&gt;By thread-hostile, I mean that it is not possible in general for two different threads to use the class safely.&lt;br/&gt;
If one thread changes any of the static fields, there is no way of knowing how the methods called by the other thread will behave. This is partly because the values are not safely published currently, but even if they were, the threads don't know what settings will be used as they can be changed at any time by another thread.&lt;/p&gt;

&lt;p&gt;In general, any class which relies on mutable static state for its behaviour is thread-hostile.&lt;br/&gt;
The shared state cannot simultaneously satisfy two threads needing different behaviour.&lt;/p&gt;

&lt;p&gt;I think the only safe way for two threads to use the class as it stands is if they both synchronize on the class.&lt;br/&gt;
This will ensure safe publication of any field changes, and enforce serial usage which can guarantee the setting that will be used (but the lock will have to be held for the set call as well).&lt;/p&gt;

&lt;p&gt;ChiSquareTestImpl has a non-final instance field which means its value won't necessarily be safely published.&lt;br/&gt;
The field also has a setter which could be invoked by one thread while another was using it.&lt;/p&gt;

&lt;p&gt;TTestImpl is immutable (has no fields), and OneWayAnovaImpl can be made immutable, but other implementations of the interfaces might exist which are not immutable.&lt;/p&gt;

&lt;p&gt;The simplest way to make the class thread-safe would be to convert all the methods and fields from static to instance, but I don't know if that is acceptable.&lt;/p&gt;
, &lt;p&gt;Making the methods instance sort of defeats the purpose of the class.  None of the instance data in any of the static singletons is actually used or depended on by the methods of this class.  You are correct though that if one thread changes the impl for one of the singletons while another is using the class, the other could see a different than expected impl.  I think the practical likelihood of this is pretty much nil, as it is hard to imagine an application supplying two different implementations for the tests and wanting different threads to use different impls.  Personally, I would be happy just documenting the fact that the class is not threadsafe and if concurrent threads want to plug in different implementations, they need to synchronize on the class.  If this is not acceptable, my next preference would be to remove the pluggability - i.e., make the singletons final or get rid of them altogether, creating instances as needed for static method calls.  There is no initialization overhead creating the test classes.&lt;/p&gt;
, &lt;p&gt;@Phil: Please also keep in mind that M3 supports now (currently optional) parallel execution and it might be no longer a proper assumption that all tests are executed serially.&lt;/p&gt;
, &lt;p&gt;There is another possible option, which would be to fix the default implementations, and create new static methods that took an extra parameter for the implementation to be used.&lt;/p&gt;

&lt;p&gt;At present, changes to the static fields are not guaranteed to be published correctly. Making them volatile would fix this, but would not help with concurrent access.&lt;/p&gt;
, &lt;p&gt;Thanks, Joerg.  There should be no problems with the unit tests unless and until we introduce different tests that actually test the pluggability.  &lt;/p&gt;

&lt;p&gt;I thought about the additional parameter option, Sebb; but that again defeats the purpose of this "convenience class" - you might as well just instantiate the implementation and use it.&lt;/p&gt;

&lt;p&gt;I think the best solution is to just make the fields final and drop the getters and setters.  This is consistent with StatUtils.  So we should document the "hostility" issues in 2.2 and deprecate there and drop in 3.0.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[sebb@apache.org], commentAuthors=[psteitz, sebb@apache.org, joehni], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,950 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-484
2016-01-13 22:10:13,950 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-484, created=Tue Jan 18 21:49:51 CET 2011, updated=Wed Mar 23 21:35:01 CET 2011, resolved=Mon Feb 14 15:20:29 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=events detection in ODE solvers is too complex and not robust, link=https://issues.apache.org/jira/browse/MATH-484, description=&lt;p&gt;All ODE solvers support multiple events detection since a long time. Events are specified by users by implementing the EventHandler interface. Events occur when the g(t, y) function evaluates to 0. When an event occurs, the solver step is shortened to make sure the event is located at the end of the step, and the event is triggered by calling the eventOccurred method in the user defined implementation class. Depending on the return value of this method, integration can continue, it can be stopped, or the state vector can be reset.&lt;/p&gt;

&lt;p&gt;Some ODE solvers are adaptive step size solvers. They can modify step size to match an integration error setting, increasing step size when error is low (thus reducing computing costs) or reducing step size when error is high (thus fulfilling accuracy requirements).&lt;/p&gt;

&lt;p&gt;The step adaptations due to events on one side and due to adaptive step size solvers are quite intricate by now, due to numerous fixes (&lt;a href="https://issues.apache.org/jira/browse/MATH-161" title="patch for Mantissa"&gt;&lt;del&gt;MATH-161&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-213" title="FirstOrderIntegrator.integrate does not give back integration stop time when an event handler stops integration"&gt;&lt;del&gt;MATH-213&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-358" title="ODE integrator goes past specified end of integration range"&gt;&lt;del&gt;MATH-358&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-421" title="restarting an ODE solver that has been stopped by an event doesn&amp;#39;t work"&gt;&lt;del&gt;MATH-421&lt;/del&gt;&lt;/a&gt; and also during standard maintenance - see for example r781157). The code is very difficult to maintain. It seems each bug fix introduces new bugs (r781157/&lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;) or tighten the link between adaptive step size and event detection (&lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;/r927202).&lt;/p&gt;

&lt;p&gt;A new bug discovered recently on an external library using a slightly modified version of this code could not be retroffitted into commons-math, despite the same problem is present. At the beginning of EventState.evaluateStep, the initial step may be exactly 0 thus preventing root solving, but preventing this size to drop to 0 would reopen &lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;. I could not fix both bugs at the same time.&lt;/p&gt;

&lt;p&gt;So it is now time to untangle events detection and adaptive step size, simplify code, and remove some inefficiency (event root solving is always done twice, once before step truncation and another time after truncation, of course with slightly different results, events shortened steps induce high computation load until the integrator recovers its optimal pace again, steps are rejected even when the event does not requires it ...).&lt;/p&gt;, comments=[&lt;p&gt;fixed in subversion repository as of r1061507 for branch 2.X and as of r1061508 for trunk&lt;/p&gt;
, &lt;p&gt;The fix introduced in r1061507 fails in several cases. If several events of the same type occur within a single long step, only the first one is triggered. If several events of different types occur during a backward integration, they are triggered in the wrong order (i.e. they are triggered in forward occurrence time order instead of backward).&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1070498 for branch 2.X and r1070499 for trunk&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,950 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-481
2016-01-13 22:10:13,950 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-481, created=Mon Jan 17 18:15:41 CET 2011, updated=Wed Mar 23 21:33:40 CET 2011, resolved=Mon Jan 17 23:39:52 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=MathUtils.equals(double x, double y) disagrees with Javadoc, link=https://issues.apache.org/jira/browse/MATH-481, description=&lt;p&gt;MathUtils.equals(double x, double y) disagrees with Javadoc.&lt;/p&gt;

&lt;p&gt;The Javadoc says:&lt;/p&gt;

&lt;p&gt;Returns true iff they are equal as defined by  {@link #equals(double,double,int)}&lt;/p&gt;

&lt;p&gt;However, the code actually uses == and checks for NaN:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; &lt;span class="code-object"&gt;boolean&lt;/span&gt; equals(&lt;span class="code-object"&gt;double&lt;/span&gt; x, &lt;span class="code-object"&gt;double&lt;/span&gt; y) {
    &lt;span class="code-keyword"&gt;return&lt;/span&gt; (&lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(x) &amp;amp;&amp;amp; &lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(y)) || x == y;
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The method is deprecated, but it should probably still be consistent with its documentation.&lt;/p&gt;, comments=[&lt;p&gt;Corrected Javadoc in revision 1060117.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,950 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-465
2016-01-13 22:10:13,950 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-465, created=Wed Jan 05 18:34:41 CET 2011, updated=Sat Mar 24 17:17:03 CET 2012, resolved=Wed Jul 20 14:20:51 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Incorrect matrix rank via SVD, link=https://issues.apache.org/jira/browse/MATH-465, description=&lt;p&gt;The getRank() function of SingularValueDecompositionImpl does not work properly. This problem is probably related to the numerical stability problems mentioned in &lt;a href="https://issues.apache.org/jira/browse/MATH-327"&gt;MATH-327&lt;/a&gt; and &lt;a href="https://issues.apache.org/jira/browse/MATH-320"&gt;MATH-320&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Example call with the standard matrix from R (rank 2):&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeHeader panelHeader" style="border-bottom-width: 1px;"&gt;&lt;b&gt;TestSVDRank.java&lt;/b&gt;&lt;/div&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.Array2DRowRealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.RealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecomposition;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecompositionImpl;

&lt;span class="code-keyword"&gt;public&lt;/span&gt; class TestSVDRank {
	&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; void main(&lt;span class="code-object"&gt;String&lt;/span&gt;[] args) {
		&lt;span class="code-object"&gt;double&lt;/span&gt;[][] d = { { 1, 1, 1 }, { 0, 0, 0 }, { 1, 2, 3 } };
		RealMatrix m = &lt;span class="code-keyword"&gt;new&lt;/span&gt; Array2DRowRealMatrix(d);
		SingularValueDecomposition svd = &lt;span class="code-keyword"&gt;new&lt;/span&gt; SingularValueDecompositionImpl(m);
		&lt;span class="code-object"&gt;int&lt;/span&gt; r = svd.getRank();
		&lt;span class="code-object"&gt;System&lt;/span&gt;.out.println(&lt;span class="code-quote"&gt;"Rank: "&lt;/span&gt;+r);
	}
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;The rank is computed as 3. This problem also occurs for larger matrices. I discovered the problem when trying to replace the corresponding JAMA method.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  Looks like it could as you suggest be related to &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt;.  &lt;/p&gt;
, &lt;p&gt;For now, pushing to 3.0.  If we get a fix for this and &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt; before 3.0 is ready, I may propose a 2.2.1 to include it.&lt;/p&gt;
, &lt;p&gt;My apologies if I am missing something, but here is what I noticed about the SVD. &lt;/p&gt;

&lt;p&gt;On lines 124-127 of SingularValueDecompositionImpl we have:&lt;/p&gt;

&lt;p&gt;        for (int i = 0; i &amp;lt; p; i++) {
            singularValues[i] = FastMath.sqrt(FastMath.abs(singularValues[i]));
        }&lt;/p&gt;

&lt;p&gt;This is potentially the offending line. First is the problem of negative eigenvalues. Negative variance in the principal components should probably be dealt with explicitly? Perhaps by throwing a MathException? Second, and the issue which this bug report deals with, is taking a square root of a very small number (&amp;lt;1) will return a larger number. If you apply the threshold test in getRank() (final double threshold = FastMath.max(m, n) * FastMath.ulp(singularValues&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;) )  prior to taking the square root, I believe this problem would be resolved. More importantly, philosophically, you test for zero variance. This is the appropriate test.&lt;/p&gt;

&lt;p&gt;Also, rank could be precalculated in the above loop. &lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1148714.&lt;/p&gt;

&lt;p&gt;This issue was fixed by changing SVD implementation according to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-611" title="A fast and stable SVD implementation from JAMA"&gt;&lt;del&gt;MATH-611&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
], resolution=Fixed, reporter=marisa, assignees=[], commentAuthors=[psteitz, gsteri1, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,950 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-464
2016-01-13 22:10:13,965 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-464, created=Fri Dec 31 08:00:42 CET 2010, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Wed Aug 24 00:37:41 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Critical, summary=LegendreGaussIntegrator ignores defaultMaximalIterationCount and does 38 million iterations, link=https://issues.apache.org/jira/browse/MATH-464, description=&lt;p&gt;The following code results in count = 37801710 which is effectively an infinite loop for typical functions we are using&lt;br/&gt;
(in GeoGebra)&lt;/p&gt;

&lt;p&gt;The argument defaultMaximalIterationCount = 100 is being ignored&lt;/p&gt;

&lt;p&gt;This is the version we are using:&lt;br/&gt;
&lt;a href="http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java"&gt;http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    	LegendreGaussIntegrator gauss = new LegendreGaussIntegrator(5, 100);&lt;/p&gt;

&lt;p&gt;	try {
		double result = gauss.integrate(new testFun(), -10, 0.32462367623786328);
	} catch (Exception ee) {
		ee.printStackTrace();
	}&lt;/p&gt;



&lt;p&gt;class testFun implements UnivariateRealFunction {&lt;/p&gt;

&lt;p&gt;    public double value(double x) throws FunctionEvaluationException {
    	count ++;
        if (x&amp;gt;=0 &amp;amp;&amp;amp; x&amp;lt;=5) return 0.2; else return 0;
    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.&lt;/p&gt;

&lt;p&gt;The problem here is not with the iteration count.  In the example above, only 26 iterations are executed and the method returns the correct value.  What is causing the number of function evaluations to be so large is that each iteration involves multiple function evaluations.   I need to dig more deeply into the algorithm to determine what (if anything) the problem is, but what is causing the high number of function evaluations is the following&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// prepare next iteration
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; ratio = FastMath.min(4, FastMath.pow(delta / limit, 0.5 / abscissas.length));
n = FastMath.max((&lt;span class="code-object"&gt;int&lt;/span&gt;) (ratio * n), n + 1);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the example, delta / limit becomes large, causing n to increase rapidly.  As n increases, the number of function evaluations increases.&lt;/p&gt;
, &lt;p&gt;I am now thinking that this is not a bug, but a consequence of the fact that the integrand in the example is not at all well-approximated by a polynomial.  With a small-enough stepsize, the algorithm does converge, but requiring the large number of function evaluations above.  Here are some stepsize values for the example and the associated absolute error:&lt;/p&gt;

&lt;p&gt;n 8 error 0.05738431110184819&lt;br/&gt;
n 28 error 0.027423287634332688&lt;br/&gt;
n 100 error 8.62162720248888E-5&lt;br/&gt;
n 249 error 5.308122631570711E-4&lt;br/&gt;
n 650 error 4.3582615516528367E-4&lt;br/&gt;
n 1641 error 2.519984967931377E-4&lt;br/&gt;
n 3829 error 5.838605030586419E-5&lt;br/&gt;
...&lt;br/&gt;
 n 1102593 error 6.71416523906343E-8&lt;/p&gt;

&lt;p&gt;The last entry is from the last (26th) iteration.  I haven't verified the rationale for the updating formula for n above, but it does appear warranted in this case to increase n quickly as large n (= small stepsize) is required to get a decent estimate of the integral using Gaussian quadrature.&lt;/p&gt;
, &lt;p&gt;Perhaps we should also provide higher order formulas, using either a fixed set of precomputed constants or a way to compute the coefficients for any order.&lt;/p&gt;
, &lt;p&gt;Moving to 3.0.  I don't think this is a bug, but points to a couple of possible enhancements:&lt;/p&gt;

&lt;p&gt;1) higher order formulas (+0 on this suggestion from Luc - IMO the example and others like it are not suitable for Legendre-Gauss)&lt;br/&gt;
2) bound on the number of function evaluations (I vaguely recall us talking about this elsewhere, but can't find the reference.  If anyone else can, pls add.)&lt;/p&gt;
, &lt;p&gt;We restarted a thread about this a few days after the previous comment on this issue.&lt;br/&gt;
The thread can be read here: &lt;a href="http://markmail.org/thread/rnazrggnnuehz4qv"&gt;http://markmail.org/thread/rnazrggnnuehz4qv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think adding maxEvaluations while still preserving the existing maxIterations would be fine.&lt;/p&gt;
, &lt;p&gt;Coming back to this issue.&lt;/p&gt;

&lt;p&gt;I would propose to follow the same pattern we used for root solvers: adding a maxEval parameter in the top level integrate interface declaration. So we would have the same kind of configuration, with tolerances set at integrator/solver level and maxEval and function pointer passed at integrate/solve method call.&lt;/p&gt;

&lt;p&gt;Since we are just in the phase we change interfaces, this would be a good time to add this parameter.&lt;/p&gt;

&lt;p&gt;Does this seems reasonable ?&lt;/p&gt;
, &lt;p&gt;+1 for your suggestion, Luc.  Lets try to get this into 3.0.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1160914.&lt;/p&gt;

&lt;p&gt;The API of the integrators has been changed for consistency with solvers API. Now the main convergence parameters are set in the constructor and remain fixed, but a maximal number of function evaluation must be provided at each call to the integration method.&lt;/p&gt;

&lt;p&gt;Thanks for the report&lt;/p&gt;
], resolution=Fixed, reporter=murkle, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=180, timeSpent=null]
2016-01-13 22:10:13,965 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-453
2016-01-13 22:10:13,965 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-453, created=Mon Dec 06 03:01:08 CET 2010, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Mon Dec 06 13:53:56 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function, link=https://issues.apache.org/jira/browse/MATH-453, description=&lt;p&gt;RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function.&lt;/p&gt;

&lt;p&gt;As this explains how to recode deprecated method calls, it ought to be corrected before release.&lt;/p&gt;, comments=[&lt;p&gt;Removed references to the &lt;tt&gt;analysis.function&lt;/tt&gt; package (revision 1042610).&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[erans], commentAuthors=[erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,981 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-434
2016-01-13 22:10:13,981 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-434, created=Sun Nov 07 04:55:32 CET 2010, updated=Sat Mar 24 17:16:29 CET 2012, resolved=Sat Apr 09 21:21:59 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=SimplexSolver returns unfeasible solution, link=https://issues.apache.org/jira/browse/MATH-434, description=&lt;p&gt;The SimplexSolver is returning an unfeasible solution:&lt;/p&gt;

&lt;p&gt;import java.util.ArrayList;&lt;br/&gt;
import java.text.DecimalFormat;&lt;br/&gt;
import org.apache.commons.math.linear.ArrayRealVector;&lt;br/&gt;
import org.apache.commons.math.optimization.GoalType;&lt;br/&gt;
import org.apache.commons.math.optimization.OptimizationException;&lt;br/&gt;
import org.apache.commons.math.optimization.linear.*;&lt;/p&gt;

&lt;p&gt;public class SimplexSolverBug {&lt;/p&gt;

&lt;p&gt;    public static void main(String[] args) throws OptimizationException {&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction c = new LinearObjectiveFunction(new double[]{0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d}, 0.0d);&lt;/p&gt;

&lt;p&gt;        ArrayList&amp;lt;LinearConstraint&amp;gt; cnsts = new ArrayList&amp;lt;LinearConstraint&amp;gt;(5);&lt;br/&gt;
        LinearConstraint cnst;&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, -0.1d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.EQ, -0.1d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, -1e-18d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 1.0d, 0.0d, -0.0128588d, 1e-5d}, Relationship.EQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 0.0d, 1.0d, 1e-5d, -0.0128586d}, Relationship.EQ, 1e-10d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, -1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, -1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, 1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;/p&gt;

&lt;p&gt;        DecimalFormat df = new java.text.DecimalFormat("0.#####E0");&lt;/p&gt;

&lt;p&gt;        System.out.println("Constraints:");&lt;br/&gt;
        for(LinearConstraint con : cnsts) {
            for (int i = 0; i &amp;lt; con.getCoefficients().getDimension(); ++i)
                System.out.print(df.format(con.getCoefficients().getData()[i]) + " ");
            System.out.println(con.getRelationship() + " " + con.getValue());
        }&lt;/p&gt;

&lt;p&gt;        SimplexSolver simplex = new SimplexSolver(1e-7);&lt;br/&gt;
        double[] sol = simplex.optimize(c, cnsts, GoalType.MINIMIZE, false).getPointRef();&lt;br/&gt;
        System.out.println("Solution:\n" + new ArrayRealVector(sol));&lt;br/&gt;
        System.out.println("Second constraint is violated!");&lt;br/&gt;
    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;It's an odd problem, but something I ran across.  I tracked the problem to the getPivotRow routine in SimplexSolver.  It was choosing a pivot that resulted in a negative right-hand-side.  I recommend a fix by replacing&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
                ...&lt;br/&gt;
with&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;br/&gt;
                ...&lt;/p&gt;

&lt;p&gt;I believe this would be more appropriate (and at least resolves this particular problem).&lt;/p&gt;

&lt;p&gt;Also, you may want to consider making a change in getPivotColumn to replace&lt;br/&gt;
            ...&lt;br/&gt;
            if (MathUtils.compareTo(tableau.getEntry(0, i), minValue, epsilon) &amp;lt; 0) {&lt;br/&gt;
            ...&lt;br/&gt;
with&lt;br/&gt;
            ...&lt;br/&gt;
            if (tableau.getEntry(0, i) &amp;lt; minValue) &lt;br/&gt;
            ...&lt;br/&gt;
because I don't see the point of biasing earlier columns when multiple entries are within epsilon of each other.  Why not pick the absolute smallest.  I don't know that any problem can result from doing it the other way, but the latter may be a safer bet.&lt;/p&gt;

&lt;p&gt;VERY IMPORTANT: I discovered another bug that occurs when not restricting to non-negatives.  In SimplexTableu::getSolution(), &lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) &lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = 0;&lt;br/&gt;
          ...&lt;br/&gt;
should be&lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) {&lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = (restrictToNonNegative ? 0 : -mostNegative);&lt;br/&gt;
          ...&lt;br/&gt;
If necessary, I can give an example of where this bug causes a problem, but it should be fairly obvious why this was wrong.&lt;/p&gt;, comments=[&lt;p&gt;My original suggested fix had a potential for overflow errors (since minRatio is initialized to Double.MAX_VALUE).  Also, I added another suggestion and pointed out another bug which leads to invalid solutions.&lt;/p&gt;
, &lt;p&gt;Could you attach unit tests that demonstrate each problem?  Thank you.&lt;/p&gt;
, &lt;p&gt;I'll try to send some examples soon.  I'm noticing more problems with the right-hand-side going negative and want to cover all bases (as much as possible).&lt;/p&gt;
, &lt;p&gt;Code, and resulting output, that illustrates issues with the SimplexSolver.&lt;/p&gt;
, &lt;p&gt;Pushing out to 3.0.&lt;/p&gt;
, &lt;p&gt;Hey, sorry I took so long to look at this.  I've had very little time and am not working on this stuff anymore.  I'm honestly not going to be able to look at this stuff much moving forward, so hopefully there's a Commons Math contributor that can act as a reviewer.&lt;/p&gt;

&lt;p&gt;When you say it's choosing a pivot with a negative RHS, I'm assuming that means it's not within the epsilon?&lt;br/&gt;
Why would it be more appropriate to divide by the entry?  I'm not sure I see why you'd want to use a bigger epsilon when the entry is 0.1 and a smaller epsilon when the entry is 10.  Maybe we should just make the default epsilon smaller?  I'm no expert with floating point math so I'm not real sure how to set the epsilon and just made up a value.&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
...&lt;br/&gt;
with&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;/p&gt;
, &lt;p&gt;Attached a patch for the reported problems.&lt;br/&gt;
The problems can be split into two groups:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;wrong solution calculation with negative&lt;br/&gt;
   variables&lt;/li&gt;
	&lt;li&gt;failing to select an appropriate pivot&lt;br/&gt;
   row when values are below a given &lt;br/&gt;
   epsilon&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch addresses both problems:&lt;/p&gt;

&lt;p&gt; 1. fix in SimplexTableau.getSolution()&lt;br/&gt;
 2. use BigReal for arbitrary precision  &lt;br/&gt;
    support when selecting the pivot row&lt;/p&gt;

&lt;p&gt;Additionally, 4 test cases are included, as well as a minor typo fix for a method name.&lt;/p&gt;

&lt;p&gt;The fixed epsilon is also used in some other places of the code, this may also create problems under certain circumstances. So if this patch is accepted, the other places could also be adapted.&lt;/p&gt;
, &lt;p&gt;Thanks Thomas.&lt;/p&gt;

&lt;p&gt;I had a look at the patch. I'm not a big fan of using BigReal, mainly when we don't specify a scale and we don't link it to the choice for epsilon. Also reading back Ben comments, I wonder if we should not replace epsilon by an integer number of ulps with a default set to a very small value (say something like 10 ulps).&lt;/p&gt;

&lt;p&gt;What problem did you see in the accuracy of the variables to use BigReal ?&lt;/p&gt;
, &lt;p&gt;Hi Luc,&lt;/p&gt;

&lt;p&gt;my initial idea was to use an epsilon that is adjusted to the magnitude of the respective value used for comparison. To be honest, I was not aware of &lt;span class="error"&gt;&amp;#91;Math,FastMath&amp;#93;&lt;/span&gt;.ulp, therefore I went with BigReal/BigDecimal to circumvent the problem in another way (by using an arbitrary precision datatype). After reading your comment, I investigated more into the problem, e.g. using &lt;a href="http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm"&gt;http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm&lt;/a&gt;, and addressed it (hopefully correct) in the way you proposed.&lt;/p&gt;

&lt;p&gt;Though, I had to split up the epsilon test into two categories:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;general comparison of floating-point values: using ulp, as values can be arbitrarily small&lt;/li&gt;
	&lt;li&gt;algorithm convergence check: using a standard epsilon, as the algorithm may not converge due to limited precision of&lt;br/&gt;
    the double datatype otherwise&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Please find attached my updated patch, any comments are welcome (e.g. I was unsure whether to expose the maxUlps parameter in the constructor, or to use a generic comparison epsilon, e.g. using FastMath.ulp(1d) instead of one adjusted to the current value in question).&lt;/p&gt;
, &lt;p&gt;updated patch, incorporating comments from luc&lt;/p&gt;
, &lt;p&gt;&lt;span class="error"&gt;&amp;#91;Pardon the possibly nave questions.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In "SimplexTableau":&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Why not use directly "equals(double, double, int)" from "MathUtils" instead of computing an epsilon with "getEpsilon"?&lt;/li&gt;
	&lt;li&gt;Why is the "isOptimal" method not using the adjusted "epsilon" (at line 385)?&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;hmm, I feel a bit stupid now, as I have re-implemented MathUtils.equals(double, double, int) but in a mediocre way. So all calls to getEpsilon should be replaced with the equivalent MathUtils.equals.&lt;/p&gt;

&lt;p&gt;for the isOptimal:&lt;/p&gt;

&lt;p&gt;the idea was to have a user-defined threshold for the convergence criteria, which defaults to the original value of 1e-6. Using the same adjusted epsilon would possibly lead to more iterations as before. As the feasibility check in SimplexSolver.solvePhase1 has to use a static epsilon for convergence reasons, I thought to use the same epsilon in isOptimal makes sense for symmetry reasons (use the same epsilon to check for convergence /feasibility).&lt;/p&gt;

&lt;p&gt;But it's good that you raise these points, because I was hesitating myself what is the best way to go forward, as I am also not considering myself a floating-point expert. I am mainly interested in the simplex algorithm, that's why I have chosen to provide a patch for this (very nice) implementation of it.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1090656.&lt;br/&gt;
Path applied with a very small change: adding the maxUlps parameter to the detailed constructor.&lt;/p&gt;

&lt;p&gt;Thanks for the report and thanks for the patch.&lt;/p&gt;
, &lt;p&gt;Thanks for accepting the patch. The comparison using maxUlps has already been adapted according to &lt;a href="https://issues.apache.org/jira/browse/MATH-557" title="add a compareTo method to MathUtils that use a number of ulps for equality tolerance"&gt;&lt;del&gt;MATH-557&lt;/del&gt;&lt;/a&gt;, but it was missing for SimplexTableau. The cleanup patch fixes this and also renames the test names for similarity.&lt;/p&gt;
, &lt;p&gt;Cleanup patch applied.&lt;/p&gt;

&lt;p&gt;thanks again&lt;/p&gt;
], resolution=Fixed, reporter=wmwitzel, assignees=[], commentAuthors=[wmwitzel, erans, psteitz, bmccann, tn, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:13,981 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-429
2016-01-13 22:10:13,981 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-429, created=Fri Oct 22 10:01:54 CEST 2010, updated=Wed Mar 23 21:25:46 CET 2011, resolved=Sat Oct 23 21:35:26 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Blocker, summary=KMeansPlusPlusClusterer breaks by division by zero, link=https://issues.apache.org/jira/browse/MATH-429, description=&lt;p&gt;For a certain space, KMeansPlusPlusClusterer  breaks. This is a blocker because this space occurs in our domain. &lt;/p&gt;, comments=[&lt;p&gt;The testcase which breaks KMeansPlusPlusClusterer&lt;/p&gt;
, &lt;p&gt;You have encountered one classical problem with k-means: at some stage (here at the first iteration), one of the clusters becomes empty.&lt;br/&gt;
This case is currently no handled by commons-math (which is a bug, so we have to fix it).&lt;br/&gt;
When a cluster is empty, a new centroid must be defined from the other clusters. There are different strategies:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;take the point farthest from any cluster&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest distance variance&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest number of points&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;My prefered choice would be 2, what do other people think ?&lt;/p&gt;
, &lt;p&gt;How about make it configurable?  Take a look at how the Mallet project did it:&lt;/p&gt;

&lt;p&gt;&lt;a href="http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html"&gt;http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By the way, I have suggested that they try to enter the Incubator here at the ASF and they seem somewhat receptive to the idea!&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1026666 for branche 2.X and as of r1026667 for trunk.&lt;br/&gt;
Users can now choose among four different strategies to deal with empty clusters:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;split the cluster with largest distance variance,&lt;/li&gt;
	&lt;li&gt;split the cluster with largest number of points,&lt;/li&gt;
	&lt;li&gt;create a cluster around the point farthest from its centroid,&lt;/li&gt;
	&lt;li&gt;generate an error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The default is to split according to largest variance.&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erikvaningen, assignees=[], commentAuthors=[erikvaningen, luc, jwcarman], timeEstimate=180, timeSpent=null]
2016-01-13 22:10:14,215 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-421
2016-01-13 22:10:14,231 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-421, created=Wed Sep 29 20:24:56 CEST 2010, updated=Wed Mar 23 21:23:12 CET 2011, resolved=Wed Sep 29 21:51:49 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=restarting an ODE solver that has been stopped by an event doesn't work, link=https://issues.apache.org/jira/browse/MATH-421, description=&lt;p&gt;If an ODE solver is setup with an EventHandler that return STOP when the even is triggered, the integrators stops (which is exactly the expected behavior).&lt;br/&gt;
If however the user want to restart the solver from the final state reached at the event with the same configuration (expecting the event to be triggered again at a later time), then the integrator may fail to start. It can get stuck at the previous event.&lt;/p&gt;

&lt;p&gt;The occurrence of the bug depends on the residual sign of the g function which is not exactly 0, it depends on the convergence of the first event.&lt;/p&gt;

&lt;p&gt;As this use case is fairly general, event occurring less than epsilon after the solver start in the first step should be ignored, where epsilon is the convergence threshold of the event. The sign of the g function should be evaluated after this initial ignore zone, not exactly at beginning (if there are no event at the very beginning g(t0) and g(t0+epsilon) have the same sign, so this does not hurt ; if there is an event at the very beginning, g(t0) and g(t0+epsilon) have opposite signs and we want to start with the second one. Of course, the sign of epsilon depend on the integration direction (forward or backward).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository, as of r1002827 for branch 2.X and 1002829 for trunk (3.0)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,231 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-414
2016-01-13 22:10:14,231 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-414, created=Tue Aug 31 13:01:44 CEST 2010, updated=Wed Mar 23 21:20:43 CET 2011, resolved=Tue Nov 30 12:57:23 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=ConvergenceException in NormalDistributionImpl.cumulativeProbability(), link=https://issues.apache.org/jira/browse/MATH-414, description=&lt;p&gt;I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.&lt;br/&gt;
For instance in the following code:&lt;/p&gt;

&lt;p&gt;	@Test&lt;br/&gt;
	public void testCumulative() {&lt;br/&gt;
		final NormalDistribution nd = new NormalDistributionImpl();&lt;br/&gt;
		for (int i = 0; i &amp;lt; 500; i++) {&lt;br/&gt;
			final double val = Math.exp&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/information.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt;;&lt;br/&gt;
			try {
				System.out.println("val = " + val + " cumulative = " + nd.cumulativeProbability(val));
			} catch (MathException e) {
				e.printStackTrace();
				fail();
			}&lt;br/&gt;
		}&lt;br/&gt;
	}&lt;/p&gt;

&lt;p&gt;In version 2.0, I get no exception. &lt;/p&gt;

&lt;p&gt;My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.&lt;/p&gt;, comments=[&lt;p&gt;The difference between 2.0 and 2.1 is due to the changes in ContinuedFraction included in the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-282" title="ChiSquaredDistributionImpl.cumulativeProbability &amp;gt; 1"&gt;&lt;del&gt;MATH-282&lt;/del&gt;&lt;/a&gt;.  For very large values, continued fractions are diverging to NaN. The suggested fix will work, but at this point, I wonder if we should just move the top-coding out of the catch - i.e., test the arguments and return 0 or 1 for extreme values without attempting the approximation.&lt;/p&gt;
, &lt;p&gt;I am leaning toward adding top-coding outside of the catch.  Based on the inequality p(Z &amp;gt; t) &amp;lt; exp(-t^2/2) derived in &lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; and Double.MIN_VALUE  = 2^-1074, I get that tail probabilities are not distinguishable from 0 for |t| &amp;gt; 39, so I propose that we top-code at 40 outside the catch.  Appreciate others checking my arithmetic.&lt;/p&gt;

&lt;p&gt;&lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href="http://www.johndcook.com/normalbounds.pdf"&gt;http://www.johndcook.com/normalbounds.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Your suggestion seems good to me.&lt;br/&gt;
I've check exp(-t^2/2) becomes lower than Double.MIN_VALUE/2 (i.e. rounds to 0) when |t|&amp;gt; 38.604&lt;/p&gt;
, &lt;p&gt;Fixed in r1040471&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=gustav.ryd, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=120, timeSpent=null]
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-411
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-411, created=Sun Aug 29 00:14:32 CEST 2010, updated=Wed Mar 23 21:20:06 CET 2011, resolved=Mon Sep 13 04:04:01 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression newSampleData methods inconsistently create / omit intercepts, link=https://issues.apache.org/jira/browse/MATH-411, description=&lt;p&gt;The newSampleData(double[], nrows, ncols) method used in the unit tests adds a unitary column to the design matrix, resulting in an intercept term being estimated among the regression parameters.  The other newSampleData methods do not do this, forcing users to add the column of "1"s to estimate models with intercept.  Behavior should be consistent and users should not have to add the column.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r993574.  Modified multiple regression newSample methods to ensure that by default in all cases, regression models are estimated with intercept terms.  Prior to the fix for this issue,  newXSampleData(double[][]), newSampleData(double[], double[][]) and newSampleData(double[], double[][], double[][]) all required columns of "1's  to be inserted into the x[][] arrays to create a model with an intercept term;while newSampleData(double[], int, int) created a model including an intercept term without requiring the unitary column.  All methods have  been changed to eliminate the need for users to add unitary columns to specify regression models.&lt;/p&gt;

&lt;p&gt;Leaving open until &lt;a href="https://issues.apache.org/jira/browse/MATH-409" title="Multiple Regression API should allow specification of whether or not to estimate intercept term"&gt;&lt;del&gt;MATH-409&lt;/del&gt;&lt;/a&gt; is resolved. &lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-409
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-409, created=Tue Aug 24 11:55:32 CEST 2010, updated=Wed Mar 23 21:19:13 CET 2011, resolved=Mon Sep 13 04:02:43 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression API should allow specification of whether or not to estimate intercept term, link=https://issues.apache.org/jira/browse/MATH-409, description=&lt;p&gt;The OLS and GLS regression APIs should support estimating models including intercepts using design matrices including only variable data.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r996404 (both trunk and 2.x branch)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-408
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-408, created=Mon Aug 23 05:11:23 CEST 2010, updated=Wed Mar 23 21:18:48 CET 2011, resolved=Sun Dec 12 22:49:44 CET 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=GLSMultipleLinearRegression has no nontrivial validation tests, link=https://issues.apache.org/jira/browse/MATH-408, description=&lt;p&gt;There are no non-trivial tests verifying the computations for GLSMultipleLinearRegression.  Tests verifying computations against analytically determined models, R or some other reference package / datasets should be added to ensure that the statistics reported by this class are valid.&lt;/p&gt;, comments=[&lt;p&gt;Added a non-trivial test in r1044935.  While still not really a full verification test, it does at least verify that the GLS impl provided does better than OLS for models with error structure conforming to its covariance matrix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-407
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-407, created=Mon Aug 23 05:07:08 CEST 2010, updated=Wed Mar 23 21:18:29 CET 2011, resolved=Mon Sep 20 03:57:59 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Documentation improvements for multiple regression classes, link=https://issues.apache.org/jira/browse/MATH-407, description=&lt;p&gt;The user guide examples showing how to set up and estimate linear models using OLS and GLS multiple regression need to be updated to reflect changes in the API.  The javadoc for these classes and user guide descriptions also need to be improved to make it clear how to estimate a model with an intercept term.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r998761&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-406
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-406, created=Sat Aug 14 23:57:56 CEST 2010, updated=Wed Mar 23 21:18:04 CET 2011, resolved=Sun Aug 15 00:02:03 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Wrong weight handling in Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-406, description=&lt;p&gt;A comparison with a Fortran version of Levenberg-Marquardt reveals that when observations have different weights, the 2.1 version reaches a value of the function which does not necessary correspond to the minimum&lt;/p&gt;, comments=[&lt;p&gt;Correction patch.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-405
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-405, created=Wed Aug 11 15:24:39 CEST 2010, updated=Wed Mar 23 21:17:42 CET 2011, resolved=Wed Aug 11 15:46:55 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Inconsistent result from Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-405, description=&lt;p&gt;Levenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost&lt;/p&gt;, comments=[&lt;p&gt;Correction patch&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-404
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-404, created=Mon Aug 09 13:44:12 CEST 2010, updated=Sat Mar 24 17:17:04 CET 2012, resolved=Mon Aug 30 15:53:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Confusing interface for "LevenbergMarquardtOptimizer", link=https://issues.apache.org/jira/browse/MATH-404, description=&lt;p&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; which in turn implements &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt;. That interface mandates methods for setting and getting a &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;.&lt;br/&gt;
In v2.1, however, that checker is never used! The convergence check is performed using parameters specific to the Levenberg-Marquardt algorithm. Such circumvention of the superclass interface is confusing and leads to totally unexpected behaviour (such as changing the values of the thresholds of the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; being ineffective).&lt;br/&gt;
In the development version, the default constructor of &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; sets the the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; field to "null" and when such is the case, the behaviour is as in v2.1. Although it is documented, this is still confusing since it is impossible to use &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; through its &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt; interface: When using the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;, one does not know what parameters to use in order to reproduce the results obtained with the LM-specific convergence check (i.e. how to reproduce the result from v2.1).&lt;br/&gt;
Unless I'm missing something, I think that there should be an LM-specific implementation of &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; that, when given the usual relative and absolute thresholds, can perform a check that will give the same result as the currently specific check (when the "checker" field is "null").&lt;/p&gt;, comments=[&lt;p&gt;The problem was identified and discussed as &lt;a href="https://issues.apache.org/jira/browse/MATH-362" title="LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it"&gt;&lt;del&gt;MATH-362&lt;/del&gt;&lt;/a&gt;. It was decided to let both convergence methods available.&lt;/p&gt;

&lt;p&gt;The reason there are two different way is that the Levenberg-Marquardt implementation originally came from Netlib and I kept the way it behaved. I think the general interface with the new generic convergence was set up later and at that time I forgot to implement it properly, so the settings were ignored.&lt;/p&gt;

&lt;p&gt;Reporter of issue 362 explicitly asked to keep the ortho-tolerance setting and this setting does not fit with the general scheme.&lt;/p&gt;
, &lt;p&gt;Sorry I hadn't followed that other report.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was decided to let both convergence methods available. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is &lt;tt&gt;null&lt;/tt&gt; or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;

&lt;p&gt;As explained above, from an OOP point-of-view, it is surprising that a class completely circumvents its base class interface.&lt;br/&gt;
At least one of the following is wrong:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; has a second interface for convergence checking&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; defines the interface for  convergence checking&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; does not fit with the general scheme.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;br/&gt;
Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;

&lt;p&gt;If it is really impossible to fit LM within the hierarchy it currently belongs to, then it should not belong to it, since one cannot leverage the advantages of "interface programming" anyways.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is null or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or LevenbergMarquardtOptimizer needs to be changed and the orthogonality concept be finally discarded.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I know, and I am not happy with this. However, I don't want LevenbergMarquardtOptimizer to be special. It &lt;em&gt;must&lt;/em&gt; fit. We can take the opportunity of a 3.0 major release to fix this problem too, with some incompatible changes. What would you propose for this ?&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;What would you propose for this ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don't know.&lt;/p&gt;

&lt;p&gt;However, it seems that this "non-fitting checker" case is not isolated. I wanted to replace the original check in "BrentOptimizer" (package "optimization.univariate") by a call to an appropriate subclass of "RealConvergenceChecker", but here too there are more values to be considered than those stored in a pair of "RealPointValuePair". The check needs&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the "current" point&lt;/li&gt;
	&lt;li&gt;the points at both interval ends&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;but it does not use the "previous" point.&lt;/p&gt;

&lt;p&gt;So it seems that this also does not fit with the "converged" method of the "RealConvergenceChecker" interface.&lt;/p&gt;

&lt;p&gt;At first sight, I'd say that there should be a more general "ConvergenceChecker" (not existing yet) interface. Maybe using generics...&lt;/p&gt;
, &lt;p&gt;I'm trying to define a more general "ConvergenceChecker" interface. This is an incompatible change.&lt;/p&gt;
, &lt;p&gt;Final resolution is delegated to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-413"&gt;MATH-413&lt;/a&gt;.&lt;/p&gt;
], resolution=Unknown, reporter=erans, assignees=[erans], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,246 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-395
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-395, created=Sun Jul 25 23:26:33 CEST 2010, updated=Wed Mar 23 21:14:58 CET 2011, resolved=Wed Jul 28 14:11:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Bugs in "BrentOptimizer", link=https://issues.apache.org/jira/browse/MATH-395, description=&lt;p&gt;I apologize for having provided a buggy implementation of Brent's optimization algorithm (class "BrentOptimizer" in package "optimization.univariate").&lt;br/&gt;
The unit tests didn't show that there was something wrong, although (from the "changes.xml" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.&lt;br/&gt;
Comparing with an implementation in Python, I could figure out the fixes. I'll modify "BrentOptimizer" and add a test. I also propose to change the name of the unit test class from "BrentMinimizerTest" to "BrentOptimizerTest".&lt;/p&gt;, comments=[&lt;p&gt;Bugs corrected in revision 979257.&lt;br/&gt;
Not resolving yet because the implementation still does not behave as the Python one. I've added a unit test that indicates the discrepancies (with "XXX" markers).&lt;/p&gt;
, &lt;p&gt;Last bug fixed in revision 980032.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;This revision also contains the modifications due to the changes in &amp;quot;AbstractUnivariateRealOptimizer&amp;quot;.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The test comparing with Python has been removed because a tracing of the execution paths (in Python and Java) showed that the remaining discrepancies were due to different values being used for the "golden ratio" constant.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[erans], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-392
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-392, created=Wed Jul 21 20:43:10 CEST 2010, updated=Wed Mar 23 21:13:58 CET 2011, resolved=Sun Aug 22 15:16:29 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=calculateYVariance in OLS/GLSMultipleLinearRegression uses residuals not Y vars, link=https://issues.apache.org/jira/browse/MATH-392, description=&lt;p&gt;Implementation of OLS/GLSMultipleLinearRegression is:&lt;br/&gt;
@Override&lt;br/&gt;
173        protected double calculateYVariance() {
174            RealVector residuals = calculateResiduals();
175            return residuals.dotProduct(residuals) /
176                   (X.getRowDimension() - X.getColumnDimension());
177        }&lt;/p&gt;

&lt;p&gt;This gives variance of residuals not variance of the dependent (Y) variable as the documentation suggests.&lt;/p&gt;, comments=[&lt;p&gt;Thank you for reporting this.  Patches welcome!&lt;/p&gt;
, &lt;p&gt;Can't test a patch as I'm not able to build current repository version:&lt;br/&gt;
math/src/test/java/org/apache/commons/math/optimization/univariate/BrentOptimizerTest.java:&lt;span class="error"&gt;&amp;#91;28,39&amp;#93;&lt;/span&gt; cannot find symbol&lt;br/&gt;
symbol  : class SincFunction&lt;/p&gt;

&lt;p&gt;Implementation for both GLS/OLS:&lt;/p&gt;

&lt;p&gt;protected double calculateYVariance() {
    return new Variance().evaluate(Y);
}&lt;/p&gt;
, &lt;p&gt;There was an error in a file committed this afternoon. It should be OK now.&lt;/p&gt;
, &lt;p&gt;corrected implementations of calculateYVariance() for OLS/GLSMultipleRegression&lt;/p&gt;

&lt;p&gt;added unit tests for both calculateYVariance implementations&lt;/p&gt;

&lt;p&gt;fixed AbstractMultipleRegression.estimateRegressionParametersStandardErrors() to use residuals &lt;/p&gt;
, &lt;p&gt;Fixed in 987897.   I added calcluate/estimateErrorVariance methods to return what was previously incorrectly reported as "Y variance."&lt;br/&gt;
Thanks for the patch!&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=markdevaney, assignees=[], commentAuthors=[psteitz, markdevaney, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-391
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-391, created=Wed Jul 21 10:57:46 CEST 2010, updated=Wed Mar 23 21:13:27 CET 2011, resolved=Sun Oct 03 18:43:11 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Inconsistent behaviour of constructors in ArrayRealVector class, link=https://issues.apache.org/jira/browse/MATH-391, description=&lt;p&gt;ArrayRealVector(double[] d) allows to construct a zero-length vector, but ArrayRealVector(double[] d, boolean copyArray) doesn't. Both should allow this as zero-length vectors are mathematically well-defined objects and they are useful boundary cases in many algorithms.&lt;/p&gt;

&lt;p&gt;This breaks some arithmetic operators (addition) on zero-length real vectors which worked in 2.0 but don't work in 2.1&lt;/p&gt;, comments=[&lt;p&gt;I agree that the code should be consistent.  I agree as well that a zero-dimensional vector is legit.   Can anyone explain why ArrayRealVector(double[] d, boolean copyArray) requires positive length?&lt;/p&gt;
, &lt;p&gt;Most probably my bad ...&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1003993 for barnch 2.X and r1003994 for trunk.&lt;br/&gt;
Note that the same problem occurred also in ArrayFieldVector but the fix is different. For Field-based vectors, we need to get the field, so either we use a non-empty array and retrieve the field from the first array element or we add a parameter for the field and allow the array to be empty. The two choices are now possible, as new constructors have been added and the javadoc updated to explain this behavior.&lt;br/&gt;
Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-390
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-390, created=Wed Jul 21 00:47:21 CEST 2010, updated=Wed Jul 21 01:32:12 CEST 2010, resolved=Wed Jul 21 01:32:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Major, summary=Simplex Solver is very inaccurate on a large problem, even a very low value for epsilon, link=https://issues.apache.org/jira/browse/MATH-390, description=&lt;p&gt;I'm currently playing with a program for solving a rather simple chess puzzle. The goal is to place 12 knights on a 8x8 board, such that each field is either attacked by a knight, or contains a knight. To solve this problem (and different variants) I want to use a handcrafted Branch and Bound algorithm that uses Linear Programming to calculate an upperbound on the number of fields that can be covered by a certain amount of knights.&lt;/p&gt;

&lt;p&gt;The idea is to create variables for each field that has to be covered, and to create variables for each field to contain a knight. A cover variable can only become positive if a corresponding knight variable for an adjacent field is also positive, there is a limit to the amount of knights we may place (so the sum of all knight variables cannot be larger than 12) and the cover variables cannot be larger than one. Also, only the cover variables have a coefficient of one in the objective function, all other variables have zero. Because we want to cover the entire board our goal will be to maximize the objective function, since we want to maximize the number of fields that are covered.&lt;/p&gt;

&lt;p&gt;Since a basic chessboard has 64 fields and since it is possible to cover the chessboard with 12 knights, we know there is an integer solution that has value 64. Since we are solving a relaxed variant of the problem, the value should be at least 64. However, when I use the Simplex Solver, I get a value of around 58.6, which is much too low. Even when I relax the constraints in such a fashion that 64 knights may be placed on the board, the solution value remains the same. I've lowered the value of epsilon as much as I can and it still gives the incorrect value. What makes it worse is that the calculation is totally useless as an upperbound (if the value would have been around 70, it would have been an upperbound at least).&lt;/p&gt;

&lt;p&gt;I've heard that using the revised simplex method is a lot better with respect to stacked errors, so I am not sure this is really a bug, or just a problem that arises when the two phase simplex method is used for large problems.&lt;/p&gt;

&lt;p&gt;I will try to attach a code example that implements the problem (but possibly isn't that readable).&lt;/p&gt;, comments=[&lt;p&gt;Example of the 8x8 Knight covering Chess problem. The objective value should at least be 64, but it is around 59.&lt;/p&gt;
, &lt;p&gt;Hmm, it seems I made a programming mistake in the type of the relationship: I used an equality where I should have used a greater-equals. I created a much nicer version of the example, which actually works. Feel free to use it for an example or something.&lt;/p&gt;

&lt;p&gt;My bad, I will close the issue.&lt;/p&gt;
, &lt;p&gt;The correct and more readable example, which actually works.&lt;/p&gt;
, &lt;p&gt;It seems I made a programming error. I included a correct example to solve the problem.&lt;/p&gt;
], resolution=Fixed, reporter=pcbouman, assignees=[], commentAuthors=[pcbouman], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-380
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-380, created=Thu Jun 24 18:47:54 CEST 2010, updated=Sat Mar 24 17:16:33 CET 2012, resolved=Sat Oct 01 15:54:20 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Minor, summary=Need to (re)initialize dYdY0 for multiple integrate with FirstOrderIntegratorWithJacobians, link=https://issues.apache.org/jira/browse/MATH-380, description=&lt;p&gt;There is a lack in the method integrate of FirstOrderIntegratorWithJacobians. The jacobian DYDY0 can't be initialized by the user, unlike DFDP with DF0DP.&lt;br/&gt;
So, for several successive integrations, the matrix is reinitialized to identity and that is not what we might want.&lt;/p&gt;, comments=[&lt;p&gt;You are perfectly right.&lt;/p&gt;

&lt;p&gt;The FirstOrderIntegratorWithJacobians class is a brand new one and it clearly has some design flaws.&lt;br/&gt;
It will most probably be deprecated in its current form and replaced by a new mechanism, better integrated (sorry for the joke) with the standard ODE solvers.&lt;br/&gt;
The ability for user to set an initial value for dydy0 will be present in the new design, but will probably not be back-ported to the current one.&lt;br/&gt;
In the meantime, you can save the final value of the jacobian matrix dydy0 after first part of integration, which we could call dy1dy0 as it represents dy(t1)/dy(t0). Start the second part from t1 to t2 that will reset the initial matrix to identity and hence compute compute dy(t2)/dy(t1) and do the multiplication by yourself of the two matrices to really get what you need: dy(t2)/dy(t1) = dy(t2)/dy(t1) * dy(t1)/dy(t0).&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue &lt;/p&gt;
, &lt;p&gt;changing target fix version to 3.0.&lt;br/&gt;
Fixing this and several other problems requires a complete rewrite of the jacobians computation with ODE, and this rewrite implies user interfaces changes, so it cannot be fixed before 3.0.&lt;/p&gt;
, &lt;p&gt;A first attempt to implement Jacobians computation again in ODE has been committed in subversion repository as of r1175409.&lt;br/&gt;
This implementation still lacks the ability for step handlers to also retrieve the additional equations and their derivatives.&lt;br/&gt;
This implementation is based on the Orekit one described here: &lt;a href="https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf"&gt;https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1176745.&lt;/p&gt;
], resolution=Fixed, reporter=pparraud, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,262 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-377
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-377, created=Thu Jun 17 11:06:03 CEST 2010, updated=Wed Mar 23 21:08:36 CET 2011, resolved=Sun Jul 25 21:49:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=weight versus sigma in AbstractLeastSquares, link=https://issues.apache.org/jira/browse/MATH-377, description=&lt;p&gt;In AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.&lt;/p&gt;

&lt;p&gt; Once corrected, getRMS() can even reduce&lt;/p&gt;

&lt;p&gt; public double getRMS() {return Math.sqrt(getChiSquare()/rows);}&lt;/p&gt;, comments=[&lt;p&gt;It is not clear to me exactly what is being computed in getChiSquare.  Step 0 is to get an actual definition in the javadoc for what it is trying to compute.  I agree it seems odd to be dividing by residual weights; but I could be missing the intent.&lt;/p&gt;
, &lt;p&gt;OK, let us define ChiSquare as the sum of the weighted square of the residual in order to be consistent with the rest of the definitions in that class.  That would also be consistent with what users expect from a parameter labeled 'weight' rather than 'sigma'.  If we reach consensus on that definition, I can take care of that issue.&lt;/p&gt;
, &lt;p&gt;I could be missing something, but I see no reason that the weighted sum of squared residuals computed here (after the proposed change) should in general follow a chi-square distribution or be related to a chi-square test statistic of any kind.   Why is it called chi-square?  Sorry if I am missing something simple here.&lt;/p&gt;
, &lt;p&gt;I guess if you assume normalliy distributed errors, it makes sense, so drop the last comment and I am +1 for the change (with definition added to the javadoc).&lt;/p&gt;
, &lt;p&gt;Indeed, the confusion comes from the fact that, in some textbooks, each residual is divided by 'sigma_i' which leads to a weight of 1/(sigma_i^2).  In CM, we adopted the terminology 'weight' without reference to sigma.  I will change the javadoc accordingly.&lt;/p&gt;
, &lt;p&gt;Patch to correct issue &lt;a href="https://issues.apache.org/jira/browse/MATH-377" title="weight versus sigma in AbstractLeastSquares"&gt;&lt;del&gt;MATH-377&lt;/del&gt;&lt;/a&gt;.  The change in getChiSquare let to a tiny update in one of Levenberg-Marquardt unit tests.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[psteitz, dimpbx, luc], timeEstimate=1, timeSpent=null]
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-373
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-373, created=Mon Jun 07 16:54:00 CEST 2010, updated=Sat Mar 24 17:16:56 CET 2012, resolved=Thu Sep 02 06:52:33 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=StatUtils.sum returns NaN for zero-length arrays, link=https://issues.apache.org/jira/browse/MATH-373, description=&lt;p&gt;StatUtils.sum returns NaN for zero-length arrays, which is:&lt;/p&gt;

&lt;p&gt;1. inconsistent with the mathematical notion of sum: in maths, sum_{i=0}^{N-1} a_i will be 0 for N=0. In particular, the identity&lt;br/&gt;
&lt;br/&gt;
sum_{i=0}^{k-1} a_i + sum_{i=k}^{N-1} = sum_{i=0}^{N-1}&lt;/p&gt;

&lt;p&gt;is broken for k = 0, since NaN + x = NaN, not x.&lt;/p&gt;

&lt;p&gt;2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition, as NaNs propagate silently and require manual tracing during the debugging)&lt;/p&gt;

&lt;p&gt;3. enforces "special case" handling when the user expects that the summed array can have a zero length.&lt;/p&gt;

&lt;p&gt;The correct behaviour is, in my opinion, to return 0.0, not NaN in the above case.&lt;/p&gt;, comments=[&lt;p&gt;I agree with the reasoning here, and we should do it this way in 3.0.  However it is an incompatible change to do in a point release, so I'm going to wait for more feed back from other developers before I make any changes to the current code.&lt;/p&gt;

&lt;p&gt;I'm thinking that adding a method to AbstractUnivariateStatistic that looks like:&lt;br/&gt;
   protected boolean test( final double[] values,  final int begin,   final int length, final boolean allowEmpty)&lt;/p&gt;

&lt;p&gt;that would have the test:&lt;br/&gt;
   if(length == 0 &amp;amp;&amp;amp; !allowEmpty)&lt;br/&gt;
        return false;&lt;/p&gt;

&lt;p&gt;The current test method can call the new one with allowEmpty=false for backwards compatibility.  Then we can decide on which statistics should have a zero value on the empty set.&lt;/p&gt;
, &lt;p&gt;The consensus of the commons-math developers is that, since the current behavior is documented in 2.x, that this will have to wait for 3.0.  Fixing this in 2.x would introduce a too large incompatibility change to include in 2.x.&lt;/p&gt;

&lt;p&gt;I can attach a patch against 2.x that fixes this, as long as anybody using the patch understands that it isn't supported.&lt;/p&gt;

, &lt;p&gt;Possibly crazy idea: &lt;/p&gt;

&lt;p&gt;if Math 3.0 is going to change package names (which may be necessary), one could introduce the fix using a math3 package name?&lt;/p&gt;
, &lt;p&gt;IIRC, changing the package name had been suggested and discussed for 2.0.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;One argument is that, to be consistent,  you&amp;#39;d have to change the name at every major release...&amp;#93;&lt;/span&gt;&lt;/p&gt;
, &lt;p&gt;Speaking as a maintainer of client code which uses ACM, I'd rather cope with occasional incompatibilities in the same packages, than have to change ALL my client code to keep up with the package name changes after every release. A reason to change the package name would be if you wanted to use the old and new version side by side, but that would not be a common usage pattern for ACM, I think.&lt;/p&gt;
, &lt;p&gt;As Gilles mentioned, changing the package name for commons-math was discussed and voted on for 2.x.  The result of the vote was to keep the package name, since commons-math won't usually be provided by a third party library.  Since nothing much has changed, I can't see that commons-math would change it's package for version 3.0.&lt;/p&gt;
, &lt;p&gt;This will be fixed in the 3.0 build.&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[billbarker, sebb@apache.org, erans, rwerp], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-369
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-369, created=Mon May 03 17:48:27 CEST 2010, updated=Wed Mar 23 21:05:06 CET 2011, resolved=Mon May 03 20:43:59 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Minor, summary=BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException, link=https://issues.apache.org/jira/browse/MATH-369, description=&lt;p&gt;Method &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  &lt;/p&gt;

&lt;p&gt;invokes &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(double min, double max) &lt;/p&gt;

&lt;p&gt;which throws NullPointerException, as member variable&lt;/p&gt;

&lt;p&gt;    UnivariateRealSolverImpl.f &lt;/p&gt;

&lt;p&gt;is null.&lt;/p&gt;

&lt;p&gt;Instead the method:&lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)&lt;/p&gt;

&lt;p&gt;should be called.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;/p&gt;

&lt;p&gt;invoke:&lt;/p&gt;

&lt;p&gt;     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);&lt;/p&gt;

&lt;p&gt;NullPointerException will be thrown.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository as of r940565.&lt;br/&gt;
Thanks for the report and for the fix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sasunpundev@abv.bg, assignees=[], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-368
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-368, created=Thu Apr 29 05:41:10 CEST 2010, updated=Wed Mar 23 21:04:17 CET 2011, resolved=Mon May 10 01:07:24 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=OpenMapRealVector.getSparcity should be getSparsity, link=https://issues.apache.org/jira/browse/MATH-368, description=&lt;p&gt;The term for describing the ratio of nonzero elements to zero elements in a matrix/vector is sparsity, not sparcity.  Suggest renaming getSparcity() to getSparsity()&lt;/p&gt;, comments=[&lt;p&gt;The policy of this project is to not remove methods from the public API in a point release.  However, the misspelled method has been deprecated and the correctly spelled method has been added.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-367
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-367, created=Thu Apr 22 20:31:06 CEST 2010, updated=Wed Mar 23 21:03:42 CET 2011, resolved=Mon May 10 03:17:14 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=AbstractRealVector.sparseIterator fails when vector has exactly one non-zero entry, link=https://issues.apache.org/jira/browse/MATH-367, description=&lt;p&gt;The following program:&lt;br/&gt;
===&lt;br/&gt;
import java.util.Iterator;&lt;br/&gt;
import org.apache.commons.math.linear.*;&lt;/p&gt;

&lt;p&gt;public class SparseIteratorTester&lt;br/&gt;
{&lt;br/&gt;
    public static void main(String[] args) {&lt;br/&gt;
        double vdata[] = { 0.0, 1.0, 0.0 };&lt;br/&gt;
        RealVector v = new ArrayRealVector(vdata);&lt;br/&gt;
        Iterator&amp;lt;RealVector.Entry&amp;gt; iter = v.sparseIterator();&lt;br/&gt;
        while(iter.hasNext()) {
            RealVector.Entry entry = iter.next();
            System.out.printf("%d: %f\n", entry.getIndex(), entry.getValue());
        }   &lt;br/&gt;
    }       &lt;br/&gt;
} &lt;br/&gt;
===&lt;br/&gt;
generates this output:&lt;/p&gt;

&lt;p&gt;1: 1.000000&lt;br/&gt;
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: -1&lt;br/&gt;
	at org.apache.commons.math.linear.ArrayRealVector.getEntry(ArrayRealVector.java:995)&lt;br/&gt;
	at org.apache.commons.math.linear.AbstractRealVector$EntryImpl.getValue(AbstractRealVector.java:850)&lt;br/&gt;
	at test.SparseIteratorTester.main(SparseIteratorTester.java:13)&lt;br/&gt;
===&lt;/p&gt;

&lt;p&gt;This patch fixes it, and simplifies AbstractRealVector.SparseEntryIterator  (sorry, i don't see any form entry for attaching a file)&lt;br/&gt;
===&lt;br/&gt;
Index: src/main/java/org/apache/commons/math/linear/AbstractRealVector.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(revision 936985)&lt;br/&gt;
+++ src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(working copy)&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.commons.math.linear;&lt;/p&gt;

&lt;p&gt; import java.util.Iterator;&lt;br/&gt;
+import java.util.NoSuchElementException;&lt;/p&gt;

&lt;p&gt; import org.apache.commons.math.FunctionEvaluationException;&lt;br/&gt;
 import org.apache.commons.math.MathRuntimeException;&lt;br/&gt;
@@ -875,40 +876,25 @@&lt;br/&gt;
         /** Dimension of the vector. */&lt;br/&gt;
         private final int dim;&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Temporary entry (reused on each call to {@link #next()}. */&lt;/li&gt;
	&lt;li&gt;private EntryImpl tmp = new EntryImpl();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;/** Current entry. */&lt;br/&gt;
+        /** Last entry returned by #next(). */&lt;br/&gt;
         private EntryImpl current;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Next entry. */&lt;br/&gt;
+        /** Next entry for #next() to return. */&lt;br/&gt;
         private EntryImpl next;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** Simple constructor. */&lt;br/&gt;
         protected SparseEntryIterator() {&lt;br/&gt;
             dim = getDimension();&lt;br/&gt;
             current = new EntryImpl();&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (current.getValue() == 0) {
-                advance(current);
-            }&lt;/li&gt;
	&lt;li&gt;if(current.getIndex() &amp;gt;= 0){
-                // There is at least one non-zero entry
-                next = new EntryImpl();
-                next.setIndex(current.getIndex());
+            next = new EntryImpl();
+            if(next.getValue() == 0)
                 advance(next);
-            } else {
-                // The vector consists of only zero entries, so deny having a next
-                current = null;
-            }&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Advance an entry up to the next non null one.&lt;br/&gt;
+        /** Advance an entry up to the next nonzero value.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param e entry to advance&lt;br/&gt;
          */&lt;br/&gt;
         protected void advance(EntryImpl e) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (e == null) {
-                return;
-            }&lt;br/&gt;
             do {
                 e.setIndex(e.getIndex() + 1);
             } while (e.getIndex() &amp;lt; dim &amp;amp;&amp;amp; e.getValue() == 0);&lt;br/&gt;
@@ -919,22 +905,17 @@&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;br/&gt;
         public boolean hasNext() {
-            return current != null;
+            return next.getIndex() &amp;gt;= 0;
         }&lt;br/&gt;
 &lt;br/&gt;
         /** {@inheritDoc} */&lt;br/&gt;
         public Entry next() {&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;tmp.setIndex(current.getIndex());&lt;/li&gt;
	&lt;li&gt;if (next != null) {&lt;/li&gt;
	&lt;li&gt;current.setIndex(next.getIndex());&lt;/li&gt;
	&lt;li&gt;advance(next);&lt;/li&gt;
	&lt;li&gt;if (next.getIndex() &amp;lt; 0) {
-                    next = null;
-                }&lt;/li&gt;
	&lt;li&gt;} else {
-                current = null;
-            }&lt;/li&gt;
	&lt;li&gt;return tmp;&lt;br/&gt;
+            int index = next.getIndex();&lt;br/&gt;
+            if(index &amp;lt; 0)&lt;br/&gt;
+                throw new NoSuchElementException();&lt;br/&gt;
+            current.setIndex(index);&lt;br/&gt;
+            advance(next);&lt;br/&gt;
+            return current;&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;/p&gt;, comments=[&lt;p&gt;patch fixing the bug&lt;/p&gt;
, &lt;p&gt;I've applied your patch (with a couple of style tweaks).  It should be available in the next release of commons-math.&lt;/p&gt;

&lt;p&gt;Thank you for your contribution.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[ashuang, billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-365
2016-01-13 22:10:14,277 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-365, created=Tue Apr 20 16:21:20 CEST 2010, updated=Wed Mar 23 21:02:52 CET 2011, resolved=Wed Apr 21 16:35:53 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=Issue with "SmoothingBicubicSplineInterpolator", link=https://issues.apache.org/jira/browse/MATH-365, description=&lt;p&gt;I figured out that the name of this class is misleading as the implementation doesn't perform the intended smoothing.&lt;/p&gt;

&lt;p&gt;In order to solve this issue, I propose to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;deprecate the "SmoothingBicubicSplineInterpolator" class&lt;/li&gt;
	&lt;li&gt;create a "BicubicSplineInterpolator" class (similar to the above class but with the useless code removed)&lt;/li&gt;
	&lt;li&gt;remove the "SmoothingBicubicSplineInterpolatorTest" class&lt;/li&gt;
	&lt;li&gt;add a "BicubicSplineInterpolatorTest" with essentially the same contents as the above one&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Then I would also add a new "SmoothingPolynomialBicubicSplineInterpolator" where I used the "PolynomialFitter" class to smooth the input data along both dimensions before the interpolating function is computed.&lt;/p&gt;

&lt;p&gt;Does someone object to these changes?&lt;/p&gt;, comments=[&lt;p&gt;removing the test class would badly impact test coverage, so it would be better to simply deprecae it also and to remove the library class and its associated test class together when releasing 3.0&lt;/p&gt;
, &lt;p&gt;revision 936295.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,683 : INFO  : KNIME-Worker-1 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:2 : Transforming to jira entries.
2016-01-13 22:10:14,683 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-724
2016-01-13 22:10:14,699 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-724, created=Mon Dec 12 16:03:41 CET 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Tue Dec 20 22:14:16 CET 2011, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=RandomDataImpl.nextInt does not distribute uniformly for negative lower bound, link=https://issues.apache.org/jira/browse/MATH-724, description=&lt;p&gt;When using the RandomDataImpl.nextInt function to get a uniform sample in a &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt; interval, when the lower value is less than zero, the output is not uniformly distributed, as the lowest value is practically never returned.&lt;/p&gt;

&lt;p&gt;See the attached NextIntUniformTest.java file. It uses a &lt;span class="error"&gt;&amp;#91;-3, 5&amp;#93;&lt;/span&gt; interval. For several values between 0 and 1, testNextIntUniform1 prints the return value of RandomDataImpl.nextInt (as double and as int). We see that -2 through 5 are returned several times. The -3 value however, is only returned for 0.0, and is thus under-respresented in the integer samples. The output of test method testNextIntUniform2 also clearly shows that value -3 is never sampled.&lt;/p&gt;, comments=[&lt;p&gt;NextIntUniformTest.java: see issue description&lt;/p&gt;
, &lt;p&gt;Thanks for reporting this. The problem is in the rounding, which does not work correctly for negative values.  My first inclination is to test for negative lower bound and just shift the interval in that case.  Any better ideas?&lt;/p&gt;
, &lt;p&gt;math-724.patch: it first scales the [0..1) interval to [0..length), then discretizes it, and finally shifts it to &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;It may be a good idea to also add some tests for cases such as &lt;span class="error"&gt;&amp;#91;0,3&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-5, -3&amp;#93;&lt;/span&gt;, and see if the distribution of sampled values is uniform. It seems RandomDataTest.testNextInt does this using chiSquare, but since I'm not familiar with that, I'm not sure how to add more tests for the other lower/upper bound pairs...&lt;/p&gt;
, &lt;p&gt;I just ran the unit tests with my patch applied, an the following test, in RandomDataTest:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;@Test
    &lt;span class="code-keyword"&gt;public&lt;/span&gt; void testNextIntExtremeValues() {
        &lt;span class="code-object"&gt;int&lt;/span&gt; x = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        &lt;span class="code-object"&gt;int&lt;/span&gt; y = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        Assert.assertFalse(x == y);
    }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails, as does testNextLongExtremeValues. Both x and y become equal to Integer.MIN_VALUE, making x == y to become true, causing the assertion to fail...&lt;/p&gt;
, &lt;p&gt;Also note that RandomDataImpl.nextUniform uses a similar scale/shift method to transform the range. It may thus suffer from the same failure in case of extreme values...&lt;/p&gt;
, &lt;p&gt;math-724-v2.patch: 2nd patch.&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;I think all unit tests work now, including the ones for the Integer.MIN_VALUE to Integer.MAX_VALUE interval.&lt;/li&gt;
	&lt;li&gt;The original problem was that negative values were rounded up by the conversion from double to int, while positive numbers were rounded down. By using floor, we first round the numbers down, and then convert to integer, thus ensuring a proper uniform distribution.&lt;/li&gt;
	&lt;li&gt;Test cases for negative values are still missing... Could someone else add them?&lt;/li&gt;
	&lt;li&gt;RandomDataImpl.nextUniform: I haven't changed this, as the change that I used for integers does not have the desired effect for doubles... This may be caused by the fact that Double.MIN_VALUE is more negative than Double.MAX_VALUE is positive, but I'm not really sure. Maybe it is not even an issue for the nextUniform method?&lt;/li&gt;
&lt;/ul&gt;

, &lt;blockquote&gt;&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; the fact that Double.MIN_VALUE is more negative &lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="http://docs.oracle.com/javase/6/docs/api/java/lang/Double.html#MIN_VALUE"&gt;Double.Min_VALUE&lt;/a&gt; is a &lt;em&gt;positive&lt;/em&gt; number.&lt;/p&gt;
, &lt;blockquote&gt;&lt;p&gt;Double.Min_VALUE is a positive number.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops...&lt;/p&gt;

&lt;p&gt;OK, I uploaded a third version of the patch (math-724-v3.patch), which also applies the new formula for nextUniform. I included two test files (NextUniformTest3.java and NextIntTest3.java), that show the results for nextInt and nextUniform, for both the old and new formulas. As for as I can see, the new formula works equally well or better in all cases. Also, all existing unit tests pass.&lt;/p&gt;
, &lt;p&gt;Thanks for reporting and diagnosing this, Dennis.&lt;/p&gt;

&lt;p&gt;Slightly modified version of the third patch (just removing unecessary parens), along with tests, committed in r1221490.  The "negativeToPositiveRange" tests fail before the fix.  The change to nextUniform is also needed to prevent overflows. I changed the relevant test cases to use the TestUtils chisquare test, which is more straightforward and has better output.  This was added after the original versions of these tests were written.  Others in this class should be similarly updated.  Patches welcome to further tidy the tests, but this issue can be resolved.&lt;/p&gt;
], resolution=Fixed, reporter=dhendriks, assignees=[], commentAuthors=[dhendriks, psteitz, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,699 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-723
2016-01-13 22:10:14,699 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-723, created=Sun Dec 11 22:03:37 CET 2011, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Sun Dec 11 22:59:41 CET 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=BitStreamGenerators (MersenneTwister, Well generators) do not clear normal deviate cache on setSeed, link=https://issues.apache.org/jira/browse/MATH-723, description=&lt;p&gt;The BitStream generators generate normal deviates (for nextGaussian) in pairs, caching the last value generated. When reseeded, the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1213087.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,699 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-719
2016-01-13 22:10:14,699 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-719, created=Tue Dec 06 18:07:24 CET 2011, updated=Sat Mar 24 17:16:38 CET 2012, resolved=Mon Jan 23 12:28:07 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[], priority=Minor, summary=Strange deprecations in API, link=https://issues.apache.org/jira/browse/MATH-719, description=&lt;p&gt;Sorry if this doesn't belong here. I couldn't find any sort of mailing list or other feedback mechanism on the website.&lt;/p&gt;

&lt;p&gt;RealMatrix has some very odd deprecations. In particular inverse(), getDeterminant() and isSingular(). The last has the message:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Deprecated. as of release 2.0, replaced by the boolean negation of new LUDecompositionImpl(m).getSolver().isNonSingular()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's an implementation, not an interface. The whole point of having an interface is that &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I can query whether a matrix is singular withou having to know about LUDecompositions&lt;/li&gt;
	&lt;li&gt;You guys can change the implementation of isSingular() if something better pops up without us guys having to change our code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I'm not using these methods now, because they're deprecated, but I've basically recreated them in as static methods in a utility class. Wouldn't it be much better to just put code from the deprecation message into the method and remove the deprecation?&lt;/p&gt;, comments=[&lt;blockquote&gt;&lt;p&gt;Sorry if this doesn't belong here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Indeed, you'd better bring this kind of issue to the "dev" ML. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
The more so that there have been recent discussions about changing the matrix API and decisions ought to be made quite soon now.&lt;/p&gt;
, &lt;p&gt;Ah, so there is a mailing list. I guess I should have looked a little harder. I'll bring it up there.&lt;/p&gt;
, &lt;p&gt;It is unlikely that we can come up with a new design before the release of v3.0.&lt;br/&gt;
This must be thoroughly discussed first on the "dev" ML, together with other matrix interface issues.&lt;/p&gt;
], resolution=Unknown, reporter=pbloem, assignees=[], commentAuthors=[erans, pbloem], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,699 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-692
2016-01-13 22:10:14,714 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-692, created=Tue Oct 18 20:01:57 CEST 2011, updated=Sat Mar 24 17:16:26 CET 2012, resolved=Thu Feb 02 07:45:59 CET 2012, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 1.3
, 2.0
, 2.1
, 2.2
, 2.2.1
, 3.0
], fixVersion=[3.0
], priority=Minor, summary=Cumulative probability and inverse cumulative probability inconsistencies, link=https://issues.apache.org/jira/browse/MATH-692, description=&lt;p&gt;There are some inconsistencies in the documentation and implementation of functions regarding cumulative probabilities and inverse cumulative probabilities. More precisely, '&amp;lt;' and '&amp;lt;=' are not used in a consistent way.&lt;/p&gt;

&lt;p&gt;Besides I would move the function inverseCumulativeProbability(double) to the interface Distribution. A true inverse of the distribution function does neither exist for Distribution nor for ContinuosDistribution. Thus we need to define the inverse in terms of quantiles anyway, and this can already be done for Distribution.&lt;/p&gt;

&lt;p&gt;On the whole I would declare the (inverse) cumulative probability functions in the basic distribution interfaces as follows:&lt;/p&gt;

&lt;p&gt;Distribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(double x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(double x0, double x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1)&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;inverseCumulativeProbability(double p):&lt;br/&gt;
  returns the quantile function inf{x in R | P(X&amp;lt;=x) &amp;gt;= p} &lt;span class="error"&gt;&amp;#91;see also 2), 3), and 4)&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1) An aternative definition could be P(x0 &amp;lt;= X &amp;lt;= x1). But this requires to put the function probability(double x) or another cumulative probability function into the interface Distribution in order be able to calculate P(x0 &amp;lt;= X &amp;lt;= x1) in AbstractDistribution.&lt;br/&gt;
2) This definition is stricter than the definition in ContinuousDistribution, because the definition there does not specify what to do if there are multiple x satisfying P(X&amp;lt;=x) = p.&lt;br/&gt;
3) A modification could be defined for p=0: Returning sup{x in R | P(X&amp;lt;=x) = 0} would yield the infimum of the distribution's support instead of a mandatory -infinity.&lt;br/&gt;
4) This affects issue &lt;a href="https://issues.apache.org/jira/browse/MATH-540" title="AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug"&gt;&lt;del&gt;MATH-540&lt;/del&gt;&lt;/a&gt;. I'd prefere the definition from above for the following reasons:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;This definition simplifies inverse transform sampling (as mentioned in the other issue).&lt;/li&gt;
	&lt;li&gt;It is the standard textbook definition for the quantile function.&lt;/li&gt;
	&lt;li&gt;For integer distributions it has the advantage that the result doesn't change when switching to "x in Z", i.e. the result is independent of considering the intergers as sole set or as part of the reals.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ContinuousDistribution:&lt;br/&gt;
nothing to be added regarding (inverse) cumulative probability functions&lt;/p&gt;

&lt;p&gt;IntegerDistribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(int x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(int x0, int x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1) above&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;, comments=[&lt;p&gt;Thanks for raising this issue, Christian - especially now as we finalize the 3.0 API.&lt;/p&gt;

&lt;p&gt;I am +1 for these changes.  I agree that the inf-based definition of inverse cum is more standard and we are in a position now make the change, so I say lets do it.  I am also +1 on the move of this up to the distribution interface.  The reason we did not include it there originally was that we thought we might implement distributions for which we could not define inverses.  That has not happened in the last 8 years, so I think its safe enough to push it up.&lt;/p&gt;

&lt;p&gt;The code, test, user guide and doc changes for this have to be done carefully.  Patches most welcome.&lt;/p&gt;

&lt;p&gt;Is everyone else OK with this change?&lt;/p&gt;
, &lt;p&gt;I have neither used nor developed this part of CM, so my view on this is of but little value. Having said that, anything improving consistency can only be desirable, especially at this stage. So I'm all for it, and will be soon available (when I'm done on SYMMLQ) for an (novice on these issues) help.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;+1&lt;/p&gt;
, &lt;p&gt;Thanks for the feedback to all. Sbastien, thanks for offering your help. If you like and find time for it, you could implement AbstractDistribution.inverseCumulativeProbability(double p).&lt;/p&gt;

&lt;p&gt;I will provide some patches next week, but adjusting AbstractContinuousDistribution.inverseCumulativeProbability(double p) will take some more time.&lt;/p&gt;

&lt;p&gt;After thinking a little more about the structure of the interfaces, I'd like to put the function probability(double x) to Distribution anyway (independently of the thought in point 1) above).&lt;/p&gt;

&lt;p&gt;Are there any preferences on P(x0 &amp;lt;= X &amp;lt;= x1) or P(x0 &amp;lt; X &amp;lt;= x1) for cumulativeProbability(double x0, double x1)?&lt;/p&gt;
, &lt;p&gt;I am not sure it is really makes sense to add probability(double x) to the Distribution interface.  It would have to be defined as density (referring to the distribution function) to make sense in the continuous case, since defined as p(X = x) it would in most cases be identically 0 for continuous distributions.&lt;/p&gt;

&lt;p&gt;Regarding the cum definition, I am fine with P(x0 &amp;lt; X &amp;lt;= x1).&lt;/p&gt;
, &lt;p&gt;Happy to help on the inverse cumulative probability. You will have to be patient and forgieving with me, though, as I discover this part of CM.&lt;/p&gt;

&lt;p&gt;As for the definition, I think that one of the bounds should be excluded, so that these cumulative probabilities can be summed&lt;br/&gt;
P(a &amp;lt; X &amp;lt;= c) = P(a &amp;lt; X &amp;lt;= b) + P(b &amp;lt; X &amp;lt;= c),&lt;br/&gt;
even in the case of discrete PDFs.&lt;/p&gt;

&lt;p&gt;Whether the lower or upper bound should be excluded is another matter. I usually work with continuous pdfs, so I don't know if there is a common practice in the probability community. If there is none, I would tend to chose the following definition&lt;br/&gt;
P(x0 &amp;lt;= X &amp;lt; x1)&lt;br/&gt;
(sorry Phil!), because it would be consistent with the way things are usually indexed in java (a&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;.. a&lt;span class="error"&gt;&amp;#91;a.length-1&amp;#93;&lt;/span&gt;). See also &lt;tt&gt;org.apache.commons.math.util.MultidimensionalCounter&lt;/tt&gt;. Although this type of consistency is not an absolute requirement, I think it is nice for the user to have such simple principle: "lower bound always included, upper bound always excluded". Appart from this small point, I really have no objection to any choice.&lt;/p&gt;
, &lt;p&gt;Have a look at the default implementation of cum(x0,x1) now in AbstractDistribution.  I think the incorrectness in the documentation there may have been what triggered Christian to raise this issue.  The equation cum(a,b) = F(b) - F(a) where F is the distribution function is natural and what the impl there is trying to do.  In the discrete case, this equation fails, however, unless you define the cum to exclude the &lt;b&gt;lower&lt;/b&gt; endpoint.  That's why P(x0 &amp;lt; X &amp;lt;= x1) is a better definition.&lt;/p&gt;
, &lt;p&gt;OK, Phil, it makes perfect sense.&lt;/p&gt;
, &lt;p&gt;Good, the definition of cum(x0,x1) will be P(x0 &amp;lt; X &amp;lt;= x1). Phil, you are right: cum(x0,x1) in AbstractDistribution was a reason for raising this issue. Another reason was cum(int x0, int x1) in AbstractIntegerDistribution.&lt;/p&gt;

&lt;p&gt;The idea behind probability(double x) is in fact to define it as p(X = x) and to return 0 for continuous distributions. This function would be useful for discrete distributions not inheriting from IntergerDistribution and for distributions being composed of discrete and continuous parts.&lt;/p&gt;
, &lt;p&gt;I guess I am OK with pushing p&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/error.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt; up.  See related post to follow in commons-dev. &lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
I've started looking into this issue. As I said, you will have to be patient with me &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;.&lt;br/&gt;
I can see there already is a default implementation of &lt;tt&gt;AbstractContinuousDistribution.inverseCumulativeProbability&lt;/tt&gt;. So what exactly would you like me to do? Is this implementation fragile? Would you like me to improve robustness? Provide full testing?&lt;/p&gt;

&lt;p&gt;I think there might be issues when the PDF falls down to zero in a range (in which case the cum exhibits a plateau). The returned value might differ from the mathematical definition you proposed. Is this what you want me to work on? Have you already identified other issues?&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;

&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;

&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;

&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;
, &lt;p&gt;Another point for discussion:&lt;br/&gt;
I'd like to introduce&lt;br/&gt;
getDomainBracket(double p): returns double[]&lt;br/&gt;
to AbstractDistribution as helper function for inverseCumulativeProbability. This allows to avoid searching a bracket where a bracket can be specified directly.&lt;br/&gt;
The function getDomainBracket could be made abstract (which means to remove getInitialDomain, getDomainLowerBound, and getDomainUpperBound as these functions aren't needed any more), or it could have a default implementation (according to the corresponding part of the current implementation of inverseCumulativeProbability) which uses getInitialDomain, getDomainLowerBound, and getDomainUpperBound. However, getInitialDomain, getDomainLowerBound, and getDomainUpperBound should not be abstract in the latter case. Otherwise a derived class would be forced to implement something it potentially doesn't use. Thus the functions getInitialDomain, getDomainLowerBound, and getDomainUpperBound should have default implementations which either return default values (0, -infinity, +infinity) or throw an exception saying something like "has to be implemented".&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I'm working on it...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, for now, I'm concentrating on making the current impl in &lt;tt&gt;AbstractContinuousDistribution&lt;/tt&gt; more robust. The other impl should be easier.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current implementation uses a Brent solver. I think the solver itself is only one side of the issue. The other point is the algorithm used to bracket the solution, in order to ensure that the result is consistent with the definition of the cumprob. As for the &lt;tt&gt;DifferentiableUnivariateRealSolver&lt;/tt&gt;, I'm not too sure. I guess it depends on what is meant by "continuous distribution". For me, it means that the random variable takes values in a continuous set, and possibly its distribution is defined by a density. However, in my view, nothing prevents occurences of Dirac functions, in which case the cum sum is only piecewise C1. It's all a matter of definition, of course, and I'll ask the question on the forum to check whether or not people want to allow for such a situation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I'm very interested.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Please note that &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt; has been created specifically to handle plateaux.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;Here is the first patch for this issue (unfortunately with some delay). It adjusts the distributions with real domain to the definitions in this issue, and it mainly changes documentations.&lt;/p&gt;

&lt;p&gt;I could not move inverseCumulativeProbability(double) up to Distribution because there would be a conflict with IntegerDistribution.inverseCumulativeProbability(double): This method returns int. This problem will be removed by solving issue &lt;a href="https://issues.apache.org/jira/browse/MATH-703" title="Splitting up the distribution hierarchy"&gt;&lt;del&gt;MATH-703&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The implementation of inverseCumulativeProbability(double) is not changed as Sbastien is working on this.&lt;/p&gt;

&lt;p&gt;I will provide the patch for the integer distributions as soon as I have adjusted the test data to the new inequalities and reverified the adjusted test data.&lt;/p&gt;
, &lt;p&gt;All,&lt;br/&gt;
since I'm already working on this package, I'm happy to commit the patch on behalf of Christian. However, since I'm a relatively new committer, I would feel more confident if one of the "old, wise committers" could double check the svn log afterwards.&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hey, that's how it always works &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;  &lt;/p&gt;

&lt;p&gt;I don't know about "wise" but I certainly qualify as "old" by any standard, so will have a look once you have reviewed and committed.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
, &lt;p&gt;Patch &lt;tt&gt;Math-692_realDomain_patch1.patch&lt;/tt&gt; (20111108) applied in rev 1200179, with minor modifications (mostly checkstyle fixes).&lt;br/&gt;
Thanks Christian!&lt;/p&gt;
, &lt;p&gt;As mentioned by Sbastien in &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt;, the implementation of &lt;tt&gt;IntegerDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; can benefit from the ideas which came up for &lt;tt&gt;RealDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; in that thread.&lt;/p&gt;

&lt;p&gt;Thus I will remove &lt;tt&gt;getDomainLowerBound(double p)&lt;/tt&gt; and &lt;tt&gt;getDomainUpperBound(double p)&lt;/tt&gt; from the integer distributions. I checked that all current implementations of the lower/upper bound methods provide the whole support of the distribution as starting bracket. This means that using &lt;tt&gt;getSupportLowerBound()&lt;/tt&gt; and &lt;tt&gt;getSupportUpperBound()&lt;/tt&gt; for the starting bracket won't degrade the performance of the current distribution implementations. However, a user might want the improve the performance of his distribution implementations by providing a more targeted starting bracket for probability &lt;tt&gt;p&lt;/tt&gt;. Thus I will swap the solving step to a protected function &lt;tt&gt;solveInverseCumulativeProbability(double p, int lower, int upper)&lt;/tt&gt;, so that it gets easy to override &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; with an implementation which finds a better starting bracket.&lt;/p&gt;

&lt;p&gt;Furthermore, Phil's idea with Chebyshev's inequality can be applied to the generic implementation of &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; in order to get a better starting bracket.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
If you agree with that, I suggest that you also take care of &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;, as the two issues seem to be very much connected.&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;my changes in the integer distributions don't solve &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;. Instead I found a probably related problem with the Pascal distribution.&lt;/p&gt;

&lt;p&gt;The integer distribution patch for this issue still isn't ready. I will provide it next week.&lt;/p&gt;

&lt;p&gt;Christian&lt;/p&gt;
, &lt;p&gt;This is the patch which adjusts the integer distributions to the agreements above.&lt;/p&gt;

&lt;p&gt;The changes to the test cases for the random generators may be unexpected. But these changes initially were triggered by adjusting &lt;tt&gt;RandomDataTest.checkNextPoissonConsistency(double)&lt;/tt&gt; to the new contract for integer distributions. Then some random generator tests failed due to chance. While adjusting their seeds, I found some other tests with a high failure probability. Thus I also set some failure probabilities to 0.01 in order to find suitable seeds more quickly.&lt;/p&gt;

&lt;p&gt;My next task on this issue is to adjust the user guid.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
thanks for this contribution. I am away for a few days, but am very happy to commit this patch as soon as I am back, if you are not in too much of a hurry.&lt;br/&gt;
Thanks again,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Well, we've recently run into some troubles with SVN, but it seems everything is working fine again. Patch {{&lt;a href="https://issues.apache.org/jira/browse/MATH-692" title="Cumulative probability and inverse cumulative probability inconsistencies"&gt;&lt;del&gt;MATH-692&lt;/del&gt;&lt;/a&gt;_integerDomain_patch1.patch}} (with minor checkstyle changes) committed in revision &lt;tt&gt;1226041&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Please do not forget to run &lt;tt&gt;mvn clean; mvn site:site&lt;/tt&gt; and check the reports (in particular, &lt;tt&gt;checkstyle&lt;/tt&gt;) prior to submitting a patch!&lt;/p&gt;

&lt;p&gt;Thanks for this contribution.&lt;/p&gt;
, &lt;p&gt;The committed patch actually causes failure of &lt;tt&gt;Well1024Test&lt;/tt&gt; in &lt;tt&gt;o.a.c.m.random&lt;/tt&gt;.&lt;/p&gt;
, &lt;p&gt;Thanks for committing the patch, Sbastien. I see you already changed the seed in &lt;tt&gt;Well1024aTest&lt;/tt&gt;. This hopefully removes the failure.&lt;/p&gt;

&lt;p&gt;I'll have a look into Maven to prepare a better patch next time. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;I see you already changed the seed in Well1024aTest.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I did, but is this really how we want &lt;tt&gt;Well2004aTest&lt;/tt&gt; to pass?&lt;/p&gt;
, &lt;p&gt;I guess there is no alternative to this way of making probabilistic test cases pass. However, I understand your bad feeling with this kind of failure fixing. The problem is that probabilistic tests are quiet fuzzy: Neither a passed test nor a failed test provides a clear answer whether something is right or wrong in the implementation. There is just a high chance to pass such a test with a correct implementation. The chance for failure increases with an erroneous implementation due to systematic deviations in the generated data. These chances tell whether it is easy to find a seed which passes the tests or not. Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's exactly the point I've raised on the mailing-list: out of three seeds (100, 1000 and 1001), only one works. Of course, I would not dare to call that representative statistics, but I'm wondering whether or not we should be worried...&lt;/p&gt;
, &lt;p&gt;The issue about selection of an appropriate seed has been raised elsewhere. No definitive answer has been provided so far, so I suggest we consider this issue as solved for the time being.&lt;/p&gt;
], resolution=Fixed, reporter=cwinter, assignees=[], commentAuthors=[psteitz, celestin, mikl, cwinter], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,714 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-654
2016-01-13 22:10:14,714 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-654, created=Tue Aug 30 19:23:19 CEST 2011, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Thu Sep 01 02:14:02 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=ValueServer not deterministic for a fixed random number seed, link=https://issues.apache.org/jira/browse/MATH-654, description=&lt;p&gt;I have built an agent-based model using the Apache Commons Math library, which has come in handy.&lt;/p&gt;

&lt;p&gt;The ValueServer seemed particularly helpful, as explained at:&lt;br/&gt;
&lt;a href="http://commons.apache.org/math/userguide/random.html"&gt;http://commons.apache.org/math/userguide/random.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My simulation needs repeatable randomness, so I used this form of the ValueServer constructor:&lt;/p&gt;

&lt;p&gt;    ValueServer(RandomData randomData) &lt;br/&gt;
    Construct a ValueServer instance using a RandomData as its source of random data.&lt;br/&gt;
    // &lt;a href="http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html"&gt;http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, in my simulation, I found that the ValueServer did not act deterministically if I supplied the same random number seed.&lt;/p&gt;

&lt;p&gt;I have not inspected the source code, but I suspect that the ValueServer is not using the `randomData` generator correctly. If it was, then it should be deterministic.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  I assume you are using DIGEST_MODE.  If this is the case and you are comfortable compiling the code in trunk, the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-634" title="EmpiricalDistributionImpl should use a pluggable RandomGenerator"&gt;&lt;del&gt;MATH-634&lt;/del&gt;&lt;/a&gt; enables a workaround for this.  Using the reseed method added to EmpiricalDistributionImpl in trunk, you can use ValueServer's getEmpiricalDistribution to get the distribution and then invoke reseed.  Unfortunately, this method does not exist in any released version yet.&lt;/p&gt;

&lt;p&gt;The problem is that ValueServer#getNextDigest (what it does for getNext in DIGEST_MODE) delegates to EmpiricalDistributionImpl#getNextValue.  EmpiricalDistributionImpl has its own RandomData instance.  To fix this issue, EmpiricalDistirbutionImpl should add a constructor taking a RandomData and ValueServer should provide this.&lt;/p&gt;
, &lt;p&gt;Fixed in r1163875. ValueServer now exposes a reSeed method that when supplied a fixed seed will generate a fixed sequence in any stochastic mode. The RandomDataImpl that it uses internally is passed to the EmpiricalDistributionImpl it creates when used in DIGEST_MODE.  The changes for this issue include an incompatible (vs. 2.x) change: the constructor for EmpiricalDistributionImpl that previously took a RandomData now takes a RandomDataImpl.  The plan for 3.0 is to merge these.&lt;/p&gt;
], resolution=Fixed, reporter=d.james, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,714 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-640
2016-01-13 22:10:14,714 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-640, created=Tue Aug 02 21:06:35 CEST 2011, updated=Sat Mar 24 17:16:52 CET 2012, resolved=Wed Aug 03 06:17:43 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=AbstractRandomGenerator nextInt() and nextLong() default implementations generate only positive values, link=https://issues.apache.org/jira/browse/MATH-640, description=&lt;p&gt;The javadoc for these methods (and what is specified in the RandomGenerator interface) says that all int / long values should be in the range of these methods.  The default implementations provided in this class do not generate negative values.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1153338&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,714 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-618
2016-01-13 22:10:14,714 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-618, created=Wed Jul 13 22:23:43 CEST 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Thu Jul 14 08:08:54 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same, link=https://issues.apache.org/jira/browse/MATH-618, description=&lt;p&gt;For both Complex add and subtract, the javadoc states that&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;* If either &lt;span class="code-keyword"&gt;this&lt;/span&gt; or &amp;lt;code&amp;gt;rhs&amp;lt;/code&amp;gt; has a NaN value in either part,
     * {@link #NaN} is returned; otherwise Inifinite and NaN values are
     * returned in the parts of the result according to the rules &lt;span class="code-keyword"&gt;for&lt;/span&gt;
     * {@link java.lang.&lt;span class="code-object"&gt;Double&lt;/span&gt;} arithmetic&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1146573&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,714 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-588
2016-01-13 22:10:14,714 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-588, created=Sun Jun 12 20:19:07 CEST 2011, updated=Sat Mar 24 17:16:31 CET 2012, resolved=Sun Feb 05 20:54:50 CET 2012, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Weighted Mean evaluation may not have optimal numerics, link=https://issues.apache.org/jira/browse/MATH-588, description=&lt;p&gt;I recently got this in a test run&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;testWeightedConsistency(org.apache.commons.math.stat.descriptive.moment.MeanTest)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;0.002282165958997601&amp;gt; but was:&amp;lt;0.002282165958997157&amp;gt;
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:441)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:178)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:153)
	at org.apache.commons.math.stat.descriptive.UnivariateStatisticAbstractTest.testWeightedConsistency(UnivariateStatisticAbstractTest.java:170)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The correction formula used to compute the unweighted mean may not be appropriate or optimal in the presence of weights:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// Compute initial estimate using definitional formula
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; sumw = sum.evaluate(weights,begin,length);
&lt;span class="code-object"&gt;double&lt;/span&gt; xbarw = sum.evaluate(values, weights, begin, length) / sumw;

&lt;span class="code-comment"&gt;// Compute correction factor in second pass
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; correction = 0;
&lt;span class="code-keyword"&gt;for&lt;/span&gt; (&lt;span class="code-object"&gt;int&lt;/span&gt; i = begin; i &amp;lt; begin + length; i++) {
  correction += weights[i] * (values[i] - xbarw);
}
&lt;span class="code-keyword"&gt;return&lt;/span&gt; xbarw + (correction/sumw);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;, comments=[&lt;p&gt;Fixed it in r1240790.&lt;/p&gt;

&lt;p&gt;There was a too strict equality test using an relative error of 10-14 which resulted in certain unforunate cases of an absolute error of 10-18.&lt;/p&gt;
, &lt;p&gt;Corrected the equality test in r1240795 as it was leading to failure. In fact the test can range from very small to very large values which really requires a relative error estimate.&lt;/p&gt;

&lt;p&gt;The test is problematic in general, as it may contain values from very different scales (due to its random nature), leading to unavoidable precision errors in the above formula.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[tn], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,683 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-362
2016-01-13 22:10:14,745 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-362, created=Tue Apr 06 13:38:46 CEST 2010, updated=Wed Mar 23 21:02:00 CET 2011, resolved=Sat May 29 20:16:50 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it, link=https://issues.apache.org/jira/browse/MATH-362, description=&lt;p&gt;LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.&lt;/p&gt;, comments=[&lt;p&gt;Ooops. You are right.&lt;br/&gt;
The Levenberg-Marquardt optimizer uses specific convergence parameters which can be set by   setInitialStepBoundFactor, setCostRelativeTolerance, setParRelativeTolerance and setOrthoTolerance.&lt;br/&gt;
The most important convergence tuning are either setCostRelativeTolerance for a convergence on the cost itself or setParRelativeTolerance for a convergence on the parameters.&lt;/p&gt;

&lt;p&gt;I'm not sure how to solve this. Do the existing tuning parameters fit your needs or not ? Some convergence criteria can be expressed with both methods, but not all. Should we keep both setting as alternate methods or should we remove one and rely on the remaining one ?&lt;/p&gt;
, &lt;p&gt;I would keep using orthoTolerance as it is used now:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;292                if (maxCosine &amp;lt;= orthoTolerance) {&lt;br/&gt;
293                    // convergence has been reached&lt;br/&gt;
294                    return new VectorialPointValuePair(point, objective);&lt;br/&gt;
295                }&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;and then use costRelativeTolerance &amp;amp; parRelativeTolerance if and only if the convergence checker is null, otherwise use the convergence checker and ignore {costRelativeTolerance, parRelativeTolerance}.&lt;/p&gt;

&lt;p&gt;What I am missing now is the ability to bail out if the absolute distance from the target falls below some value ("close enough").&lt;/p&gt;
, &lt;p&gt;I've spent that last few days trying to find a good curve fitting library for Java and got excited when I learned of Commons Math.  Unfortunately, its curve fitting is very unreliable.  I'm hoping that this bug is what is causing the problems that I'm seeing.  I'm comparing data from NIST and results from DataFitX and it is apparent that Commons Math is not yet up to the task.  My fingers are crossed that its quality in the curve fitting area will be improved in the near future.  Keep up the good work Apache.&lt;/p&gt;

&lt;p&gt;I've opened an issue about the problems I'm seeing, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Double check how you use it, Matt. I have succesfully used this curve fitting in production.&lt;/p&gt;
, &lt;p&gt;Matt, could you please describe the problem you encounter more precisely (i.e. with numerical examples) and preferably in a new JIRA issue ? We will check if the two problems are related and link the issues afterwards if it appears they are.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
, &lt;p&gt;It's good to see such quick responses.  I'll open a new JIRA issue and spend some time putting together code, data and a detailed description of the problem I'm seeing.  Thanks Apache for all your hard work.&lt;/p&gt;

&lt;p&gt;I've opened an issue regarding the problem, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r949433.&lt;br/&gt;
Thanks for reporting the issue&lt;/p&gt;
, &lt;p&gt;Thank you.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=roman.werpachowski, assignees=[], commentAuthors=[luc, roman.werpachowski, mprice], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,745 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-288
2016-01-13 22:10:14,745 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-575
2016-01-13 22:10:14,761 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-575, created=Sat May 14 18:40:34 CEST 2011, updated=Sat Mar 24 17:16:54 CET 2012, resolved=Thu Feb 02 12:12:52 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=Exceptions in genetics package or not consistent with the rest of [math], link=https://issues.apache.org/jira/browse/MATH-575, description=&lt;p&gt;InvalidRepresentationException is checked and non-localized.  This exception should be placed in the &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; hierarchy.  The AbstractListChromosome constructor also throws a non-localised IAE, which should be replaced by an appropriate &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; exception.&lt;/p&gt;, comments=[&lt;p&gt;Phil started to work on this issue in r1135025.&lt;/p&gt;

&lt;p&gt;In r1235038 additional cleanups have been performed:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;add localized messages for all exceptions&lt;/li&gt;
	&lt;li&gt;add @throws to javadoc where appropriate&lt;/li&gt;
	&lt;li&gt;add final to method parameters&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What is missing:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;Phil mentioned that InvalidRepresentationException should be placed into &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, although I am not sure why, as it is not used outside the genetics package&lt;/li&gt;
	&lt;li&gt;add more custom exception classes specific to the genetics package (optional). By now mostly MathIllegalArgumentException or other appropriate ones have been used.&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;Thanks for working on this, but before you do start to make modifications, please assign the issue to yourself!&lt;/p&gt;

&lt;p&gt;For the changes themselves, I don't agree with the creation of those many localized messages: We have been trying to rationalize and reduce the number of those, by removing duplicates and combining several ones to convey the full explanation of the problem. See my reply to the commit message.&lt;/p&gt;
, &lt;p&gt;Fixed in r1235197.&lt;/p&gt;

&lt;p&gt;Thanks for your suggestions!&lt;/p&gt;
, &lt;p&gt;Thomas,&lt;br/&gt;
Could please check whether this issue is resolved? And if it is, mark it so? Thanks.&lt;/p&gt;
, &lt;p&gt;As from the original issue description, Phil intended to move the InvalidRepresentationException to the general o.a.c.m.exceptions package. I am not sure about this, that's why I kept it aside for the time being. If we agree on keeping it in the genetics package we can resolve this issue.&lt;/p&gt;
, &lt;p&gt;Phil had always been opposed to having all exceptions grouped in their own package; so I doubt that he meant to move that one over there... &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
Here, the description just indicates that the exception should become &lt;em&gt;unchecked&lt;/em&gt; and that the "detailed message" should be an element from the "LocalizedFormats" enum (i.e. derive from one of the base CM exceptions).&lt;/p&gt;
, &lt;p&gt;Ah ok, that makes it clear. When reading hierarchy I was just thinking in terms of packages rather than class hierarchy.&lt;/p&gt;

&lt;p&gt;Thus, I resolve this issue.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[tn], commentAuthors=[tn, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,745 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-288, created=Tue Aug 25 00:31:11 CEST 2009, updated=Wed Apr 14 02:30:17 CEST 2010, resolved=Tue Aug 25 20:10:08 CEST 2009, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.1
], priority=Major, summary=SimplexSolver not working as expected 2, link=https://issues.apache.org/jira/browse/MATH-288, description=&lt;p&gt;SimplexSolver didn't find the optimal solution.&lt;/p&gt;

&lt;p&gt;Program for Lpsolve:&lt;br/&gt;
=====================&lt;br/&gt;
/* Objective function */&lt;br/&gt;
max: 7 a 3 b;&lt;/p&gt;

&lt;p&gt;/* Constraints */&lt;br/&gt;
R1: +3 a -5 c &amp;lt;= 0;&lt;br/&gt;
R2: +2 a -5 d &amp;lt;= 0;&lt;br/&gt;
R3: +2 b -5 c &amp;lt;= 0;&lt;br/&gt;
R4: +3 b -5 d &amp;lt;= 0;&lt;br/&gt;
R5: +3 a +2 b &amp;lt;= 5;&lt;br/&gt;
R6: +2 a +3 b &amp;lt;= 5;&lt;/p&gt;

&lt;p&gt;/* Variable bounds */&lt;br/&gt;
a &amp;lt;= 1;&lt;br/&gt;
b &amp;lt;= 1;&lt;br/&gt;
=====================&lt;br/&gt;
Results(correct): a = 1, b = 1, value = 10&lt;/p&gt;


&lt;p&gt;Program for SimplexSolve:&lt;br/&gt;
=====================&lt;br/&gt;
LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]{7, 3, 0, 0}, 0);&lt;br/&gt;
Collection&amp;lt;LinearConstraint&amp;gt; podmienky = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{1, 0, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 1, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 0, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 0, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 2, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 3, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 2, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 3, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
RealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);&lt;br/&gt;
=====================&lt;br/&gt;
Results(incorrect): a = 1, b = 0.5, value = 8.5&lt;/p&gt;

&lt;p&gt;P.S. I used the latest software from the repository (including &lt;a href="https://issues.apache.org/jira/browse/MATH-286" title="SimplexSolver not working as expected?"&gt;&lt;del&gt;MATH-286&lt;/del&gt;&lt;/a&gt; fix).&lt;/p&gt;, comments=[&lt;p&gt;Thanks for the bug report.  I've confirmed this is an issue.&lt;/p&gt;

&lt;p&gt;Here's a slightly smaller version of the problem that causes the same bug, which might be easier for debugging:&lt;/p&gt;

&lt;p&gt;MAX 7 a + 3 b&lt;br/&gt;
s.t.&lt;br/&gt;
3 a -5 c &amp;lt;= 0&lt;br/&gt;
2 a -5 d &amp;lt;= 0&lt;br/&gt;
3 b -5 d &amp;lt;= 0&lt;br/&gt;
a &amp;lt;= 1&lt;br/&gt;
b &amp;lt;= 1&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 7, 3, 0, 0 }, 0 );&lt;br/&gt;
        Collection&amp;lt;LinearConstraint&amp;gt; constraints = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 3, 0, -5, 0 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 2, 0, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 3, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0 }, Relationship.LEQ, 1.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 0 }, Relationship.LEQ, 1.0));&lt;/p&gt;

&lt;p&gt;        SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
        RealPointValuePair solution = solver.optimize(f, constraints, GoalType.MAXIMIZE, true);&lt;br/&gt;
        assertEquals(10.0, solution.getValue(), .0000001);&lt;/p&gt;
, &lt;p&gt;Patch attached.  It was a 1 character bug.  I was saying to only do the minimum ratio test if the entry is &amp;gt;= 0, but it should have been &amp;gt; 0 (dividing by 0 is never good :o)&lt;br/&gt;
Thanks again for the bug report.&lt;/p&gt;
, &lt;p&gt;resolved in subversion repository as of r807738&lt;br/&gt;
patch applied (except for debug print function)&lt;br/&gt;
thanks for the repoart and thanks for the patch&lt;/p&gt;
], resolution=Fixed, reporter=kefa, assignees=[], commentAuthors=[bmccann, luc], timeEstimate=480, timeSpent=null]
2016-01-13 22:10:14,761 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-555
2016-01-13 22:10:14,777 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-555, created=Mon Apr 04 06:13:04 CEST 2011, updated=Sat Mar 24 17:16:43 CET 2012, resolved=Mon Apr 04 06:53:13 CEST 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=MathUtils round method should propagate rather than wrap Runitme exceptions, link=https://issues.apache.org/jira/browse/MATH-555, description=&lt;p&gt;MathUtils.round(double, int, int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException, the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in trunk in r1088473&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-540
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-540, created=Sun Mar 06 01:43:45 CET 2011, updated=Sat Mar 24 17:16:36 CET 2012, resolved=Sun Jun 12 07:58:50 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug, link=https://issues.apache.org/jira/browse/MATH-540, description=&lt;p&gt;The AbstractIntegerDistribution.inverseCumulativeProbability(...) function attempts to decrement the lower bound of discrete distributions to values that go below the lower bound.&lt;/p&gt;, comments=[&lt;p&gt;I don't think this is a bug.  Per the javadoc, the contract for inverse cum is&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/**
 * For a random variable {@code X} whose values are distributed according
 * to &lt;span class="code-keyword"&gt;this&lt;/span&gt; distribution, &lt;span class="code-keyword"&gt;this&lt;/span&gt; method returns the largest {@code x}, such
 * that {@code P(X &amp;lt; x) &amp;lt; p}.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This implies that if the first non-zero mass point has probability greater than p, the right value to return is one less than that value, which is whet the method will do.  Your example distribution throws NPE when trying to compute probabilities outside of its domain of support. &lt;/p&gt;
, &lt;p&gt;I'm looking at it like this.  I have very simple distribution like the one provided (Four sided dice).  I'm trying to write a simulation that draws values of x for a a set of uniform 0-1 probabilities.  So I'm expecting:&lt;/p&gt;

&lt;p&gt;0 When p is less than or equal to 0.25&lt;br/&gt;
1 When p is greater than 0.25 but less than or equal to 0.50&lt;br/&gt;
2 When p is greater than 0.50 but less than or equal to 0.75&lt;br/&gt;
3 When p is greater than 0.75 but less than or equal to 1.0&lt;/p&gt;

&lt;p&gt;So for the line &lt;/p&gt;

&lt;p&gt;int neverSucceeds = d.inverseCumulativeProbability(0.0001);&lt;/p&gt;

&lt;p&gt;I'm really expecting 0 to be returned.&lt;/p&gt;

&lt;p&gt;Make sense?&lt;/p&gt;
, &lt;p&gt;I see now that there actually does appear to be an error in the javadoc.  The implementation really returns the largest x such that p(X &amp;lt;= x) &amp;lt;= p.  In the discrete case, &amp;lt;= matters and I think both inequalities in the javadoc should be changed.&lt;/p&gt;

&lt;p&gt;In your example, if the probability distribution vanishes outside 0, 1, 2, 3 and puts .25 mass on each of these values, the inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;

&lt;p&gt;If you fix your distribution so that both probability and cumulativeProbability return correct values (rather than throwing NPEs) outside of the mass values, you should get -1 returned.&lt;/p&gt;
, &lt;p&gt;Reading your last comment a little more carefully, it looks like what you are trying to do is implement sampling.  IIUC, something like what you are suggesting should work - you just have an off-by-one problem vis-s-vis the contract of inverse cumulative probabilities as we define them.  I would be +1 for adding direct support for sampling from discrete distributions, but we should open a separate ticket for that.&lt;/p&gt;
, &lt;p&gt;OK - I'll close this one and open a separate ticket.&lt;/p&gt;
, &lt;p&gt;There is a javadoc bug that needs to be fixed here&lt;/p&gt;
, &lt;p&gt;Ooops - Thanks.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;...inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems to me that users would be better served if it returned 0 and that it is also correct to do so.&lt;/p&gt;

&lt;p&gt;In the definition we say "For a random variables X whose values are distributed according to this distribution...".&lt;/p&gt;

&lt;p&gt;Suppose the distribution was for a six sided dice.  One could assert that the distribution is only defined for the values 1,2,3,4,5,6.  In this case the inverseCumulativeDistribution returns 0, but that does not have any meaning.  So now developers are forced to define the meaning of 0 for a six sided dice implementation.  &lt;/p&gt;

&lt;p&gt;In Grad school we were taught the the inverse cumulative distribution is for sampling.  So for a six sided dice uniform probabilities less than 1/6 would return 1, less than 2/6 would return 2, etc.&lt;/p&gt;

&lt;p&gt;With the current implementation for values less than 1/6 we get 0 which is meaningless, and the only time we get 6 is when the uniform probability argument is 1.&lt;/p&gt;

&lt;p&gt;So if someone mistakenly tries to use the inverseCumulativeProbability function for sampling the results are going to be wacked.  What is the use case for the inverseCumulativeProbability the way it is right now?&lt;/p&gt;
, &lt;p&gt;You have a choice in defining the inverse cum whether to define it the way we have or to use and inf rather than a sup.  We can implement sampling using the current impl.  We just need to take into account the way the inverse cum is defined in AbstractIntegerDistribution.  &lt;/p&gt;
, &lt;p&gt;OK - I think it's starting to make more sense to me now.  So when implementing sampling we just add one to the value returned by inverseCumulativeDistribution, unless the uniform probability argument is 1?&lt;/p&gt;
, &lt;p&gt;I am sorry.  I forgot that we had in fact already implemented this in version 2.2. See AbstractIntegerDistribution#sample.  The base class implementation delegates to RandomDataImpl#nextInversionDeviate (adding one per the last comment).&lt;/p&gt;
, &lt;p&gt;Sorry for the noise. I closed the wrong ticket.  Still need to fix the javadoc to match behavior and user guide.&lt;/p&gt;
, &lt;p&gt;Javadoc fixed in trunk r1134866&lt;/p&gt;
], resolution=Fixed, reporter=ole, assignees=[], commentAuthors=[psteitz, ole], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-506
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-506, created=Tue Feb 01 19:38:01 CET 2011, updated=Sat Mar 24 17:16:41 CET 2012, resolved=Sat Aug 20 23:14:57 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=The static field ChiSquareTestImpl.distribution serves no purpose, link=https://issues.apache.org/jira/browse/MATH-506, description=&lt;p&gt;The static field ChiSquareTestImpl.distribution serves no purpose.&lt;/p&gt;

&lt;p&gt;There is a setter for it, but in every case where the field is used, it is first overwritten with a new value.&lt;/p&gt;

&lt;p&gt;The field and the setter should be removed, and the methods that create a new instance should create a local variable instead.&lt;/p&gt;

&lt;p&gt;For Math 2.1, the field can be removed and the setter deprecated.&lt;/p&gt;, comments=[&lt;p&gt;Agreed.  Since the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; this instance field is unnecessary.&lt;/p&gt;
, &lt;p&gt;See the discussion in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; where it was decided to remove the distribution pluggability in 3.0.  In 2.x, the distribution is pluggable and the instance field is useful.  The 3.0 code in trunk removes the pluggability and makes the field useless.&lt;/p&gt;
, &lt;p&gt;Sorry - I thought I had checked the 2.x implementation as well, but obviously not, as it does use the field.&lt;/p&gt;

&lt;p&gt;However, we should still deprecate the setter in 2.2, as it is removed in 3.0 - OK?&lt;/p&gt;
, &lt;p&gt;Just tried removing the field and setter in 3.0, and found that the constructors rely on the setter (which is a separate bug, as the setter is not final - but easily fixable if required).&lt;/p&gt;

&lt;p&gt;The fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; merely removed deprecated code.&lt;/p&gt;

&lt;p&gt;It replaced "distribution.setDegreesOfFreedom(dof)" with "distribution = new ChiSquaredDistributionImpl(dof)" which is how the field became useless.&lt;/p&gt;

&lt;p&gt;There are two constructors which still create values for the distribution field.&lt;/p&gt;

&lt;p&gt;I don't know enough about the Math to know whether there would be any use cases for having additional methods that used a distribution provided by the class instance, rather than calculated by the individual methods (as at present).&lt;/p&gt;

&lt;p&gt;If there is no need for external provision of the distribution degree of freedom, then the constructor with parameter can be dropped.&lt;/p&gt;

&lt;p&gt;Otherwise, we need to add some methods that can use the provided distribution (which should be a final instance field).&lt;/p&gt;

&lt;p&gt;In any case, I think the setter needs to be dropped from 3.x&lt;/p&gt;
, &lt;p&gt;The instance field was there originally so that different ChiSquareDistribution implementations could be provided at construction time or via a setter (making the underlying ChiSquareDistribution pluggable).  &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; pointed to a different problem related to mutability of implementation instances.  The simplest solution to both problems is to eliminate the pluggability, which the change in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; does for this class.  The degrees of freedom are always computed from the data, so there is no need for the constructor that takes a distribution instance as argument.  Both the constructor and setter can be deprecated in 2.2 and removed in 3.0 unless we want to keep pluggability, which would require&lt;/p&gt;

&lt;p&gt;1) making the distribution field final (so removing the setter)&lt;br/&gt;
2) copying, rather than referencing the actual parameter provided to the constructor&lt;/p&gt;

&lt;p&gt;I am on the fence on this.  Maybe others can chime in (next week &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;p&gt;OK, I see now, thanks!&lt;/p&gt;
, &lt;p&gt;I removed the field (hence eliminating pluggability) in r1159916.  As of 3.0, the distribution classes are immutable, so to support pluggability a factory or class name rather than a distribution instance would have to be provided.  There is only one implementation provided by &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, so I do not see this as worth the effort and complexity to retain.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[psteitz], commentAuthors=[psteitz, sebb@apache.org], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-505
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-505, created=Tue Feb 01 01:28:56 CET 2011, updated=Sat Mar 24 17:16:40 CET 2012, resolved=Tue Feb 01 19:58:30 CET 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
], fixVersion=[3.0
], priority=Major, summary=TestUtils is thread-hostile, link=https://issues.apache.org/jira/browse/MATH-505, description=&lt;p&gt;TestUtils has several mutable static fields which are not synchronised, or volatile.&lt;/p&gt;

&lt;p&gt;If one of the fields is updated by thread A, there is no guarantee that thread B will see the full update - it may see a partially updated object.&lt;/p&gt;

&lt;p&gt;Furthermore, at least some of the static fields reference a mutable object, which can be changed whilst another thread is using it.&lt;/p&gt;

&lt;p&gt;As far as I can tell, this class must only ever be used by a single thread otherwise the results will be unpredictable.&lt;/p&gt;, comments=[&lt;p&gt;What fields, exactly?&lt;/p&gt;
, &lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/** Singleton TTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; TTest tTest = &lt;span class="code-keyword"&gt;new&lt;/span&gt; TTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; ChiSquareTest chiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; UnknownDistributionChiSquareTest unknownDistributionChiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton OneWayAnova instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; OneWayAnova oneWayAnova =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; OneWayAnovaImpl();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of the above may be changed by set methods. There is no synch.&lt;/p&gt;
, &lt;p&gt;OK, I was looking at the wrong TestUtils &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;

&lt;p&gt;The reason for this strange-looking setup is to allow the implementations to be pluggable at runtime.  "Hostile" is a harsh word, but this class is certainly &lt;b&gt;not&lt;/b&gt; threadsafe.  Ideas / patches to achieve the design goal with less "hostility" would be appreciated.&lt;/p&gt;

&lt;p&gt;I would have to double-check, but I don't think that there is any test instance state used by the methods in this class. &lt;/p&gt;
, &lt;p&gt;By thread-hostile, I mean that it is not possible in general for two different threads to use the class safely.&lt;br/&gt;
If one thread changes any of the static fields, there is no way of knowing how the methods called by the other thread will behave. This is partly because the values are not safely published currently, but even if they were, the threads don't know what settings will be used as they can be changed at any time by another thread.&lt;/p&gt;

&lt;p&gt;In general, any class which relies on mutable static state for its behaviour is thread-hostile.&lt;br/&gt;
The shared state cannot simultaneously satisfy two threads needing different behaviour.&lt;/p&gt;

&lt;p&gt;I think the only safe way for two threads to use the class as it stands is if they both synchronize on the class.&lt;br/&gt;
This will ensure safe publication of any field changes, and enforce serial usage which can guarantee the setting that will be used (but the lock will have to be held for the set call as well).&lt;/p&gt;

&lt;p&gt;ChiSquareTestImpl has a non-final instance field which means its value won't necessarily be safely published.&lt;br/&gt;
The field also has a setter which could be invoked by one thread while another was using it.&lt;/p&gt;

&lt;p&gt;TTestImpl is immutable (has no fields), and OneWayAnovaImpl can be made immutable, but other implementations of the interfaces might exist which are not immutable.&lt;/p&gt;

&lt;p&gt;The simplest way to make the class thread-safe would be to convert all the methods and fields from static to instance, but I don't know if that is acceptable.&lt;/p&gt;
, &lt;p&gt;Making the methods instance sort of defeats the purpose of the class.  None of the instance data in any of the static singletons is actually used or depended on by the methods of this class.  You are correct though that if one thread changes the impl for one of the singletons while another is using the class, the other could see a different than expected impl.  I think the practical likelihood of this is pretty much nil, as it is hard to imagine an application supplying two different implementations for the tests and wanting different threads to use different impls.  Personally, I would be happy just documenting the fact that the class is not threadsafe and if concurrent threads want to plug in different implementations, they need to synchronize on the class.  If this is not acceptable, my next preference would be to remove the pluggability - i.e., make the singletons final or get rid of them altogether, creating instances as needed for static method calls.  There is no initialization overhead creating the test classes.&lt;/p&gt;
, &lt;p&gt;@Phil: Please also keep in mind that M3 supports now (currently optional) parallel execution and it might be no longer a proper assumption that all tests are executed serially.&lt;/p&gt;
, &lt;p&gt;There is another possible option, which would be to fix the default implementations, and create new static methods that took an extra parameter for the implementation to be used.&lt;/p&gt;

&lt;p&gt;At present, changes to the static fields are not guaranteed to be published correctly. Making them volatile would fix this, but would not help with concurrent access.&lt;/p&gt;
, &lt;p&gt;Thanks, Joerg.  There should be no problems with the unit tests unless and until we introduce different tests that actually test the pluggability.  &lt;/p&gt;

&lt;p&gt;I thought about the additional parameter option, Sebb; but that again defeats the purpose of this "convenience class" - you might as well just instantiate the implementation and use it.&lt;/p&gt;

&lt;p&gt;I think the best solution is to just make the fields final and drop the getters and setters.  This is consistent with StatUtils.  So we should document the "hostility" issues in 2.2 and deprecate there and drop in 3.0.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[sebb@apache.org], commentAuthors=[psteitz, sebb@apache.org, joehni], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-484
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-484, created=Tue Jan 18 21:49:51 CET 2011, updated=Wed Mar 23 21:35:01 CET 2011, resolved=Mon Feb 14 15:20:29 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=events detection in ODE solvers is too complex and not robust, link=https://issues.apache.org/jira/browse/MATH-484, description=&lt;p&gt;All ODE solvers support multiple events detection since a long time. Events are specified by users by implementing the EventHandler interface. Events occur when the g(t, y) function evaluates to 0. When an event occurs, the solver step is shortened to make sure the event is located at the end of the step, and the event is triggered by calling the eventOccurred method in the user defined implementation class. Depending on the return value of this method, integration can continue, it can be stopped, or the state vector can be reset.&lt;/p&gt;

&lt;p&gt;Some ODE solvers are adaptive step size solvers. They can modify step size to match an integration error setting, increasing step size when error is low (thus reducing computing costs) or reducing step size when error is high (thus fulfilling accuracy requirements).&lt;/p&gt;

&lt;p&gt;The step adaptations due to events on one side and due to adaptive step size solvers are quite intricate by now, due to numerous fixes (&lt;a href="https://issues.apache.org/jira/browse/MATH-161" title="patch for Mantissa"&gt;&lt;del&gt;MATH-161&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-213" title="FirstOrderIntegrator.integrate does not give back integration stop time when an event handler stops integration"&gt;&lt;del&gt;MATH-213&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-358" title="ODE integrator goes past specified end of integration range"&gt;&lt;del&gt;MATH-358&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-421" title="restarting an ODE solver that has been stopped by an event doesn&amp;#39;t work"&gt;&lt;del&gt;MATH-421&lt;/del&gt;&lt;/a&gt; and also during standard maintenance - see for example r781157). The code is very difficult to maintain. It seems each bug fix introduces new bugs (r781157/&lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;) or tighten the link between adaptive step size and event detection (&lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;/r927202).&lt;/p&gt;

&lt;p&gt;A new bug discovered recently on an external library using a slightly modified version of this code could not be retroffitted into commons-math, despite the same problem is present. At the beginning of EventState.evaluateStep, the initial step may be exactly 0 thus preventing root solving, but preventing this size to drop to 0 would reopen &lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;. I could not fix both bugs at the same time.&lt;/p&gt;

&lt;p&gt;So it is now time to untangle events detection and adaptive step size, simplify code, and remove some inefficiency (event root solving is always done twice, once before step truncation and another time after truncation, of course with slightly different results, events shortened steps induce high computation load until the integrator recovers its optimal pace again, steps are rejected even when the event does not requires it ...).&lt;/p&gt;, comments=[&lt;p&gt;fixed in subversion repository as of r1061507 for branch 2.X and as of r1061508 for trunk&lt;/p&gt;
, &lt;p&gt;The fix introduced in r1061507 fails in several cases. If several events of the same type occur within a single long step, only the first one is triggered. If several events of different types occur during a backward integration, they are triggered in the wrong order (i.e. they are triggered in forward occurrence time order instead of backward).&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1070498 for branch 2.X and r1070499 for trunk&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-481
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-481, created=Mon Jan 17 18:15:41 CET 2011, updated=Wed Mar 23 21:33:40 CET 2011, resolved=Mon Jan 17 23:39:52 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=MathUtils.equals(double x, double y) disagrees with Javadoc, link=https://issues.apache.org/jira/browse/MATH-481, description=&lt;p&gt;MathUtils.equals(double x, double y) disagrees with Javadoc.&lt;/p&gt;

&lt;p&gt;The Javadoc says:&lt;/p&gt;

&lt;p&gt;Returns true iff they are equal as defined by  {@link #equals(double,double,int)}&lt;/p&gt;

&lt;p&gt;However, the code actually uses == and checks for NaN:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; &lt;span class="code-object"&gt;boolean&lt;/span&gt; equals(&lt;span class="code-object"&gt;double&lt;/span&gt; x, &lt;span class="code-object"&gt;double&lt;/span&gt; y) {
    &lt;span class="code-keyword"&gt;return&lt;/span&gt; (&lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(x) &amp;amp;&amp;amp; &lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(y)) || x == y;
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The method is deprecated, but it should probably still be consistent with its documentation.&lt;/p&gt;, comments=[&lt;p&gt;Corrected Javadoc in revision 1060117.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,792 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-465
2016-01-13 22:10:14,808 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-465, created=Wed Jan 05 18:34:41 CET 2011, updated=Sat Mar 24 17:17:03 CET 2012, resolved=Wed Jul 20 14:20:51 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Incorrect matrix rank via SVD, link=https://issues.apache.org/jira/browse/MATH-465, description=&lt;p&gt;The getRank() function of SingularValueDecompositionImpl does not work properly. This problem is probably related to the numerical stability problems mentioned in &lt;a href="https://issues.apache.org/jira/browse/MATH-327"&gt;MATH-327&lt;/a&gt; and &lt;a href="https://issues.apache.org/jira/browse/MATH-320"&gt;MATH-320&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Example call with the standard matrix from R (rank 2):&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeHeader panelHeader" style="border-bottom-width: 1px;"&gt;&lt;b&gt;TestSVDRank.java&lt;/b&gt;&lt;/div&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.Array2DRowRealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.RealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecomposition;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecompositionImpl;

&lt;span class="code-keyword"&gt;public&lt;/span&gt; class TestSVDRank {
	&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; void main(&lt;span class="code-object"&gt;String&lt;/span&gt;[] args) {
		&lt;span class="code-object"&gt;double&lt;/span&gt;[][] d = { { 1, 1, 1 }, { 0, 0, 0 }, { 1, 2, 3 } };
		RealMatrix m = &lt;span class="code-keyword"&gt;new&lt;/span&gt; Array2DRowRealMatrix(d);
		SingularValueDecomposition svd = &lt;span class="code-keyword"&gt;new&lt;/span&gt; SingularValueDecompositionImpl(m);
		&lt;span class="code-object"&gt;int&lt;/span&gt; r = svd.getRank();
		&lt;span class="code-object"&gt;System&lt;/span&gt;.out.println(&lt;span class="code-quote"&gt;"Rank: "&lt;/span&gt;+r);
	}
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;The rank is computed as 3. This problem also occurs for larger matrices. I discovered the problem when trying to replace the corresponding JAMA method.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  Looks like it could as you suggest be related to &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt;.  &lt;/p&gt;
, &lt;p&gt;For now, pushing to 3.0.  If we get a fix for this and &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt; before 3.0 is ready, I may propose a 2.2.1 to include it.&lt;/p&gt;
, &lt;p&gt;My apologies if I am missing something, but here is what I noticed about the SVD. &lt;/p&gt;

&lt;p&gt;On lines 124-127 of SingularValueDecompositionImpl we have:&lt;/p&gt;

&lt;p&gt;        for (int i = 0; i &amp;lt; p; i++) {
            singularValues[i] = FastMath.sqrt(FastMath.abs(singularValues[i]));
        }&lt;/p&gt;

&lt;p&gt;This is potentially the offending line. First is the problem of negative eigenvalues. Negative variance in the principal components should probably be dealt with explicitly? Perhaps by throwing a MathException? Second, and the issue which this bug report deals with, is taking a square root of a very small number (&amp;lt;1) will return a larger number. If you apply the threshold test in getRank() (final double threshold = FastMath.max(m, n) * FastMath.ulp(singularValues&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;) )  prior to taking the square root, I believe this problem would be resolved. More importantly, philosophically, you test for zero variance. This is the appropriate test.&lt;/p&gt;

&lt;p&gt;Also, rank could be precalculated in the above loop. &lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1148714.&lt;/p&gt;

&lt;p&gt;This issue was fixed by changing SVD implementation according to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-611" title="A fast and stable SVD implementation from JAMA"&gt;&lt;del&gt;MATH-611&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
], resolution=Fixed, reporter=marisa, assignees=[], commentAuthors=[psteitz, gsteri1, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,808 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-464
2016-01-13 22:10:14,808 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-464, created=Fri Dec 31 08:00:42 CET 2010, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Wed Aug 24 00:37:41 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Critical, summary=LegendreGaussIntegrator ignores defaultMaximalIterationCount and does 38 million iterations, link=https://issues.apache.org/jira/browse/MATH-464, description=&lt;p&gt;The following code results in count = 37801710 which is effectively an infinite loop for typical functions we are using&lt;br/&gt;
(in GeoGebra)&lt;/p&gt;

&lt;p&gt;The argument defaultMaximalIterationCount = 100 is being ignored&lt;/p&gt;

&lt;p&gt;This is the version we are using:&lt;br/&gt;
&lt;a href="http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java"&gt;http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    	LegendreGaussIntegrator gauss = new LegendreGaussIntegrator(5, 100);&lt;/p&gt;

&lt;p&gt;	try {
		double result = gauss.integrate(new testFun(), -10, 0.32462367623786328);
	} catch (Exception ee) {
		ee.printStackTrace();
	}&lt;/p&gt;



&lt;p&gt;class testFun implements UnivariateRealFunction {&lt;/p&gt;

&lt;p&gt;    public double value(double x) throws FunctionEvaluationException {
    	count ++;
        if (x&amp;gt;=0 &amp;amp;&amp;amp; x&amp;lt;=5) return 0.2; else return 0;
    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.&lt;/p&gt;

&lt;p&gt;The problem here is not with the iteration count.  In the example above, only 26 iterations are executed and the method returns the correct value.  What is causing the number of function evaluations to be so large is that each iteration involves multiple function evaluations.   I need to dig more deeply into the algorithm to determine what (if anything) the problem is, but what is causing the high number of function evaluations is the following&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// prepare next iteration
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; ratio = FastMath.min(4, FastMath.pow(delta / limit, 0.5 / abscissas.length));
n = FastMath.max((&lt;span class="code-object"&gt;int&lt;/span&gt;) (ratio * n), n + 1);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the example, delta / limit becomes large, causing n to increase rapidly.  As n increases, the number of function evaluations increases.&lt;/p&gt;
, &lt;p&gt;I am now thinking that this is not a bug, but a consequence of the fact that the integrand in the example is not at all well-approximated by a polynomial.  With a small-enough stepsize, the algorithm does converge, but requiring the large number of function evaluations above.  Here are some stepsize values for the example and the associated absolute error:&lt;/p&gt;

&lt;p&gt;n 8 error 0.05738431110184819&lt;br/&gt;
n 28 error 0.027423287634332688&lt;br/&gt;
n 100 error 8.62162720248888E-5&lt;br/&gt;
n 249 error 5.308122631570711E-4&lt;br/&gt;
n 650 error 4.3582615516528367E-4&lt;br/&gt;
n 1641 error 2.519984967931377E-4&lt;br/&gt;
n 3829 error 5.838605030586419E-5&lt;br/&gt;
...&lt;br/&gt;
 n 1102593 error 6.71416523906343E-8&lt;/p&gt;

&lt;p&gt;The last entry is from the last (26th) iteration.  I haven't verified the rationale for the updating formula for n above, but it does appear warranted in this case to increase n quickly as large n (= small stepsize) is required to get a decent estimate of the integral using Gaussian quadrature.&lt;/p&gt;
, &lt;p&gt;Perhaps we should also provide higher order formulas, using either a fixed set of precomputed constants or a way to compute the coefficients for any order.&lt;/p&gt;
, &lt;p&gt;Moving to 3.0.  I don't think this is a bug, but points to a couple of possible enhancements:&lt;/p&gt;

&lt;p&gt;1) higher order formulas (+0 on this suggestion from Luc - IMO the example and others like it are not suitable for Legendre-Gauss)&lt;br/&gt;
2) bound on the number of function evaluations (I vaguely recall us talking about this elsewhere, but can't find the reference.  If anyone else can, pls add.)&lt;/p&gt;
, &lt;p&gt;We restarted a thread about this a few days after the previous comment on this issue.&lt;br/&gt;
The thread can be read here: &lt;a href="http://markmail.org/thread/rnazrggnnuehz4qv"&gt;http://markmail.org/thread/rnazrggnnuehz4qv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think adding maxEvaluations while still preserving the existing maxIterations would be fine.&lt;/p&gt;
, &lt;p&gt;Coming back to this issue.&lt;/p&gt;

&lt;p&gt;I would propose to follow the same pattern we used for root solvers: adding a maxEval parameter in the top level integrate interface declaration. So we would have the same kind of configuration, with tolerances set at integrator/solver level and maxEval and function pointer passed at integrate/solve method call.&lt;/p&gt;

&lt;p&gt;Since we are just in the phase we change interfaces, this would be a good time to add this parameter.&lt;/p&gt;

&lt;p&gt;Does this seems reasonable ?&lt;/p&gt;
, &lt;p&gt;+1 for your suggestion, Luc.  Lets try to get this into 3.0.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1160914.&lt;/p&gt;

&lt;p&gt;The API of the integrators has been changed for consistency with solvers API. Now the main convergence parameters are set in the constructor and remain fixed, but a maximal number of function evaluation must be provided at each call to the integration method.&lt;/p&gt;

&lt;p&gt;Thanks for the report&lt;/p&gt;
], resolution=Fixed, reporter=murkle, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=180, timeSpent=null]
2016-01-13 22:10:14,808 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-453
2016-01-13 22:10:14,808 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-453, created=Mon Dec 06 03:01:08 CET 2010, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Mon Dec 06 13:53:56 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function, link=https://issues.apache.org/jira/browse/MATH-453, description=&lt;p&gt;RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function.&lt;/p&gt;

&lt;p&gt;As this explains how to recode deprecated method calls, it ought to be corrected before release.&lt;/p&gt;, comments=[&lt;p&gt;Removed references to the &lt;tt&gt;analysis.function&lt;/tt&gt; package (revision 1042610).&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[erans], commentAuthors=[erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,808 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-434
2016-01-13 22:10:14,808 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-434, created=Sun Nov 07 04:55:32 CET 2010, updated=Sat Mar 24 17:16:29 CET 2012, resolved=Sat Apr 09 21:21:59 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=SimplexSolver returns unfeasible solution, link=https://issues.apache.org/jira/browse/MATH-434, description=&lt;p&gt;The SimplexSolver is returning an unfeasible solution:&lt;/p&gt;

&lt;p&gt;import java.util.ArrayList;&lt;br/&gt;
import java.text.DecimalFormat;&lt;br/&gt;
import org.apache.commons.math.linear.ArrayRealVector;&lt;br/&gt;
import org.apache.commons.math.optimization.GoalType;&lt;br/&gt;
import org.apache.commons.math.optimization.OptimizationException;&lt;br/&gt;
import org.apache.commons.math.optimization.linear.*;&lt;/p&gt;

&lt;p&gt;public class SimplexSolverBug {&lt;/p&gt;

&lt;p&gt;    public static void main(String[] args) throws OptimizationException {&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction c = new LinearObjectiveFunction(new double[]{0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d}, 0.0d);&lt;/p&gt;

&lt;p&gt;        ArrayList&amp;lt;LinearConstraint&amp;gt; cnsts = new ArrayList&amp;lt;LinearConstraint&amp;gt;(5);&lt;br/&gt;
        LinearConstraint cnst;&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, -0.1d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.EQ, -0.1d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, -1e-18d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 1.0d, 0.0d, -0.0128588d, 1e-5d}, Relationship.EQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 0.0d, 1.0d, 1e-5d, -0.0128586d}, Relationship.EQ, 1e-10d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, -1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, -1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, 1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;/p&gt;

&lt;p&gt;        DecimalFormat df = new java.text.DecimalFormat("0.#####E0");&lt;/p&gt;

&lt;p&gt;        System.out.println("Constraints:");&lt;br/&gt;
        for(LinearConstraint con : cnsts) {
            for (int i = 0; i &amp;lt; con.getCoefficients().getDimension(); ++i)
                System.out.print(df.format(con.getCoefficients().getData()[i]) + " ");
            System.out.println(con.getRelationship() + " " + con.getValue());
        }&lt;/p&gt;

&lt;p&gt;        SimplexSolver simplex = new SimplexSolver(1e-7);&lt;br/&gt;
        double[] sol = simplex.optimize(c, cnsts, GoalType.MINIMIZE, false).getPointRef();&lt;br/&gt;
        System.out.println("Solution:\n" + new ArrayRealVector(sol));&lt;br/&gt;
        System.out.println("Second constraint is violated!");&lt;br/&gt;
    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;It's an odd problem, but something I ran across.  I tracked the problem to the getPivotRow routine in SimplexSolver.  It was choosing a pivot that resulted in a negative right-hand-side.  I recommend a fix by replacing&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
                ...&lt;br/&gt;
with&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;br/&gt;
                ...&lt;/p&gt;

&lt;p&gt;I believe this would be more appropriate (and at least resolves this particular problem).&lt;/p&gt;

&lt;p&gt;Also, you may want to consider making a change in getPivotColumn to replace&lt;br/&gt;
            ...&lt;br/&gt;
            if (MathUtils.compareTo(tableau.getEntry(0, i), minValue, epsilon) &amp;lt; 0) {&lt;br/&gt;
            ...&lt;br/&gt;
with&lt;br/&gt;
            ...&lt;br/&gt;
            if (tableau.getEntry(0, i) &amp;lt; minValue) &lt;br/&gt;
            ...&lt;br/&gt;
because I don't see the point of biasing earlier columns when multiple entries are within epsilon of each other.  Why not pick the absolute smallest.  I don't know that any problem can result from doing it the other way, but the latter may be a safer bet.&lt;/p&gt;

&lt;p&gt;VERY IMPORTANT: I discovered another bug that occurs when not restricting to non-negatives.  In SimplexTableu::getSolution(), &lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) &lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = 0;&lt;br/&gt;
          ...&lt;br/&gt;
should be&lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) {&lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = (restrictToNonNegative ? 0 : -mostNegative);&lt;br/&gt;
          ...&lt;br/&gt;
If necessary, I can give an example of where this bug causes a problem, but it should be fairly obvious why this was wrong.&lt;/p&gt;, comments=[&lt;p&gt;My original suggested fix had a potential for overflow errors (since minRatio is initialized to Double.MAX_VALUE).  Also, I added another suggestion and pointed out another bug which leads to invalid solutions.&lt;/p&gt;
, &lt;p&gt;Could you attach unit tests that demonstrate each problem?  Thank you.&lt;/p&gt;
, &lt;p&gt;I'll try to send some examples soon.  I'm noticing more problems with the right-hand-side going negative and want to cover all bases (as much as possible).&lt;/p&gt;
, &lt;p&gt;Code, and resulting output, that illustrates issues with the SimplexSolver.&lt;/p&gt;
, &lt;p&gt;Pushing out to 3.0.&lt;/p&gt;
, &lt;p&gt;Hey, sorry I took so long to look at this.  I've had very little time and am not working on this stuff anymore.  I'm honestly not going to be able to look at this stuff much moving forward, so hopefully there's a Commons Math contributor that can act as a reviewer.&lt;/p&gt;

&lt;p&gt;When you say it's choosing a pivot with a negative RHS, I'm assuming that means it's not within the epsilon?&lt;br/&gt;
Why would it be more appropriate to divide by the entry?  I'm not sure I see why you'd want to use a bigger epsilon when the entry is 0.1 and a smaller epsilon when the entry is 10.  Maybe we should just make the default epsilon smaller?  I'm no expert with floating point math so I'm not real sure how to set the epsilon and just made up a value.&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
...&lt;br/&gt;
with&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;/p&gt;
, &lt;p&gt;Attached a patch for the reported problems.&lt;br/&gt;
The problems can be split into two groups:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;wrong solution calculation with negative&lt;br/&gt;
   variables&lt;/li&gt;
	&lt;li&gt;failing to select an appropriate pivot&lt;br/&gt;
   row when values are below a given &lt;br/&gt;
   epsilon&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch addresses both problems:&lt;/p&gt;

&lt;p&gt; 1. fix in SimplexTableau.getSolution()&lt;br/&gt;
 2. use BigReal for arbitrary precision  &lt;br/&gt;
    support when selecting the pivot row&lt;/p&gt;

&lt;p&gt;Additionally, 4 test cases are included, as well as a minor typo fix for a method name.&lt;/p&gt;

&lt;p&gt;The fixed epsilon is also used in some other places of the code, this may also create problems under certain circumstances. So if this patch is accepted, the other places could also be adapted.&lt;/p&gt;
, &lt;p&gt;Thanks Thomas.&lt;/p&gt;

&lt;p&gt;I had a look at the patch. I'm not a big fan of using BigReal, mainly when we don't specify a scale and we don't link it to the choice for epsilon. Also reading back Ben comments, I wonder if we should not replace epsilon by an integer number of ulps with a default set to a very small value (say something like 10 ulps).&lt;/p&gt;

&lt;p&gt;What problem did you see in the accuracy of the variables to use BigReal ?&lt;/p&gt;
, &lt;p&gt;Hi Luc,&lt;/p&gt;

&lt;p&gt;my initial idea was to use an epsilon that is adjusted to the magnitude of the respective value used for comparison. To be honest, I was not aware of &lt;span class="error"&gt;&amp;#91;Math,FastMath&amp;#93;&lt;/span&gt;.ulp, therefore I went with BigReal/BigDecimal to circumvent the problem in another way (by using an arbitrary precision datatype). After reading your comment, I investigated more into the problem, e.g. using &lt;a href="http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm"&gt;http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm&lt;/a&gt;, and addressed it (hopefully correct) in the way you proposed.&lt;/p&gt;

&lt;p&gt;Though, I had to split up the epsilon test into two categories:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;general comparison of floating-point values: using ulp, as values can be arbitrarily small&lt;/li&gt;
	&lt;li&gt;algorithm convergence check: using a standard epsilon, as the algorithm may not converge due to limited precision of&lt;br/&gt;
    the double datatype otherwise&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Please find attached my updated patch, any comments are welcome (e.g. I was unsure whether to expose the maxUlps parameter in the constructor, or to use a generic comparison epsilon, e.g. using FastMath.ulp(1d) instead of one adjusted to the current value in question).&lt;/p&gt;
, &lt;p&gt;updated patch, incorporating comments from luc&lt;/p&gt;
, &lt;p&gt;&lt;span class="error"&gt;&amp;#91;Pardon the possibly nave questions.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In "SimplexTableau":&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Why not use directly "equals(double, double, int)" from "MathUtils" instead of computing an epsilon with "getEpsilon"?&lt;/li&gt;
	&lt;li&gt;Why is the "isOptimal" method not using the adjusted "epsilon" (at line 385)?&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;hmm, I feel a bit stupid now, as I have re-implemented MathUtils.equals(double, double, int) but in a mediocre way. So all calls to getEpsilon should be replaced with the equivalent MathUtils.equals.&lt;/p&gt;

&lt;p&gt;for the isOptimal:&lt;/p&gt;

&lt;p&gt;the idea was to have a user-defined threshold for the convergence criteria, which defaults to the original value of 1e-6. Using the same adjusted epsilon would possibly lead to more iterations as before. As the feasibility check in SimplexSolver.solvePhase1 has to use a static epsilon for convergence reasons, I thought to use the same epsilon in isOptimal makes sense for symmetry reasons (use the same epsilon to check for convergence /feasibility).&lt;/p&gt;

&lt;p&gt;But it's good that you raise these points, because I was hesitating myself what is the best way to go forward, as I am also not considering myself a floating-point expert. I am mainly interested in the simplex algorithm, that's why I have chosen to provide a patch for this (very nice) implementation of it.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1090656.&lt;br/&gt;
Path applied with a very small change: adding the maxUlps parameter to the detailed constructor.&lt;/p&gt;

&lt;p&gt;Thanks for the report and thanks for the patch.&lt;/p&gt;
, &lt;p&gt;Thanks for accepting the patch. The comparison using maxUlps has already been adapted according to &lt;a href="https://issues.apache.org/jira/browse/MATH-557" title="add a compareTo method to MathUtils that use a number of ulps for equality tolerance"&gt;&lt;del&gt;MATH-557&lt;/del&gt;&lt;/a&gt;, but it was missing for SimplexTableau. The cleanup patch fixes this and also renames the test names for similarity.&lt;/p&gt;
, &lt;p&gt;Cleanup patch applied.&lt;/p&gt;

&lt;p&gt;thanks again&lt;/p&gt;
], resolution=Fixed, reporter=wmwitzel, assignees=[], commentAuthors=[wmwitzel, erans, psteitz, bmccann, tn, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,808 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-429
2016-01-13 22:10:14,808 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-429, created=Fri Oct 22 10:01:54 CEST 2010, updated=Wed Mar 23 21:25:46 CET 2011, resolved=Sat Oct 23 21:35:26 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Blocker, summary=KMeansPlusPlusClusterer breaks by division by zero, link=https://issues.apache.org/jira/browse/MATH-429, description=&lt;p&gt;For a certain space, KMeansPlusPlusClusterer  breaks. This is a blocker because this space occurs in our domain. &lt;/p&gt;, comments=[&lt;p&gt;The testcase which breaks KMeansPlusPlusClusterer&lt;/p&gt;
, &lt;p&gt;You have encountered one classical problem with k-means: at some stage (here at the first iteration), one of the clusters becomes empty.&lt;br/&gt;
This case is currently no handled by commons-math (which is a bug, so we have to fix it).&lt;br/&gt;
When a cluster is empty, a new centroid must be defined from the other clusters. There are different strategies:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;take the point farthest from any cluster&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest distance variance&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest number of points&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;My prefered choice would be 2, what do other people think ?&lt;/p&gt;
, &lt;p&gt;How about make it configurable?  Take a look at how the Mallet project did it:&lt;/p&gt;

&lt;p&gt;&lt;a href="http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html"&gt;http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By the way, I have suggested that they try to enter the Incubator here at the ASF and they seem somewhat receptive to the idea!&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1026666 for branche 2.X and as of r1026667 for trunk.&lt;br/&gt;
Users can now choose among four different strategies to deal with empty clusters:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;split the cluster with largest distance variance,&lt;/li&gt;
	&lt;li&gt;split the cluster with largest number of points,&lt;/li&gt;
	&lt;li&gt;create a cluster around the point farthest from its centroid,&lt;/li&gt;
	&lt;li&gt;generate an error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The default is to split according to largest variance.&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erikvaningen, assignees=[], commentAuthors=[erikvaningen, luc, jwcarman], timeEstimate=180, timeSpent=null]
2016-01-13 22:10:14,823 : INFO  : KNIME-Worker-0 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:1 : Jira table created.
2016-01-13 22:10:14,823 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 End execute (2 secs)
2016-01-13 22:10:14,823 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doBeforePostExecution
2016-01-13 22:10:14,823 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: POSTEXECUTE
2016-01-13 22:10:14,823 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doAfterExecute - success
2016-01-13 22:10:14,823 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: EXECUTED
2016-01-13 22:10:14,823 : DEBUG : KNIME-Worker-0 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-421
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-421, created=Wed Sep 29 20:24:56 CEST 2010, updated=Wed Mar 23 21:23:12 CET 2011, resolved=Wed Sep 29 21:51:49 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=restarting an ODE solver that has been stopped by an event doesn't work, link=https://issues.apache.org/jira/browse/MATH-421, description=&lt;p&gt;If an ODE solver is setup with an EventHandler that return STOP when the even is triggered, the integrators stops (which is exactly the expected behavior).&lt;br/&gt;
If however the user want to restart the solver from the final state reached at the event with the same configuration (expecting the event to be triggered again at a later time), then the integrator may fail to start. It can get stuck at the previous event.&lt;/p&gt;

&lt;p&gt;The occurrence of the bug depends on the residual sign of the g function which is not exactly 0, it depends on the convergence of the first event.&lt;/p&gt;

&lt;p&gt;As this use case is fairly general, event occurring less than epsilon after the solver start in the first step should be ignored, where epsilon is the convergence threshold of the event. The sign of the g function should be evaluated after this initial ignore zone, not exactly at beginning (if there are no event at the very beginning g(t0) and g(t0+epsilon) have the same sign, so this does not hurt ; if there is an event at the very beginning, g(t0) and g(t0+epsilon) have opposite signs and we want to start with the second one. Of course, the sign of epsilon depend on the integration direction (forward or backward).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository, as of r1002827 for branch 2.X and 1002829 for trunk (3.0)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-414
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-414, created=Tue Aug 31 13:01:44 CEST 2010, updated=Wed Mar 23 21:20:43 CET 2011, resolved=Tue Nov 30 12:57:23 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=ConvergenceException in NormalDistributionImpl.cumulativeProbability(), link=https://issues.apache.org/jira/browse/MATH-414, description=&lt;p&gt;I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.&lt;br/&gt;
For instance in the following code:&lt;/p&gt;

&lt;p&gt;	@Test&lt;br/&gt;
	public void testCumulative() {&lt;br/&gt;
		final NormalDistribution nd = new NormalDistributionImpl();&lt;br/&gt;
		for (int i = 0; i &amp;lt; 500; i++) {&lt;br/&gt;
			final double val = Math.exp&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/information.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt;;&lt;br/&gt;
			try {
				System.out.println("val = " + val + " cumulative = " + nd.cumulativeProbability(val));
			} catch (MathException e) {
				e.printStackTrace();
				fail();
			}&lt;br/&gt;
		}&lt;br/&gt;
	}&lt;/p&gt;

&lt;p&gt;In version 2.0, I get no exception. &lt;/p&gt;

&lt;p&gt;My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.&lt;/p&gt;, comments=[&lt;p&gt;The difference between 2.0 and 2.1 is due to the changes in ContinuedFraction included in the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-282" title="ChiSquaredDistributionImpl.cumulativeProbability &amp;gt; 1"&gt;&lt;del&gt;MATH-282&lt;/del&gt;&lt;/a&gt;.  For very large values, continued fractions are diverging to NaN. The suggested fix will work, but at this point, I wonder if we should just move the top-coding out of the catch - i.e., test the arguments and return 0 or 1 for extreme values without attempting the approximation.&lt;/p&gt;
, &lt;p&gt;I am leaning toward adding top-coding outside of the catch.  Based on the inequality p(Z &amp;gt; t) &amp;lt; exp(-t^2/2) derived in &lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; and Double.MIN_VALUE  = 2^-1074, I get that tail probabilities are not distinguishable from 0 for |t| &amp;gt; 39, so I propose that we top-code at 40 outside the catch.  Appreciate others checking my arithmetic.&lt;/p&gt;

&lt;p&gt;&lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href="http://www.johndcook.com/normalbounds.pdf"&gt;http://www.johndcook.com/normalbounds.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Your suggestion seems good to me.&lt;br/&gt;
I've check exp(-t^2/2) becomes lower than Double.MIN_VALUE/2 (i.e. rounds to 0) when |t|&amp;gt; 38.604&lt;/p&gt;
, &lt;p&gt;Fixed in r1040471&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=gustav.ryd, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=120, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-411
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-411, created=Sun Aug 29 00:14:32 CEST 2010, updated=Wed Mar 23 21:20:06 CET 2011, resolved=Mon Sep 13 04:04:01 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression newSampleData methods inconsistently create / omit intercepts, link=https://issues.apache.org/jira/browse/MATH-411, description=&lt;p&gt;The newSampleData(double[], nrows, ncols) method used in the unit tests adds a unitary column to the design matrix, resulting in an intercept term being estimated among the regression parameters.  The other newSampleData methods do not do this, forcing users to add the column of "1"s to estimate models with intercept.  Behavior should be consistent and users should not have to add the column.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r993574.  Modified multiple regression newSample methods to ensure that by default in all cases, regression models are estimated with intercept terms.  Prior to the fix for this issue,  newXSampleData(double[][]), newSampleData(double[], double[][]) and newSampleData(double[], double[][], double[][]) all required columns of "1's  to be inserted into the x[][] arrays to create a model with an intercept term;while newSampleData(double[], int, int) created a model including an intercept term without requiring the unitary column.  All methods have  been changed to eliminate the need for users to add unitary columns to specify regression models.&lt;/p&gt;

&lt;p&gt;Leaving open until &lt;a href="https://issues.apache.org/jira/browse/MATH-409" title="Multiple Regression API should allow specification of whether or not to estimate intercept term"&gt;&lt;del&gt;MATH-409&lt;/del&gt;&lt;/a&gt; is resolved. &lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-409
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-409, created=Tue Aug 24 11:55:32 CEST 2010, updated=Wed Mar 23 21:19:13 CET 2011, resolved=Mon Sep 13 04:02:43 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression API should allow specification of whether or not to estimate intercept term, link=https://issues.apache.org/jira/browse/MATH-409, description=&lt;p&gt;The OLS and GLS regression APIs should support estimating models including intercepts using design matrices including only variable data.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r996404 (both trunk and 2.x branch)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-408
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-408, created=Mon Aug 23 05:11:23 CEST 2010, updated=Wed Mar 23 21:18:48 CET 2011, resolved=Sun Dec 12 22:49:44 CET 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=GLSMultipleLinearRegression has no nontrivial validation tests, link=https://issues.apache.org/jira/browse/MATH-408, description=&lt;p&gt;There are no non-trivial tests verifying the computations for GLSMultipleLinearRegression.  Tests verifying computations against analytically determined models, R or some other reference package / datasets should be added to ensure that the statistics reported by this class are valid.&lt;/p&gt;, comments=[&lt;p&gt;Added a non-trivial test in r1044935.  While still not really a full verification test, it does at least verify that the GLS impl provided does better than OLS for models with error structure conforming to its covariance matrix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-407
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-407, created=Mon Aug 23 05:07:08 CEST 2010, updated=Wed Mar 23 21:18:29 CET 2011, resolved=Mon Sep 20 03:57:59 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Documentation improvements for multiple regression classes, link=https://issues.apache.org/jira/browse/MATH-407, description=&lt;p&gt;The user guide examples showing how to set up and estimate linear models using OLS and GLS multiple regression need to be updated to reflect changes in the API.  The javadoc for these classes and user guide descriptions also need to be improved to make it clear how to estimate a model with an intercept term.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r998761&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-406
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-406, created=Sat Aug 14 23:57:56 CEST 2010, updated=Wed Mar 23 21:18:04 CET 2011, resolved=Sun Aug 15 00:02:03 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Wrong weight handling in Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-406, description=&lt;p&gt;A comparison with a Fortran version of Levenberg-Marquardt reveals that when observations have different weights, the 2.1 version reaches a value of the function which does not necessary correspond to the minimum&lt;/p&gt;, comments=[&lt;p&gt;Correction patch.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-405
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-405, created=Wed Aug 11 15:24:39 CEST 2010, updated=Wed Mar 23 21:17:42 CET 2011, resolved=Wed Aug 11 15:46:55 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Inconsistent result from Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-405, description=&lt;p&gt;Levenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost&lt;/p&gt;, comments=[&lt;p&gt;Correction patch&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-404
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-404, created=Mon Aug 09 13:44:12 CEST 2010, updated=Sat Mar 24 17:17:04 CET 2012, resolved=Mon Aug 30 15:53:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Confusing interface for "LevenbergMarquardtOptimizer", link=https://issues.apache.org/jira/browse/MATH-404, description=&lt;p&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; which in turn implements &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt;. That interface mandates methods for setting and getting a &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;.&lt;br/&gt;
In v2.1, however, that checker is never used! The convergence check is performed using parameters specific to the Levenberg-Marquardt algorithm. Such circumvention of the superclass interface is confusing and leads to totally unexpected behaviour (such as changing the values of the thresholds of the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; being ineffective).&lt;br/&gt;
In the development version, the default constructor of &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; sets the the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; field to "null" and when such is the case, the behaviour is as in v2.1. Although it is documented, this is still confusing since it is impossible to use &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; through its &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt; interface: When using the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;, one does not know what parameters to use in order to reproduce the results obtained with the LM-specific convergence check (i.e. how to reproduce the result from v2.1).&lt;br/&gt;
Unless I'm missing something, I think that there should be an LM-specific implementation of &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; that, when given the usual relative and absolute thresholds, can perform a check that will give the same result as the currently specific check (when the "checker" field is "null").&lt;/p&gt;, comments=[&lt;p&gt;The problem was identified and discussed as &lt;a href="https://issues.apache.org/jira/browse/MATH-362" title="LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it"&gt;&lt;del&gt;MATH-362&lt;/del&gt;&lt;/a&gt;. It was decided to let both convergence methods available.&lt;/p&gt;

&lt;p&gt;The reason there are two different way is that the Levenberg-Marquardt implementation originally came from Netlib and I kept the way it behaved. I think the general interface with the new generic convergence was set up later and at that time I forgot to implement it properly, so the settings were ignored.&lt;/p&gt;

&lt;p&gt;Reporter of issue 362 explicitly asked to keep the ortho-tolerance setting and this setting does not fit with the general scheme.&lt;/p&gt;
, &lt;p&gt;Sorry I hadn't followed that other report.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was decided to let both convergence methods available. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is &lt;tt&gt;null&lt;/tt&gt; or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;

&lt;p&gt;As explained above, from an OOP point-of-view, it is surprising that a class completely circumvents its base class interface.&lt;br/&gt;
At least one of the following is wrong:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; has a second interface for convergence checking&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; defines the interface for  convergence checking&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; does not fit with the general scheme.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;br/&gt;
Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;

&lt;p&gt;If it is really impossible to fit LM within the hierarchy it currently belongs to, then it should not belong to it, since one cannot leverage the advantages of "interface programming" anyways.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is null or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or LevenbergMarquardtOptimizer needs to be changed and the orthogonality concept be finally discarded.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I know, and I am not happy with this. However, I don't want LevenbergMarquardtOptimizer to be special. It &lt;em&gt;must&lt;/em&gt; fit. We can take the opportunity of a 3.0 major release to fix this problem too, with some incompatible changes. What would you propose for this ?&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;What would you propose for this ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don't know.&lt;/p&gt;

&lt;p&gt;However, it seems that this "non-fitting checker" case is not isolated. I wanted to replace the original check in "BrentOptimizer" (package "optimization.univariate") by a call to an appropriate subclass of "RealConvergenceChecker", but here too there are more values to be considered than those stored in a pair of "RealPointValuePair". The check needs&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the "current" point&lt;/li&gt;
	&lt;li&gt;the points at both interval ends&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;but it does not use the "previous" point.&lt;/p&gt;

&lt;p&gt;So it seems that this also does not fit with the "converged" method of the "RealConvergenceChecker" interface.&lt;/p&gt;

&lt;p&gt;At first sight, I'd say that there should be a more general "ConvergenceChecker" (not existing yet) interface. Maybe using generics...&lt;/p&gt;
, &lt;p&gt;I'm trying to define a more general "ConvergenceChecker" interface. This is an incompatible change.&lt;/p&gt;
, &lt;p&gt;Final resolution is delegated to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-413"&gt;MATH-413&lt;/a&gt;.&lt;/p&gt;
], resolution=Unknown, reporter=erans, assignees=[erans], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-395
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-395, created=Sun Jul 25 23:26:33 CEST 2010, updated=Wed Mar 23 21:14:58 CET 2011, resolved=Wed Jul 28 14:11:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Bugs in "BrentOptimizer", link=https://issues.apache.org/jira/browse/MATH-395, description=&lt;p&gt;I apologize for having provided a buggy implementation of Brent's optimization algorithm (class "BrentOptimizer" in package "optimization.univariate").&lt;br/&gt;
The unit tests didn't show that there was something wrong, although (from the "changes.xml" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.&lt;br/&gt;
Comparing with an implementation in Python, I could figure out the fixes. I'll modify "BrentOptimizer" and add a test. I also propose to change the name of the unit test class from "BrentMinimizerTest" to "BrentOptimizerTest".&lt;/p&gt;, comments=[&lt;p&gt;Bugs corrected in revision 979257.&lt;br/&gt;
Not resolving yet because the implementation still does not behave as the Python one. I've added a unit test that indicates the discrepancies (with "XXX" markers).&lt;/p&gt;
, &lt;p&gt;Last bug fixed in revision 980032.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;This revision also contains the modifications due to the changes in &amp;quot;AbstractUnivariateRealOptimizer&amp;quot;.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The test comparing with Python has been removed because a tracing of the execution paths (in Python and Java) showed that the remaining discrepancies were due to different values being used for the "golden ratio" constant.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[erans], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-392
2016-01-13 22:10:14,839 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-392, created=Wed Jul 21 20:43:10 CEST 2010, updated=Wed Mar 23 21:13:58 CET 2011, resolved=Sun Aug 22 15:16:29 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=calculateYVariance in OLS/GLSMultipleLinearRegression uses residuals not Y vars, link=https://issues.apache.org/jira/browse/MATH-392, description=&lt;p&gt;Implementation of OLS/GLSMultipleLinearRegression is:&lt;br/&gt;
@Override&lt;br/&gt;
173        protected double calculateYVariance() {
174            RealVector residuals = calculateResiduals();
175            return residuals.dotProduct(residuals) /
176                   (X.getRowDimension() - X.getColumnDimension());
177        }&lt;/p&gt;

&lt;p&gt;This gives variance of residuals not variance of the dependent (Y) variable as the documentation suggests.&lt;/p&gt;, comments=[&lt;p&gt;Thank you for reporting this.  Patches welcome!&lt;/p&gt;
, &lt;p&gt;Can't test a patch as I'm not able to build current repository version:&lt;br/&gt;
math/src/test/java/org/apache/commons/math/optimization/univariate/BrentOptimizerTest.java:&lt;span class="error"&gt;&amp;#91;28,39&amp;#93;&lt;/span&gt; cannot find symbol&lt;br/&gt;
symbol  : class SincFunction&lt;/p&gt;

&lt;p&gt;Implementation for both GLS/OLS:&lt;/p&gt;

&lt;p&gt;protected double calculateYVariance() {
    return new Variance().evaluate(Y);
}&lt;/p&gt;
, &lt;p&gt;There was an error in a file committed this afternoon. It should be OK now.&lt;/p&gt;
, &lt;p&gt;corrected implementations of calculateYVariance() for OLS/GLSMultipleRegression&lt;/p&gt;

&lt;p&gt;added unit tests for both calculateYVariance implementations&lt;/p&gt;

&lt;p&gt;fixed AbstractMultipleRegression.estimateRegressionParametersStandardErrors() to use residuals &lt;/p&gt;
, &lt;p&gt;Fixed in 987897.   I added calcluate/estimateErrorVariance methods to return what was previously incorrectly reported as "Y variance."&lt;br/&gt;
Thanks for the patch!&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=markdevaney, assignees=[], commentAuthors=[psteitz, markdevaney, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-391
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-391, created=Wed Jul 21 10:57:46 CEST 2010, updated=Wed Mar 23 21:13:27 CET 2011, resolved=Sun Oct 03 18:43:11 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Inconsistent behaviour of constructors in ArrayRealVector class, link=https://issues.apache.org/jira/browse/MATH-391, description=&lt;p&gt;ArrayRealVector(double[] d) allows to construct a zero-length vector, but ArrayRealVector(double[] d, boolean copyArray) doesn't. Both should allow this as zero-length vectors are mathematically well-defined objects and they are useful boundary cases in many algorithms.&lt;/p&gt;

&lt;p&gt;This breaks some arithmetic operators (addition) on zero-length real vectors which worked in 2.0 but don't work in 2.1&lt;/p&gt;, comments=[&lt;p&gt;I agree that the code should be consistent.  I agree as well that a zero-dimensional vector is legit.   Can anyone explain why ArrayRealVector(double[] d, boolean copyArray) requires positive length?&lt;/p&gt;
, &lt;p&gt;Most probably my bad ...&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1003993 for barnch 2.X and r1003994 for trunk.&lt;br/&gt;
Note that the same problem occurred also in ArrayFieldVector but the fix is different. For Field-based vectors, we need to get the field, so either we use a non-empty array and retrieve the field from the first array element or we add a parameter for the field and allow the array to be empty. The two choices are now possible, as new constructors have been added and the javadoc updated to explain this behavior.&lt;br/&gt;
Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-390
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-390, created=Wed Jul 21 00:47:21 CEST 2010, updated=Wed Jul 21 01:32:12 CEST 2010, resolved=Wed Jul 21 01:32:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Major, summary=Simplex Solver is very inaccurate on a large problem, even a very low value for epsilon, link=https://issues.apache.org/jira/browse/MATH-390, description=&lt;p&gt;I'm currently playing with a program for solving a rather simple chess puzzle. The goal is to place 12 knights on a 8x8 board, such that each field is either attacked by a knight, or contains a knight. To solve this problem (and different variants) I want to use a handcrafted Branch and Bound algorithm that uses Linear Programming to calculate an upperbound on the number of fields that can be covered by a certain amount of knights.&lt;/p&gt;

&lt;p&gt;The idea is to create variables for each field that has to be covered, and to create variables for each field to contain a knight. A cover variable can only become positive if a corresponding knight variable for an adjacent field is also positive, there is a limit to the amount of knights we may place (so the sum of all knight variables cannot be larger than 12) and the cover variables cannot be larger than one. Also, only the cover variables have a coefficient of one in the objective function, all other variables have zero. Because we want to cover the entire board our goal will be to maximize the objective function, since we want to maximize the number of fields that are covered.&lt;/p&gt;

&lt;p&gt;Since a basic chessboard has 64 fields and since it is possible to cover the chessboard with 12 knights, we know there is an integer solution that has value 64. Since we are solving a relaxed variant of the problem, the value should be at least 64. However, when I use the Simplex Solver, I get a value of around 58.6, which is much too low. Even when I relax the constraints in such a fashion that 64 knights may be placed on the board, the solution value remains the same. I've lowered the value of epsilon as much as I can and it still gives the incorrect value. What makes it worse is that the calculation is totally useless as an upperbound (if the value would have been around 70, it would have been an upperbound at least).&lt;/p&gt;

&lt;p&gt;I've heard that using the revised simplex method is a lot better with respect to stacked errors, so I am not sure this is really a bug, or just a problem that arises when the two phase simplex method is used for large problems.&lt;/p&gt;

&lt;p&gt;I will try to attach a code example that implements the problem (but possibly isn't that readable).&lt;/p&gt;, comments=[&lt;p&gt;Example of the 8x8 Knight covering Chess problem. The objective value should at least be 64, but it is around 59.&lt;/p&gt;
, &lt;p&gt;Hmm, it seems I made a programming mistake in the type of the relationship: I used an equality where I should have used a greater-equals. I created a much nicer version of the example, which actually works. Feel free to use it for an example or something.&lt;/p&gt;

&lt;p&gt;My bad, I will close the issue.&lt;/p&gt;
, &lt;p&gt;The correct and more readable example, which actually works.&lt;/p&gt;
, &lt;p&gt;It seems I made a programming error. I included a correct example to solve the problem.&lt;/p&gt;
], resolution=Fixed, reporter=pcbouman, assignees=[], commentAuthors=[pcbouman], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-380
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-380, created=Thu Jun 24 18:47:54 CEST 2010, updated=Sat Mar 24 17:16:33 CET 2012, resolved=Sat Oct 01 15:54:20 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Minor, summary=Need to (re)initialize dYdY0 for multiple integrate with FirstOrderIntegratorWithJacobians, link=https://issues.apache.org/jira/browse/MATH-380, description=&lt;p&gt;There is a lack in the method integrate of FirstOrderIntegratorWithJacobians. The jacobian DYDY0 can't be initialized by the user, unlike DFDP with DF0DP.&lt;br/&gt;
So, for several successive integrations, the matrix is reinitialized to identity and that is not what we might want.&lt;/p&gt;, comments=[&lt;p&gt;You are perfectly right.&lt;/p&gt;

&lt;p&gt;The FirstOrderIntegratorWithJacobians class is a brand new one and it clearly has some design flaws.&lt;br/&gt;
It will most probably be deprecated in its current form and replaced by a new mechanism, better integrated (sorry for the joke) with the standard ODE solvers.&lt;br/&gt;
The ability for user to set an initial value for dydy0 will be present in the new design, but will probably not be back-ported to the current one.&lt;br/&gt;
In the meantime, you can save the final value of the jacobian matrix dydy0 after first part of integration, which we could call dy1dy0 as it represents dy(t1)/dy(t0). Start the second part from t1 to t2 that will reset the initial matrix to identity and hence compute compute dy(t2)/dy(t1) and do the multiplication by yourself of the two matrices to really get what you need: dy(t2)/dy(t1) = dy(t2)/dy(t1) * dy(t1)/dy(t0).&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue &lt;/p&gt;
, &lt;p&gt;changing target fix version to 3.0.&lt;br/&gt;
Fixing this and several other problems requires a complete rewrite of the jacobians computation with ODE, and this rewrite implies user interfaces changes, so it cannot be fixed before 3.0.&lt;/p&gt;
, &lt;p&gt;A first attempt to implement Jacobians computation again in ODE has been committed in subversion repository as of r1175409.&lt;br/&gt;
This implementation still lacks the ability for step handlers to also retrieve the additional equations and their derivatives.&lt;br/&gt;
This implementation is based on the Orekit one described here: &lt;a href="https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf"&gt;https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1176745.&lt;/p&gt;
], resolution=Fixed, reporter=pparraud, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-377
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-377, created=Thu Jun 17 11:06:03 CEST 2010, updated=Wed Mar 23 21:08:36 CET 2011, resolved=Sun Jul 25 21:49:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=weight versus sigma in AbstractLeastSquares, link=https://issues.apache.org/jira/browse/MATH-377, description=&lt;p&gt;In AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.&lt;/p&gt;

&lt;p&gt; Once corrected, getRMS() can even reduce&lt;/p&gt;

&lt;p&gt; public double getRMS() {return Math.sqrt(getChiSquare()/rows);}&lt;/p&gt;, comments=[&lt;p&gt;It is not clear to me exactly what is being computed in getChiSquare.  Step 0 is to get an actual definition in the javadoc for what it is trying to compute.  I agree it seems odd to be dividing by residual weights; but I could be missing the intent.&lt;/p&gt;
, &lt;p&gt;OK, let us define ChiSquare as the sum of the weighted square of the residual in order to be consistent with the rest of the definitions in that class.  That would also be consistent with what users expect from a parameter labeled 'weight' rather than 'sigma'.  If we reach consensus on that definition, I can take care of that issue.&lt;/p&gt;
, &lt;p&gt;I could be missing something, but I see no reason that the weighted sum of squared residuals computed here (after the proposed change) should in general follow a chi-square distribution or be related to a chi-square test statistic of any kind.   Why is it called chi-square?  Sorry if I am missing something simple here.&lt;/p&gt;
, &lt;p&gt;I guess if you assume normalliy distributed errors, it makes sense, so drop the last comment and I am +1 for the change (with definition added to the javadoc).&lt;/p&gt;
, &lt;p&gt;Indeed, the confusion comes from the fact that, in some textbooks, each residual is divided by 'sigma_i' which leads to a weight of 1/(sigma_i^2).  In CM, we adopted the terminology 'weight' without reference to sigma.  I will change the javadoc accordingly.&lt;/p&gt;
, &lt;p&gt;Patch to correct issue &lt;a href="https://issues.apache.org/jira/browse/MATH-377" title="weight versus sigma in AbstractLeastSquares"&gt;&lt;del&gt;MATH-377&lt;/del&gt;&lt;/a&gt;.  The change in getChiSquare let to a tiny update in one of Levenberg-Marquardt unit tests.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[psteitz, dimpbx, luc], timeEstimate=1, timeSpent=null]
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-373
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-373, created=Mon Jun 07 16:54:00 CEST 2010, updated=Sat Mar 24 17:16:56 CET 2012, resolved=Thu Sep 02 06:52:33 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=StatUtils.sum returns NaN for zero-length arrays, link=https://issues.apache.org/jira/browse/MATH-373, description=&lt;p&gt;StatUtils.sum returns NaN for zero-length arrays, which is:&lt;/p&gt;

&lt;p&gt;1. inconsistent with the mathematical notion of sum: in maths, sum_{i=0}^{N-1} a_i will be 0 for N=0. In particular, the identity&lt;br/&gt;
&lt;br/&gt;
sum_{i=0}^{k-1} a_i + sum_{i=k}^{N-1} = sum_{i=0}^{N-1}&lt;/p&gt;

&lt;p&gt;is broken for k = 0, since NaN + x = NaN, not x.&lt;/p&gt;

&lt;p&gt;2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition, as NaNs propagate silently and require manual tracing during the debugging)&lt;/p&gt;

&lt;p&gt;3. enforces "special case" handling when the user expects that the summed array can have a zero length.&lt;/p&gt;

&lt;p&gt;The correct behaviour is, in my opinion, to return 0.0, not NaN in the above case.&lt;/p&gt;, comments=[&lt;p&gt;I agree with the reasoning here, and we should do it this way in 3.0.  However it is an incompatible change to do in a point release, so I'm going to wait for more feed back from other developers before I make any changes to the current code.&lt;/p&gt;

&lt;p&gt;I'm thinking that adding a method to AbstractUnivariateStatistic that looks like:&lt;br/&gt;
   protected boolean test( final double[] values,  final int begin,   final int length, final boolean allowEmpty)&lt;/p&gt;

&lt;p&gt;that would have the test:&lt;br/&gt;
   if(length == 0 &amp;amp;&amp;amp; !allowEmpty)&lt;br/&gt;
        return false;&lt;/p&gt;

&lt;p&gt;The current test method can call the new one with allowEmpty=false for backwards compatibility.  Then we can decide on which statistics should have a zero value on the empty set.&lt;/p&gt;
, &lt;p&gt;The consensus of the commons-math developers is that, since the current behavior is documented in 2.x, that this will have to wait for 3.0.  Fixing this in 2.x would introduce a too large incompatibility change to include in 2.x.&lt;/p&gt;

&lt;p&gt;I can attach a patch against 2.x that fixes this, as long as anybody using the patch understands that it isn't supported.&lt;/p&gt;

, &lt;p&gt;Possibly crazy idea: &lt;/p&gt;

&lt;p&gt;if Math 3.0 is going to change package names (which may be necessary), one could introduce the fix using a math3 package name?&lt;/p&gt;
, &lt;p&gt;IIRC, changing the package name had been suggested and discussed for 2.0.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;One argument is that, to be consistent,  you&amp;#39;d have to change the name at every major release...&amp;#93;&lt;/span&gt;&lt;/p&gt;
, &lt;p&gt;Speaking as a maintainer of client code which uses ACM, I'd rather cope with occasional incompatibilities in the same packages, than have to change ALL my client code to keep up with the package name changes after every release. A reason to change the package name would be if you wanted to use the old and new version side by side, but that would not be a common usage pattern for ACM, I think.&lt;/p&gt;
, &lt;p&gt;As Gilles mentioned, changing the package name for commons-math was discussed and voted on for 2.x.  The result of the vote was to keep the package name, since commons-math won't usually be provided by a third party library.  Since nothing much has changed, I can't see that commons-math would change it's package for version 3.0.&lt;/p&gt;
, &lt;p&gt;This will be fixed in the 3.0 build.&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[billbarker, sebb@apache.org, erans, rwerp], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-369
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-369, created=Mon May 03 17:48:27 CEST 2010, updated=Wed Mar 23 21:05:06 CET 2011, resolved=Mon May 03 20:43:59 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Minor, summary=BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException, link=https://issues.apache.org/jira/browse/MATH-369, description=&lt;p&gt;Method &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  &lt;/p&gt;

&lt;p&gt;invokes &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(double min, double max) &lt;/p&gt;

&lt;p&gt;which throws NullPointerException, as member variable&lt;/p&gt;

&lt;p&gt;    UnivariateRealSolverImpl.f &lt;/p&gt;

&lt;p&gt;is null.&lt;/p&gt;

&lt;p&gt;Instead the method:&lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)&lt;/p&gt;

&lt;p&gt;should be called.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;/p&gt;

&lt;p&gt;invoke:&lt;/p&gt;

&lt;p&gt;     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);&lt;/p&gt;

&lt;p&gt;NullPointerException will be thrown.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository as of r940565.&lt;br/&gt;
Thanks for the report and for the fix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sasunpundev@abv.bg, assignees=[], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-368
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-368, created=Thu Apr 29 05:41:10 CEST 2010, updated=Wed Mar 23 21:04:17 CET 2011, resolved=Mon May 10 01:07:24 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=OpenMapRealVector.getSparcity should be getSparsity, link=https://issues.apache.org/jira/browse/MATH-368, description=&lt;p&gt;The term for describing the ratio of nonzero elements to zero elements in a matrix/vector is sparsity, not sparcity.  Suggest renaming getSparcity() to getSparsity()&lt;/p&gt;, comments=[&lt;p&gt;The policy of this project is to not remove methods from the public API in a point release.  However, the misspelled method has been deprecated and the correctly spelled method has been added.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-367
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-367, created=Thu Apr 22 20:31:06 CEST 2010, updated=Wed Mar 23 21:03:42 CET 2011, resolved=Mon May 10 03:17:14 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=AbstractRealVector.sparseIterator fails when vector has exactly one non-zero entry, link=https://issues.apache.org/jira/browse/MATH-367, description=&lt;p&gt;The following program:&lt;br/&gt;
===&lt;br/&gt;
import java.util.Iterator;&lt;br/&gt;
import org.apache.commons.math.linear.*;&lt;/p&gt;

&lt;p&gt;public class SparseIteratorTester&lt;br/&gt;
{&lt;br/&gt;
    public static void main(String[] args) {&lt;br/&gt;
        double vdata[] = { 0.0, 1.0, 0.0 };&lt;br/&gt;
        RealVector v = new ArrayRealVector(vdata);&lt;br/&gt;
        Iterator&amp;lt;RealVector.Entry&amp;gt; iter = v.sparseIterator();&lt;br/&gt;
        while(iter.hasNext()) {
            RealVector.Entry entry = iter.next();
            System.out.printf("%d: %f\n", entry.getIndex(), entry.getValue());
        }   &lt;br/&gt;
    }       &lt;br/&gt;
} &lt;br/&gt;
===&lt;br/&gt;
generates this output:&lt;/p&gt;

&lt;p&gt;1: 1.000000&lt;br/&gt;
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: -1&lt;br/&gt;
	at org.apache.commons.math.linear.ArrayRealVector.getEntry(ArrayRealVector.java:995)&lt;br/&gt;
	at org.apache.commons.math.linear.AbstractRealVector$EntryImpl.getValue(AbstractRealVector.java:850)&lt;br/&gt;
	at test.SparseIteratorTester.main(SparseIteratorTester.java:13)&lt;br/&gt;
===&lt;/p&gt;

&lt;p&gt;This patch fixes it, and simplifies AbstractRealVector.SparseEntryIterator  (sorry, i don't see any form entry for attaching a file)&lt;br/&gt;
===&lt;br/&gt;
Index: src/main/java/org/apache/commons/math/linear/AbstractRealVector.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(revision 936985)&lt;br/&gt;
+++ src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(working copy)&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.commons.math.linear;&lt;/p&gt;

&lt;p&gt; import java.util.Iterator;&lt;br/&gt;
+import java.util.NoSuchElementException;&lt;/p&gt;

&lt;p&gt; import org.apache.commons.math.FunctionEvaluationException;&lt;br/&gt;
 import org.apache.commons.math.MathRuntimeException;&lt;br/&gt;
@@ -875,40 +876,25 @@&lt;br/&gt;
         /** Dimension of the vector. */&lt;br/&gt;
         private final int dim;&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Temporary entry (reused on each call to {@link #next()}. */&lt;/li&gt;
	&lt;li&gt;private EntryImpl tmp = new EntryImpl();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;/** Current entry. */&lt;br/&gt;
+        /** Last entry returned by #next(). */&lt;br/&gt;
         private EntryImpl current;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Next entry. */&lt;br/&gt;
+        /** Next entry for #next() to return. */&lt;br/&gt;
         private EntryImpl next;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** Simple constructor. */&lt;br/&gt;
         protected SparseEntryIterator() {&lt;br/&gt;
             dim = getDimension();&lt;br/&gt;
             current = new EntryImpl();&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (current.getValue() == 0) {
-                advance(current);
-            }&lt;/li&gt;
	&lt;li&gt;if(current.getIndex() &amp;gt;= 0){
-                // There is at least one non-zero entry
-                next = new EntryImpl();
-                next.setIndex(current.getIndex());
+            next = new EntryImpl();
+            if(next.getValue() == 0)
                 advance(next);
-            } else {
-                // The vector consists of only zero entries, so deny having a next
-                current = null;
-            }&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Advance an entry up to the next non null one.&lt;br/&gt;
+        /** Advance an entry up to the next nonzero value.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param e entry to advance&lt;br/&gt;
          */&lt;br/&gt;
         protected void advance(EntryImpl e) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (e == null) {
-                return;
-            }&lt;br/&gt;
             do {
                 e.setIndex(e.getIndex() + 1);
             } while (e.getIndex() &amp;lt; dim &amp;amp;&amp;amp; e.getValue() == 0);&lt;br/&gt;
@@ -919,22 +905,17 @@&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;br/&gt;
         public boolean hasNext() {
-            return current != null;
+            return next.getIndex() &amp;gt;= 0;
         }&lt;br/&gt;
 &lt;br/&gt;
         /** {@inheritDoc} */&lt;br/&gt;
         public Entry next() {&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;tmp.setIndex(current.getIndex());&lt;/li&gt;
	&lt;li&gt;if (next != null) {&lt;/li&gt;
	&lt;li&gt;current.setIndex(next.getIndex());&lt;/li&gt;
	&lt;li&gt;advance(next);&lt;/li&gt;
	&lt;li&gt;if (next.getIndex() &amp;lt; 0) {
-                    next = null;
-                }&lt;/li&gt;
	&lt;li&gt;} else {
-                current = null;
-            }&lt;/li&gt;
	&lt;li&gt;return tmp;&lt;br/&gt;
+            int index = next.getIndex();&lt;br/&gt;
+            if(index &amp;lt; 0)&lt;br/&gt;
+                throw new NoSuchElementException();&lt;br/&gt;
+            current.setIndex(index);&lt;br/&gt;
+            advance(next);&lt;br/&gt;
+            return current;&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;/p&gt;, comments=[&lt;p&gt;patch fixing the bug&lt;/p&gt;
, &lt;p&gt;I've applied your patch (with a couple of style tweaks).  It should be available in the next release of commons-math.&lt;/p&gt;

&lt;p&gt;Thank you for your contribution.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[ashuang, billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-365
2016-01-13 22:10:14,855 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-365, created=Tue Apr 20 16:21:20 CEST 2010, updated=Wed Mar 23 21:02:52 CET 2011, resolved=Wed Apr 21 16:35:53 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=Issue with "SmoothingBicubicSplineInterpolator", link=https://issues.apache.org/jira/browse/MATH-365, description=&lt;p&gt;I figured out that the name of this class is misleading as the implementation doesn't perform the intended smoothing.&lt;/p&gt;

&lt;p&gt;In order to solve this issue, I propose to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;deprecate the "SmoothingBicubicSplineInterpolator" class&lt;/li&gt;
	&lt;li&gt;create a "BicubicSplineInterpolator" class (similar to the above class but with the useless code removed)&lt;/li&gt;
	&lt;li&gt;remove the "SmoothingBicubicSplineInterpolatorTest" class&lt;/li&gt;
	&lt;li&gt;add a "BicubicSplineInterpolatorTest" with essentially the same contents as the above one&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Then I would also add a new "SmoothingPolynomialBicubicSplineInterpolator" where I used the "PolynomialFitter" class to smooth the input data along both dimensions before the interpolating function is computed.&lt;/p&gt;

&lt;p&gt;Does someone object to these changes?&lt;/p&gt;, comments=[&lt;p&gt;removing the test class would badly impact test coverage, so it would be better to simply deprecae it also and to remove the library class and its associated test class together when releasing 3.0&lt;/p&gt;
, &lt;p&gt;revision 936295.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,933 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-362
2016-01-13 22:10:14,933 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-362, created=Tue Apr 06 13:38:46 CEST 2010, updated=Wed Mar 23 21:02:00 CET 2011, resolved=Sat May 29 20:16:50 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it, link=https://issues.apache.org/jira/browse/MATH-362, description=&lt;p&gt;LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.&lt;/p&gt;, comments=[&lt;p&gt;Ooops. You are right.&lt;br/&gt;
The Levenberg-Marquardt optimizer uses specific convergence parameters which can be set by   setInitialStepBoundFactor, setCostRelativeTolerance, setParRelativeTolerance and setOrthoTolerance.&lt;br/&gt;
The most important convergence tuning are either setCostRelativeTolerance for a convergence on the cost itself or setParRelativeTolerance for a convergence on the parameters.&lt;/p&gt;

&lt;p&gt;I'm not sure how to solve this. Do the existing tuning parameters fit your needs or not ? Some convergence criteria can be expressed with both methods, but not all. Should we keep both setting as alternate methods or should we remove one and rely on the remaining one ?&lt;/p&gt;
, &lt;p&gt;I would keep using orthoTolerance as it is used now:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;292                if (maxCosine &amp;lt;= orthoTolerance) {&lt;br/&gt;
293                    // convergence has been reached&lt;br/&gt;
294                    return new VectorialPointValuePair(point, objective);&lt;br/&gt;
295                }&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;and then use costRelativeTolerance &amp;amp; parRelativeTolerance if and only if the convergence checker is null, otherwise use the convergence checker and ignore {costRelativeTolerance, parRelativeTolerance}.&lt;/p&gt;

&lt;p&gt;What I am missing now is the ability to bail out if the absolute distance from the target falls below some value ("close enough").&lt;/p&gt;
, &lt;p&gt;I've spent that last few days trying to find a good curve fitting library for Java and got excited when I learned of Commons Math.  Unfortunately, its curve fitting is very unreliable.  I'm hoping that this bug is what is causing the problems that I'm seeing.  I'm comparing data from NIST and results from DataFitX and it is apparent that Commons Math is not yet up to the task.  My fingers are crossed that its quality in the curve fitting area will be improved in the near future.  Keep up the good work Apache.&lt;/p&gt;

&lt;p&gt;I've opened an issue about the problems I'm seeing, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Double check how you use it, Matt. I have succesfully used this curve fitting in production.&lt;/p&gt;
, &lt;p&gt;Matt, could you please describe the problem you encounter more precisely (i.e. with numerical examples) and preferably in a new JIRA issue ? We will check if the two problems are related and link the issues afterwards if it appears they are.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
, &lt;p&gt;It's good to see such quick responses.  I'll open a new JIRA issue and spend some time putting together code, data and a detailed description of the problem I'm seeing.  Thanks Apache for all your hard work.&lt;/p&gt;

&lt;p&gt;I've opened an issue regarding the problem, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r949433.&lt;br/&gt;
Thanks for reporting the issue&lt;/p&gt;
, &lt;p&gt;Thank you.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=roman.werpachowski, assignees=[], commentAuthors=[luc, roman.werpachowski, mprice], timeEstimate=null, timeSpent=null]
2016-01-13 22:10:14,933 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry, issueId: MATH-288
2016-01-13 22:10:14,933 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:2 : Transforming issue entry:ITSDataType [issueId=MATH-288, created=Tue Aug 25 00:31:11 CEST 2009, updated=Wed Apr 14 02:30:17 CEST 2010, resolved=Tue Aug 25 20:10:08 CEST 2009, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.1
], priority=Major, summary=SimplexSolver not working as expected 2, link=https://issues.apache.org/jira/browse/MATH-288, description=&lt;p&gt;SimplexSolver didn't find the optimal solution.&lt;/p&gt;

&lt;p&gt;Program for Lpsolve:&lt;br/&gt;
=====================&lt;br/&gt;
/* Objective function */&lt;br/&gt;
max: 7 a 3 b;&lt;/p&gt;

&lt;p&gt;/* Constraints */&lt;br/&gt;
R1: +3 a -5 c &amp;lt;= 0;&lt;br/&gt;
R2: +2 a -5 d &amp;lt;= 0;&lt;br/&gt;
R3: +2 b -5 c &amp;lt;= 0;&lt;br/&gt;
R4: +3 b -5 d &amp;lt;= 0;&lt;br/&gt;
R5: +3 a +2 b &amp;lt;= 5;&lt;br/&gt;
R6: +2 a +3 b &amp;lt;= 5;&lt;/p&gt;

&lt;p&gt;/* Variable bounds */&lt;br/&gt;
a &amp;lt;= 1;&lt;br/&gt;
b &amp;lt;= 1;&lt;br/&gt;
=====================&lt;br/&gt;
Results(correct): a = 1, b = 1, value = 10&lt;/p&gt;


&lt;p&gt;Program for SimplexSolve:&lt;br/&gt;
=====================&lt;br/&gt;
LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]{7, 3, 0, 0}, 0);&lt;br/&gt;
Collection&amp;lt;LinearConstraint&amp;gt; podmienky = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{1, 0, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 1, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 0, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 0, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 2, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 3, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 2, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 3, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
RealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);&lt;br/&gt;
=====================&lt;br/&gt;
Results(incorrect): a = 1, b = 0.5, value = 8.5&lt;/p&gt;

&lt;p&gt;P.S. I used the latest software from the repository (including &lt;a href="https://issues.apache.org/jira/browse/MATH-286" title="SimplexSolver not working as expected?"&gt;&lt;del&gt;MATH-286&lt;/del&gt;&lt;/a&gt; fix).&lt;/p&gt;, comments=[&lt;p&gt;Thanks for the bug report.  I've confirmed this is an issue.&lt;/p&gt;

&lt;p&gt;Here's a slightly smaller version of the problem that causes the same bug, which might be easier for debugging:&lt;/p&gt;

&lt;p&gt;MAX 7 a + 3 b&lt;br/&gt;
s.t.&lt;br/&gt;
3 a -5 c &amp;lt;= 0&lt;br/&gt;
2 a -5 d &amp;lt;= 0&lt;br/&gt;
3 b -5 d &amp;lt;= 0&lt;br/&gt;
a &amp;lt;= 1&lt;br/&gt;
b &amp;lt;= 1&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 7, 3, 0, 0 }, 0 );&lt;br/&gt;
        Collection&amp;lt;LinearConstraint&amp;gt; constraints = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 3, 0, -5, 0 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 2, 0, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 3, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0 }, Relationship.LEQ, 1.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 0 }, Relationship.LEQ, 1.0));&lt;/p&gt;

&lt;p&gt;        SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
        RealPointValuePair solution = solver.optimize(f, constraints, GoalType.MAXIMIZE, true);&lt;br/&gt;
        assertEquals(10.0, solution.getValue(), .0000001);&lt;/p&gt;
, &lt;p&gt;Patch attached.  It was a 1 character bug.  I was saying to only do the minimum ratio test if the entry is &amp;gt;= 0, but it should have been &amp;gt; 0 (dividing by 0 is never good :o)&lt;br/&gt;
Thanks again for the bug report.&lt;/p&gt;
, &lt;p&gt;resolved in subversion repository as of r807738&lt;br/&gt;
patch applied (except for debug print function)&lt;br/&gt;
thanks for the repoart and thanks for the patch&lt;/p&gt;
], resolution=Fixed, reporter=kefa, assignees=[], commentAuthors=[bmccann, luc], timeEstimate=480, timeSpent=null]
2016-01-13 22:10:14,933 : INFO  : KNIME-Worker-1 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:2 : Jira table created.
2016-01-13 22:10:14,933 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 End execute (2 secs)
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 doBeforePostExecution
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: POSTEXECUTE
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 doAfterExecute - success
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:2 : Jira Adapter (Offline) 0:2 has new state: EXECUTED
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-1 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:2 : Table Difference Checker 0:3 has new state: CONFIGURED_QUEUED
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-0 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePreExecution
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: PREEXECUTE
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-0 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforeExecution
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTING
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Adding handler cc9ec6d1-4e70-4d70-8c63-7c5d0b9227df (Table Difference Checker 0:3: <no directory>) - 3 in total
2016-01-13 22:10:14,948 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 Start execute
2016-01-13 22:10:14,995 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 End execute (0 secs)
2016-01-13 22:10:14,995 : DEBUG : KNIME-Worker-0 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePostExecution
2016-01-13 22:10:14,995 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: POSTEXECUTE
2016-01-13 22:10:14,995 : DEBUG : KNIME-Worker-0 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doAfterExecute - success
2016-01-13 22:10:14,995 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTED
2016-01-13 22:10:14,995 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : JiraOfflineTest 0 has new state: EXECUTED
2016-01-13 22:10:15,011 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test execute workflow -----------------
2016-01-13 22:10:15,011 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test node messages -----------------
2016-01-13 22:10:15,011 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test node messages -----------------
2016-01-13 22:10:15,011 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test hilite rows -----------------
2016-01-13 22:10:15,011 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:10:15,073 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test hilite rows -----------------
2016-01-13 22:10:15,073 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test close views -----------------
2016-01-13 22:10:15,073 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test close views -----------------
2016-01-13 22:10:15,073 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test log messages -----------------
2016-01-13 22:10:15,089 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test log messages -----------------
2016-01-13 22:10:15,089 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test uncaught exceptions -----------------
2016-01-13 22:10:15,089 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test uncaught exceptions -----------------
2016-01-13 22:10:15,931 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ===== Memory statistics: 993,000 MB max, 49,831 MB used, 943,169 MB free ====
2016-01-13 22:10:15,931 : DEBUG : Service Thread : MemoryAlertSystem :  :  : Memory usage below threshold of 0.7125915080527087 after GC run
2016-01-13 22:10:15,931 : INFO  : Worker-1 : GUIWorkflowTestSuite :  :  : ================= Finished testflow WorkflowTests\JiraOfflineTest =================
2016-01-13 22:10:16,165 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:10:16,165 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:10:16,181 : DEBUG : Worker-1 : WorkflowManager :  :  : Removing project "JiraOfflineTest 0"
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Removing handler cc9ec6d1-4e70-4d70-8c63-7c5d0b9227df (Table Difference Checker 0:3: <no directory>) - 2 remaining
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : DifferenceCheckerNodeModel : Table Difference Checker : 0:3 : Removing all (0) views from model.
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:2 : Removing handler 8c21a786-a673-485c-b8de-3becfc0a13c1 (Jira Adapter (Offline) 0:2: <no directory>) - 1 remaining
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : JiraAdapterNodeModel : Jira Adapter (Offline) : 0:2 : Removing all (0) views from model.
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : clean output ports.
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:1 : Removing handler 93835152-8d52-4ae6-bc44-8e95dab6448a (Jira Adapter (Offline) 0:1: <no directory>) - 0 remaining
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : JiraAdapterNodeModel : Jira Adapter (Offline) : 0:1 : Removing all (0) views from model.
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : clean output ports.
2016-01-13 22:10:16,290 : DEBUG : Worker-1 : WorkflowManager :  :  : Project "JiraOfflineTest 0" removed (1 remaining)
2016-01-13 22:10:19,675 : DEBUG : KNIME-Node-Usage-Writer : NodeTimer$GlobalNodeStats :  :  : Successfully wrote node usage stats to file: D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\nodeusage_3.0.json
2016-01-13 22:10:19,675 : DEBUG : KNIME-Node-Usage-Sender : NodeTimer$GlobalNodeStats :  :  : Sending of usage stats disabled.
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # Welcome to the KNIME Analytics Platform v3.1.0.v201512031304 (Build December 06, 2015 #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # Based on Eclipse, http://www.eclipse.org                                              #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # Copyright by KNIME GmbH, Konstanz, Germany and others.                                #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # Website: http://www.knime.org                                                         #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # E-mail: contact@knime.org                                                             #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # For more details see the KNIME log file:                                              #
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\knime.log
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : #---------------------------------------------------------------------------------------#
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # logging date=Wed Jan 13 22:19:49 CET 2016
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # java.version=1.8.0_60
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # java.vm.version=25.60-b23
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # java.vendor=Oracle Corporation
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # os.name=Windows 7
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # os.arch=amd64
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # number of CPUs=2
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # assertions=off
2016-01-13 22:19:49,082 : INFO  : main : NodeLogger :  :  : # host=SONY-Komputer
2016-01-13 22:19:49,097 : INFO  : main : NodeLogger :  :  : # username=SONY
2016-01-13 22:19:49,097 : INFO  : main : NodeLogger :  :  : # max mem=910MB
2016-01-13 22:19:49,097 : INFO  : main : NodeLogger :  :  : # application=org.knime.product.KNIME_APPLICATION
2016-01-13 22:19:49,097 : INFO  : main : NodeLogger :  :  : # ID=01-9c587cb4eccee8b8
2016-01-13 22:19:49,097 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:19:57,118 : INFO  : main : StringHistory :  :  : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_database_drivers.txt' does not exist.
2016-01-13 22:19:57,118 : INFO  : main : StringHistory :  :  : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_database_urls.txt' does not exist.
2016-01-13 22:19:57,118 : DEBUG : main : DatabaseConnectionSettings :  :  : Settings database timeout to 15 seconds
2016-01-13 22:19:57,180 : DEBUG : main : DatabaseConnectionSettings :  :  : Database concurrency (sync via database connection) is true.
2016-01-13 22:19:57,180 : DEBUG : main : KNIMECorePlugin :  :  : Setting KNIME max thread count to 4
2016-01-13 22:19:57,180 : DEBUG : main : KNIMECorePlugin :  :  : Setting KNIME temp dir to "C:\Users\SONY\AppData\Local\Temp"
2016-01-13 22:19:57,289 : INFO  : main : KNIMECorePlugin :  :  : Setting console view log level to WARN
2016-01-13 22:19:57,570 : DEBUG : main : KnimeEncryption :  :  : Replacing current encryption key supplier "null" with this new one "org.knime.workbench.core.EclipseEncryptionKeySupplier@6f986501".
2016-01-13 22:19:57,570 : DEBUG : main : DatabaseConnectionSettings :  :  : Settings database timeout to 15 seconds
2016-01-13 22:19:57,586 : DEBUG : main : KnimeEncryption :  :  : Replacing current encryption key supplier "org.knime.workbench.core.EclipseEncryptionKeySupplier@6f986501" with this new one "org.knime.workbench.ui.masterkey.MasterKeyPreferencePage$1@1186374c".
2016-01-13 22:19:58,272 : DEBUG : main : SvgPluginActivator :  :  : Added SVG export option to node view class
2016-01-13 22:19:59,817 : DEBUG : main : KnimeEnterpriseFileSystemPlugin :  :  : Started KNIME Enterprise Remote File System plug-in
2016-01-13 22:19:59,910 : INFO  : main : ExplorerMountTable :  :  : Mounted Explorer Temp Space 'knime-temp-space' - com.knime.explorer.tempspace
2016-01-13 22:20:00,035 : DEBUG : main : UpdateManager :  :  : Updating registered ServerSpaces every 2000 msec.
2016-01-13 22:20:01,564 : DEBUG : main : NodeTimer$GlobalNodeStats :  :  : Successfully read node usage stats from file: D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\nodeusage_3.0.json
2016-01-13 22:20:01,611 : DEBUG : main : NodeContainer :  :  : ROOT  has new state: EXECUTED
2016-01-13 22:20:01,611 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 
2016-01-13 22:20:01,611 : DEBUG : main : NodeContainer :  :  : KNIME MetaNode Repository 1 has new state: EXECUTED
2016-01-13 22:20:01,611 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1
2016-01-13 22:20:01,611 : DEBUG : main : WorkflowManager :  :  : Added new subworkflow 1
2016-01-13 22:20:01,611 : DEBUG : main : WorkflowManager :  :  : Created project 1
2016-01-13 22:20:01,626 : DEBUG : main : RepositoryManager :  :  : Found category extension 'io' on path '/'
2016-01-13 22:20:01,626 : DEBUG : main : RepositoryManager :  :  : Found category extension 'manipulation' on path '/'
2016-01-13 22:20:01,642 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database' on path '/'
2016-01-13 22:20:01,642 : DEBUG : main : RepositoryManager :  :  : Found category extension 'view' on path '/'
2016-01-13 22:20:01,642 : DEBUG : main : RepositoryManager :  :  : Found category extension 'analytics' on path '/'
2016-01-13 22:20:01,642 : DEBUG : main : RepositoryManager :  :  : Found category extension 'toolintegration' on path '/'
2016-01-13 22:20:01,642 : DEBUG : main : RepositoryManager :  :  : Found category extension 'misc' on path '/'
2016-01-13 22:20:01,642 : DEBUG : main : RepositoryManager :  :  : Found category extension 'labs' on path '/'
2016-01-13 22:20:01,657 : DEBUG : main : RepositoryManager :  :  : Found category extension 'community' on path '/'
2016-01-13 22:20:01,657 : DEBUG : main : RepositoryManager :  :  : Found category extension 'social-media' on path '/'
2016-01-13 22:20:01,657 : DEBUG : main : RepositoryManager :  :  : Found category extension 'report' on path '/'
2016-01-13 22:20:01,657 : DEBUG : main : RepositoryManager :  :  : Found category extension 'chemistry' on path '/'
2016-01-13 22:20:01,657 : DEBUG : main : RepositoryManager :  :  : Found category extension 'applications' on path '/'
2016-01-13 22:20:01,657 : DEBUG : main : RepositoryManager :  :  : Found category extension 'struct-data' on path '/'
2016-01-13 22:20:01,657 : DEBUG : main : RepositoryManager :  :  : Found category extension 'scripting' on path '/'
2016-01-13 22:20:01,673 : DEBUG : main : RepositoryManager :  :  : Found category extension 'flowcontrol' on path '/'
2016-01-13 22:20:01,673 : DEBUG : main : RepositoryManager :  :  : Found category extension 'uncategorized' on path '/'
2016-01-13 22:20:01,673 : DEBUG : main : RepositoryManager :  :  : Found category extension 'testing' on path '/'
2016-01-13 22:20:01,673 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress' on path '/community'
2016-01-13 22:20:01,673 : DEBUG : main : RepositoryManager :  :  : Found category extension 'read' on path '/io'
2016-01-13 22:20:01,673 : DEBUG : main : RepositoryManager :  :  : Found category extension 'write' on path '/io'
2016-01-13 22:20:01,673 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column' on path '/manipulation'
2016-01-13 22:20:01,689 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row' on path '/manipulation'
2016-01-13 22:20:01,689 : DEBUG : main : RepositoryManager :  :  : Found category extension 'table' on path '/manipulation'
2016-01-13 22:20:01,689 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pmml' on path '/manipulation'
2016-01-13 22:20:01,689 : DEBUG : main : RepositoryManager :  :  : Found category extension 'property' on path '/view'
2016-01-13 22:20:01,689 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mining' on path '/analytics'
2016-01-13 22:20:01,689 : DEBUG : main : RepositoryManager :  :  : Found category extension 'statistics' on path '/analytics'
2016-01-13 22:20:01,689 : DEBUG : main : RepositoryManager :  :  : Found category extension 'io-other' on path '/io'
2016-01-13 22:20:01,689 : DEBUG : main : RepositoryManager :  :  : Found category extension 'java-snippet' on path '/scripting'
2016-01-13 22:20:01,689 : DEBUG : main : RepositoryManager :  :  : Found category extension 'view-util' on path '/view'
2016-01-13 22:20:01,704 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-io' on path '/database'
2016-01-13 22:20:01,704 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-manipulation' on path '/database'
2016-01-13 22:20:01,704 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-connector' on path '/database'
2016-01-13 22:20:01,704 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-utility' on path '/database'
2016-01-13 22:20:01,704 : DEBUG : main : RepositoryManager :  :  : Found category extension 'automation' on path '/flowcontrol'
2016-01-13 22:20:01,704 : DEBUG : main : RepositoryManager :  :  : Found category extension 'quickforms' on path '/flowcontrol'
2016-01-13 22:20:01,704 : DEBUG : main : RepositoryManager :  :  : Found category extension 'variables' on path '/flowcontrol'
2016-01-13 22:20:01,704 : DEBUG : main : RepositoryManager :  :  : Found category extension 'switches' on path '/flowcontrol'
2016-01-13 22:20:01,704 : DEBUG : main : RepositoryManager :  :  : Found category extension 'trycatch' on path '/flowcontrol'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/flowcontrol'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'filestore' on path '/testing'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'timeseries' on path '/applications'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress.scm' on path '/community/depress'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress.its' on path '/community/depress'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-other' on path '/manipulation/row'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-split+combine' on path '/manipulation/column'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-filter' on path '/manipulation/column'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-transform' on path '/manipulation/column'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'binning' on path '/manipulation/column'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-convert+replace' on path '/manipulation/column'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-filter' on path '/manipulation/row'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-transform' on path '/manipulation/row'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'clustering' on path '/analytics/mining'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'nn' on path '/analytics/mining'
2016-01-13 22:20:01,720 : DEBUG : main : RepositoryManager :  :  : Found category extension 'regression' on path '/analytics/statistics'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'rules' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'dtree' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'modeleval' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'subgroup' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'miscClass' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'bayes' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mds' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'svm' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'featureselection' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pca' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'weka' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mining-pmml' on path '/analytics/mining'
2016-01-13 22:20:01,735 : DEBUG : main : RepositoryManager :  :  : Found category extension 'loopsupport' on path '/flowcontrol/'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'treeensemble' on path '/analytics/mining'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'regression' on path 'analytics/mining/treeensemble'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'ensembles' on path '/analytics/mining'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'hypothesis-testing' on path '/analytics/statistics'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/applications/timeseries'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'basisfunction' on path '/analytics/mining/rules'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mlp' on path '/analytics/mining/nn'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pnn' on path '/analytics/mining/nn'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/featureselection'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'crossvalidation' on path '/analytics/mining/modeleval'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/modeleval'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'classification' on path '/analytics/mining/treeensemble'
2016-01-13 22:20:01,751 : DEBUG : main : RepositoryManager :  :  : Found category extension 'ensembles-combine' on path '/analytics/mining/ensembles'
2016-01-13 22:20:01,767 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/ensembles'
2016-01-13 22:20:02,640 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.its.bugzilla': Bugzilla Adapter (Offline)
2016-01-13 22:20:02,656 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.its.jira': Jira Adapter (Offline)
2016-01-13 22:20:02,671 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.scm.gitoffline': Git SCM
2016-01-13 22:20:02,687 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.scm.svnoffline': SVN SCM
2016-01-13 22:20:02,718 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.smote.SmoteNodeFactory': SMOTE
2016-01-13 22:20:02,734 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.filereader.FileReaderNodeFactory': File Reader
2016-01-13 22:20:02,749 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.ColorManager2NodeFactory': Color Manager
2016-01-13 22:20:02,765 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.size.SizeManager2NodeFactory': Size Manager
2016-01-13 22:20:02,781 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.shape.ShapeManagerNodeFactory': Shape Manager
2016-01-13 22:20:02,796 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.ColorAppenderNodeFactory': Color Appender
2016-01-13 22:20:02,859 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.size.SizeAppenderNodeFactory': Size Appender
2016-01-13 22:20:02,921 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.shape.ShapeAppenderNodeFactory': Shape Appender
2016-01-13 22:20:02,952 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.table.TableNodeFactory': Interactive Table
2016-01-13 22:20:02,999 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.binner.BinnerNodeFactory': Numeric Binner
2016-01-13 22:20:03,046 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.binnerdictionary.BinByDictionaryNodeFactory': Binner (Dictionary)
2016-01-13 22:20:03,061 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.cache.CacheNodeFactory': Cache
2016-01-13 22:20:03,077 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.fuzzy.FuzzyBasisFunctionLearnerNodeFactory': Fuzzy Rule Learner
2016-01-13 22:20:04,403 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.fuzzy.FuzzyBasisFunctionPredictor2NodeFactory': Fuzzy Rule Predictor
2016-01-13 22:20:04,419 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.radial.RadialBasisFunctionLearnerNodeFactory': PNN Learner (DDA)
2016-01-13 22:20:04,434 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.radial.RadialBasisFunctionPredictor2NodeFactory': PNN Predictor
2016-01-13 22:20:04,465 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.csvwriter.CSVWriterNodeFactory': CSV Writer
2016-01-13 22:20:04,481 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.joiner.Joiner2NodeFactory': Joiner
2016-01-13 22:20:04,497 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.crossjoin.CrossJoinerNodeFactory': Cross Joiner
2016-01-13 22:20:04,512 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.split2.SplitNodeFactory2': Column Splitter
2016-01-13 22:20:04,512 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnappend.ColumnAppenderNodeFactory': Column Appender
2016-01-13 22:20:04,528 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.arffwriter.ARFFWriterNodeFactory': ARFF Writer
2016-01-13 22:20:04,543 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.sorter.SorterNodeFactory': Sorter
2016-01-13 22:20:04,543 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.arffreader.ARFFReaderNodeFactory': ARFF Reader
2016-01-13 22:20:04,559 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.csvreader.CSVReaderNodeFactory': CSV Reader
2016-01-13 22:20:04,575 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.linereader.LineReaderNodeFactory': Line Reader
2016-01-13 22:20:04,575 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.crosstable.CrosstabNodeFactory': Crosstab
2016-01-13 22:20:04,590 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.valcount.ValueCounterNodeFactory': Value Counter
2016-01-13 22:20:04,606 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize3.Normalize3NodeFactory': Normalizer
2016-01-13 22:20:04,606 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.PMMLNormalizerApplyNodeFactory': Normalizer Apply (PMML)
2016-01-13 22:20:04,621 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columnfilter.DataColumnSpecFilterPMMLNodeFactory': Column Filter (PMML)
2016-01-13 22:20:04,637 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.append.row.AppendedRowsNodeFactory': Concatenate
2016-01-13 22:20:04,637 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.append.row.AppendedRowsWithOptionalInNodeFactory': Concatenate (Optional in)
2016-01-13 22:20:04,653 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.row.RowFilterNodeFactory': Row Filter
2016-01-13 22:20:04,653 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.row.RowFilter2PortNodeFactory': Row Splitter
2016-01-13 22:20:04,668 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.shuffle.ShuffleNodeFactory': Shuffle
2016-01-13 22:20:04,684 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.sample.SamplingNodeFactory': Row Sampling
2016-01-13 22:20:04,684 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bootstrap.BootstrapNodeFactory': Bootstrap Sampling
2016-01-13 22:20:04,699 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.equalsizesampling.EqualSizeSamplingNodeFactory': Equal Size Sampling
2016-01-13 22:20:04,715 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.partition.PartitionNodeFactory': Partitioning
2016-01-13 22:20:04,731 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.fuzzycmeans.FuzzyClusterNodeFactory2': Fuzzy c-Means
2016-01-13 22:20:04,731 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.neural.mlp2.MLPPredictorNodeFactory': MultiLayerPerceptron Predictor
2016-01-13 22:20:04,762 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.predictor.PredictorReaderNodeFactory': Model Reader
2016-01-13 22:20:04,777 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.transpose.TransposeTableNodeFactory': Transpose
2016-01-13 22:20:04,777 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.extracttabledimension.ExtractTableDimensionNodeFactory': Extract Table Dimension
2016-01-13 22:20:04,793 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.extracttablespec.ExtractTableSpecNodeFactory': Extract Table Spec
2016-01-13 22:20:04,809 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.predictor2.DecTreePredictorNodeFactory': Decision Tree Predictor
2016-01-13 22:20:04,824 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.image.DecTreeToImageNodeFactory': Decision Tree To Image
2016-01-13 22:20:04,824 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.sota.SotaLearnerNodeFactory': SOTA Learner
2016-01-13 22:20:04,840 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rename.RenameNodeFactory': Column Rename
2016-01-13 22:20:04,855 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnrenameregex.ColumnRenameRegexNodeFactory': Column Rename (Regex)
2016-01-13 22:20:04,855 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.constantvalue.ConstantValueColumnNodeFactory': Constant Value Column
2016-01-13 22:20:04,871 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.create.CreateBitVectorNodeFactory': Create Bit Vector
2016-01-13 22:20:04,887 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.subgroupminer.SubgroupMinerFactory2': Association Rule Learner
2016-01-13 22:20:04,887 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.linear2.predict.GeneralRegressionPredictorNodeFactory': Regression Predictor
2016-01-13 22:20:04,902 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.table.read.ReadTableNodeFactory': Table Reader
2016-01-13 22:20:04,918 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.table.write.WriteTableNodeFactory': Table Writer
2016-01-13 22:20:04,918 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.create.CreateBitVectorNodeFactory': Create Bit Vector
2016-01-13 22:20:04,933 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.expand.ExpandBitVectorNodeFactory': Expand Bit Vector
2016-01-13 22:20:04,949 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.histogram.node.HistogramNodeFactory': Histogram (interactive)
2016-01-13 22:20:04,965 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.histogram.node.FixedColumnHistogramNodeFactory': Histogram
2016-01-13 22:20:04,965 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.NormalizeApplyNodeFactory': Normalizer (Apply)
2016-01-13 22:20:05,011 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.box.BoxPlotNodeFactory': Box Plot
2016-01-13 22:20:05,027 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.line.LinePlotterNodeFactory': Line Plot
2016-01-13 22:20:05,043 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.parcoord.ParallelCoordinateNodeFactory': Parallel Coordinates
2016-01-13 22:20:05,058 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.scatter.ScatterPlotterNodeFactory': Scatter Plot
2016-01-13 22:20:05,074 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.scattermatrix.ScatterMatrixNodeFactory': Scatter Matrix
2016-01-13 22:20:05,105 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.hilite': HiLite Row Splitter
2016-01-13 22:20:05,121 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.discretization.caim.modelcreator.CAIMDiscretizationNodeFactory': CAIM Binner
2016-01-13 22:20:05,121 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.discretization.caim.modelapply.DiscretizationApplyNodeFactory': CAIM Applier
2016-01-13 22:20:05,136 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rowkey2.RowKeyNodeFactory2': RowID
2016-01-13 22:20:05,152 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.knn.KnnNodeFactory': K Nearest Neighbor
2016-01-13 22:20:05,183 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.hierarchical.HierarchicalClusterNodeFactory': Hierarchical Clustering
2016-01-13 22:20:05,230 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.sota.predictor.SotaPredictorNodeFactory': SOTA Predictor
2016-01-13 22:20:05,245 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.pie.node.fixed.FixedPieNodeFactory': Pie chart
2016-01-13 22:20:05,261 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.pie.node.interactive.InteractivePieNodeFactory': Pie chart (interactive)
2016-01-13 22:20:05,277 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.groupby.GroupByNodeFactory': GroupBy
2016-01-13 22:20:05,292 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.ungroup.UngroupNodeFactory': Ungroup
2016-01-13 22:20:05,292 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pivot.Pivot2NodeFactory': Pivoting
2016-01-13 22:20:05,308 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bayes.naivebayes.predictor3.NaiveBayesPredictorNodeFactory2': Naive Bayes Predictor
2016-01-13 22:20:05,323 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.compute.CorrelationComputeNodeFactory': Linear Correlation
2016-01-13 22:20:05,323 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.compute.CorrelationComputeNodeFactory': Linear Correlation
2016-01-13 22:20:05,339 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.filter.CorrelationFilterNodeFactory': Correlation Filter
2016-01-13 22:20:05,355 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.lowvarfilter2.LowVarFilter2NodeFactory': Low Variance Filter
2016-01-13 22:20:05,370 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.mds.MDSNodeFactory': MDS
2016-01-13 22:20:05,370 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.mds.mdsprojection.MDSProjectionNodeFactory': MDS Projection
2016-01-13 22:20:05,386 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.svm.predictor2.SVMPredictorNodeFactory': SVM Predictor
2016-01-13 22:20:05,386 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colcompare.ColumnComparatorNodeFactory': Column Comparator
2016-01-13 22:20:05,401 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rowsplit.NumericRowSplitterNodeFactory': Numeric Row Splitter
2016-01-13 22:20:05,417 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringreplacer.StringReplacerNodeFactory': String Replacer
2016-01-13 22:20:05,417 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.dialog2.DomainNodeFactory': Domain Calculator
2016-01-13 22:20:05,433 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnumeric.EditNumericDomainNodeFactory': Edit Numeric Domain
2016-01-13 22:20:05,448 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnominal.dic.EditNominalDomainDicNodeFactory': Edit Nominal Domain (Dictionary)
2016-01-13 22:20:05,448 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnominal.EditNominalDomainNodeFactory': Edit Nominal Domain
2016-01-13 22:20:05,464 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.caseconvert.CaseConvertNodeFactory': Case Converter
2016-01-13 22:20:05,464 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringreplacer.dict.SearchReplaceDictNodeFactory': String Replace (Dictionary)
2016-01-13 22:20:05,479 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellsplit.CellSplitterNodeFactory': Cell Splitter
2016-01-13 22:20:05,479 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.numbertostring.NumberToStringNodeFactory': Number To String
2016-01-13 22:20:05,495 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.stringtonumber.StringToNumberNodeFactory': String To Number
2016-01-13 22:20:05,511 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntrans2.One2ManyCol2NodeFactory': One to Many
2016-01-13 22:20:05,511 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntrans2.Many2OneCol2NodeFactory': Many to One
2016-01-13 22:20:05,526 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colcombine2.ColCombine2NodeFactory': Column Combiner
2016-01-13 22:20:05,526 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnmerge.ColumnMergerNodeFactory': Column Merger
2016-01-13 22:20:05,542 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.assign.ClusterAssignerNodeFactory': Cluster Assigner
2016-01-13 22:20:05,557 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.accuracy.AccuracyScorerNodeFactory': Scorer
2016-01-13 22:20:05,573 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.numeric.NumericScorerNodeFactory': Numeric Scorer
2016-01-13 22:20:05,573 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.entrop.NewEntropyNodeFactory': Entropy Scorer
2016-01-13 22:20:05,589 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.roc.ROCNodeFactory': ROC Curve
2016-01-13 22:20:05,589 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.chem.node.viz.enrich2.EnrichmentPlotterFactory': Enrichment Plotter
2016-01-13 22:20:05,604 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBReaderNodeFactory': Database Reader
2016-01-13 22:20:05,620 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBReaderConnectionNodeFactory': Database Table Connector
2016-01-13 22:20:05,620 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DatabaseLoopingNodeFactory': Database Looping
2016-01-13 22:20:05,635 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBConnectionNodeFactory': Database Connection Table Reader
2016-01-13 22:20:05,635 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBRowFilterNodeFactory': Database Row Filter
2016-01-13 22:20:05,651 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBQueryNodeFactory2': Database Query
2016-01-13 22:20:05,651 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBColumnFilterNodeFactory': Database Column Filter
2016-01-13 22:20:05,667 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBSorterNodeFactory': Database Sorter
2016-01-13 22:20:05,667 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBGroupByNodeFactory': Database GroupBy
2016-01-13 22:20:05,682 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBJoinerNodeFactory': Database Joiner
2016-01-13 22:20:05,698 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBConnectionWriterNodeFactory': Database Connection Table Writer
2016-01-13 22:20:05,698 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBWriterNodeFactory': Database Writer
2016-01-13 22:20:05,713 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBUpdateNodeFactory': Database Update
2016-01-13 22:20:05,713 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBDeleteRowsNodeFactory': Database Delete
2016-01-13 22:20:05,729 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBSQLExecutorNodeFactory': Database SQL Executor
2016-01-13 22:20:05,729 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellsplitbypos.CellSplitterByPositionNodeFactory': Cell Splitter By Position
2016-01-13 22:20:05,745 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.condbox.ConditionalBoxPlotNodeFactory': Conditional Box Plot
2016-01-13 22:20:05,760 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnFilterRefNodeFactory': Reference Column Filter
2016-01-13 22:20:05,760 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.MissingValueColumnFilterNodeFactory': Missing Value Column Filter
2016-01-13 22:20:05,776 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowFilterRefNodeFactory': Reference Row Filter
2016-01-13 22:20:05,776 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.collection.list.create2.CollectionCreate2NodeFactory': Create Collection Column
2016-01-13 22:20:05,791 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.collection.list.split.CollectionSplitNodeFactory': Split Collection Column
2016-01-13 22:20:05,791 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.pmml.read.PMMLReaderNodeFactory': PMML Reader
2016-01-13 22:20:05,807 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.regexsplit.RegexSplitNodeFactory': Regex Split
2016-01-13 22:20:05,807 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.pmml.write.PMMLWriterNodeFactory': PMML Writer
2016-01-13 22:20:05,823 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.predictor.PredictorWriterNodeFactory': Model Writer
2016-01-13 22:20:05,823 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.writemage.WriteImageNodeFactory': Image Port Writer
2016-01-13 22:20:05,838 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.imagecolwriter.ImageColumnWriterNodeFactory': Image Column Writer
2016-01-13 22:20:05,854 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.liftchart.LiftChartNodeFactory': Lift Chart
2016-01-13 22:20:05,854 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.setoperator.SetOperatorNodeFactory': Set Operator
2016-01-13 22:20:05,869 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.xvalidation.XValidatePartitionerFactory': X-Partitioner
2016-01-13 22:20:05,869 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.xvalidation.AggregateOutputNodeFactory': X-Aggregator
2016-01-13 22:20:05,885 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopStartCountNodeFactory': Counting Loop Start
2016-01-13 22:20:05,885 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.chunk.LoopStartChunkNodeFactory': Chunk Loop Start
2016-01-13 22:20:05,901 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.columnlist2.ColumnListLoopStartNodeFactory': Column List Loop Start
2016-01-13 22:20:05,901 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.condition.LoopStartGenericNodeFactory': Generic Loop Start
2016-01-13 22:20:05,916 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.variableloophead.LoopStartVariableNodeFactory': Table Row To Variable Loop Start
2016-01-13 22:20:05,932 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopEndNodeFactory': Loop End
2016-01-13 22:20:05,932 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.condition.LoopEndConditionNodeFactory': Variable Condition Loop End
2016-01-13 22:20:05,947 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.extractvariables.ExtractVariablesNodeFactory': Extract Variables (Data)
2016-01-13 22:20:05,979 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.extractvariables.ExtractVariablesDBNodeFactory': Extract Variables (Database)
2016-01-13 22:20:05,994 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopStart1NodeFactory': Backward Feature Elimination Start (1:1)
2016-01-13 22:20:05,994 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopStart2NodeFactory': Backward Feature Elimination Start (2:2)
2016-01-13 22:20:06,010 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopEndNodeFactory': Backward Feature Elimination End
2016-01-13 22:20:06,010 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimFilterNodeFactory': Backward Feature Elimination Filter
2016-01-13 22:20:06,025 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.appendvariabletotable2.AppendVariableToTable2NodeFactory': Variable to Table Column
2016-01-13 22:20:06,041 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.variabletotablerow2.VariableToTable2NodeFactory': Variable to Table Row
2016-01-13 22:20:06,041 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.tablerowtovariable.TableToVariableNodeFactory': Table Row to Variable
2016-01-13 22:20:06,041 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.injectvariables.InjectVariablesNodeFactory': Inject Variables (Data)
2016-01-13 22:20:06,057 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.injectvariables.InjectVariablesDBNodeFactory': Inject Variables (Database)
2016-01-13 22:20:06,072 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.nominal.NominalValueRowFilterNodeFactory': Nominal Value Row Filter
2016-01-13 22:20:06,072 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopStartIntervalNodeFactory': Interval Loop Start
2016-01-13 22:20:06,088 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.breakpoint.BreakpointNodeFactory': Breakpoint
2016-01-13 22:20:06,088 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.unpivot2.Unpivot2NodeFactory': Unpivoting
2016-01-13 22:20:06,103 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCANodeFactory': PCA
2016-01-13 22:20:06,103 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAComputeNodeFactory': PCA Compute
2016-01-13 22:20:06,119 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAApplyNodeFactory': PCA Apply
2016-01-13 22:20:06,119 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAReverseNodeFactory': PCA Inversion
2016-01-13 22:20:06,135 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.double2int.DoubleToIntNodeFactory': Double To Int
2016-01-13 22:20:06,150 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.hilite.collector.InteractiveHiLiteCollectorNodeFactory': Interactive HiLite Collector
2016-01-13 22:20:06,150 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.exp.node.meta.looper.LoopEnd2NodeFactory': Loop End (2 ports)
2016-01-13 22:20:06,166 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.matcher.SubsetMatcherNodeFactory': Subset Matcher
2016-01-13 22:20:06,166 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.matcher.SubsetMatcherNodeFactory': Subset Matcher
2016-01-13 22:20:06,181 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.ImageToTableNodeFactory': Image To Table
2016-01-13 22:20:06,181 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.tablerowtoimage.TableRowToImageNodeFactory': Table To Image
2016-01-13 22:20:06,197 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.manualif.ManualIfNodeFactory': IF Switch
2016-01-13 22:20:06,197 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endif.EndifNodeFactory': End IF
2016-01-13 22:20:06,213 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.startcase.StartcaseNodeFactory': CASE Switch Data (Start)
2016-01-13 22:20:06,213 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endcase.EndcaseNodeFactory': CASE Switch Data (End)
2016-01-13 22:20:06,228 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.model.CaseStartModelNodeFactory': CASE Switch Model (Start)
2016-01-13 22:20:06,228 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endmodelcase.EndmodelcaseNodeFactory': CASE Switch Model (End)
2016-01-13 22:20:06,244 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.variable.CaseStartVariableNodeFactory': CASE Switch Variable (Start)
2016-01-13 22:20:06,244 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.variable.CaseEndVariableNodeFactory': CASE Switch Variable (End)
2016-01-13 22:20:06,259 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.emptytableswitch.EmptyTableSwitchNodeFactory': Empty Table Switch
2016-01-13 22:20:06,259 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntogrid2.ColumnToGrid2NodeFactory': Column to Grid
2016-01-13 22:20:06,275 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnheaderextract.ColumnHeaderExtractorNodeFactory': Extract Column Header
2016-01-13 22:20:06,275 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnheaderinsert.ColumnHeaderInsertNodeFactory': Insert Column Header
2016-01-13 22:20:06,291 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.addemptyrows.AddEmptyRowsNodeFactory': Add Empty Rows
2016-01-13 22:20:06,291 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellreplace.CellReplacerNodeFactory': Cell Replacer
2016-01-13 22:20:06,306 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.autobinner3.AutoBinnerLearnNodeFactory': Auto-Binner
2016-01-13 22:20:06,306 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.autobinner.apply.AutoBinnerApplyNodeFactory': Auto-Binner (Apply)
2016-01-13 22:20:06,322 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopEndJoin2NodeFactory': Loop End (Column Append)
2016-01-13 22:20:06,322 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.listfiles2.ListFilesNodeFactory': List Files
2016-01-13 22:20:06,337 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.tablecreator.TableCreator2NodeFactory': Table Creator
2016-01-13 22:20:06,353 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.sampledata.SampleDataNodeFactory': Data Generator
2016-01-13 22:20:06,353 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.createtablestructure.CreateTableStructureNodeFactory': Create Table Structure
2016-01-13 22:20:06,369 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.createtempdir.CreateTempDirectoryNodeFactory': Create Temp Dir
2016-01-13 22:20:06,369 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.sendmail.SendMailNodeFactory': Send Email
2016-01-13 22:20:06,384 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.extractsysprop.ReadSysPropertyNodeFactory': Extract System Properties
2016-01-13 22:20:06,384 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.extractcontextprop.ReadContextPropertyNodeFactory': Extract Context Properties
2016-01-13 22:20:06,400 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.PMMLNormalizerDeNodeFactory': Denormalizer (PMML)
2016-01-13 22:20:06,400 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.NormalizerDeNodeFactory': Denormalizer
2016-01-13 22:20:06,400 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.extract.ColorExtractNodeFactory': Extract Color
2016-01-13 22:20:06,415 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.categorytonumber2.CategoryToNumberNodeFactory2': Category To Number
2016-01-13 22:20:06,431 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.categorytonumber.CategoryToNumberApplyNodeFactory': Category To Number (Apply)
2016-01-13 22:20:06,431 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.column.DataColumnSpecFilterNodeFactory': Column Filter
2016-01-13 22:20:06,447 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rounddouble.RoundDoubleNodeFactory': Round Double
2016-01-13 22:20:06,447 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnresorter.ColumnResorterNodeFactory': Column Resorter
2016-01-13 22:20:06,462 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnlag.LagColumnNodeFactory': Lag Column
2016-01-13 22:20:06,478 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.datavalidator.DataValidatorNodeFactory': Table Validator
2016-01-13 22:20:06,478 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.datavalidator.DataValidatorSpecNodeFactory': Table Validator (Reference)
2016-01-13 22:20:06,493 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.mergevariables.MergeVariablesNodeFactory': Merge Variables
2016-01-13 22:20:06,493 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.group.GroupLoopStartNodeFactory': Group Loop Start
2016-01-13 22:20:06,509 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.variableloopend.VariableLoopEndNodeFactory': Variable Loop End
2016-01-13 22:20:06,525 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnaggregator.ColumnAggregatorNodeFactory': Column Aggregator
2016-01-13 22:20:06,525 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bytevector.create.CreateByteVectorNodeFactory': Create Byte Vector
2016-01-13 22:20:06,540 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bytevector.expand.ExpandByteVectorNodeFactory': Expand Byte Vector
2016-01-13 22:20:06,540 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.generictry.DataPortTryNodeFactory': Try (Data Ports)
2016-01-13 22:20:06,540 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.generictry.VariablePortTryNodeFactory': Try (Variable Ports)
2016-01-13 22:20:06,556 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.DataPortCatchNodeFactory': Catch Errors (Data Ports)
2016-01-13 22:20:06,556 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.VariablePortCatchNodeFactory': Catch Errors (Var Ports)
2016-01-13 22:20:06,556 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.DBPortCatchNodeFactory': Catch Errors (DB Ports)
2016-01-13 22:20:06,571 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.GenericPortCatchNodeFactory': Catch Errors (Generic Ports)
2016-01-13 22:20:06,571 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.inverter.ActiveBranchInverterNodeFactory': Active Branch Inverter
2016-01-13 22:20:06,571 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.tablecoltovariable.TableColumnToVariableNodeFactory': Table Column to Variable
2016-01-13 22:20:06,587 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.sleep.SleepNodeFactory': Wait...
2016-01-13 22:20:06,587 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.workflow.save.SaveWorkflowNodeFactory': Save Workflow
2016-01-13 22:20:06,603 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.timerinfo.TimerinfoNodeFactory': Timer Info
2016-01-13 22:20:06,603 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.globaltimerinfo.GlobalTimerinfoNodeFactory': Global Timer Info
2016-01-13 22:20:06,618 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopStartNodeFactory': Recursive Loop Start
2016-01-13 22:20:06,618 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopEndNodeFactory': Recursive Loop End
2016-01-13 22:20:06,634 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopStart2NodeFactory': Recursive Loop Start (2 ports)
2016-01-13 22:20:06,634 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopEnd2NodeFactory': Recursive Loop End (2 ports)
2016-01-13 22:20:06,649 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.xml2pmml.XML2PMMLNodeFactory': XML To PMML
2016-01-13 22:20:06,649 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.JDBCConnectorNodeFactory': Database Connector
2016-01-13 22:20:06,665 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.connection.DBTableSelectorNodeFactory': Database Table Selector
2016-01-13 22:20:06,665 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.SQLInjectNodeFactory': SQL Inject
2016-01-13 22:20:06,681 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.SQLExtractNodeFactory': SQL Extract
2016-01-13 22:20:06,681 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.drop.DBDropTableNodeFactory': Database Drop Table
2016-01-13 22:20:06,681 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.hilite.AutoHiLiteNodeFactory': HiLite Table
2016-01-13 22:20:06,696 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.coltypechanger.ColumnTypeChangerNodeFactory': Column Auto Type Cast
2016-01-13 22:20:06,712 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.fixedwidthfr.FixedWidthFRNodeFactory': Fixed Width File Reader
2016-01-13 22:20:06,712 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.targetshuffling.TargetShufflingNodeFactory': Target Shuffling
2016-01-13 22:20:06,790 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMeanMissingCellHandlerFactory
2016-01-13 22:20:06,930 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMeanMissingCellHandlerFactory
2016-01-13 22:20:06,946 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMovingAverageMissingCellHandlerFactory
2016-01-13 22:20:06,946 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMovingAverageMissingCellHandlerFactory
2016-01-13 22:20:06,946 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedDoubleValueMissingCellHandlerFactory
2016-01-13 22:20:06,946 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedDoubleValueMissingCellHandlerFactory
2016-01-13 22:20:06,961 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MaxMissingCellHandlerFactory
2016-01-13 22:20:06,961 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MaxMissingCellHandlerFactory
2016-01-13 22:20:06,961 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.IntegerMeanMissingCellHandlerFactory
2016-01-13 22:20:06,961 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.IntegerMeanMissingCellHandlerFactory
2016-01-13 22:20:06,977 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedIntegerValueMissingCellHandlerFactory
2016-01-13 22:20:06,977 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedIntegerValueMissingCellHandlerFactory
2016-01-13 22:20:06,977 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MinMissingCellHandlerFactory
2016-01-13 22:20:06,977 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MinMissingCellHandlerFactory
2016-01-13 22:20:06,977 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MostFrequentValueMissingCellHandlerFactory
2016-01-13 22:20:06,977 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MostFrequentValueMissingCellHandlerFactory
2016-01-13 22:20:06,993 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.NextMissingCellHandlerFactory
2016-01-13 22:20:06,993 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.NextMissingCellHandlerFactory
2016-01-13 22:20:06,993 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.RemoveRowMissingCellHandlerFactory
2016-01-13 22:20:06,993 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.RemoveRowMissingCellHandlerFactory
2016-01-13 22:20:07,008 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MedianNumberMissingCellHandlerFactory
2016-01-13 22:20:07,008 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MedianNumberMissingCellHandlerFactory
2016-01-13 22:20:07,024 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.PreviousMissingCellHandlerFactory
2016-01-13 22:20:07,024 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.PreviousMissingCellHandlerFactory
2016-01-13 22:20:07,024 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.LinearInterpolationMissingCellHandlerFactory
2016-01-13 22:20:07,024 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.LinearInterpolationMissingCellHandlerFactory
2016-01-13 22:20:07,039 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedStringValueMissingCellHandlerFactory
2016-01-13 22:20:07,039 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedStringValueMissingCellHandlerFactory
2016-01-13 22:20:07,039 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.AverageInterpolationMissingCellHandlerFactory
2016-01-13 22:20:07,039 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.AverageInterpolationMissingCellHandlerFactory
2016-01-13 22:20:07,039 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedLongValueMissingCellHandlerFactory
2016-01-13 22:20:07,055 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedLongValueMissingCellHandlerFactory
2016-01-13 22:20:07,086 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.missingval.compute.MissingValueHandlerNodeFactory': Missing Value
2016-01-13 22:20:07,086 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.missingval.apply.MissingValueApplyNodeFactory': Missing Value (Apply)
2016-01-13 22:20:07,102 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.numbertocategory.NumberToCategoryApplyNodeFactory': Number To Category (Apply)
2016-01-13 22:20:07,102 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.columnrename.DBColumnRenameNodeFactory': Database Column Rename
2016-01-13 22:20:07,117 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.normalize.NormalizerPMMLNodeFactory2': Normalizer (PMML)
2016-01-13 22:20:07,117 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.numbertostring.NumberToStringNodeFactory2': Number To String (PMML)
2016-01-13 22:20:07,133 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.stringtonumber.StringToNumberNodeFactory2': String To Number (PMML)
2016-01-13 22:20:07,133 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.binner.BinnerNodeFactory2': Numeric Binner (PMML)
2016-01-13 22:20:07,149 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columntrans2.One2ManyCol2PMMLNodeFactory2': One to Many (PMML)
2016-01-13 22:20:07,149 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columntrans2.Many2OneCol2PMMLNodeFactory2': Many to One (PMML)
2016-01-13 22:20:07,164 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.learner2.DecisionTreeLearnerNodeFactory3': Decision Tree Learner
2016-01-13 22:20:07,180 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.linear2.learner.LinReg2LearnerNodeFactory2': Linear Regression Learner
2016-01-13 22:20:07,180 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.polynomial.learner2.PolyRegLearnerNodeFactory2': Polynomial Regression Learner
2016-01-13 22:20:07,195 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.logistic.learner3.LogRegLearnerNodeFactory3': Logistic Regression Learner
2016-01-13 22:20:07,211 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.neural.rprop.RPropNodeFactory2': RProp MLP Learner
2016-01-13 22:20:07,211 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.svm.learner.SVMLearnerNodeFactory2': SVM Learner
2016-01-13 22:20:07,227 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bayes.naivebayes.learner2.NaiveBayesLearnerNodeFactory3': Naive Bayes Learner
2016-01-13 22:20:07,242 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.kmeans.ClusterNodeFactory': k-Means
2016-01-13 22:20:07,242 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.pivot.DBPivotNodeFactory': Database Pivot
2016-01-13 22:20:07,258 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.sampling.DBSamplingNodeFactory': Database Sampling
2016-01-13 22:20:07,258 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.auto.DBAutoBinnerNodeFactory': Database Auto-Binner
2016-01-13 22:20:07,273 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.numeric.DBNumericBinnerNodeFactory': Database Numeric-Binner
2016-01-13 22:20:07,273 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.apply.DBApplyBinnerNodeFactory': Database Apply-Binner
2016-01-13 22:20:07,289 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowSplitRefNodeFactory': Reference Row Splitter
2016-01-13 22:20:07,289 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnSplitRefNodeFactory': Reference Column Splitter
2016-01-13 22:20:07,305 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rank.RankNodeFactory': Rank
2016-01-13 22:20:07,305 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowSplitRefNodeFactory': Reference Row Splitter
2016-01-13 22:20:07,305 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnSplitRefNodeFactory': Reference Column Splitter
2016-01-13 22:20:07,305 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rank.RankNodeFactory': Rank
2016-01-13 22:20:07,320 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.learner.classification.TreeEnsembleClassificationLearnerNodeFactory': Tree Ensemble Learner
2016-01-13 22:20:07,336 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.predictor.classification.TreeEnsembleClassificationPredictorNodeFactory': Tree Ensemble Predictor
2016-01-13 22:20:07,336 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.modelextractor.TreeEnsembleModelExtractorNodeFactory': Tree Ensemble Model Extract
2016-01-13 22:20:07,351 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.learner.regression.TreeEnsembleRegressionLearnerNodeFactory': Tree Ensemble Learner (Regression)
2016-01-13 22:20:07,367 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.predictor.regression.TreeEnsembleRegressionPredictorNodeFactory': Tree Ensemble Predictor (Regression)
2016-01-13 22:20:07,383 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.learner.classification.RandomForestClassificationLearnerNodeFactory': Random Forest Learner
2016-01-13 22:20:07,398 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.learner.regression.RandomForestRegressionLearnerNodeFactory': Random Forest Learner (Regression)
2016-01-13 22:20:07,398 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.predictor.classification.RandomForestClassificationPredictorNodeFactory': Random Forest Predictor
2016-01-13 22:20:07,398 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.predictor.regression.RandomForestRegressionPredictorNodeFactory': Random Forest Predictor (Regression)
2016-01-13 22:20:07,414 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.regressiontree.learner.RegressionTreeLearnerNodeFactory': Simple Regression Tree Learner
2016-01-13 22:20:07,414 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.regressiontree.predictor.RegressionTreePredictorNodeFactory': Simple Regression Tree Predictor
2016-01-13 22:20:07,429 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.metalearning.pmmlporttocell.PMMLPortToCellNodeFactory': PMML To Cell
2016-01-13 22:20:07,429 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.modeltotable.ModelToTableNodeFactory': Model to Cell
2016-01-13 22:20:07,445 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.tabletomodel.TableToModelNodeFactory': Cell To Model
2016-01-13 22:20:07,445 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingLearnerLoopStartNodeFactory': Boosting Learner Loop Start
2016-01-13 22:20:07,461 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingLearnerLoopEndNodeFactory': Boosting Learner Loop End
2016-01-13 22:20:07,461 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingPredictorLoopStartNodeFactory': Boosting Predictor Loop Start
2016-01-13 22:20:07,476 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingPredictorLoopEndNodeFactory': Boosting Predictor Loop End
2016-01-13 22:20:07,476 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.bagging.ModelLoopStartNodeFactory': Model Loop Start
2016-01-13 22:20:07,492 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.bagging.ModelLoopEndNodeFactory': Model Loop End
2016-01-13 22:20:07,492 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.tabletopmmlport.TableToPMMLNodeFactory': Cell To PMML
2016-01-13 22:20:07,507 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.voting.VotingLoopEndNodeFactory': Voting Loop End
2016-01-13 22:20:07,507 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmmlpredict2.PMMLPredictor2NodeFactory': PMML Predictor
2016-01-13 22:20:07,523 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.combine.PMMLEnsembleNodeFactory': Table to PMML Ensemble
2016-01-13 22:20:07,539 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.totable.PMMLEnsemble2TableNodeFactory': PMML Ensemble to Table
2016-01-13 22:20:07,539 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.predictor2.PMMLEnsemblePredictor2NodeFactory': PMML Ensemble Predictor
2016-01-13 22:20:07,554 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.loopend.PMMLEnsembleLoopEndNodeFactory': PMML Ensemble Loop End
2016-01-13 22:20:07,554 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.predictionfusion.PredictionFusionNodeFactory': Prediction Fusion
2016-01-13 22:20:07,570 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.JavaScriptingNodeFactory': Java Snippet (simple)
2016-01-13 22:20:07,585 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.rowfilter.JavaRowFilterNodeFactory': Java Snippet Row Filter
2016-01-13 22:20:07,585 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.rowsplitter.JavaRowSplitterNodeFactory': Java Snippet Row Splitter
2016-01-13 22:20:07,601 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.editvar.JavaEditVariableNodeFactory': Java Edit Variable (simple)
2016-01-13 22:20:07,601 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.ifswitch.JavaIfSwitchNodeFactory': Java IF (Table)
2016-01-13 22:20:07,617 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.svg.node.sparklines.SparkLineNodeFactory': Spark Line Appender
2016-01-13 22:20:07,632 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.svg.node.radarplot.RadarplotAppenderFactory': Radar Plot Appender
2016-01-13 22:20:07,632 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.renderer2image.Renderer2ImageNodeFactory': Renderer to Image
2016-01-13 22:20:07,648 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.readimage.ReadImageFromUrlNodeFactory': Read Images
2016-01-13 22:20:07,648 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.stringtosvg.StringToSvgNodeFactory': String To SVG
2016-01-13 22:20:07,663 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.jsnippet.JavaSnippetNodeFactory': Java Snippet
2016-01-13 22:20:07,679 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.jsnippet.JavaEditVarNodeFactory': Java Edit Variable
2016-01-13 22:20:07,679 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineVariableNodeFactory': Rule Engine Variable
2016-01-13 22:20:07,695 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngineVariable2PortsNodeFactory': Rule Engine Variable (Dictionary)
2016-01-13 22:20:07,710 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringmanipulation.StringManipulationNodeFactory': String Manipulation
2016-01-13 22:20:07,710 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineNodeFactory': Rule Engine
2016-01-13 22:20:07,710 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineFilterNodeFactory': Rule-based Row Filter
2016-01-13 22:20:07,726 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineSplitterNodeFactory': Rule-based Row Splitter
2016-01-13 22:20:07,726 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngine2PortsNodeFactory': Rule Engine (Dictionary)
2016-01-13 22:20:07,741 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngineFilter2PortsNodeFactory': Rule-based Row Filter (Dictionary)
2016-01-13 22:20:07,741 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngine2PortsSplitterNodeFactory': Rule-based Row Splitter (Dictionary)
2016-01-13 22:20:07,757 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.pmml.PMMLRuleEditorNodeFactory': Ruleset Editor
2016-01-13 22:20:07,757 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.pmml.PMMLRuleSetPredictorNodeFactory': Ruleset Predictor
2016-01-13 22:20:07,773 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.totable.RulesToTableNodeFactory': Ruleset to Table
2016-01-13 22:20:07,773 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.decisiontree.FromDecisionTreeNodeFactory': Decision Tree to Ruleset
2016-01-13 22:20:07,788 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.OneSampleTTestNodeFactory': Single sample t-test
2016-01-13 22:20:07,804 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.TwoSampleTTestNodeFactory': Independent groups t-test
2016-01-13 22:20:07,804 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.PairedTTestNodeFactory': Paired t-test
2016-01-13 22:20:07,819 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.OneWayANOVANodeFactory': One-way ANOVA
2016-01-13 22:20:07,835 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.viz.extended.ExtendedStatisticsNodeFactory': Statistics
2016-01-13 22:20:07,835 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.disturber.DisturberNodeFactory': Disturber Node
2016-01-13 22:20:07,835 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.differModelContent.DiffModelContentFactory': Model Content Difference Checker
2016-01-13 22:20:07,851 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.blocking.BlockingNodeFactory': Block Programmatically
2016-01-13 22:20:07,851 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.failing.FailingNodeFactory': Fail in execution
2016-01-13 22:20:07,866 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.credentialsvalidate.CredentialsValidateNodeFactory': Credentials Validate Test
2016-01-13 22:20:07,866 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.datagenerator.TestDataNodeFactory': Test Data Generator
2016-01-13 22:20:07,882 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.executioncount.ExecutionCountNodeFactory': Count Execution Programmatically
2016-01-13 22:20:07,882 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.file.DifferFileNodeFactory': File Difference Checker
2016-01-13 22:20:07,897 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.imagecomp.ImageCompNodeFactory': Image Comparator (deprecated)
2016-01-13 22:20:07,897 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.differ.DifferenceCheckerNodeFactory': Table Difference Checker
2016-01-13 22:20:07,913 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.internal.nodes.image.ImageDifferNodeFactory': Image Difference Checker
2016-01-13 22:20:07,913 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.config.TestConfigNodeFactory': Testflow Configuration
2016-01-13 22:20:07,929 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.internal.nodes.pmml.PMMLDifferenceCheckerNodeFactory': PMML Difference Checker
2016-01-13 22:20:07,929 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.create.FileStoreCreateNodeFactory': Create FileStore Column
2016-01-13 22:20:07,929 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.check.FileStoreTestNodeFactory': Test FileStore Column
2016-01-13 22:20:07,944 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.createloopend.FileStoreCreateLoopEndNodeFactory': Create FileStore Column in LoopEnd
2016-01-13 22:20:07,944 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.fsloopend.LoopEndFileStorePortObjectTestNodeFactory': Test FileStore Port Object Loop End
2016-01-13 22:20:07,960 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.fsobject2cell.FileStoreObjectToCellNodeFactory': Test FileStore Port Object to Table
2016-01-13 22:20:07,960 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.logging.LoggerOptionNodeFactory': Logger Option
2016-01-13 22:20:07,975 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.filter.extract.ExtractFromToNodeFactory': Extract Time Window
2016-01-13 22:20:07,975 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.movavg.MovingAverageNodeFactory': Moving Average
2016-01-13 22:20:07,991 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.stringtotimestamp.String2DateNodeFactory': String to Date/Time
2016-01-13 22:20:07,991 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.diff.TimeDifferenceNodeFactory': Time Difference
2016-01-13 22:20:08,022 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.generator.DateGeneratorNodeFactory': Time Generator
2016-01-13 22:20:08,022 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.extract.TimeFieldExtractorNodeFactory': Time Field Extractor
2016-01-13 22:20:08,038 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.time2string.Time2StringNodeFactory': Time to String
2016-01-13 22:20:08,038 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.preset.TimePresetNodeFactory': Preset Date/Time
2016-01-13 22:20:08,053 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.mask.MaskTimeNodeFactory': Mask Date/Time
2016-01-13 22:20:08,053 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.extract.date.DateFieldExtractorNodeFactory': Date Field Extractor
2016-01-13 22:20:08,069 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.movagg.MovingAggregationNodeFactory': Moving Aggregation
2016-01-13 22:20:08,069 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.converter.DateShiftNodeFactory': Date/Time Shift 
2016-01-13 22:20:08,085 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Cross Validation/
2016-01-13 22:20:08,085 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Cross Validation
2016-01-13 22:20:08,131 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Cross Validation") is not locked
2016-01-13 22:20:08,147 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Cross Validation" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:08,194 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:0
2016-01-13 22:20:08,194 : DEBUG : main : NodeContainer :  :  : KNIME MetaNode Repository 1 has new state: IDLE
2016-01-13 22:20:08,209 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("X_Aggregator (#1)") is not locked
2016-01-13 22:20:08,241 : DEBUG : main : AggregateOutputNodeFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,506 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("X_Partitioner (#2)") is not locked
2016-01-13 22:20:08,521 : DEBUG : main : XValidatePartitionerFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,537 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("Decision Tree Learner (#14)") is not locked
2016-01-13 22:20:08,568 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,631 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("Decision Tree Predictor (#15)") is not locked
2016-01-13 22:20:08,646 : DEBUG : main : DecTreePredictorNodeFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,693 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:14(1) to node 1:0:15(1)
2016-01-13 22:20:08,693 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:2(1) to node 1:0:14(1)
2016-01-13 22:20:08,693 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:2(2) to node 1:0:15(2)
2016-01-13 22:20:08,693 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0(0) to node 1:0:2(1)
2016-01-13 22:20:08,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:1(2) to node 1:0(1)
2016-01-13 22:20:08,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:1(1) to node 1:0(0)
2016-01-13 22:20:08,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:15(1) to node 1:0:1(1)
2016-01-13 22:20:08,724 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Cross Validation"  with no errors
2016-01-13 22:20:08,740 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'cross_validation': Cross Validation
2016-01-13 22:20:08,740 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Feature Elimination/
2016-01-13 22:20:08,740 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Feature Elimination
2016-01-13 22:20:08,740 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Feature Elimination") is not locked
2016-01-13 22:20:08,740 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Feature Elimination" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:08,755 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:1
2016-01-13 22:20:08,755 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination Start _1_1_ (#1)") is not locked
2016-01-13 22:20:08,755 : DEBUG : main : BWElimLoopStart1NodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,755 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination Filter (#2)") is not locked
2016-01-13 22:20:08,771 : DEBUG : main : BWElimFilterNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,771 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination End (#3)") is not locked
2016-01-13 22:20:08,787 : DEBUG : main : BWElimLoopEndNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,787 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Partitioning (#7)") is not locked
2016-01-13 22:20:08,802 : DEBUG : main : PartitionNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,802 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Naive Bayes Learner (#8)") is not locked
2016-01-13 22:20:08,818 : DEBUG : main : NaiveBayesLearnerNodeFactory2 : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,818 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Naive Bayes Predictor (#9)") is not locked
2016-01-13 22:20:08,833 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:3(2) to node 1:1:2(1)
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:8(1) to node 1:1:9(1)
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:1(1) to node 1:1:7(1)
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:9(1) to node 1:1:3(1)
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:3(1) to node 1:1(0)
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1(1) to node 1:1:2(2)
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:2(1) to node 1:1(1)
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:7(2) to node 1:1:9(2)
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1(0) to node 1:1:1(1)
2016-01-13 22:20:08,833 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:7(1) to node 1:1:8(1)
2016-01-13 22:20:08,880 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Feature Elimination"  with no errors
2016-01-13 22:20:08,880 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'feature_elimination': Feature Elimination
2016-01-13 22:20:08,880 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Variables Loop (Data)/
2016-01-13 22:20:08,880 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Variables Loop (Data)
2016-01-13 22:20:08,880 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Variables Loop (Data)") is not locked
2016-01-13 22:20:08,880 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Data)" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:08,896 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:2
2016-01-13 22:20:08,896 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 22:20:08,911 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Row To Variable Loop Start (#3)") is not locked
2016-01-13 22:20:08,911 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Inject Variables _Data_ (#4)") is not locked
2016-01-13 22:20:08,927 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2:3(1) to node 1:2:4(2)
2016-01-13 22:20:08,927 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2(1) to node 1:2:3(1)
2016-01-13 22:20:08,927 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2(0) to node 1:2:4(1)
2016-01-13 22:20:08,927 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2:2(1) to node 1:2(0)
2016-01-13 22:20:08,943 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Data)"  with no errors
2016-01-13 22:20:08,943 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'variables_loop': Variables Loop (Data)
2016-01-13 22:20:08,943 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Variables Loop (Database)/
2016-01-13 22:20:08,943 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Variables Loop (Database)
2016-01-13 22:20:08,943 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Variables Loop (Database)") is not locked
2016-01-13 22:20:08,943 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Database)" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:08,958 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:3
2016-01-13 22:20:08,958 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 22:20:08,958 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Row To Variable Loop Start (#3)") is not locked
2016-01-13 22:20:08,974 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Inject Variables _Database_ (#4)") is not locked
2016-01-13 22:20:08,974 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3:3(1) to node 1:3:4(2)
2016-01-13 22:20:08,974 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3(1) to node 1:3:3(1)
2016-01-13 22:20:08,974 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3(0) to node 1:3:4(1)
2016-01-13 22:20:08,974 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3:2(1) to node 1:3(0)
2016-01-13 22:20:08,989 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Database)"  with no errors
2016-01-13 22:20:08,989 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'variables_loop_db': Variables Loop (Database)
2016-01-13 22:20:08,989 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Iterate list of files/
2016-01-13 22:20:08,989 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Iterate list of files
2016-01-13 22:20:09,005 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Iterate list of files") is not locked
2016-01-13 22:20:09,005 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Iterate list of files" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:09,005 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:4
2016-01-13 22:20:09,005 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("TableRow To Variable Loop Start (#2)") is not locked
2016-01-13 22:20:09,005 : DEBUG : main : LoopStartVariableNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,005 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("Loop End (#3)") is not locked
2016-01-13 22:20:09,021 : DEBUG : main : LoopEndNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,021 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("File Reader (#4)") is not locked
2016-01-13 22:20:09,021 : DEBUG : main : FileReaderNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,036 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:2(1) to node 1:4:4(0)
2016-01-13 22:20:09,036 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:4(1) to node 1:4:3(1)
2016-01-13 22:20:09,036 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:3(1) to node 1:4(0)
2016-01-13 22:20:09,036 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4(0) to node 1:4:2(1)
2016-01-13 22:20:09,099 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Iterate list of files"  with no errors
2016-01-13 22:20:09,114 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'iterate_list_of_files': Iterate List of Files
2016-01-13 22:20:09,114 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Looper/
2016-01-13 22:20:09,114 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Looper
2016-01-13 22:20:09,130 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Looper") is not locked
2016-01-13 22:20:09,130 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Looper" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:09,130 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:5
2016-01-13 22:20:09,130 : DEBUG : main : FileNodeContainerMetaPersistor : Loop x-times : 1:5 : Workflow being loaded ("Counting Loop Start (#1)") is not locked
2016-01-13 22:20:09,145 : DEBUG : main : FileNodeContainerMetaPersistor : Loop x-times : 1:5 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 22:20:09,161 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:5:2(1) to node 1:5(0)
2016-01-13 22:20:09,161 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:5(0) to node 1:5:1(1)
2016-01-13 22:20:09,161 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Looper"  with no errors
2016-01-13 22:20:09,177 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'looper': Loop x-times
2016-01-13 22:20:09,177 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Boosting Learner/
2016-01-13 22:20:09,177 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Boosting Learner
2016-01-13 22:20:09,177 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Boosting Learner") is not locked
2016-01-13 22:20:09,177 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Learner" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:09,192 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:6
2016-01-13 22:20:09,192 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Boosting Learner Loop Start (#1)") is not locked
2016-01-13 22:20:09,192 : DEBUG : main : BoostingLearnerLoopStartNodeFactory : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,192 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Boosting Learner Loop End (#4)") is not locked
2016-01-13 22:20:09,208 : DEBUG : main : BoostingLearnerLoopEndNodeFactory : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,223 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Naive Bayes Learner (#7)") is not locked
2016-01-13 22:20:09,223 : DEBUG : main : NaiveBayesLearnerNodeFactory2 : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,223 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Naive Bayes Predictor (#8)") is not locked
2016-01-13 22:20:09,239 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,239 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:7(1) to node 1:6:4(1)
2016-01-13 22:20:09,239 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:1(1) to node 1:6:7(1)
2016-01-13 22:20:09,255 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:1(2) to node 1:6:8(2)
2016-01-13 22:20:09,255 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:4(1) to node 1:6(0)
2016-01-13 22:20:09,255 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:8(1) to node 1:6:4(2)
2016-01-13 22:20:09,255 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6(0) to node 1:6:1(1)
2016-01-13 22:20:09,255 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:7(1) to node 1:6:8(1)
2016-01-13 22:20:09,255 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Learner"  with no errors
2016-01-13 22:20:09,255 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.boosting_learner': Boosting Learner
2016-01-13 22:20:09,255 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Boosting Predictor/
2016-01-13 22:20:09,255 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Boosting Predictor
2016-01-13 22:20:09,270 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Boosting Predictor") is not locked
2016-01-13 22:20:09,270 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Predictor" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:09,270 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:7
2016-01-13 22:20:09,270 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Boosting Predictor Loop Start (#1)") is not locked
2016-01-13 22:20:09,286 : DEBUG : main : BoostingPredictorLoopStartNodeFactory : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,286 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Boosting Predictor Loop End (#3)") is not locked
2016-01-13 22:20:09,301 : DEBUG : main : BoostingPredictorLoopEndNodeFactory : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,301 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Naive Bayes Predictor (#4)") is not locked
2016-01-13 22:20:09,301 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,301 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:1(1) to node 1:7:4(1)
2016-01-13 22:20:09,301 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:4(1) to node 1:7:3(1)
2016-01-13 22:20:09,301 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7(1) to node 1:7:4(2)
2016-01-13 22:20:09,301 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:3(1) to node 1:7(0)
2016-01-13 22:20:09,301 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7(0) to node 1:7:1(1)
2016-01-13 22:20:09,317 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Predictor"  with no errors
2016-01-13 22:20:09,317 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.boosting_predictor': Boosting Predictor
2016-01-13 22:20:09,317 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Delegating/
2016-01-13 22:20:09,317 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Delegating
2016-01-13 22:20:09,317 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Delegating") is not locked
2016-01-13 22:20:09,317 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Delegating" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:09,333 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:8
2016-01-13 22:20:09,333 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Filter well (#61)") is not locked
2016-01-13 22:20:09,333 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Decision Tree Learner (#62)") is not locked
2016-01-13 22:20:09,333 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,348 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Recursive Loop Start (#63)") is not locked
2016-01-13 22:20:09,348 : DEBUG : main : RecursiveLoopStartNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,364 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Recursive Loop End (#64)") is not locked
2016-01-13 22:20:09,364 : DEBUG : main : RecursiveLoopEndNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,364 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("PMML Predictor (#65)") is not locked
2016-01-13 22:20:09,379 : DEBUG : main : PMMLPredictor2NodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,379 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Reference Column Filter (#66)") is not locked
2016-01-13 22:20:09,395 : DEBUG : main : ColumnFilterRefNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,395 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("PMML To Cell (#67)") is not locked
2016-01-13 22:20:09,411 : DEBUG : main : PMMLPortToCellNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,411 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:8:61
2016-01-13 22:20:09,411 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8(0) to node 1:8:63(1)
2016-01-13 22:20:09,411 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:62(1)
2016-01-13 22:20:09,411 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:66(1) to node 1:8:64(2)
2016-01-13 22:20:09,411 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:67(1) to node 1:8:64(1)
2016-01-13 22:20:09,411 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:65(1) to node 1:8:61(0)
2016-01-13 22:20:09,411 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:62(1) to node 1:8:67(1)
2016-01-13 22:20:09,426 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:66(2)
2016-01-13 22:20:09,426 : DEBUG : main : Workflow :  :  : Triggering graph analysis on 1:8:61
2016-01-13 22:20:09,426 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:65(2)
2016-01-13 22:20:09,426 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:66(1)
2016-01-13 22:20:09,426 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:62(1) to node 1:8:65(1)
2016-01-13 22:20:09,426 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:64(1) to node 1:8(0)
2016-01-13 22:20:09,426 : DEBUG : main : FileNodeContainerMetaPersistor : Filter well predicted rows : 1:8:61 : Workflow being loaded ("Joiner (#61)") is not locked
2016-01-13 22:20:09,442 : DEBUG : main : Joiner2NodeFactory : Filter well predicted rows : 1:8:61 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,442 : DEBUG : main : FileNodeContainerMetaPersistor : Filter well predicted rows : 1:8:61 : Workflow being loaded ("Reference Row Filter (#62)") is not locked
2016-01-13 22:20:09,457 : DEBUG : main : RowFilterRefNodeFactory : Filter well predicted rows : 1:8:61 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,473 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61:62(1) to node 1:8:61(0)
2016-01-13 22:20:09,473 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:62(1)
2016-01-13 22:20:09,473 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:61(1)
2016-01-13 22:20:09,473 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:61(2)
2016-01-13 22:20:09,473 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61:61(1) to node 1:8:61:62(2)
2016-01-13 22:20:09,489 : DEBUG : main : Workflow :  :  : Triggering graph analysis on 1:8:61
2016-01-13 22:20:09,489 : DEBUG : main : NodeContainer :  :  : Recursive Loop Start 1:8:63 has new state: IDLE
2016-01-13 22:20:09,489 : DEBUG : main : NodeContainer :  :  : Decision Tree Learner (deprecated) 1:8:62 has new state: IDLE
2016-01-13 22:20:09,504 : DEBUG : main : NodeContainer :  :  : PMML Predictor 1:8:65 has new state: IDLE
2016-01-13 22:20:09,504 : DEBUG : main : NodeContainer :  :  : PMML To Cell 1:8:67 has new state: IDLE
2016-01-13 22:20:09,504 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Delegating"  with warnings
2016-01-13 22:20:09,504 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.delegated_learning': Delegating
2016-01-13 22:20:09,504 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Bagging/
2016-01-13 22:20:09,504 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Bagging
2016-01-13 22:20:09,520 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Bagging") is not locked
2016-01-13 22:20:09,520 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Bagging" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:09,567 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:9
2016-01-13 22:20:09,567 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Model Loop End (#7)") is not locked
2016-01-13 22:20:09,598 : DEBUG : main : ModelLoopEndNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,598 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Model Loop Start (#8)") is not locked
2016-01-13 22:20:09,598 : DEBUG : main : ModelLoopStartNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,613 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Voting Loop End (#9)") is not locked
2016-01-13 22:20:09,629 : DEBUG : main : VotingLoopEndNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,629 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Chunk Loop Start (#12)") is not locked
2016-01-13 22:20:09,645 : DEBUG : main : LoopStartChunkNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,645 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Shuffle (#13)") is not locked
2016-01-13 22:20:09,645 : DEBUG : main : ShuffleNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,645 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Decision Tree Learner (#14)") is not locked
2016-01-13 22:20:09,660 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,660 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Decision Tree Predictor (#15)") is not locked
2016-01-13 22:20:09,660 : DEBUG : main : DecTreePredictorNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,660 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9(1) to node 1:9:15(2)
2016-01-13 22:20:09,660 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:13(1) to node 1:9:12(1)
2016-01-13 22:20:09,660 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:12(1) to node 1:9:14(1)
2016-01-13 22:20:09,660 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9(0) to node 1:9:13(1)
2016-01-13 22:20:09,660 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:9(1) to node 1:9(0)
2016-01-13 22:20:09,676 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:15(1) to node 1:9:9(1)
2016-01-13 22:20:09,676 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:8(1) to node 1:9:15(1)
2016-01-13 22:20:09,676 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:14(1) to node 1:9:7(1)
2016-01-13 22:20:09,676 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:7(1) to node 1:9:8(1)
2016-01-13 22:20:09,676 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Bagging"  with no errors
2016-01-13 22:20:09,676 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.bagging': Bagging
2016-01-13 22:20:09,676 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Seasonality Correction/
2016-01-13 22:20:09,676 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Seasonality Correction
2016-01-13 22:20:09,691 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Seasonality Correction") is not locked
2016-01-13 22:20:09,691 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Seasonality Correction" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:09,691 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:10
2016-01-13 22:20:09,691 : DEBUG : main : FileNodeContainerMetaPersistor : Seasonality Correction : 1:10 : Workflow being loaded ("Lag Column (#24)") is not locked
2016-01-13 22:20:09,707 : DEBUG : main : LagColumnNodeFactory : Seasonality Correction : 1:10 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,707 : DEBUG : main : FileNodeContainerMetaPersistor : Seasonality Correction : 1:10 : Workflow being loaded ("Java Snippet _simple_ (#25)") is not locked
2016-01-13 22:20:09,723 : DEBUG : main : JavaScriptingNodeFactory : Seasonality Correction : 1:10 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,723 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10:24(1) to node 1:10:25(1)
2016-01-13 22:20:09,723 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10:25(1) to node 1:10(0)
2016-01-13 22:20:09,723 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10(0) to node 1:10:24(1)
2016-01-13 22:20:09,723 : DEBUG : main : NodeContainer :  :  : Lag Column 1:10:24 has new state: IDLE
2016-01-13 22:20:09,723 : DEBUG : main : NodeContainer :  :  : Java Snippet (simple) 1:10:25 has new state: IDLE
2016-01-13 22:20:09,723 : DEBUG : main : NodeContainer :  :  : Seasonality Correction 1:10 has new state: IDLE
2016-01-13 22:20:09,723 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Seasonality Correction"  with warnings
2016-01-13 22:20:09,723 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'SeasonalityCorrection': Seasonality Correction
2016-01-13 22:20:09,723 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Time Series Auto-Prediction Training/
2016-01-13 22:20:09,754 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Time Series Auto-Prediction Training
2016-01-13 22:20:09,754 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Time Series Auto-Prediction Training") is not locked
2016-01-13 22:20:09,754 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Training" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:09,754 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:11
2016-01-13 22:20:09,754 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Partitioning (#147)") is not locked
2016-01-13 22:20:09,769 : DEBUG : main : PartitionNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,769 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Lag Column (#216)") is not locked
2016-01-13 22:20:09,785 : DEBUG : main : LagColumnNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,785 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Linear Regression Learner (#234)") is not locked
2016-01-13 22:20:09,801 : DEBUG : main : LinReg2LearnerNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,816 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:234(1) to node 1:11(0)
2016-01-13 22:20:09,816 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:234(2) to node 1:11(1)
2016-01-13 22:20:09,816 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11(0) to node 1:11:216(1)
2016-01-13 22:20:09,816 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:147(1) to node 1:11:234(1)
2016-01-13 22:20:09,816 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:216(1) to node 1:11:147(1)
2016-01-13 22:20:09,816 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:147(2) to node 1:11(2)
2016-01-13 22:20:09,832 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Training"  with no errors
2016-01-13 22:20:09,832 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'Time-SeriesAuto-PredictionTraining': Time-Series Auto-Prediction Training
2016-01-13 22:20:09,832 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Time Series Auto-Prediction Predictor/
2016-01-13 22:20:09,832 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Time Series Auto-Prediction Predictor
2016-01-13 22:20:09,847 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Time Series Auto-Prediction Predictor") is not locked
2016-01-13 22:20:09,847 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Predictor" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:09,847 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:12
2016-01-13 22:20:09,847 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Predictor : 1:12 : Workflow being loaded ("Numeric Scorer (#176)") is not locked
2016-01-13 22:20:09,863 : DEBUG : main : NumericScorerNodeFactory : Time Series Auto-Prediction Predictor : 1:12 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,863 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Predictor : 1:12 : Workflow being loaded ("Regression Predictor (#237)") is not locked
2016-01-13 22:20:09,879 : DEBUG : main : RegressionPredictorNodeFactory : Time Series Auto-Prediction Predictor : 1:12 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:09,879 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12(1) to node 1:12:237(2)
2016-01-13 22:20:09,879 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:237(1) to node 1:12(0)
2016-01-13 22:20:09,879 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12(0) to node 1:12:237(1)
2016-01-13 22:20:09,879 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:237(1) to node 1:12:176(1)
2016-01-13 22:20:09,879 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:176(1) to node 1:12(1)
2016-01-13 22:20:09,879 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Predictor"  with no errors
2016-01-13 22:20:09,879 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'Time-SeriesAuto-PredictionPredictor': Time-Series Auto-Prediction Predictor
2016-01-13 22:20:10,128 : DEBUG : main : KNIMEEditorPlugin :  :  : Workflow SVG export not available, unable to instantiate "org.knime.workbench.editor.svgexport.exportservice.WorkflowSVGExportImpl"
2016-01-13 22:20:13,498 : ERROR : main : CategorySorter :  :  : CODING PROBLEM	After-ID 'toolintegration' of [Id: community Name: Community Nodes After-id: toolintegration] does not exist - in plug-in org.knime.base
2016-01-13 22:20:16,943 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".all" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:20:16,943 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".csv" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:20:16,943 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".csv.gz" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:20:16,943 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".pmml" registered for Node Factory: PMMLReaderNodeFactory.
2016-01-13 22:20:16,943 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".table" registered for Node Factory: ReadTableNodeFactory.
2016-01-13 22:20:16,943 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".tsv" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:20:16,943 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".txt" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:20:16,943 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".txt.gz" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:20:20,079 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:20:20,110 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:20:20,328 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:20:20,328 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on workflow.knime
2016-01-13 22:20:20,328 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:20:20,344 : DEBUG : main : WorkflowEditor :  :  : Resource File's project: file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/
2016-01-13 22:20:20,500 : DEBUG : ModalContext : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:20,516 : DEBUG : ModalContext : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:20:20,516 : DEBUG : ModalContext : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:20:20,594 : DEBUG : ModalContext : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:20,625 : DEBUG : ModalContext : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:20,656 : DEBUG : ModalContext : DifferenceCheckerNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:20,672 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:2(1) to node 0:3(2)
2016-01-13 22:20:20,672 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:3(1)
2016-01-13 22:20:20,765 : DEBUG : ModalContext : Git SCM : Git SCM : 0:1 : Configure succeeded. (Git SCM)
2016-01-13 22:20:20,765 : DEBUG : ModalContext : Git SCM : Git SCM : 0:2 : Configure succeeded. (Git SCM)
2016-01-13 22:20:20,796 : DEBUG : ModalContext : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:20:20,796 : DEBUG : ModalContext : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest"  with no errors
2016-01-13 22:20:20,812 : DEBUG : main : ProjectWorkflowMap :  :  : Adding "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/" to project map (1 in total)
2016-01-13 22:20:20,828 : DEBUG : main : ProjectWorkflowMap :  :  : registering org.knime.workbench.editor2.WorkflowEditor@22decfa2 to file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/. 1 registered clients now.
2016-01-13 22:20:21,218 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:20:21,342 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:20:21,342 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:20:21,358 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:1 (CONFIGURED) )
2016-01-13 22:20:21,530 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:20:21,530 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:21,530 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:2 (CONFIGURED) )
2016-01-13 22:20:21,545 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:20:21,545 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:21,545 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:3 (CONFIGURED) )
2016-01-13 22:20:21,545 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:20:21,545 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:21,545 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:20:21,545 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:26,537 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:20:26,537 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:20:26,553 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:20:26,553 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on workflow.knime
2016-01-13 22:20:26,553 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:20:26,553 : DEBUG : main : WorkflowEditor :  :  : Resource File's project: file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/
2016-01-13 22:20:26,600 : DEBUG : ModalContext : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:26,600 : DEBUG : ModalContext : WorkflowManager :  :  : Created subworkflow 2
2016-01-13 22:20:26,646 : DEBUG : ModalContext : JiraAdapterNodeFactory : JiraOfflineTest : 2 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:26,693 : DEBUG : ModalContext : JiraAdapterNodeFactory : JiraOfflineTest : 2 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:26,709 : DEBUG : ModalContext : DifferenceCheckerNodeFactory : JiraOfflineTest : 2 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:26,709 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 2:2(1) to node 2:3(2)
2016-01-13 22:20:26,709 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 2:1(1) to node 2:3(1)
2016-01-13 22:20:26,724 : DEBUG : ModalContext : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:20:26,724 : DEBUG : ModalContext : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:20:26,724 : DEBUG : ModalContext : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:20:26,724 : DEBUG : ModalContext : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest"  with no errors
2016-01-13 22:20:26,802 : DEBUG : main : ProjectWorkflowMap :  :  : Adding "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/" to project map (2 in total)
2016-01-13 22:20:26,802 : DEBUG : main : ProjectWorkflowMap :  :  : registering org.knime.workbench.editor2.WorkflowEditor@730611a0 to file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/. 1 registered clients now.
2016-01-13 22:20:26,834 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:20:26,834 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:20:26,834 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:20:26,834 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 2:1 (CONFIGURED) )
2016-01-13 22:20:26,834 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:1(1) -> 2:3( 1)]
2016-01-13 22:20:26,834 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:26,834 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 2:2 (CONFIGURED) )
2016-01-13 22:20:26,834 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:2(1) -> 2:3( 2)]
2016-01-13 22:20:26,834 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:26,834 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 2:3 (CONFIGURED) )
2016-01-13 22:20:26,849 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:1(1) -> 2:3( 1)]
2016-01-13 22:20:26,849 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:26,849 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:2(1) -> 2:3( 2)]
2016-01-13 22:20:26,849 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:28,097 : DEBUG : main : NodeContainerEditPart :  :  : Table Difference Checker 2:3 (CONFIGURED)
2016-01-13 22:20:28,097 : DEBUG : main : NodeContainerEditPart :  :  : Jira Adapter (Offline) 2:2 (CONFIGURED)
2016-01-13 22:20:30,049 : DEBUG : main : ExecuteAction :  :  : Creating execution job for 1 node(s)...
2016-01-13 22:20:30,049 : DEBUG : main : NodeContainer :  :  : Setting dirty flag on Jira Adapter (Offline) 2:2
2016-01-13 22:20:30,049 : DEBUG : main : NodeContainer :  :  : Setting dirty flag on JiraOfflineTest 2
2016-01-13 22:20:30,049 : DEBUG : main : NodeContainer :  :  : Jira Adapter (Offline) 2:2 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:20:30,049 : DEBUG : main : NodeContainer :  :  : Jira Adapter (Offline) 2:2 has new state: CONFIGURED_QUEUED
2016-01-13 22:20:30,080 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=2;old=null;new=null;timestamp=2016-01-13 22:20:30]
2016-01-13 22:20:30,096 : DEBUG : main : NodeContainer :  :  : JiraOfflineTest 2 has new state: EXECUTING
2016-01-13 22:20:30,158 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 doBeforePreExecution
2016-01-13 22:20:30,158 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: PREEXECUTE
2016-01-13 22:20:30,158 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 doBeforeExecution
2016-01-13 22:20:30,158 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: EXECUTING
2016-01-13 22:20:30,221 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 2:2 : Adding handler 7e095683-5535-4a22-a735-aa5fc9aa65a7 (Jira Adapter (Offline) 2:2: <no directory>) - 1 in total
2016-01-13 22:20:30,221 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 Start execute
2016-01-13 22:20:30,268 : INFO  : KNIME-Worker-0 : ITSOfflineNodeModel : Jira Adapter (Offline) : 2:2 : Preparing to read jira entries.
2016-01-13 22:20:30,283 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: EXECUTING
2016-01-13 22:20:32,296 : INFO  : KNIME-Worker-0 : ITSOfflineNodeModel : Jira Adapter (Offline) : 2:2 : Transforming to jira entries.
2016-01-13 22:20:32,311 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-724
2016-01-13 22:20:32,327 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-724, created=Mon Dec 12 16:03:41 CET 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Tue Dec 20 22:14:16 CET 2011, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=RandomDataImpl.nextInt does not distribute uniformly for negative lower bound, link=https://issues.apache.org/jira/browse/MATH-724, description=&lt;p&gt;When using the RandomDataImpl.nextInt function to get a uniform sample in a &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt; interval, when the lower value is less than zero, the output is not uniformly distributed, as the lowest value is practically never returned.&lt;/p&gt;

&lt;p&gt;See the attached NextIntUniformTest.java file. It uses a &lt;span class="error"&gt;&amp;#91;-3, 5&amp;#93;&lt;/span&gt; interval. For several values between 0 and 1, testNextIntUniform1 prints the return value of RandomDataImpl.nextInt (as double and as int). We see that -2 through 5 are returned several times. The -3 value however, is only returned for 0.0, and is thus under-respresented in the integer samples. The output of test method testNextIntUniform2 also clearly shows that value -3 is never sampled.&lt;/p&gt;, comments=[&lt;p&gt;NextIntUniformTest.java: see issue description&lt;/p&gt;
, &lt;p&gt;Thanks for reporting this. The problem is in the rounding, which does not work correctly for negative values.  My first inclination is to test for negative lower bound and just shift the interval in that case.  Any better ideas?&lt;/p&gt;
, &lt;p&gt;math-724.patch: it first scales the [0..1) interval to [0..length), then discretizes it, and finally shifts it to &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;It may be a good idea to also add some tests for cases such as &lt;span class="error"&gt;&amp;#91;0,3&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-5, -3&amp;#93;&lt;/span&gt;, and see if the distribution of sampled values is uniform. It seems RandomDataTest.testNextInt does this using chiSquare, but since I'm not familiar with that, I'm not sure how to add more tests for the other lower/upper bound pairs...&lt;/p&gt;
, &lt;p&gt;I just ran the unit tests with my patch applied, an the following test, in RandomDataTest:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;@Test
    &lt;span class="code-keyword"&gt;public&lt;/span&gt; void testNextIntExtremeValues() {
        &lt;span class="code-object"&gt;int&lt;/span&gt; x = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        &lt;span class="code-object"&gt;int&lt;/span&gt; y = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        Assert.assertFalse(x == y);
    }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails, as does testNextLongExtremeValues. Both x and y become equal to Integer.MIN_VALUE, making x == y to become true, causing the assertion to fail...&lt;/p&gt;
, &lt;p&gt;Also note that RandomDataImpl.nextUniform uses a similar scale/shift method to transform the range. It may thus suffer from the same failure in case of extreme values...&lt;/p&gt;
, &lt;p&gt;math-724-v2.patch: 2nd patch.&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;I think all unit tests work now, including the ones for the Integer.MIN_VALUE to Integer.MAX_VALUE interval.&lt;/li&gt;
	&lt;li&gt;The original problem was that negative values were rounded up by the conversion from double to int, while positive numbers were rounded down. By using floor, we first round the numbers down, and then convert to integer, thus ensuring a proper uniform distribution.&lt;/li&gt;
	&lt;li&gt;Test cases for negative values are still missing... Could someone else add them?&lt;/li&gt;
	&lt;li&gt;RandomDataImpl.nextUniform: I haven't changed this, as the change that I used for integers does not have the desired effect for doubles... This may be caused by the fact that Double.MIN_VALUE is more negative than Double.MAX_VALUE is positive, but I'm not really sure. Maybe it is not even an issue for the nextUniform method?&lt;/li&gt;
&lt;/ul&gt;

, &lt;blockquote&gt;&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; the fact that Double.MIN_VALUE is more negative &lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="http://docs.oracle.com/javase/6/docs/api/java/lang/Double.html#MIN_VALUE"&gt;Double.Min_VALUE&lt;/a&gt; is a &lt;em&gt;positive&lt;/em&gt; number.&lt;/p&gt;
, &lt;blockquote&gt;&lt;p&gt;Double.Min_VALUE is a positive number.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops...&lt;/p&gt;

&lt;p&gt;OK, I uploaded a third version of the patch (math-724-v3.patch), which also applies the new formula for nextUniform. I included two test files (NextUniformTest3.java and NextIntTest3.java), that show the results for nextInt and nextUniform, for both the old and new formulas. As for as I can see, the new formula works equally well or better in all cases. Also, all existing unit tests pass.&lt;/p&gt;
, &lt;p&gt;Thanks for reporting and diagnosing this, Dennis.&lt;/p&gt;

&lt;p&gt;Slightly modified version of the third patch (just removing unecessary parens), along with tests, committed in r1221490.  The "negativeToPositiveRange" tests fail before the fix.  The change to nextUniform is also needed to prevent overflows. I changed the relevant test cases to use the TestUtils chisquare test, which is more straightforward and has better output.  This was added after the original versions of these tests were written.  Others in this class should be similarly updated.  Patches welcome to further tidy the tests, but this issue can be resolved.&lt;/p&gt;
], resolution=Fixed, reporter=dhendriks, assignees=[], commentAuthors=[dhendriks, psteitz, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,467 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-723
2016-01-13 22:20:32,467 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-723, created=Sun Dec 11 22:03:37 CET 2011, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Sun Dec 11 22:59:41 CET 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=BitStreamGenerators (MersenneTwister, Well generators) do not clear normal deviate cache on setSeed, link=https://issues.apache.org/jira/browse/MATH-723, description=&lt;p&gt;The BitStream generators generate normal deviates (for nextGaussian) in pairs, caching the last value generated. When reseeded, the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1213087.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-719
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-719, created=Tue Dec 06 18:07:24 CET 2011, updated=Sat Mar 24 17:16:38 CET 2012, resolved=Mon Jan 23 12:28:07 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[], priority=Minor, summary=Strange deprecations in API, link=https://issues.apache.org/jira/browse/MATH-719, description=&lt;p&gt;Sorry if this doesn't belong here. I couldn't find any sort of mailing list or other feedback mechanism on the website.&lt;/p&gt;

&lt;p&gt;RealMatrix has some very odd deprecations. In particular inverse(), getDeterminant() and isSingular(). The last has the message:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Deprecated. as of release 2.0, replaced by the boolean negation of new LUDecompositionImpl(m).getSolver().isNonSingular()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's an implementation, not an interface. The whole point of having an interface is that &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I can query whether a matrix is singular withou having to know about LUDecompositions&lt;/li&gt;
	&lt;li&gt;You guys can change the implementation of isSingular() if something better pops up without us guys having to change our code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I'm not using these methods now, because they're deprecated, but I've basically recreated them in as static methods in a utility class. Wouldn't it be much better to just put code from the deprecation message into the method and remove the deprecation?&lt;/p&gt;, comments=[&lt;blockquote&gt;&lt;p&gt;Sorry if this doesn't belong here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Indeed, you'd better bring this kind of issue to the "dev" ML. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
The more so that there have been recent discussions about changing the matrix API and decisions ought to be made quite soon now.&lt;/p&gt;
, &lt;p&gt;Ah, so there is a mailing list. I guess I should have looked a little harder. I'll bring it up there.&lt;/p&gt;
, &lt;p&gt;It is unlikely that we can come up with a new design before the release of v3.0.&lt;br/&gt;
This must be thoroughly discussed first on the "dev" ML, together with other matrix interface issues.&lt;/p&gt;
], resolution=Unknown, reporter=pbloem, assignees=[], commentAuthors=[erans, pbloem], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-692
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-692, created=Tue Oct 18 20:01:57 CEST 2011, updated=Sat Mar 24 17:16:26 CET 2012, resolved=Thu Feb 02 07:45:59 CET 2012, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 1.3
, 2.0
, 2.1
, 2.2
, 2.2.1
, 3.0
], fixVersion=[3.0
], priority=Minor, summary=Cumulative probability and inverse cumulative probability inconsistencies, link=https://issues.apache.org/jira/browse/MATH-692, description=&lt;p&gt;There are some inconsistencies in the documentation and implementation of functions regarding cumulative probabilities and inverse cumulative probabilities. More precisely, '&amp;lt;' and '&amp;lt;=' are not used in a consistent way.&lt;/p&gt;

&lt;p&gt;Besides I would move the function inverseCumulativeProbability(double) to the interface Distribution. A true inverse of the distribution function does neither exist for Distribution nor for ContinuosDistribution. Thus we need to define the inverse in terms of quantiles anyway, and this can already be done for Distribution.&lt;/p&gt;

&lt;p&gt;On the whole I would declare the (inverse) cumulative probability functions in the basic distribution interfaces as follows:&lt;/p&gt;

&lt;p&gt;Distribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(double x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(double x0, double x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1)&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;inverseCumulativeProbability(double p):&lt;br/&gt;
  returns the quantile function inf{x in R | P(X&amp;lt;=x) &amp;gt;= p} &lt;span class="error"&gt;&amp;#91;see also 2), 3), and 4)&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1) An aternative definition could be P(x0 &amp;lt;= X &amp;lt;= x1). But this requires to put the function probability(double x) or another cumulative probability function into the interface Distribution in order be able to calculate P(x0 &amp;lt;= X &amp;lt;= x1) in AbstractDistribution.&lt;br/&gt;
2) This definition is stricter than the definition in ContinuousDistribution, because the definition there does not specify what to do if there are multiple x satisfying P(X&amp;lt;=x) = p.&lt;br/&gt;
3) A modification could be defined for p=0: Returning sup{x in R | P(X&amp;lt;=x) = 0} would yield the infimum of the distribution's support instead of a mandatory -infinity.&lt;br/&gt;
4) This affects issue &lt;a href="https://issues.apache.org/jira/browse/MATH-540" title="AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug"&gt;&lt;del&gt;MATH-540&lt;/del&gt;&lt;/a&gt;. I'd prefere the definition from above for the following reasons:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;This definition simplifies inverse transform sampling (as mentioned in the other issue).&lt;/li&gt;
	&lt;li&gt;It is the standard textbook definition for the quantile function.&lt;/li&gt;
	&lt;li&gt;For integer distributions it has the advantage that the result doesn't change when switching to "x in Z", i.e. the result is independent of considering the intergers as sole set or as part of the reals.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ContinuousDistribution:&lt;br/&gt;
nothing to be added regarding (inverse) cumulative probability functions&lt;/p&gt;

&lt;p&gt;IntegerDistribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(int x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(int x0, int x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1) above&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;, comments=[&lt;p&gt;Thanks for raising this issue, Christian - especially now as we finalize the 3.0 API.&lt;/p&gt;

&lt;p&gt;I am +1 for these changes.  I agree that the inf-based definition of inverse cum is more standard and we are in a position now make the change, so I say lets do it.  I am also +1 on the move of this up to the distribution interface.  The reason we did not include it there originally was that we thought we might implement distributions for which we could not define inverses.  That has not happened in the last 8 years, so I think its safe enough to push it up.&lt;/p&gt;

&lt;p&gt;The code, test, user guide and doc changes for this have to be done carefully.  Patches most welcome.&lt;/p&gt;

&lt;p&gt;Is everyone else OK with this change?&lt;/p&gt;
, &lt;p&gt;I have neither used nor developed this part of CM, so my view on this is of but little value. Having said that, anything improving consistency can only be desirable, especially at this stage. So I'm all for it, and will be soon available (when I'm done on SYMMLQ) for an (novice on these issues) help.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;+1&lt;/p&gt;
, &lt;p&gt;Thanks for the feedback to all. Sbastien, thanks for offering your help. If you like and find time for it, you could implement AbstractDistribution.inverseCumulativeProbability(double p).&lt;/p&gt;

&lt;p&gt;I will provide some patches next week, but adjusting AbstractContinuousDistribution.inverseCumulativeProbability(double p) will take some more time.&lt;/p&gt;

&lt;p&gt;After thinking a little more about the structure of the interfaces, I'd like to put the function probability(double x) to Distribution anyway (independently of the thought in point 1) above).&lt;/p&gt;

&lt;p&gt;Are there any preferences on P(x0 &amp;lt;= X &amp;lt;= x1) or P(x0 &amp;lt; X &amp;lt;= x1) for cumulativeProbability(double x0, double x1)?&lt;/p&gt;
, &lt;p&gt;I am not sure it is really makes sense to add probability(double x) to the Distribution interface.  It would have to be defined as density (referring to the distribution function) to make sense in the continuous case, since defined as p(X = x) it would in most cases be identically 0 for continuous distributions.&lt;/p&gt;

&lt;p&gt;Regarding the cum definition, I am fine with P(x0 &amp;lt; X &amp;lt;= x1).&lt;/p&gt;
, &lt;p&gt;Happy to help on the inverse cumulative probability. You will have to be patient and forgieving with me, though, as I discover this part of CM.&lt;/p&gt;

&lt;p&gt;As for the definition, I think that one of the bounds should be excluded, so that these cumulative probabilities can be summed&lt;br/&gt;
P(a &amp;lt; X &amp;lt;= c) = P(a &amp;lt; X &amp;lt;= b) + P(b &amp;lt; X &amp;lt;= c),&lt;br/&gt;
even in the case of discrete PDFs.&lt;/p&gt;

&lt;p&gt;Whether the lower or upper bound should be excluded is another matter. I usually work with continuous pdfs, so I don't know if there is a common practice in the probability community. If there is none, I would tend to chose the following definition&lt;br/&gt;
P(x0 &amp;lt;= X &amp;lt; x1)&lt;br/&gt;
(sorry Phil!), because it would be consistent with the way things are usually indexed in java (a&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;.. a&lt;span class="error"&gt;&amp;#91;a.length-1&amp;#93;&lt;/span&gt;). See also &lt;tt&gt;org.apache.commons.math.util.MultidimensionalCounter&lt;/tt&gt;. Although this type of consistency is not an absolute requirement, I think it is nice for the user to have such simple principle: "lower bound always included, upper bound always excluded". Appart from this small point, I really have no objection to any choice.&lt;/p&gt;
, &lt;p&gt;Have a look at the default implementation of cum(x0,x1) now in AbstractDistribution.  I think the incorrectness in the documentation there may have been what triggered Christian to raise this issue.  The equation cum(a,b) = F(b) - F(a) where F is the distribution function is natural and what the impl there is trying to do.  In the discrete case, this equation fails, however, unless you define the cum to exclude the &lt;b&gt;lower&lt;/b&gt; endpoint.  That's why P(x0 &amp;lt; X &amp;lt;= x1) is a better definition.&lt;/p&gt;
, &lt;p&gt;OK, Phil, it makes perfect sense.&lt;/p&gt;
, &lt;p&gt;Good, the definition of cum(x0,x1) will be P(x0 &amp;lt; X &amp;lt;= x1). Phil, you are right: cum(x0,x1) in AbstractDistribution was a reason for raising this issue. Another reason was cum(int x0, int x1) in AbstractIntegerDistribution.&lt;/p&gt;

&lt;p&gt;The idea behind probability(double x) is in fact to define it as p(X = x) and to return 0 for continuous distributions. This function would be useful for discrete distributions not inheriting from IntergerDistribution and for distributions being composed of discrete and continuous parts.&lt;/p&gt;
, &lt;p&gt;I guess I am OK with pushing p&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/error.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt; up.  See related post to follow in commons-dev. &lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
I've started looking into this issue. As I said, you will have to be patient with me &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;.&lt;br/&gt;
I can see there already is a default implementation of &lt;tt&gt;AbstractContinuousDistribution.inverseCumulativeProbability&lt;/tt&gt;. So what exactly would you like me to do? Is this implementation fragile? Would you like me to improve robustness? Provide full testing?&lt;/p&gt;

&lt;p&gt;I think there might be issues when the PDF falls down to zero in a range (in which case the cum exhibits a plateau). The returned value might differ from the mathematical definition you proposed. Is this what you want me to work on? Have you already identified other issues?&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;

&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;

&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;

&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;
, &lt;p&gt;Another point for discussion:&lt;br/&gt;
I'd like to introduce&lt;br/&gt;
getDomainBracket(double p): returns double[]&lt;br/&gt;
to AbstractDistribution as helper function for inverseCumulativeProbability. This allows to avoid searching a bracket where a bracket can be specified directly.&lt;br/&gt;
The function getDomainBracket could be made abstract (which means to remove getInitialDomain, getDomainLowerBound, and getDomainUpperBound as these functions aren't needed any more), or it could have a default implementation (according to the corresponding part of the current implementation of inverseCumulativeProbability) which uses getInitialDomain, getDomainLowerBound, and getDomainUpperBound. However, getInitialDomain, getDomainLowerBound, and getDomainUpperBound should not be abstract in the latter case. Otherwise a derived class would be forced to implement something it potentially doesn't use. Thus the functions getInitialDomain, getDomainLowerBound, and getDomainUpperBound should have default implementations which either return default values (0, -infinity, +infinity) or throw an exception saying something like "has to be implemented".&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I'm working on it...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, for now, I'm concentrating on making the current impl in &lt;tt&gt;AbstractContinuousDistribution&lt;/tt&gt; more robust. The other impl should be easier.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current implementation uses a Brent solver. I think the solver itself is only one side of the issue. The other point is the algorithm used to bracket the solution, in order to ensure that the result is consistent with the definition of the cumprob. As for the &lt;tt&gt;DifferentiableUnivariateRealSolver&lt;/tt&gt;, I'm not too sure. I guess it depends on what is meant by "continuous distribution". For me, it means that the random variable takes values in a continuous set, and possibly its distribution is defined by a density. However, in my view, nothing prevents occurences of Dirac functions, in which case the cum sum is only piecewise C1. It's all a matter of definition, of course, and I'll ask the question on the forum to check whether or not people want to allow for such a situation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I'm very interested.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Please note that &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt; has been created specifically to handle plateaux.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;Here is the first patch for this issue (unfortunately with some delay). It adjusts the distributions with real domain to the definitions in this issue, and it mainly changes documentations.&lt;/p&gt;

&lt;p&gt;I could not move inverseCumulativeProbability(double) up to Distribution because there would be a conflict with IntegerDistribution.inverseCumulativeProbability(double): This method returns int. This problem will be removed by solving issue &lt;a href="https://issues.apache.org/jira/browse/MATH-703" title="Splitting up the distribution hierarchy"&gt;&lt;del&gt;MATH-703&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The implementation of inverseCumulativeProbability(double) is not changed as Sbastien is working on this.&lt;/p&gt;

&lt;p&gt;I will provide the patch for the integer distributions as soon as I have adjusted the test data to the new inequalities and reverified the adjusted test data.&lt;/p&gt;
, &lt;p&gt;All,&lt;br/&gt;
since I'm already working on this package, I'm happy to commit the patch on behalf of Christian. However, since I'm a relatively new committer, I would feel more confident if one of the "old, wise committers" could double check the svn log afterwards.&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hey, that's how it always works &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;  &lt;/p&gt;

&lt;p&gt;I don't know about "wise" but I certainly qualify as "old" by any standard, so will have a look once you have reviewed and committed.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
, &lt;p&gt;Patch &lt;tt&gt;Math-692_realDomain_patch1.patch&lt;/tt&gt; (20111108) applied in rev 1200179, with minor modifications (mostly checkstyle fixes).&lt;br/&gt;
Thanks Christian!&lt;/p&gt;
, &lt;p&gt;As mentioned by Sbastien in &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt;, the implementation of &lt;tt&gt;IntegerDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; can benefit from the ideas which came up for &lt;tt&gt;RealDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; in that thread.&lt;/p&gt;

&lt;p&gt;Thus I will remove &lt;tt&gt;getDomainLowerBound(double p)&lt;/tt&gt; and &lt;tt&gt;getDomainUpperBound(double p)&lt;/tt&gt; from the integer distributions. I checked that all current implementations of the lower/upper bound methods provide the whole support of the distribution as starting bracket. This means that using &lt;tt&gt;getSupportLowerBound()&lt;/tt&gt; and &lt;tt&gt;getSupportUpperBound()&lt;/tt&gt; for the starting bracket won't degrade the performance of the current distribution implementations. However, a user might want the improve the performance of his distribution implementations by providing a more targeted starting bracket for probability &lt;tt&gt;p&lt;/tt&gt;. Thus I will swap the solving step to a protected function &lt;tt&gt;solveInverseCumulativeProbability(double p, int lower, int upper)&lt;/tt&gt;, so that it gets easy to override &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; with an implementation which finds a better starting bracket.&lt;/p&gt;

&lt;p&gt;Furthermore, Phil's idea with Chebyshev's inequality can be applied to the generic implementation of &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; in order to get a better starting bracket.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
If you agree with that, I suggest that you also take care of &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;, as the two issues seem to be very much connected.&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;my changes in the integer distributions don't solve &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;. Instead I found a probably related problem with the Pascal distribution.&lt;/p&gt;

&lt;p&gt;The integer distribution patch for this issue still isn't ready. I will provide it next week.&lt;/p&gt;

&lt;p&gt;Christian&lt;/p&gt;
, &lt;p&gt;This is the patch which adjusts the integer distributions to the agreements above.&lt;/p&gt;

&lt;p&gt;The changes to the test cases for the random generators may be unexpected. But these changes initially were triggered by adjusting &lt;tt&gt;RandomDataTest.checkNextPoissonConsistency(double)&lt;/tt&gt; to the new contract for integer distributions. Then some random generator tests failed due to chance. While adjusting their seeds, I found some other tests with a high failure probability. Thus I also set some failure probabilities to 0.01 in order to find suitable seeds more quickly.&lt;/p&gt;

&lt;p&gt;My next task on this issue is to adjust the user guid.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
thanks for this contribution. I am away for a few days, but am very happy to commit this patch as soon as I am back, if you are not in too much of a hurry.&lt;br/&gt;
Thanks again,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Well, we've recently run into some troubles with SVN, but it seems everything is working fine again. Patch {{&lt;a href="https://issues.apache.org/jira/browse/MATH-692" title="Cumulative probability and inverse cumulative probability inconsistencies"&gt;&lt;del&gt;MATH-692&lt;/del&gt;&lt;/a&gt;_integerDomain_patch1.patch}} (with minor checkstyle changes) committed in revision &lt;tt&gt;1226041&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Please do not forget to run &lt;tt&gt;mvn clean; mvn site:site&lt;/tt&gt; and check the reports (in particular, &lt;tt&gt;checkstyle&lt;/tt&gt;) prior to submitting a patch!&lt;/p&gt;

&lt;p&gt;Thanks for this contribution.&lt;/p&gt;
, &lt;p&gt;The committed patch actually causes failure of &lt;tt&gt;Well1024Test&lt;/tt&gt; in &lt;tt&gt;o.a.c.m.random&lt;/tt&gt;.&lt;/p&gt;
, &lt;p&gt;Thanks for committing the patch, Sbastien. I see you already changed the seed in &lt;tt&gt;Well1024aTest&lt;/tt&gt;. This hopefully removes the failure.&lt;/p&gt;

&lt;p&gt;I'll have a look into Maven to prepare a better patch next time. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;I see you already changed the seed in Well1024aTest.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I did, but is this really how we want &lt;tt&gt;Well2004aTest&lt;/tt&gt; to pass?&lt;/p&gt;
, &lt;p&gt;I guess there is no alternative to this way of making probabilistic test cases pass. However, I understand your bad feeling with this kind of failure fixing. The problem is that probabilistic tests are quiet fuzzy: Neither a passed test nor a failed test provides a clear answer whether something is right or wrong in the implementation. There is just a high chance to pass such a test with a correct implementation. The chance for failure increases with an erroneous implementation due to systematic deviations in the generated data. These chances tell whether it is easy to find a seed which passes the tests or not. Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's exactly the point I've raised on the mailing-list: out of three seeds (100, 1000 and 1001), only one works. Of course, I would not dare to call that representative statistics, but I'm wondering whether or not we should be worried...&lt;/p&gt;
, &lt;p&gt;The issue about selection of an appropriate seed has been raised elsewhere. No definitive answer has been provided so far, so I suggest we consider this issue as solved for the time being.&lt;/p&gt;
], resolution=Fixed, reporter=cwinter, assignees=[], commentAuthors=[psteitz, celestin, mikl, cwinter], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-654
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-654, created=Tue Aug 30 19:23:19 CEST 2011, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Thu Sep 01 02:14:02 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=ValueServer not deterministic for a fixed random number seed, link=https://issues.apache.org/jira/browse/MATH-654, description=&lt;p&gt;I have built an agent-based model using the Apache Commons Math library, which has come in handy.&lt;/p&gt;

&lt;p&gt;The ValueServer seemed particularly helpful, as explained at:&lt;br/&gt;
&lt;a href="http://commons.apache.org/math/userguide/random.html"&gt;http://commons.apache.org/math/userguide/random.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My simulation needs repeatable randomness, so I used this form of the ValueServer constructor:&lt;/p&gt;

&lt;p&gt;    ValueServer(RandomData randomData) &lt;br/&gt;
    Construct a ValueServer instance using a RandomData as its source of random data.&lt;br/&gt;
    // &lt;a href="http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html"&gt;http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, in my simulation, I found that the ValueServer did not act deterministically if I supplied the same random number seed.&lt;/p&gt;

&lt;p&gt;I have not inspected the source code, but I suspect that the ValueServer is not using the `randomData` generator correctly. If it was, then it should be deterministic.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  I assume you are using DIGEST_MODE.  If this is the case and you are comfortable compiling the code in trunk, the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-634" title="EmpiricalDistributionImpl should use a pluggable RandomGenerator"&gt;&lt;del&gt;MATH-634&lt;/del&gt;&lt;/a&gt; enables a workaround for this.  Using the reseed method added to EmpiricalDistributionImpl in trunk, you can use ValueServer's getEmpiricalDistribution to get the distribution and then invoke reseed.  Unfortunately, this method does not exist in any released version yet.&lt;/p&gt;

&lt;p&gt;The problem is that ValueServer#getNextDigest (what it does for getNext in DIGEST_MODE) delegates to EmpiricalDistributionImpl#getNextValue.  EmpiricalDistributionImpl has its own RandomData instance.  To fix this issue, EmpiricalDistirbutionImpl should add a constructor taking a RandomData and ValueServer should provide this.&lt;/p&gt;
, &lt;p&gt;Fixed in r1163875. ValueServer now exposes a reSeed method that when supplied a fixed seed will generate a fixed sequence in any stochastic mode. The RandomDataImpl that it uses internally is passed to the EmpiricalDistributionImpl it creates when used in DIGEST_MODE.  The changes for this issue include an incompatible (vs. 2.x) change: the constructor for EmpiricalDistributionImpl that previously took a RandomData now takes a RandomDataImpl.  The plan for 3.0 is to merge these.&lt;/p&gt;
], resolution=Fixed, reporter=d.james, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-640
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-640, created=Tue Aug 02 21:06:35 CEST 2011, updated=Sat Mar 24 17:16:52 CET 2012, resolved=Wed Aug 03 06:17:43 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=AbstractRandomGenerator nextInt() and nextLong() default implementations generate only positive values, link=https://issues.apache.org/jira/browse/MATH-640, description=&lt;p&gt;The javadoc for these methods (and what is specified in the RandomGenerator interface) says that all int / long values should be in the range of these methods.  The default implementations provided in this class do not generate negative values.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1153338&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-618
2016-01-13 22:20:32,483 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-618, created=Wed Jul 13 22:23:43 CEST 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Thu Jul 14 08:08:54 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same, link=https://issues.apache.org/jira/browse/MATH-618, description=&lt;p&gt;For both Complex add and subtract, the javadoc states that&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;* If either &lt;span class="code-keyword"&gt;this&lt;/span&gt; or &amp;lt;code&amp;gt;rhs&amp;lt;/code&amp;gt; has a NaN value in either part,
     * {@link #NaN} is returned; otherwise Inifinite and NaN values are
     * returned in the parts of the result according to the rules &lt;span class="code-keyword"&gt;for&lt;/span&gt;
     * {@link java.lang.&lt;span class="code-object"&gt;Double&lt;/span&gt;} arithmetic&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1146573&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-588
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-588, created=Sun Jun 12 20:19:07 CEST 2011, updated=Sat Mar 24 17:16:31 CET 2012, resolved=Sun Feb 05 20:54:50 CET 2012, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Weighted Mean evaluation may not have optimal numerics, link=https://issues.apache.org/jira/browse/MATH-588, description=&lt;p&gt;I recently got this in a test run&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;testWeightedConsistency(org.apache.commons.math.stat.descriptive.moment.MeanTest)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;0.002282165958997601&amp;gt; but was:&amp;lt;0.002282165958997157&amp;gt;
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:441)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:178)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:153)
	at org.apache.commons.math.stat.descriptive.UnivariateStatisticAbstractTest.testWeightedConsistency(UnivariateStatisticAbstractTest.java:170)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The correction formula used to compute the unweighted mean may not be appropriate or optimal in the presence of weights:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// Compute initial estimate using definitional formula
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; sumw = sum.evaluate(weights,begin,length);
&lt;span class="code-object"&gt;double&lt;/span&gt; xbarw = sum.evaluate(values, weights, begin, length) / sumw;

&lt;span class="code-comment"&gt;// Compute correction factor in second pass
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; correction = 0;
&lt;span class="code-keyword"&gt;for&lt;/span&gt; (&lt;span class="code-object"&gt;int&lt;/span&gt; i = begin; i &amp;lt; begin + length; i++) {
  correction += weights[i] * (values[i] - xbarw);
}
&lt;span class="code-keyword"&gt;return&lt;/span&gt; xbarw + (correction/sumw);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;, comments=[&lt;p&gt;Fixed it in r1240790.&lt;/p&gt;

&lt;p&gt;There was a too strict equality test using an relative error of 10-14 which resulted in certain unforunate cases of an absolute error of 10-18.&lt;/p&gt;
, &lt;p&gt;Corrected the equality test in r1240795 as it was leading to failure. In fact the test can range from very small to very large values which really requires a relative error estimate.&lt;/p&gt;

&lt;p&gt;The test is problematic in general, as it may contain values from very different scales (due to its random nature), leading to unavoidable precision errors in the above formula.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[tn], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-575
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-575, created=Sat May 14 18:40:34 CEST 2011, updated=Sat Mar 24 17:16:54 CET 2012, resolved=Thu Feb 02 12:12:52 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=Exceptions in genetics package or not consistent with the rest of [math], link=https://issues.apache.org/jira/browse/MATH-575, description=&lt;p&gt;InvalidRepresentationException is checked and non-localized.  This exception should be placed in the &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; hierarchy.  The AbstractListChromosome constructor also throws a non-localised IAE, which should be replaced by an appropriate &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; exception.&lt;/p&gt;, comments=[&lt;p&gt;Phil started to work on this issue in r1135025.&lt;/p&gt;

&lt;p&gt;In r1235038 additional cleanups have been performed:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;add localized messages for all exceptions&lt;/li&gt;
	&lt;li&gt;add @throws to javadoc where appropriate&lt;/li&gt;
	&lt;li&gt;add final to method parameters&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What is missing:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;Phil mentioned that InvalidRepresentationException should be placed into &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, although I am not sure why, as it is not used outside the genetics package&lt;/li&gt;
	&lt;li&gt;add more custom exception classes specific to the genetics package (optional). By now mostly MathIllegalArgumentException or other appropriate ones have been used.&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;Thanks for working on this, but before you do start to make modifications, please assign the issue to yourself!&lt;/p&gt;

&lt;p&gt;For the changes themselves, I don't agree with the creation of those many localized messages: We have been trying to rationalize and reduce the number of those, by removing duplicates and combining several ones to convey the full explanation of the problem. See my reply to the commit message.&lt;/p&gt;
, &lt;p&gt;Fixed in r1235197.&lt;/p&gt;

&lt;p&gt;Thanks for your suggestions!&lt;/p&gt;
, &lt;p&gt;Thomas,&lt;br/&gt;
Could please check whether this issue is resolved? And if it is, mark it so? Thanks.&lt;/p&gt;
, &lt;p&gt;As from the original issue description, Phil intended to move the InvalidRepresentationException to the general o.a.c.m.exceptions package. I am not sure about this, that's why I kept it aside for the time being. If we agree on keeping it in the genetics package we can resolve this issue.&lt;/p&gt;
, &lt;p&gt;Phil had always been opposed to having all exceptions grouped in their own package; so I doubt that he meant to move that one over there... &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
Here, the description just indicates that the exception should become &lt;em&gt;unchecked&lt;/em&gt; and that the "detailed message" should be an element from the "LocalizedFormats" enum (i.e. derive from one of the base CM exceptions).&lt;/p&gt;
, &lt;p&gt;Ah ok, that makes it clear. When reading hierarchy I was just thinking in terms of packages rather than class hierarchy.&lt;/p&gt;

&lt;p&gt;Thus, I resolve this issue.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[tn], commentAuthors=[tn, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-555
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-555, created=Mon Apr 04 06:13:04 CEST 2011, updated=Sat Mar 24 17:16:43 CET 2012, resolved=Mon Apr 04 06:53:13 CEST 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=MathUtils round method should propagate rather than wrap Runitme exceptions, link=https://issues.apache.org/jira/browse/MATH-555, description=&lt;p&gt;MathUtils.round(double, int, int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException, the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in trunk in r1088473&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-540
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-540, created=Sun Mar 06 01:43:45 CET 2011, updated=Sat Mar 24 17:16:36 CET 2012, resolved=Sun Jun 12 07:58:50 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug, link=https://issues.apache.org/jira/browse/MATH-540, description=&lt;p&gt;The AbstractIntegerDistribution.inverseCumulativeProbability(...) function attempts to decrement the lower bound of discrete distributions to values that go below the lower bound.&lt;/p&gt;, comments=[&lt;p&gt;I don't think this is a bug.  Per the javadoc, the contract for inverse cum is&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/**
 * For a random variable {@code X} whose values are distributed according
 * to &lt;span class="code-keyword"&gt;this&lt;/span&gt; distribution, &lt;span class="code-keyword"&gt;this&lt;/span&gt; method returns the largest {@code x}, such
 * that {@code P(X &amp;lt; x) &amp;lt; p}.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This implies that if the first non-zero mass point has probability greater than p, the right value to return is one less than that value, which is whet the method will do.  Your example distribution throws NPE when trying to compute probabilities outside of its domain of support. &lt;/p&gt;
, &lt;p&gt;I'm looking at it like this.  I have very simple distribution like the one provided (Four sided dice).  I'm trying to write a simulation that draws values of x for a a set of uniform 0-1 probabilities.  So I'm expecting:&lt;/p&gt;

&lt;p&gt;0 When p is less than or equal to 0.25&lt;br/&gt;
1 When p is greater than 0.25 but less than or equal to 0.50&lt;br/&gt;
2 When p is greater than 0.50 but less than or equal to 0.75&lt;br/&gt;
3 When p is greater than 0.75 but less than or equal to 1.0&lt;/p&gt;

&lt;p&gt;So for the line &lt;/p&gt;

&lt;p&gt;int neverSucceeds = d.inverseCumulativeProbability(0.0001);&lt;/p&gt;

&lt;p&gt;I'm really expecting 0 to be returned.&lt;/p&gt;

&lt;p&gt;Make sense?&lt;/p&gt;
, &lt;p&gt;I see now that there actually does appear to be an error in the javadoc.  The implementation really returns the largest x such that p(X &amp;lt;= x) &amp;lt;= p.  In the discrete case, &amp;lt;= matters and I think both inequalities in the javadoc should be changed.&lt;/p&gt;

&lt;p&gt;In your example, if the probability distribution vanishes outside 0, 1, 2, 3 and puts .25 mass on each of these values, the inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;

&lt;p&gt;If you fix your distribution so that both probability and cumulativeProbability return correct values (rather than throwing NPEs) outside of the mass values, you should get -1 returned.&lt;/p&gt;
, &lt;p&gt;Reading your last comment a little more carefully, it looks like what you are trying to do is implement sampling.  IIUC, something like what you are suggesting should work - you just have an off-by-one problem vis-s-vis the contract of inverse cumulative probabilities as we define them.  I would be +1 for adding direct support for sampling from discrete distributions, but we should open a separate ticket for that.&lt;/p&gt;
, &lt;p&gt;OK - I'll close this one and open a separate ticket.&lt;/p&gt;
, &lt;p&gt;There is a javadoc bug that needs to be fixed here&lt;/p&gt;
, &lt;p&gt;Ooops - Thanks.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;...inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems to me that users would be better served if it returned 0 and that it is also correct to do so.&lt;/p&gt;

&lt;p&gt;In the definition we say "For a random variables X whose values are distributed according to this distribution...".&lt;/p&gt;

&lt;p&gt;Suppose the distribution was for a six sided dice.  One could assert that the distribution is only defined for the values 1,2,3,4,5,6.  In this case the inverseCumulativeDistribution returns 0, but that does not have any meaning.  So now developers are forced to define the meaning of 0 for a six sided dice implementation.  &lt;/p&gt;

&lt;p&gt;In Grad school we were taught the the inverse cumulative distribution is for sampling.  So for a six sided dice uniform probabilities less than 1/6 would return 1, less than 2/6 would return 2, etc.&lt;/p&gt;

&lt;p&gt;With the current implementation for values less than 1/6 we get 0 which is meaningless, and the only time we get 6 is when the uniform probability argument is 1.&lt;/p&gt;

&lt;p&gt;So if someone mistakenly tries to use the inverseCumulativeProbability function for sampling the results are going to be wacked.  What is the use case for the inverseCumulativeProbability the way it is right now?&lt;/p&gt;
, &lt;p&gt;You have a choice in defining the inverse cum whether to define it the way we have or to use and inf rather than a sup.  We can implement sampling using the current impl.  We just need to take into account the way the inverse cum is defined in AbstractIntegerDistribution.  &lt;/p&gt;
, &lt;p&gt;OK - I think it's starting to make more sense to me now.  So when implementing sampling we just add one to the value returned by inverseCumulativeDistribution, unless the uniform probability argument is 1?&lt;/p&gt;
, &lt;p&gt;I am sorry.  I forgot that we had in fact already implemented this in version 2.2. See AbstractIntegerDistribution#sample.  The base class implementation delegates to RandomDataImpl#nextInversionDeviate (adding one per the last comment).&lt;/p&gt;
, &lt;p&gt;Sorry for the noise. I closed the wrong ticket.  Still need to fix the javadoc to match behavior and user guide.&lt;/p&gt;
, &lt;p&gt;Javadoc fixed in trunk r1134866&lt;/p&gt;
], resolution=Fixed, reporter=ole, assignees=[], commentAuthors=[psteitz, ole], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-506
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-506, created=Tue Feb 01 19:38:01 CET 2011, updated=Sat Mar 24 17:16:41 CET 2012, resolved=Sat Aug 20 23:14:57 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=The static field ChiSquareTestImpl.distribution serves no purpose, link=https://issues.apache.org/jira/browse/MATH-506, description=&lt;p&gt;The static field ChiSquareTestImpl.distribution serves no purpose.&lt;/p&gt;

&lt;p&gt;There is a setter for it, but in every case where the field is used, it is first overwritten with a new value.&lt;/p&gt;

&lt;p&gt;The field and the setter should be removed, and the methods that create a new instance should create a local variable instead.&lt;/p&gt;

&lt;p&gt;For Math 2.1, the field can be removed and the setter deprecated.&lt;/p&gt;, comments=[&lt;p&gt;Agreed.  Since the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; this instance field is unnecessary.&lt;/p&gt;
, &lt;p&gt;See the discussion in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; where it was decided to remove the distribution pluggability in 3.0.  In 2.x, the distribution is pluggable and the instance field is useful.  The 3.0 code in trunk removes the pluggability and makes the field useless.&lt;/p&gt;
, &lt;p&gt;Sorry - I thought I had checked the 2.x implementation as well, but obviously not, as it does use the field.&lt;/p&gt;

&lt;p&gt;However, we should still deprecate the setter in 2.2, as it is removed in 3.0 - OK?&lt;/p&gt;
, &lt;p&gt;Just tried removing the field and setter in 3.0, and found that the constructors rely on the setter (which is a separate bug, as the setter is not final - but easily fixable if required).&lt;/p&gt;

&lt;p&gt;The fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; merely removed deprecated code.&lt;/p&gt;

&lt;p&gt;It replaced "distribution.setDegreesOfFreedom(dof)" with "distribution = new ChiSquaredDistributionImpl(dof)" which is how the field became useless.&lt;/p&gt;

&lt;p&gt;There are two constructors which still create values for the distribution field.&lt;/p&gt;

&lt;p&gt;I don't know enough about the Math to know whether there would be any use cases for having additional methods that used a distribution provided by the class instance, rather than calculated by the individual methods (as at present).&lt;/p&gt;

&lt;p&gt;If there is no need for external provision of the distribution degree of freedom, then the constructor with parameter can be dropped.&lt;/p&gt;

&lt;p&gt;Otherwise, we need to add some methods that can use the provided distribution (which should be a final instance field).&lt;/p&gt;

&lt;p&gt;In any case, I think the setter needs to be dropped from 3.x&lt;/p&gt;
, &lt;p&gt;The instance field was there originally so that different ChiSquareDistribution implementations could be provided at construction time or via a setter (making the underlying ChiSquareDistribution pluggable).  &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; pointed to a different problem related to mutability of implementation instances.  The simplest solution to both problems is to eliminate the pluggability, which the change in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; does for this class.  The degrees of freedom are always computed from the data, so there is no need for the constructor that takes a distribution instance as argument.  Both the constructor and setter can be deprecated in 2.2 and removed in 3.0 unless we want to keep pluggability, which would require&lt;/p&gt;

&lt;p&gt;1) making the distribution field final (so removing the setter)&lt;br/&gt;
2) copying, rather than referencing the actual parameter provided to the constructor&lt;/p&gt;

&lt;p&gt;I am on the fence on this.  Maybe others can chime in (next week &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;p&gt;OK, I see now, thanks!&lt;/p&gt;
, &lt;p&gt;I removed the field (hence eliminating pluggability) in r1159916.  As of 3.0, the distribution classes are immutable, so to support pluggability a factory or class name rather than a distribution instance would have to be provided.  There is only one implementation provided by &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, so I do not see this as worth the effort and complexity to retain.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[psteitz], commentAuthors=[psteitz, sebb@apache.org], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,498 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-505
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-505, created=Tue Feb 01 01:28:56 CET 2011, updated=Sat Mar 24 17:16:40 CET 2012, resolved=Tue Feb 01 19:58:30 CET 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
], fixVersion=[3.0
], priority=Major, summary=TestUtils is thread-hostile, link=https://issues.apache.org/jira/browse/MATH-505, description=&lt;p&gt;TestUtils has several mutable static fields which are not synchronised, or volatile.&lt;/p&gt;

&lt;p&gt;If one of the fields is updated by thread A, there is no guarantee that thread B will see the full update - it may see a partially updated object.&lt;/p&gt;

&lt;p&gt;Furthermore, at least some of the static fields reference a mutable object, which can be changed whilst another thread is using it.&lt;/p&gt;

&lt;p&gt;As far as I can tell, this class must only ever be used by a single thread otherwise the results will be unpredictable.&lt;/p&gt;, comments=[&lt;p&gt;What fields, exactly?&lt;/p&gt;
, &lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/** Singleton TTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; TTest tTest = &lt;span class="code-keyword"&gt;new&lt;/span&gt; TTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; ChiSquareTest chiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; UnknownDistributionChiSquareTest unknownDistributionChiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton OneWayAnova instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; OneWayAnova oneWayAnova =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; OneWayAnovaImpl();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of the above may be changed by set methods. There is no synch.&lt;/p&gt;
, &lt;p&gt;OK, I was looking at the wrong TestUtils &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;

&lt;p&gt;The reason for this strange-looking setup is to allow the implementations to be pluggable at runtime.  "Hostile" is a harsh word, but this class is certainly &lt;b&gt;not&lt;/b&gt; threadsafe.  Ideas / patches to achieve the design goal with less "hostility" would be appreciated.&lt;/p&gt;

&lt;p&gt;I would have to double-check, but I don't think that there is any test instance state used by the methods in this class. &lt;/p&gt;
, &lt;p&gt;By thread-hostile, I mean that it is not possible in general for two different threads to use the class safely.&lt;br/&gt;
If one thread changes any of the static fields, there is no way of knowing how the methods called by the other thread will behave. This is partly because the values are not safely published currently, but even if they were, the threads don't know what settings will be used as they can be changed at any time by another thread.&lt;/p&gt;

&lt;p&gt;In general, any class which relies on mutable static state for its behaviour is thread-hostile.&lt;br/&gt;
The shared state cannot simultaneously satisfy two threads needing different behaviour.&lt;/p&gt;

&lt;p&gt;I think the only safe way for two threads to use the class as it stands is if they both synchronize on the class.&lt;br/&gt;
This will ensure safe publication of any field changes, and enforce serial usage which can guarantee the setting that will be used (but the lock will have to be held for the set call as well).&lt;/p&gt;

&lt;p&gt;ChiSquareTestImpl has a non-final instance field which means its value won't necessarily be safely published.&lt;br/&gt;
The field also has a setter which could be invoked by one thread while another was using it.&lt;/p&gt;

&lt;p&gt;TTestImpl is immutable (has no fields), and OneWayAnovaImpl can be made immutable, but other implementations of the interfaces might exist which are not immutable.&lt;/p&gt;

&lt;p&gt;The simplest way to make the class thread-safe would be to convert all the methods and fields from static to instance, but I don't know if that is acceptable.&lt;/p&gt;
, &lt;p&gt;Making the methods instance sort of defeats the purpose of the class.  None of the instance data in any of the static singletons is actually used or depended on by the methods of this class.  You are correct though that if one thread changes the impl for one of the singletons while another is using the class, the other could see a different than expected impl.  I think the practical likelihood of this is pretty much nil, as it is hard to imagine an application supplying two different implementations for the tests and wanting different threads to use different impls.  Personally, I would be happy just documenting the fact that the class is not threadsafe and if concurrent threads want to plug in different implementations, they need to synchronize on the class.  If this is not acceptable, my next preference would be to remove the pluggability - i.e., make the singletons final or get rid of them altogether, creating instances as needed for static method calls.  There is no initialization overhead creating the test classes.&lt;/p&gt;
, &lt;p&gt;@Phil: Please also keep in mind that M3 supports now (currently optional) parallel execution and it might be no longer a proper assumption that all tests are executed serially.&lt;/p&gt;
, &lt;p&gt;There is another possible option, which would be to fix the default implementations, and create new static methods that took an extra parameter for the implementation to be used.&lt;/p&gt;

&lt;p&gt;At present, changes to the static fields are not guaranteed to be published correctly. Making them volatile would fix this, but would not help with concurrent access.&lt;/p&gt;
, &lt;p&gt;Thanks, Joerg.  There should be no problems with the unit tests unless and until we introduce different tests that actually test the pluggability.  &lt;/p&gt;

&lt;p&gt;I thought about the additional parameter option, Sebb; but that again defeats the purpose of this "convenience class" - you might as well just instantiate the implementation and use it.&lt;/p&gt;

&lt;p&gt;I think the best solution is to just make the fields final and drop the getters and setters.  This is consistent with StatUtils.  So we should document the "hostility" issues in 2.2 and deprecate there and drop in 3.0.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[sebb@apache.org], commentAuthors=[psteitz, sebb@apache.org, joehni], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-484
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-484, created=Tue Jan 18 21:49:51 CET 2011, updated=Wed Mar 23 21:35:01 CET 2011, resolved=Mon Feb 14 15:20:29 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=events detection in ODE solvers is too complex and not robust, link=https://issues.apache.org/jira/browse/MATH-484, description=&lt;p&gt;All ODE solvers support multiple events detection since a long time. Events are specified by users by implementing the EventHandler interface. Events occur when the g(t, y) function evaluates to 0. When an event occurs, the solver step is shortened to make sure the event is located at the end of the step, and the event is triggered by calling the eventOccurred method in the user defined implementation class. Depending on the return value of this method, integration can continue, it can be stopped, or the state vector can be reset.&lt;/p&gt;

&lt;p&gt;Some ODE solvers are adaptive step size solvers. They can modify step size to match an integration error setting, increasing step size when error is low (thus reducing computing costs) or reducing step size when error is high (thus fulfilling accuracy requirements).&lt;/p&gt;

&lt;p&gt;The step adaptations due to events on one side and due to adaptive step size solvers are quite intricate by now, due to numerous fixes (&lt;a href="https://issues.apache.org/jira/browse/MATH-161" title="patch for Mantissa"&gt;&lt;del&gt;MATH-161&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-213" title="FirstOrderIntegrator.integrate does not give back integration stop time when an event handler stops integration"&gt;&lt;del&gt;MATH-213&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-358" title="ODE integrator goes past specified end of integration range"&gt;&lt;del&gt;MATH-358&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-421" title="restarting an ODE solver that has been stopped by an event doesn&amp;#39;t work"&gt;&lt;del&gt;MATH-421&lt;/del&gt;&lt;/a&gt; and also during standard maintenance - see for example r781157). The code is very difficult to maintain. It seems each bug fix introduces new bugs (r781157/&lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;) or tighten the link between adaptive step size and event detection (&lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;/r927202).&lt;/p&gt;

&lt;p&gt;A new bug discovered recently on an external library using a slightly modified version of this code could not be retroffitted into commons-math, despite the same problem is present. At the beginning of EventState.evaluateStep, the initial step may be exactly 0 thus preventing root solving, but preventing this size to drop to 0 would reopen &lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;. I could not fix both bugs at the same time.&lt;/p&gt;

&lt;p&gt;So it is now time to untangle events detection and adaptive step size, simplify code, and remove some inefficiency (event root solving is always done twice, once before step truncation and another time after truncation, of course with slightly different results, events shortened steps induce high computation load until the integrator recovers its optimal pace again, steps are rejected even when the event does not requires it ...).&lt;/p&gt;, comments=[&lt;p&gt;fixed in subversion repository as of r1061507 for branch 2.X and as of r1061508 for trunk&lt;/p&gt;
, &lt;p&gt;The fix introduced in r1061507 fails in several cases. If several events of the same type occur within a single long step, only the first one is triggered. If several events of different types occur during a backward integration, they are triggered in the wrong order (i.e. they are triggered in forward occurrence time order instead of backward).&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1070498 for branch 2.X and r1070499 for trunk&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-481
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-481, created=Mon Jan 17 18:15:41 CET 2011, updated=Wed Mar 23 21:33:40 CET 2011, resolved=Mon Jan 17 23:39:52 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=MathUtils.equals(double x, double y) disagrees with Javadoc, link=https://issues.apache.org/jira/browse/MATH-481, description=&lt;p&gt;MathUtils.equals(double x, double y) disagrees with Javadoc.&lt;/p&gt;

&lt;p&gt;The Javadoc says:&lt;/p&gt;

&lt;p&gt;Returns true iff they are equal as defined by  {@link #equals(double,double,int)}&lt;/p&gt;

&lt;p&gt;However, the code actually uses == and checks for NaN:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; &lt;span class="code-object"&gt;boolean&lt;/span&gt; equals(&lt;span class="code-object"&gt;double&lt;/span&gt; x, &lt;span class="code-object"&gt;double&lt;/span&gt; y) {
    &lt;span class="code-keyword"&gt;return&lt;/span&gt; (&lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(x) &amp;amp;&amp;amp; &lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(y)) || x == y;
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The method is deprecated, but it should probably still be consistent with its documentation.&lt;/p&gt;, comments=[&lt;p&gt;Corrected Javadoc in revision 1060117.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-465
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-465, created=Wed Jan 05 18:34:41 CET 2011, updated=Sat Mar 24 17:17:03 CET 2012, resolved=Wed Jul 20 14:20:51 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Incorrect matrix rank via SVD, link=https://issues.apache.org/jira/browse/MATH-465, description=&lt;p&gt;The getRank() function of SingularValueDecompositionImpl does not work properly. This problem is probably related to the numerical stability problems mentioned in &lt;a href="https://issues.apache.org/jira/browse/MATH-327"&gt;MATH-327&lt;/a&gt; and &lt;a href="https://issues.apache.org/jira/browse/MATH-320"&gt;MATH-320&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Example call with the standard matrix from R (rank 2):&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeHeader panelHeader" style="border-bottom-width: 1px;"&gt;&lt;b&gt;TestSVDRank.java&lt;/b&gt;&lt;/div&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.Array2DRowRealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.RealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecomposition;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecompositionImpl;

&lt;span class="code-keyword"&gt;public&lt;/span&gt; class TestSVDRank {
	&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; void main(&lt;span class="code-object"&gt;String&lt;/span&gt;[] args) {
		&lt;span class="code-object"&gt;double&lt;/span&gt;[][] d = { { 1, 1, 1 }, { 0, 0, 0 }, { 1, 2, 3 } };
		RealMatrix m = &lt;span class="code-keyword"&gt;new&lt;/span&gt; Array2DRowRealMatrix(d);
		SingularValueDecomposition svd = &lt;span class="code-keyword"&gt;new&lt;/span&gt; SingularValueDecompositionImpl(m);
		&lt;span class="code-object"&gt;int&lt;/span&gt; r = svd.getRank();
		&lt;span class="code-object"&gt;System&lt;/span&gt;.out.println(&lt;span class="code-quote"&gt;"Rank: "&lt;/span&gt;+r);
	}
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;The rank is computed as 3. This problem also occurs for larger matrices. I discovered the problem when trying to replace the corresponding JAMA method.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  Looks like it could as you suggest be related to &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt;.  &lt;/p&gt;
, &lt;p&gt;For now, pushing to 3.0.  If we get a fix for this and &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt; before 3.0 is ready, I may propose a 2.2.1 to include it.&lt;/p&gt;
, &lt;p&gt;My apologies if I am missing something, but here is what I noticed about the SVD. &lt;/p&gt;

&lt;p&gt;On lines 124-127 of SingularValueDecompositionImpl we have:&lt;/p&gt;

&lt;p&gt;        for (int i = 0; i &amp;lt; p; i++) {
            singularValues[i] = FastMath.sqrt(FastMath.abs(singularValues[i]));
        }&lt;/p&gt;

&lt;p&gt;This is potentially the offending line. First is the problem of negative eigenvalues. Negative variance in the principal components should probably be dealt with explicitly? Perhaps by throwing a MathException? Second, and the issue which this bug report deals with, is taking a square root of a very small number (&amp;lt;1) will return a larger number. If you apply the threshold test in getRank() (final double threshold = FastMath.max(m, n) * FastMath.ulp(singularValues&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;) )  prior to taking the square root, I believe this problem would be resolved. More importantly, philosophically, you test for zero variance. This is the appropriate test.&lt;/p&gt;

&lt;p&gt;Also, rank could be precalculated in the above loop. &lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1148714.&lt;/p&gt;

&lt;p&gt;This issue was fixed by changing SVD implementation according to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-611" title="A fast and stable SVD implementation from JAMA"&gt;&lt;del&gt;MATH-611&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
], resolution=Fixed, reporter=marisa, assignees=[], commentAuthors=[psteitz, gsteri1, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-464
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-464, created=Fri Dec 31 08:00:42 CET 2010, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Wed Aug 24 00:37:41 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Critical, summary=LegendreGaussIntegrator ignores defaultMaximalIterationCount and does 38 million iterations, link=https://issues.apache.org/jira/browse/MATH-464, description=&lt;p&gt;The following code results in count = 37801710 which is effectively an infinite loop for typical functions we are using&lt;br/&gt;
(in GeoGebra)&lt;/p&gt;

&lt;p&gt;The argument defaultMaximalIterationCount = 100 is being ignored&lt;/p&gt;

&lt;p&gt;This is the version we are using:&lt;br/&gt;
&lt;a href="http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java"&gt;http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    	LegendreGaussIntegrator gauss = new LegendreGaussIntegrator(5, 100);&lt;/p&gt;

&lt;p&gt;	try {
		double result = gauss.integrate(new testFun(), -10, 0.32462367623786328);
	} catch (Exception ee) {
		ee.printStackTrace();
	}&lt;/p&gt;



&lt;p&gt;class testFun implements UnivariateRealFunction {&lt;/p&gt;

&lt;p&gt;    public double value(double x) throws FunctionEvaluationException {
    	count ++;
        if (x&amp;gt;=0 &amp;amp;&amp;amp; x&amp;lt;=5) return 0.2; else return 0;
    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.&lt;/p&gt;

&lt;p&gt;The problem here is not with the iteration count.  In the example above, only 26 iterations are executed and the method returns the correct value.  What is causing the number of function evaluations to be so large is that each iteration involves multiple function evaluations.   I need to dig more deeply into the algorithm to determine what (if anything) the problem is, but what is causing the high number of function evaluations is the following&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// prepare next iteration
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; ratio = FastMath.min(4, FastMath.pow(delta / limit, 0.5 / abscissas.length));
n = FastMath.max((&lt;span class="code-object"&gt;int&lt;/span&gt;) (ratio * n), n + 1);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the example, delta / limit becomes large, causing n to increase rapidly.  As n increases, the number of function evaluations increases.&lt;/p&gt;
, &lt;p&gt;I am now thinking that this is not a bug, but a consequence of the fact that the integrand in the example is not at all well-approximated by a polynomial.  With a small-enough stepsize, the algorithm does converge, but requiring the large number of function evaluations above.  Here are some stepsize values for the example and the associated absolute error:&lt;/p&gt;

&lt;p&gt;n 8 error 0.05738431110184819&lt;br/&gt;
n 28 error 0.027423287634332688&lt;br/&gt;
n 100 error 8.62162720248888E-5&lt;br/&gt;
n 249 error 5.308122631570711E-4&lt;br/&gt;
n 650 error 4.3582615516528367E-4&lt;br/&gt;
n 1641 error 2.519984967931377E-4&lt;br/&gt;
n 3829 error 5.838605030586419E-5&lt;br/&gt;
...&lt;br/&gt;
 n 1102593 error 6.71416523906343E-8&lt;/p&gt;

&lt;p&gt;The last entry is from the last (26th) iteration.  I haven't verified the rationale for the updating formula for n above, but it does appear warranted in this case to increase n quickly as large n (= small stepsize) is required to get a decent estimate of the integral using Gaussian quadrature.&lt;/p&gt;
, &lt;p&gt;Perhaps we should also provide higher order formulas, using either a fixed set of precomputed constants or a way to compute the coefficients for any order.&lt;/p&gt;
, &lt;p&gt;Moving to 3.0.  I don't think this is a bug, but points to a couple of possible enhancements:&lt;/p&gt;

&lt;p&gt;1) higher order formulas (+0 on this suggestion from Luc - IMO the example and others like it are not suitable for Legendre-Gauss)&lt;br/&gt;
2) bound on the number of function evaluations (I vaguely recall us talking about this elsewhere, but can't find the reference.  If anyone else can, pls add.)&lt;/p&gt;
, &lt;p&gt;We restarted a thread about this a few days after the previous comment on this issue.&lt;br/&gt;
The thread can be read here: &lt;a href="http://markmail.org/thread/rnazrggnnuehz4qv"&gt;http://markmail.org/thread/rnazrggnnuehz4qv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think adding maxEvaluations while still preserving the existing maxIterations would be fine.&lt;/p&gt;
, &lt;p&gt;Coming back to this issue.&lt;/p&gt;

&lt;p&gt;I would propose to follow the same pattern we used for root solvers: adding a maxEval parameter in the top level integrate interface declaration. So we would have the same kind of configuration, with tolerances set at integrator/solver level and maxEval and function pointer passed at integrate/solve method call.&lt;/p&gt;

&lt;p&gt;Since we are just in the phase we change interfaces, this would be a good time to add this parameter.&lt;/p&gt;

&lt;p&gt;Does this seems reasonable ?&lt;/p&gt;
, &lt;p&gt;+1 for your suggestion, Luc.  Lets try to get this into 3.0.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1160914.&lt;/p&gt;

&lt;p&gt;The API of the integrators has been changed for consistency with solvers API. Now the main convergence parameters are set in the constructor and remain fixed, but a maximal number of function evaluation must be provided at each call to the integration method.&lt;/p&gt;

&lt;p&gt;Thanks for the report&lt;/p&gt;
], resolution=Fixed, reporter=murkle, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=180, timeSpent=null]
2016-01-13 22:20:32,514 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-453
2016-01-13 22:20:32,530 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-453, created=Mon Dec 06 03:01:08 CET 2010, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Mon Dec 06 13:53:56 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function, link=https://issues.apache.org/jira/browse/MATH-453, description=&lt;p&gt;RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function.&lt;/p&gt;

&lt;p&gt;As this explains how to recode deprecated method calls, it ought to be corrected before release.&lt;/p&gt;, comments=[&lt;p&gt;Removed references to the &lt;tt&gt;analysis.function&lt;/tt&gt; package (revision 1042610).&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[erans], commentAuthors=[erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,530 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-434
2016-01-13 22:20:32,530 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-434, created=Sun Nov 07 04:55:32 CET 2010, updated=Sat Mar 24 17:16:29 CET 2012, resolved=Sat Apr 09 21:21:59 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=SimplexSolver returns unfeasible solution, link=https://issues.apache.org/jira/browse/MATH-434, description=&lt;p&gt;The SimplexSolver is returning an unfeasible solution:&lt;/p&gt;

&lt;p&gt;import java.util.ArrayList;&lt;br/&gt;
import java.text.DecimalFormat;&lt;br/&gt;
import org.apache.commons.math.linear.ArrayRealVector;&lt;br/&gt;
import org.apache.commons.math.optimization.GoalType;&lt;br/&gt;
import org.apache.commons.math.optimization.OptimizationException;&lt;br/&gt;
import org.apache.commons.math.optimization.linear.*;&lt;/p&gt;

&lt;p&gt;public class SimplexSolverBug {&lt;/p&gt;

&lt;p&gt;    public static void main(String[] args) throws OptimizationException {&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction c = new LinearObjectiveFunction(new double[]{0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d}, 0.0d);&lt;/p&gt;

&lt;p&gt;        ArrayList&amp;lt;LinearConstraint&amp;gt; cnsts = new ArrayList&amp;lt;LinearConstraint&amp;gt;(5);&lt;br/&gt;
        LinearConstraint cnst;&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, -0.1d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.EQ, -0.1d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, -1e-18d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 1.0d, 0.0d, -0.0128588d, 1e-5d}, Relationship.EQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 0.0d, 1.0d, 1e-5d, -0.0128586d}, Relationship.EQ, 1e-10d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, -1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, -1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, 1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;/p&gt;

&lt;p&gt;        DecimalFormat df = new java.text.DecimalFormat("0.#####E0");&lt;/p&gt;

&lt;p&gt;        System.out.println("Constraints:");&lt;br/&gt;
        for(LinearConstraint con : cnsts) {
            for (int i = 0; i &amp;lt; con.getCoefficients().getDimension(); ++i)
                System.out.print(df.format(con.getCoefficients().getData()[i]) + " ");
            System.out.println(con.getRelationship() + " " + con.getValue());
        }&lt;/p&gt;

&lt;p&gt;        SimplexSolver simplex = new SimplexSolver(1e-7);&lt;br/&gt;
        double[] sol = simplex.optimize(c, cnsts, GoalType.MINIMIZE, false).getPointRef();&lt;br/&gt;
        System.out.println("Solution:\n" + new ArrayRealVector(sol));&lt;br/&gt;
        System.out.println("Second constraint is violated!");&lt;br/&gt;
    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;It's an odd problem, but something I ran across.  I tracked the problem to the getPivotRow routine in SimplexSolver.  It was choosing a pivot that resulted in a negative right-hand-side.  I recommend a fix by replacing&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
                ...&lt;br/&gt;
with&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;br/&gt;
                ...&lt;/p&gt;

&lt;p&gt;I believe this would be more appropriate (and at least resolves this particular problem).&lt;/p&gt;

&lt;p&gt;Also, you may want to consider making a change in getPivotColumn to replace&lt;br/&gt;
            ...&lt;br/&gt;
            if (MathUtils.compareTo(tableau.getEntry(0, i), minValue, epsilon) &amp;lt; 0) {&lt;br/&gt;
            ...&lt;br/&gt;
with&lt;br/&gt;
            ...&lt;br/&gt;
            if (tableau.getEntry(0, i) &amp;lt; minValue) &lt;br/&gt;
            ...&lt;br/&gt;
because I don't see the point of biasing earlier columns when multiple entries are within epsilon of each other.  Why not pick the absolute smallest.  I don't know that any problem can result from doing it the other way, but the latter may be a safer bet.&lt;/p&gt;

&lt;p&gt;VERY IMPORTANT: I discovered another bug that occurs when not restricting to non-negatives.  In SimplexTableu::getSolution(), &lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) &lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = 0;&lt;br/&gt;
          ...&lt;br/&gt;
should be&lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) {&lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = (restrictToNonNegative ? 0 : -mostNegative);&lt;br/&gt;
          ...&lt;br/&gt;
If necessary, I can give an example of where this bug causes a problem, but it should be fairly obvious why this was wrong.&lt;/p&gt;, comments=[&lt;p&gt;My original suggested fix had a potential for overflow errors (since minRatio is initialized to Double.MAX_VALUE).  Also, I added another suggestion and pointed out another bug which leads to invalid solutions.&lt;/p&gt;
, &lt;p&gt;Could you attach unit tests that demonstrate each problem?  Thank you.&lt;/p&gt;
, &lt;p&gt;I'll try to send some examples soon.  I'm noticing more problems with the right-hand-side going negative and want to cover all bases (as much as possible).&lt;/p&gt;
, &lt;p&gt;Code, and resulting output, that illustrates issues with the SimplexSolver.&lt;/p&gt;
, &lt;p&gt;Pushing out to 3.0.&lt;/p&gt;
, &lt;p&gt;Hey, sorry I took so long to look at this.  I've had very little time and am not working on this stuff anymore.  I'm honestly not going to be able to look at this stuff much moving forward, so hopefully there's a Commons Math contributor that can act as a reviewer.&lt;/p&gt;

&lt;p&gt;When you say it's choosing a pivot with a negative RHS, I'm assuming that means it's not within the epsilon?&lt;br/&gt;
Why would it be more appropriate to divide by the entry?  I'm not sure I see why you'd want to use a bigger epsilon when the entry is 0.1 and a smaller epsilon when the entry is 10.  Maybe we should just make the default epsilon smaller?  I'm no expert with floating point math so I'm not real sure how to set the epsilon and just made up a value.&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
...&lt;br/&gt;
with&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;/p&gt;
, &lt;p&gt;Attached a patch for the reported problems.&lt;br/&gt;
The problems can be split into two groups:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;wrong solution calculation with negative&lt;br/&gt;
   variables&lt;/li&gt;
	&lt;li&gt;failing to select an appropriate pivot&lt;br/&gt;
   row when values are below a given &lt;br/&gt;
   epsilon&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch addresses both problems:&lt;/p&gt;

&lt;p&gt; 1. fix in SimplexTableau.getSolution()&lt;br/&gt;
 2. use BigReal for arbitrary precision  &lt;br/&gt;
    support when selecting the pivot row&lt;/p&gt;

&lt;p&gt;Additionally, 4 test cases are included, as well as a minor typo fix for a method name.&lt;/p&gt;

&lt;p&gt;The fixed epsilon is also used in some other places of the code, this may also create problems under certain circumstances. So if this patch is accepted, the other places could also be adapted.&lt;/p&gt;
, &lt;p&gt;Thanks Thomas.&lt;/p&gt;

&lt;p&gt;I had a look at the patch. I'm not a big fan of using BigReal, mainly when we don't specify a scale and we don't link it to the choice for epsilon. Also reading back Ben comments, I wonder if we should not replace epsilon by an integer number of ulps with a default set to a very small value (say something like 10 ulps).&lt;/p&gt;

&lt;p&gt;What problem did you see in the accuracy of the variables to use BigReal ?&lt;/p&gt;
, &lt;p&gt;Hi Luc,&lt;/p&gt;

&lt;p&gt;my initial idea was to use an epsilon that is adjusted to the magnitude of the respective value used for comparison. To be honest, I was not aware of &lt;span class="error"&gt;&amp;#91;Math,FastMath&amp;#93;&lt;/span&gt;.ulp, therefore I went with BigReal/BigDecimal to circumvent the problem in another way (by using an arbitrary precision datatype). After reading your comment, I investigated more into the problem, e.g. using &lt;a href="http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm"&gt;http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm&lt;/a&gt;, and addressed it (hopefully correct) in the way you proposed.&lt;/p&gt;

&lt;p&gt;Though, I had to split up the epsilon test into two categories:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;general comparison of floating-point values: using ulp, as values can be arbitrarily small&lt;/li&gt;
	&lt;li&gt;algorithm convergence check: using a standard epsilon, as the algorithm may not converge due to limited precision of&lt;br/&gt;
    the double datatype otherwise&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Please find attached my updated patch, any comments are welcome (e.g. I was unsure whether to expose the maxUlps parameter in the constructor, or to use a generic comparison epsilon, e.g. using FastMath.ulp(1d) instead of one adjusted to the current value in question).&lt;/p&gt;
, &lt;p&gt;updated patch, incorporating comments from luc&lt;/p&gt;
, &lt;p&gt;&lt;span class="error"&gt;&amp;#91;Pardon the possibly nave questions.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In "SimplexTableau":&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Why not use directly "equals(double, double, int)" from "MathUtils" instead of computing an epsilon with "getEpsilon"?&lt;/li&gt;
	&lt;li&gt;Why is the "isOptimal" method not using the adjusted "epsilon" (at line 385)?&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;hmm, I feel a bit stupid now, as I have re-implemented MathUtils.equals(double, double, int) but in a mediocre way. So all calls to getEpsilon should be replaced with the equivalent MathUtils.equals.&lt;/p&gt;

&lt;p&gt;for the isOptimal:&lt;/p&gt;

&lt;p&gt;the idea was to have a user-defined threshold for the convergence criteria, which defaults to the original value of 1e-6. Using the same adjusted epsilon would possibly lead to more iterations as before. As the feasibility check in SimplexSolver.solvePhase1 has to use a static epsilon for convergence reasons, I thought to use the same epsilon in isOptimal makes sense for symmetry reasons (use the same epsilon to check for convergence /feasibility).&lt;/p&gt;

&lt;p&gt;But it's good that you raise these points, because I was hesitating myself what is the best way to go forward, as I am also not considering myself a floating-point expert. I am mainly interested in the simplex algorithm, that's why I have chosen to provide a patch for this (very nice) implementation of it.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1090656.&lt;br/&gt;
Path applied with a very small change: adding the maxUlps parameter to the detailed constructor.&lt;/p&gt;

&lt;p&gt;Thanks for the report and thanks for the patch.&lt;/p&gt;
, &lt;p&gt;Thanks for accepting the patch. The comparison using maxUlps has already been adapted according to &lt;a href="https://issues.apache.org/jira/browse/MATH-557" title="add a compareTo method to MathUtils that use a number of ulps for equality tolerance"&gt;&lt;del&gt;MATH-557&lt;/del&gt;&lt;/a&gt;, but it was missing for SimplexTableau. The cleanup patch fixes this and also renames the test names for similarity.&lt;/p&gt;
, &lt;p&gt;Cleanup patch applied.&lt;/p&gt;

&lt;p&gt;thanks again&lt;/p&gt;
], resolution=Fixed, reporter=wmwitzel, assignees=[], commentAuthors=[wmwitzel, erans, psteitz, bmccann, tn, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,530 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-429
2016-01-13 22:20:32,530 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-429, created=Fri Oct 22 10:01:54 CEST 2010, updated=Wed Mar 23 21:25:46 CET 2011, resolved=Sat Oct 23 21:35:26 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Blocker, summary=KMeansPlusPlusClusterer breaks by division by zero, link=https://issues.apache.org/jira/browse/MATH-429, description=&lt;p&gt;For a certain space, KMeansPlusPlusClusterer  breaks. This is a blocker because this space occurs in our domain. &lt;/p&gt;, comments=[&lt;p&gt;The testcase which breaks KMeansPlusPlusClusterer&lt;/p&gt;
, &lt;p&gt;You have encountered one classical problem with k-means: at some stage (here at the first iteration), one of the clusters becomes empty.&lt;br/&gt;
This case is currently no handled by commons-math (which is a bug, so we have to fix it).&lt;br/&gt;
When a cluster is empty, a new centroid must be defined from the other clusters. There are different strategies:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;take the point farthest from any cluster&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest distance variance&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest number of points&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;My prefered choice would be 2, what do other people think ?&lt;/p&gt;
, &lt;p&gt;How about make it configurable?  Take a look at how the Mallet project did it:&lt;/p&gt;

&lt;p&gt;&lt;a href="http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html"&gt;http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By the way, I have suggested that they try to enter the Incubator here at the ASF and they seem somewhat receptive to the idea!&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1026666 for branche 2.X and as of r1026667 for trunk.&lt;br/&gt;
Users can now choose among four different strategies to deal with empty clusters:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;split the cluster with largest distance variance,&lt;/li&gt;
	&lt;li&gt;split the cluster with largest number of points,&lt;/li&gt;
	&lt;li&gt;create a cluster around the point farthest from its centroid,&lt;/li&gt;
	&lt;li&gt;generate an error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The default is to split according to largest variance.&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erikvaningen, assignees=[], commentAuthors=[erikvaningen, luc, jwcarman], timeEstimate=180, timeSpent=null]
2016-01-13 22:20:32,608 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-421
2016-01-13 22:20:32,608 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-421, created=Wed Sep 29 20:24:56 CEST 2010, updated=Wed Mar 23 21:23:12 CET 2011, resolved=Wed Sep 29 21:51:49 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=restarting an ODE solver that has been stopped by an event doesn't work, link=https://issues.apache.org/jira/browse/MATH-421, description=&lt;p&gt;If an ODE solver is setup with an EventHandler that return STOP when the even is triggered, the integrators stops (which is exactly the expected behavior).&lt;br/&gt;
If however the user want to restart the solver from the final state reached at the event with the same configuration (expecting the event to be triggered again at a later time), then the integrator may fail to start. It can get stuck at the previous event.&lt;/p&gt;

&lt;p&gt;The occurrence of the bug depends on the residual sign of the g function which is not exactly 0, it depends on the convergence of the first event.&lt;/p&gt;

&lt;p&gt;As this use case is fairly general, event occurring less than epsilon after the solver start in the first step should be ignored, where epsilon is the convergence threshold of the event. The sign of the g function should be evaluated after this initial ignore zone, not exactly at beginning (if there are no event at the very beginning g(t0) and g(t0+epsilon) have the same sign, so this does not hurt ; if there is an event at the very beginning, g(t0) and g(t0+epsilon) have opposite signs and we want to start with the second one. Of course, the sign of epsilon depend on the integration direction (forward or backward).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository, as of r1002827 for branch 2.X and 1002829 for trunk (3.0)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,623 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-414
2016-01-13 22:20:32,623 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-414, created=Tue Aug 31 13:01:44 CEST 2010, updated=Wed Mar 23 21:20:43 CET 2011, resolved=Tue Nov 30 12:57:23 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=ConvergenceException in NormalDistributionImpl.cumulativeProbability(), link=https://issues.apache.org/jira/browse/MATH-414, description=&lt;p&gt;I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.&lt;br/&gt;
For instance in the following code:&lt;/p&gt;

&lt;p&gt;	@Test&lt;br/&gt;
	public void testCumulative() {&lt;br/&gt;
		final NormalDistribution nd = new NormalDistributionImpl();&lt;br/&gt;
		for (int i = 0; i &amp;lt; 500; i++) {&lt;br/&gt;
			final double val = Math.exp&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/information.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt;;&lt;br/&gt;
			try {
				System.out.println("val = " + val + " cumulative = " + nd.cumulativeProbability(val));
			} catch (MathException e) {
				e.printStackTrace();
				fail();
			}&lt;br/&gt;
		}&lt;br/&gt;
	}&lt;/p&gt;

&lt;p&gt;In version 2.0, I get no exception. &lt;/p&gt;

&lt;p&gt;My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.&lt;/p&gt;, comments=[&lt;p&gt;The difference between 2.0 and 2.1 is due to the changes in ContinuedFraction included in the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-282" title="ChiSquaredDistributionImpl.cumulativeProbability &amp;gt; 1"&gt;&lt;del&gt;MATH-282&lt;/del&gt;&lt;/a&gt;.  For very large values, continued fractions are diverging to NaN. The suggested fix will work, but at this point, I wonder if we should just move the top-coding out of the catch - i.e., test the arguments and return 0 or 1 for extreme values without attempting the approximation.&lt;/p&gt;
, &lt;p&gt;I am leaning toward adding top-coding outside of the catch.  Based on the inequality p(Z &amp;gt; t) &amp;lt; exp(-t^2/2) derived in &lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; and Double.MIN_VALUE  = 2^-1074, I get that tail probabilities are not distinguishable from 0 for |t| &amp;gt; 39, so I propose that we top-code at 40 outside the catch.  Appreciate others checking my arithmetic.&lt;/p&gt;

&lt;p&gt;&lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href="http://www.johndcook.com/normalbounds.pdf"&gt;http://www.johndcook.com/normalbounds.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Your suggestion seems good to me.&lt;br/&gt;
I've check exp(-t^2/2) becomes lower than Double.MIN_VALUE/2 (i.e. rounds to 0) when |t|&amp;gt; 38.604&lt;/p&gt;
, &lt;p&gt;Fixed in r1040471&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=gustav.ryd, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=120, timeSpent=null]
2016-01-13 22:20:32,623 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-411
2016-01-13 22:20:32,623 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-411, created=Sun Aug 29 00:14:32 CEST 2010, updated=Wed Mar 23 21:20:06 CET 2011, resolved=Mon Sep 13 04:04:01 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression newSampleData methods inconsistently create / omit intercepts, link=https://issues.apache.org/jira/browse/MATH-411, description=&lt;p&gt;The newSampleData(double[], nrows, ncols) method used in the unit tests adds a unitary column to the design matrix, resulting in an intercept term being estimated among the regression parameters.  The other newSampleData methods do not do this, forcing users to add the column of "1"s to estimate models with intercept.  Behavior should be consistent and users should not have to add the column.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r993574.  Modified multiple regression newSample methods to ensure that by default in all cases, regression models are estimated with intercept terms.  Prior to the fix for this issue,  newXSampleData(double[][]), newSampleData(double[], double[][]) and newSampleData(double[], double[][], double[][]) all required columns of "1's  to be inserted into the x[][] arrays to create a model with an intercept term;while newSampleData(double[], int, int) created a model including an intercept term without requiring the unitary column.  All methods have  been changed to eliminate the need for users to add unitary columns to specify regression models.&lt;/p&gt;

&lt;p&gt;Leaving open until &lt;a href="https://issues.apache.org/jira/browse/MATH-409" title="Multiple Regression API should allow specification of whether or not to estimate intercept term"&gt;&lt;del&gt;MATH-409&lt;/del&gt;&lt;/a&gt; is resolved. &lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,623 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-409
2016-01-13 22:20:32,623 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-409, created=Tue Aug 24 11:55:32 CEST 2010, updated=Wed Mar 23 21:19:13 CET 2011, resolved=Mon Sep 13 04:02:43 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression API should allow specification of whether or not to estimate intercept term, link=https://issues.apache.org/jira/browse/MATH-409, description=&lt;p&gt;The OLS and GLS regression APIs should support estimating models including intercepts using design matrices including only variable data.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r996404 (both trunk and 2.x branch)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,623 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-408
2016-01-13 22:20:32,639 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-408, created=Mon Aug 23 05:11:23 CEST 2010, updated=Wed Mar 23 21:18:48 CET 2011, resolved=Sun Dec 12 22:49:44 CET 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=GLSMultipleLinearRegression has no nontrivial validation tests, link=https://issues.apache.org/jira/browse/MATH-408, description=&lt;p&gt;There are no non-trivial tests verifying the computations for GLSMultipleLinearRegression.  Tests verifying computations against analytically determined models, R or some other reference package / datasets should be added to ensure that the statistics reported by this class are valid.&lt;/p&gt;, comments=[&lt;p&gt;Added a non-trivial test in r1044935.  While still not really a full verification test, it does at least verify that the GLS impl provided does better than OLS for models with error structure conforming to its covariance matrix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,639 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-407
2016-01-13 22:20:32,639 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-407, created=Mon Aug 23 05:07:08 CEST 2010, updated=Wed Mar 23 21:18:29 CET 2011, resolved=Mon Sep 20 03:57:59 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Documentation improvements for multiple regression classes, link=https://issues.apache.org/jira/browse/MATH-407, description=&lt;p&gt;The user guide examples showing how to set up and estimate linear models using OLS and GLS multiple regression need to be updated to reflect changes in the API.  The javadoc for these classes and user guide descriptions also need to be improved to make it clear how to estimate a model with an intercept term.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r998761&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,639 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-406
2016-01-13 22:20:32,639 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-406, created=Sat Aug 14 23:57:56 CEST 2010, updated=Wed Mar 23 21:18:04 CET 2011, resolved=Sun Aug 15 00:02:03 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Wrong weight handling in Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-406, description=&lt;p&gt;A comparison with a Fortran version of Levenberg-Marquardt reveals that when observations have different weights, the 2.1 version reaches a value of the function which does not necessary correspond to the minimum&lt;/p&gt;, comments=[&lt;p&gt;Correction patch.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,639 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-405
2016-01-13 22:20:32,639 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-405, created=Wed Aug 11 15:24:39 CEST 2010, updated=Wed Mar 23 21:17:42 CET 2011, resolved=Wed Aug 11 15:46:55 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Inconsistent result from Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-405, description=&lt;p&gt;Levenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost&lt;/p&gt;, comments=[&lt;p&gt;Correction patch&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,654 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-404
2016-01-13 22:20:32,654 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-404, created=Mon Aug 09 13:44:12 CEST 2010, updated=Sat Mar 24 17:17:04 CET 2012, resolved=Mon Aug 30 15:53:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Confusing interface for "LevenbergMarquardtOptimizer", link=https://issues.apache.org/jira/browse/MATH-404, description=&lt;p&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; which in turn implements &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt;. That interface mandates methods for setting and getting a &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;.&lt;br/&gt;
In v2.1, however, that checker is never used! The convergence check is performed using parameters specific to the Levenberg-Marquardt algorithm. Such circumvention of the superclass interface is confusing and leads to totally unexpected behaviour (such as changing the values of the thresholds of the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; being ineffective).&lt;br/&gt;
In the development version, the default constructor of &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; sets the the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; field to "null" and when such is the case, the behaviour is as in v2.1. Although it is documented, this is still confusing since it is impossible to use &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; through its &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt; interface: When using the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;, one does not know what parameters to use in order to reproduce the results obtained with the LM-specific convergence check (i.e. how to reproduce the result from v2.1).&lt;br/&gt;
Unless I'm missing something, I think that there should be an LM-specific implementation of &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; that, when given the usual relative and absolute thresholds, can perform a check that will give the same result as the currently specific check (when the "checker" field is "null").&lt;/p&gt;, comments=[&lt;p&gt;The problem was identified and discussed as &lt;a href="https://issues.apache.org/jira/browse/MATH-362" title="LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it"&gt;&lt;del&gt;MATH-362&lt;/del&gt;&lt;/a&gt;. It was decided to let both convergence methods available.&lt;/p&gt;

&lt;p&gt;The reason there are two different way is that the Levenberg-Marquardt implementation originally came from Netlib and I kept the way it behaved. I think the general interface with the new generic convergence was set up later and at that time I forgot to implement it properly, so the settings were ignored.&lt;/p&gt;

&lt;p&gt;Reporter of issue 362 explicitly asked to keep the ortho-tolerance setting and this setting does not fit with the general scheme.&lt;/p&gt;
, &lt;p&gt;Sorry I hadn't followed that other report.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was decided to let both convergence methods available. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is &lt;tt&gt;null&lt;/tt&gt; or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;

&lt;p&gt;As explained above, from an OOP point-of-view, it is surprising that a class completely circumvents its base class interface.&lt;br/&gt;
At least one of the following is wrong:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; has a second interface for convergence checking&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; defines the interface for  convergence checking&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; does not fit with the general scheme.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;br/&gt;
Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;

&lt;p&gt;If it is really impossible to fit LM within the hierarchy it currently belongs to, then it should not belong to it, since one cannot leverage the advantages of "interface programming" anyways.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is null or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or LevenbergMarquardtOptimizer needs to be changed and the orthogonality concept be finally discarded.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I know, and I am not happy with this. However, I don't want LevenbergMarquardtOptimizer to be special. It &lt;em&gt;must&lt;/em&gt; fit. We can take the opportunity of a 3.0 major release to fix this problem too, with some incompatible changes. What would you propose for this ?&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;What would you propose for this ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don't know.&lt;/p&gt;

&lt;p&gt;However, it seems that this "non-fitting checker" case is not isolated. I wanted to replace the original check in "BrentOptimizer" (package "optimization.univariate") by a call to an appropriate subclass of "RealConvergenceChecker", but here too there are more values to be considered than those stored in a pair of "RealPointValuePair". The check needs&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the "current" point&lt;/li&gt;
	&lt;li&gt;the points at both interval ends&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;but it does not use the "previous" point.&lt;/p&gt;

&lt;p&gt;So it seems that this also does not fit with the "converged" method of the "RealConvergenceChecker" interface.&lt;/p&gt;

&lt;p&gt;At first sight, I'd say that there should be a more general "ConvergenceChecker" (not existing yet) interface. Maybe using generics...&lt;/p&gt;
, &lt;p&gt;I'm trying to define a more general "ConvergenceChecker" interface. This is an incompatible change.&lt;/p&gt;
, &lt;p&gt;Final resolution is delegated to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-413"&gt;MATH-413&lt;/a&gt;.&lt;/p&gt;
], resolution=Unknown, reporter=erans, assignees=[erans], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,654 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-395
2016-01-13 22:20:32,654 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-395, created=Sun Jul 25 23:26:33 CEST 2010, updated=Wed Mar 23 21:14:58 CET 2011, resolved=Wed Jul 28 14:11:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Bugs in "BrentOptimizer", link=https://issues.apache.org/jira/browse/MATH-395, description=&lt;p&gt;I apologize for having provided a buggy implementation of Brent's optimization algorithm (class "BrentOptimizer" in package "optimization.univariate").&lt;br/&gt;
The unit tests didn't show that there was something wrong, although (from the "changes.xml" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.&lt;br/&gt;
Comparing with an implementation in Python, I could figure out the fixes. I'll modify "BrentOptimizer" and add a test. I also propose to change the name of the unit test class from "BrentMinimizerTest" to "BrentOptimizerTest".&lt;/p&gt;, comments=[&lt;p&gt;Bugs corrected in revision 979257.&lt;br/&gt;
Not resolving yet because the implementation still does not behave as the Python one. I've added a unit test that indicates the discrepancies (with "XXX" markers).&lt;/p&gt;
, &lt;p&gt;Last bug fixed in revision 980032.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;This revision also contains the modifications due to the changes in &amp;quot;AbstractUnivariateRealOptimizer&amp;quot;.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The test comparing with Python has been removed because a tracing of the execution paths (in Python and Java) showed that the remaining discrepancies were due to different values being used for the "golden ratio" constant.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[erans], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,654 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-392
2016-01-13 22:20:32,654 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-392, created=Wed Jul 21 20:43:10 CEST 2010, updated=Wed Mar 23 21:13:58 CET 2011, resolved=Sun Aug 22 15:16:29 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=calculateYVariance in OLS/GLSMultipleLinearRegression uses residuals not Y vars, link=https://issues.apache.org/jira/browse/MATH-392, description=&lt;p&gt;Implementation of OLS/GLSMultipleLinearRegression is:&lt;br/&gt;
@Override&lt;br/&gt;
173        protected double calculateYVariance() {
174            RealVector residuals = calculateResiduals();
175            return residuals.dotProduct(residuals) /
176                   (X.getRowDimension() - X.getColumnDimension());
177        }&lt;/p&gt;

&lt;p&gt;This gives variance of residuals not variance of the dependent (Y) variable as the documentation suggests.&lt;/p&gt;, comments=[&lt;p&gt;Thank you for reporting this.  Patches welcome!&lt;/p&gt;
, &lt;p&gt;Can't test a patch as I'm not able to build current repository version:&lt;br/&gt;
math/src/test/java/org/apache/commons/math/optimization/univariate/BrentOptimizerTest.java:&lt;span class="error"&gt;&amp;#91;28,39&amp;#93;&lt;/span&gt; cannot find symbol&lt;br/&gt;
symbol  : class SincFunction&lt;/p&gt;

&lt;p&gt;Implementation for both GLS/OLS:&lt;/p&gt;

&lt;p&gt;protected double calculateYVariance() {
    return new Variance().evaluate(Y);
}&lt;/p&gt;
, &lt;p&gt;There was an error in a file committed this afternoon. It should be OK now.&lt;/p&gt;
, &lt;p&gt;corrected implementations of calculateYVariance() for OLS/GLSMultipleRegression&lt;/p&gt;

&lt;p&gt;added unit tests for both calculateYVariance implementations&lt;/p&gt;

&lt;p&gt;fixed AbstractMultipleRegression.estimateRegressionParametersStandardErrors() to use residuals &lt;/p&gt;
, &lt;p&gt;Fixed in 987897.   I added calcluate/estimateErrorVariance methods to return what was previously incorrectly reported as "Y variance."&lt;br/&gt;
Thanks for the patch!&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=markdevaney, assignees=[], commentAuthors=[psteitz, markdevaney, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,654 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-391
2016-01-13 22:20:32,670 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-391, created=Wed Jul 21 10:57:46 CEST 2010, updated=Wed Mar 23 21:13:27 CET 2011, resolved=Sun Oct 03 18:43:11 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Inconsistent behaviour of constructors in ArrayRealVector class, link=https://issues.apache.org/jira/browse/MATH-391, description=&lt;p&gt;ArrayRealVector(double[] d) allows to construct a zero-length vector, but ArrayRealVector(double[] d, boolean copyArray) doesn't. Both should allow this as zero-length vectors are mathematically well-defined objects and they are useful boundary cases in many algorithms.&lt;/p&gt;

&lt;p&gt;This breaks some arithmetic operators (addition) on zero-length real vectors which worked in 2.0 but don't work in 2.1&lt;/p&gt;, comments=[&lt;p&gt;I agree that the code should be consistent.  I agree as well that a zero-dimensional vector is legit.   Can anyone explain why ArrayRealVector(double[] d, boolean copyArray) requires positive length?&lt;/p&gt;
, &lt;p&gt;Most probably my bad ...&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1003993 for barnch 2.X and r1003994 for trunk.&lt;br/&gt;
Note that the same problem occurred also in ArrayFieldVector but the fix is different. For Field-based vectors, we need to get the field, so either we use a non-empty array and retrieve the field from the first array element or we add a parameter for the field and allow the array to be empty. The two choices are now possible, as new constructors have been added and the javadoc updated to explain this behavior.&lt;br/&gt;
Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,670 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-390
2016-01-13 22:20:32,670 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-390, created=Wed Jul 21 00:47:21 CEST 2010, updated=Wed Jul 21 01:32:12 CEST 2010, resolved=Wed Jul 21 01:32:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Major, summary=Simplex Solver is very inaccurate on a large problem, even a very low value for epsilon, link=https://issues.apache.org/jira/browse/MATH-390, description=&lt;p&gt;I'm currently playing with a program for solving a rather simple chess puzzle. The goal is to place 12 knights on a 8x8 board, such that each field is either attacked by a knight, or contains a knight. To solve this problem (and different variants) I want to use a handcrafted Branch and Bound algorithm that uses Linear Programming to calculate an upperbound on the number of fields that can be covered by a certain amount of knights.&lt;/p&gt;

&lt;p&gt;The idea is to create variables for each field that has to be covered, and to create variables for each field to contain a knight. A cover variable can only become positive if a corresponding knight variable for an adjacent field is also positive, there is a limit to the amount of knights we may place (so the sum of all knight variables cannot be larger than 12) and the cover variables cannot be larger than one. Also, only the cover variables have a coefficient of one in the objective function, all other variables have zero. Because we want to cover the entire board our goal will be to maximize the objective function, since we want to maximize the number of fields that are covered.&lt;/p&gt;

&lt;p&gt;Since a basic chessboard has 64 fields and since it is possible to cover the chessboard with 12 knights, we know there is an integer solution that has value 64. Since we are solving a relaxed variant of the problem, the value should be at least 64. However, when I use the Simplex Solver, I get a value of around 58.6, which is much too low. Even when I relax the constraints in such a fashion that 64 knights may be placed on the board, the solution value remains the same. I've lowered the value of epsilon as much as I can and it still gives the incorrect value. What makes it worse is that the calculation is totally useless as an upperbound (if the value would have been around 70, it would have been an upperbound at least).&lt;/p&gt;

&lt;p&gt;I've heard that using the revised simplex method is a lot better with respect to stacked errors, so I am not sure this is really a bug, or just a problem that arises when the two phase simplex method is used for large problems.&lt;/p&gt;

&lt;p&gt;I will try to attach a code example that implements the problem (but possibly isn't that readable).&lt;/p&gt;, comments=[&lt;p&gt;Example of the 8x8 Knight covering Chess problem. The objective value should at least be 64, but it is around 59.&lt;/p&gt;
, &lt;p&gt;Hmm, it seems I made a programming mistake in the type of the relationship: I used an equality where I should have used a greater-equals. I created a much nicer version of the example, which actually works. Feel free to use it for an example or something.&lt;/p&gt;

&lt;p&gt;My bad, I will close the issue.&lt;/p&gt;
, &lt;p&gt;The correct and more readable example, which actually works.&lt;/p&gt;
, &lt;p&gt;It seems I made a programming error. I included a correct example to solve the problem.&lt;/p&gt;
], resolution=Fixed, reporter=pcbouman, assignees=[], commentAuthors=[pcbouman], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,670 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-380
2016-01-13 22:20:32,686 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-380, created=Thu Jun 24 18:47:54 CEST 2010, updated=Sat Mar 24 17:16:33 CET 2012, resolved=Sat Oct 01 15:54:20 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Minor, summary=Need to (re)initialize dYdY0 for multiple integrate with FirstOrderIntegratorWithJacobians, link=https://issues.apache.org/jira/browse/MATH-380, description=&lt;p&gt;There is a lack in the method integrate of FirstOrderIntegratorWithJacobians. The jacobian DYDY0 can't be initialized by the user, unlike DFDP with DF0DP.&lt;br/&gt;
So, for several successive integrations, the matrix is reinitialized to identity and that is not what we might want.&lt;/p&gt;, comments=[&lt;p&gt;You are perfectly right.&lt;/p&gt;

&lt;p&gt;The FirstOrderIntegratorWithJacobians class is a brand new one and it clearly has some design flaws.&lt;br/&gt;
It will most probably be deprecated in its current form and replaced by a new mechanism, better integrated (sorry for the joke) with the standard ODE solvers.&lt;br/&gt;
The ability for user to set an initial value for dydy0 will be present in the new design, but will probably not be back-ported to the current one.&lt;br/&gt;
In the meantime, you can save the final value of the jacobian matrix dydy0 after first part of integration, which we could call dy1dy0 as it represents dy(t1)/dy(t0). Start the second part from t1 to t2 that will reset the initial matrix to identity and hence compute compute dy(t2)/dy(t1) and do the multiplication by yourself of the two matrices to really get what you need: dy(t2)/dy(t1) = dy(t2)/dy(t1) * dy(t1)/dy(t0).&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue &lt;/p&gt;
, &lt;p&gt;changing target fix version to 3.0.&lt;br/&gt;
Fixing this and several other problems requires a complete rewrite of the jacobians computation with ODE, and this rewrite implies user interfaces changes, so it cannot be fixed before 3.0.&lt;/p&gt;
, &lt;p&gt;A first attempt to implement Jacobians computation again in ODE has been committed in subversion repository as of r1175409.&lt;br/&gt;
This implementation still lacks the ability for step handlers to also retrieve the additional equations and their derivatives.&lt;br/&gt;
This implementation is based on the Orekit one described here: &lt;a href="https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf"&gt;https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1176745.&lt;/p&gt;
], resolution=Fixed, reporter=pparraud, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,686 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-377
2016-01-13 22:20:32,686 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-377, created=Thu Jun 17 11:06:03 CEST 2010, updated=Wed Mar 23 21:08:36 CET 2011, resolved=Sun Jul 25 21:49:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=weight versus sigma in AbstractLeastSquares, link=https://issues.apache.org/jira/browse/MATH-377, description=&lt;p&gt;In AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.&lt;/p&gt;

&lt;p&gt; Once corrected, getRMS() can even reduce&lt;/p&gt;

&lt;p&gt; public double getRMS() {return Math.sqrt(getChiSquare()/rows);}&lt;/p&gt;, comments=[&lt;p&gt;It is not clear to me exactly what is being computed in getChiSquare.  Step 0 is to get an actual definition in the javadoc for what it is trying to compute.  I agree it seems odd to be dividing by residual weights; but I could be missing the intent.&lt;/p&gt;
, &lt;p&gt;OK, let us define ChiSquare as the sum of the weighted square of the residual in order to be consistent with the rest of the definitions in that class.  That would also be consistent with what users expect from a parameter labeled 'weight' rather than 'sigma'.  If we reach consensus on that definition, I can take care of that issue.&lt;/p&gt;
, &lt;p&gt;I could be missing something, but I see no reason that the weighted sum of squared residuals computed here (after the proposed change) should in general follow a chi-square distribution or be related to a chi-square test statistic of any kind.   Why is it called chi-square?  Sorry if I am missing something simple here.&lt;/p&gt;
, &lt;p&gt;I guess if you assume normalliy distributed errors, it makes sense, so drop the last comment and I am +1 for the change (with definition added to the javadoc).&lt;/p&gt;
, &lt;p&gt;Indeed, the confusion comes from the fact that, in some textbooks, each residual is divided by 'sigma_i' which leads to a weight of 1/(sigma_i^2).  In CM, we adopted the terminology 'weight' without reference to sigma.  I will change the javadoc accordingly.&lt;/p&gt;
, &lt;p&gt;Patch to correct issue &lt;a href="https://issues.apache.org/jira/browse/MATH-377" title="weight versus sigma in AbstractLeastSquares"&gt;&lt;del&gt;MATH-377&lt;/del&gt;&lt;/a&gt;.  The change in getChiSquare let to a tiny update in one of Levenberg-Marquardt unit tests.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[psteitz, dimpbx, luc], timeEstimate=1, timeSpent=null]
2016-01-13 22:20:32,686 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-373
2016-01-13 22:20:32,686 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-373, created=Mon Jun 07 16:54:00 CEST 2010, updated=Sat Mar 24 17:16:56 CET 2012, resolved=Thu Sep 02 06:52:33 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=StatUtils.sum returns NaN for zero-length arrays, link=https://issues.apache.org/jira/browse/MATH-373, description=&lt;p&gt;StatUtils.sum returns NaN for zero-length arrays, which is:&lt;/p&gt;

&lt;p&gt;1. inconsistent with the mathematical notion of sum: in maths, sum_{i=0}^{N-1} a_i will be 0 for N=0. In particular, the identity&lt;br/&gt;
&lt;br/&gt;
sum_{i=0}^{k-1} a_i + sum_{i=k}^{N-1} = sum_{i=0}^{N-1}&lt;/p&gt;

&lt;p&gt;is broken for k = 0, since NaN + x = NaN, not x.&lt;/p&gt;

&lt;p&gt;2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition, as NaNs propagate silently and require manual tracing during the debugging)&lt;/p&gt;

&lt;p&gt;3. enforces "special case" handling when the user expects that the summed array can have a zero length.&lt;/p&gt;

&lt;p&gt;The correct behaviour is, in my opinion, to return 0.0, not NaN in the above case.&lt;/p&gt;, comments=[&lt;p&gt;I agree with the reasoning here, and we should do it this way in 3.0.  However it is an incompatible change to do in a point release, so I'm going to wait for more feed back from other developers before I make any changes to the current code.&lt;/p&gt;

&lt;p&gt;I'm thinking that adding a method to AbstractUnivariateStatistic that looks like:&lt;br/&gt;
   protected boolean test( final double[] values,  final int begin,   final int length, final boolean allowEmpty)&lt;/p&gt;

&lt;p&gt;that would have the test:&lt;br/&gt;
   if(length == 0 &amp;amp;&amp;amp; !allowEmpty)&lt;br/&gt;
        return false;&lt;/p&gt;

&lt;p&gt;The current test method can call the new one with allowEmpty=false for backwards compatibility.  Then we can decide on which statistics should have a zero value on the empty set.&lt;/p&gt;
, &lt;p&gt;The consensus of the commons-math developers is that, since the current behavior is documented in 2.x, that this will have to wait for 3.0.  Fixing this in 2.x would introduce a too large incompatibility change to include in 2.x.&lt;/p&gt;

&lt;p&gt;I can attach a patch against 2.x that fixes this, as long as anybody using the patch understands that it isn't supported.&lt;/p&gt;

, &lt;p&gt;Possibly crazy idea: &lt;/p&gt;

&lt;p&gt;if Math 3.0 is going to change package names (which may be necessary), one could introduce the fix using a math3 package name?&lt;/p&gt;
, &lt;p&gt;IIRC, changing the package name had been suggested and discussed for 2.0.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;One argument is that, to be consistent,  you&amp;#39;d have to change the name at every major release...&amp;#93;&lt;/span&gt;&lt;/p&gt;
, &lt;p&gt;Speaking as a maintainer of client code which uses ACM, I'd rather cope with occasional incompatibilities in the same packages, than have to change ALL my client code to keep up with the package name changes after every release. A reason to change the package name would be if you wanted to use the old and new version side by side, but that would not be a common usage pattern for ACM, I think.&lt;/p&gt;
, &lt;p&gt;As Gilles mentioned, changing the package name for commons-math was discussed and voted on for 2.x.  The result of the vote was to keep the package name, since commons-math won't usually be provided by a third party library.  Since nothing much has changed, I can't see that commons-math would change it's package for version 3.0.&lt;/p&gt;
, &lt;p&gt;This will be fixed in the 3.0 build.&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[billbarker, sebb@apache.org, erans, rwerp], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,686 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-369
2016-01-13 22:20:32,686 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-369, created=Mon May 03 17:48:27 CEST 2010, updated=Wed Mar 23 21:05:06 CET 2011, resolved=Mon May 03 20:43:59 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Minor, summary=BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException, link=https://issues.apache.org/jira/browse/MATH-369, description=&lt;p&gt;Method &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  &lt;/p&gt;

&lt;p&gt;invokes &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(double min, double max) &lt;/p&gt;

&lt;p&gt;which throws NullPointerException, as member variable&lt;/p&gt;

&lt;p&gt;    UnivariateRealSolverImpl.f &lt;/p&gt;

&lt;p&gt;is null.&lt;/p&gt;

&lt;p&gt;Instead the method:&lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)&lt;/p&gt;

&lt;p&gt;should be called.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;/p&gt;

&lt;p&gt;invoke:&lt;/p&gt;

&lt;p&gt;     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);&lt;/p&gt;

&lt;p&gt;NullPointerException will be thrown.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository as of r940565.&lt;br/&gt;
Thanks for the report and for the fix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sasunpundev@abv.bg, assignees=[], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,701 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-368
2016-01-13 22:20:32,701 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-368, created=Thu Apr 29 05:41:10 CEST 2010, updated=Wed Mar 23 21:04:17 CET 2011, resolved=Mon May 10 01:07:24 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=OpenMapRealVector.getSparcity should be getSparsity, link=https://issues.apache.org/jira/browse/MATH-368, description=&lt;p&gt;The term for describing the ratio of nonzero elements to zero elements in a matrix/vector is sparsity, not sparcity.  Suggest renaming getSparcity() to getSparsity()&lt;/p&gt;, comments=[&lt;p&gt;The policy of this project is to not remove methods from the public API in a point release.  However, the misspelled method has been deprecated and the correctly spelled method has been added.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,701 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-367
2016-01-13 22:20:32,701 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-367, created=Thu Apr 22 20:31:06 CEST 2010, updated=Wed Mar 23 21:03:42 CET 2011, resolved=Mon May 10 03:17:14 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=AbstractRealVector.sparseIterator fails when vector has exactly one non-zero entry, link=https://issues.apache.org/jira/browse/MATH-367, description=&lt;p&gt;The following program:&lt;br/&gt;
===&lt;br/&gt;
import java.util.Iterator;&lt;br/&gt;
import org.apache.commons.math.linear.*;&lt;/p&gt;

&lt;p&gt;public class SparseIteratorTester&lt;br/&gt;
{&lt;br/&gt;
    public static void main(String[] args) {&lt;br/&gt;
        double vdata[] = { 0.0, 1.0, 0.0 };&lt;br/&gt;
        RealVector v = new ArrayRealVector(vdata);&lt;br/&gt;
        Iterator&amp;lt;RealVector.Entry&amp;gt; iter = v.sparseIterator();&lt;br/&gt;
        while(iter.hasNext()) {
            RealVector.Entry entry = iter.next();
            System.out.printf("%d: %f\n", entry.getIndex(), entry.getValue());
        }   &lt;br/&gt;
    }       &lt;br/&gt;
} &lt;br/&gt;
===&lt;br/&gt;
generates this output:&lt;/p&gt;

&lt;p&gt;1: 1.000000&lt;br/&gt;
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: -1&lt;br/&gt;
	at org.apache.commons.math.linear.ArrayRealVector.getEntry(ArrayRealVector.java:995)&lt;br/&gt;
	at org.apache.commons.math.linear.AbstractRealVector$EntryImpl.getValue(AbstractRealVector.java:850)&lt;br/&gt;
	at test.SparseIteratorTester.main(SparseIteratorTester.java:13)&lt;br/&gt;
===&lt;/p&gt;

&lt;p&gt;This patch fixes it, and simplifies AbstractRealVector.SparseEntryIterator  (sorry, i don't see any form entry for attaching a file)&lt;br/&gt;
===&lt;br/&gt;
Index: src/main/java/org/apache/commons/math/linear/AbstractRealVector.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(revision 936985)&lt;br/&gt;
+++ src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(working copy)&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.commons.math.linear;&lt;/p&gt;

&lt;p&gt; import java.util.Iterator;&lt;br/&gt;
+import java.util.NoSuchElementException;&lt;/p&gt;

&lt;p&gt; import org.apache.commons.math.FunctionEvaluationException;&lt;br/&gt;
 import org.apache.commons.math.MathRuntimeException;&lt;br/&gt;
@@ -875,40 +876,25 @@&lt;br/&gt;
         /** Dimension of the vector. */&lt;br/&gt;
         private final int dim;&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Temporary entry (reused on each call to {@link #next()}. */&lt;/li&gt;
	&lt;li&gt;private EntryImpl tmp = new EntryImpl();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;/** Current entry. */&lt;br/&gt;
+        /** Last entry returned by #next(). */&lt;br/&gt;
         private EntryImpl current;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Next entry. */&lt;br/&gt;
+        /** Next entry for #next() to return. */&lt;br/&gt;
         private EntryImpl next;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** Simple constructor. */&lt;br/&gt;
         protected SparseEntryIterator() {&lt;br/&gt;
             dim = getDimension();&lt;br/&gt;
             current = new EntryImpl();&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (current.getValue() == 0) {
-                advance(current);
-            }&lt;/li&gt;
	&lt;li&gt;if(current.getIndex() &amp;gt;= 0){
-                // There is at least one non-zero entry
-                next = new EntryImpl();
-                next.setIndex(current.getIndex());
+            next = new EntryImpl();
+            if(next.getValue() == 0)
                 advance(next);
-            } else {
-                // The vector consists of only zero entries, so deny having a next
-                current = null;
-            }&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Advance an entry up to the next non null one.&lt;br/&gt;
+        /** Advance an entry up to the next nonzero value.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param e entry to advance&lt;br/&gt;
          */&lt;br/&gt;
         protected void advance(EntryImpl e) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (e == null) {
-                return;
-            }&lt;br/&gt;
             do {
                 e.setIndex(e.getIndex() + 1);
             } while (e.getIndex() &amp;lt; dim &amp;amp;&amp;amp; e.getValue() == 0);&lt;br/&gt;
@@ -919,22 +905,17 @@&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;br/&gt;
         public boolean hasNext() {
-            return current != null;
+            return next.getIndex() &amp;gt;= 0;
         }&lt;br/&gt;
 &lt;br/&gt;
         /** {@inheritDoc} */&lt;br/&gt;
         public Entry next() {&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;tmp.setIndex(current.getIndex());&lt;/li&gt;
	&lt;li&gt;if (next != null) {&lt;/li&gt;
	&lt;li&gt;current.setIndex(next.getIndex());&lt;/li&gt;
	&lt;li&gt;advance(next);&lt;/li&gt;
	&lt;li&gt;if (next.getIndex() &amp;lt; 0) {
-                    next = null;
-                }&lt;/li&gt;
	&lt;li&gt;} else {
-                current = null;
-            }&lt;/li&gt;
	&lt;li&gt;return tmp;&lt;br/&gt;
+            int index = next.getIndex();&lt;br/&gt;
+            if(index &amp;lt; 0)&lt;br/&gt;
+                throw new NoSuchElementException();&lt;br/&gt;
+            current.setIndex(index);&lt;br/&gt;
+            advance(next);&lt;br/&gt;
+            return current;&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;/p&gt;, comments=[&lt;p&gt;patch fixing the bug&lt;/p&gt;
, &lt;p&gt;I've applied your patch (with a couple of style tweaks).  It should be available in the next release of commons-math.&lt;/p&gt;

&lt;p&gt;Thank you for your contribution.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[ashuang, billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,701 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-365
2016-01-13 22:20:32,701 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-365, created=Tue Apr 20 16:21:20 CEST 2010, updated=Wed Mar 23 21:02:52 CET 2011, resolved=Wed Apr 21 16:35:53 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=Issue with "SmoothingBicubicSplineInterpolator", link=https://issues.apache.org/jira/browse/MATH-365, description=&lt;p&gt;I figured out that the name of this class is misleading as the implementation doesn't perform the intended smoothing.&lt;/p&gt;

&lt;p&gt;In order to solve this issue, I propose to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;deprecate the "SmoothingBicubicSplineInterpolator" class&lt;/li&gt;
	&lt;li&gt;create a "BicubicSplineInterpolator" class (similar to the above class but with the useless code removed)&lt;/li&gt;
	&lt;li&gt;remove the "SmoothingBicubicSplineInterpolatorTest" class&lt;/li&gt;
	&lt;li&gt;add a "BicubicSplineInterpolatorTest" with essentially the same contents as the above one&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Then I would also add a new "SmoothingPolynomialBicubicSplineInterpolator" where I used the "PolynomialFitter" class to smooth the input data along both dimensions before the interpolating function is computed.&lt;/p&gt;

&lt;p&gt;Does someone object to these changes?&lt;/p&gt;, comments=[&lt;p&gt;removing the test class would badly impact test coverage, so it would be better to simply deprecae it also and to remove the library class and its associated test class together when releasing 3.0&lt;/p&gt;
, &lt;p&gt;revision 936295.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,717 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-362
2016-01-13 22:20:32,717 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-362, created=Tue Apr 06 13:38:46 CEST 2010, updated=Wed Mar 23 21:02:00 CET 2011, resolved=Sat May 29 20:16:50 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it, link=https://issues.apache.org/jira/browse/MATH-362, description=&lt;p&gt;LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.&lt;/p&gt;, comments=[&lt;p&gt;Ooops. You are right.&lt;br/&gt;
The Levenberg-Marquardt optimizer uses specific convergence parameters which can be set by   setInitialStepBoundFactor, setCostRelativeTolerance, setParRelativeTolerance and setOrthoTolerance.&lt;br/&gt;
The most important convergence tuning are either setCostRelativeTolerance for a convergence on the cost itself or setParRelativeTolerance for a convergence on the parameters.&lt;/p&gt;

&lt;p&gt;I'm not sure how to solve this. Do the existing tuning parameters fit your needs or not ? Some convergence criteria can be expressed with both methods, but not all. Should we keep both setting as alternate methods or should we remove one and rely on the remaining one ?&lt;/p&gt;
, &lt;p&gt;I would keep using orthoTolerance as it is used now:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;292                if (maxCosine &amp;lt;= orthoTolerance) {&lt;br/&gt;
293                    // convergence has been reached&lt;br/&gt;
294                    return new VectorialPointValuePair(point, objective);&lt;br/&gt;
295                }&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;and then use costRelativeTolerance &amp;amp; parRelativeTolerance if and only if the convergence checker is null, otherwise use the convergence checker and ignore {costRelativeTolerance, parRelativeTolerance}.&lt;/p&gt;

&lt;p&gt;What I am missing now is the ability to bail out if the absolute distance from the target falls below some value ("close enough").&lt;/p&gt;
, &lt;p&gt;I've spent that last few days trying to find a good curve fitting library for Java and got excited when I learned of Commons Math.  Unfortunately, its curve fitting is very unreliable.  I'm hoping that this bug is what is causing the problems that I'm seeing.  I'm comparing data from NIST and results from DataFitX and it is apparent that Commons Math is not yet up to the task.  My fingers are crossed that its quality in the curve fitting area will be improved in the near future.  Keep up the good work Apache.&lt;/p&gt;

&lt;p&gt;I've opened an issue about the problems I'm seeing, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Double check how you use it, Matt. I have succesfully used this curve fitting in production.&lt;/p&gt;
, &lt;p&gt;Matt, could you please describe the problem you encounter more precisely (i.e. with numerical examples) and preferably in a new JIRA issue ? We will check if the two problems are related and link the issues afterwards if it appears they are.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
, &lt;p&gt;It's good to see such quick responses.  I'll open a new JIRA issue and spend some time putting together code, data and a detailed description of the problem I'm seeing.  Thanks Apache for all your hard work.&lt;/p&gt;

&lt;p&gt;I've opened an issue regarding the problem, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r949433.&lt;br/&gt;
Thanks for reporting the issue&lt;/p&gt;
, &lt;p&gt;Thank you.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=roman.werpachowski, assignees=[], commentAuthors=[luc, roman.werpachowski, mprice], timeEstimate=null, timeSpent=null]
2016-01-13 22:20:32,717 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry, issueId: MATH-288
2016-01-13 22:20:32,717 : DEBUG : KNIME-Worker-0 : ITSAdapterTransformer : Jira Adapter (Offline) : 2:2 : Transforming issue entry:ITSDataType [issueId=MATH-288, created=Tue Aug 25 00:31:11 CEST 2009, updated=Wed Apr 14 02:30:17 CEST 2010, resolved=Tue Aug 25 20:10:08 CEST 2009, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.1
], priority=Major, summary=SimplexSolver not working as expected 2, link=https://issues.apache.org/jira/browse/MATH-288, description=&lt;p&gt;SimplexSolver didn't find the optimal solution.&lt;/p&gt;

&lt;p&gt;Program for Lpsolve:&lt;br/&gt;
=====================&lt;br/&gt;
/* Objective function */&lt;br/&gt;
max: 7 a 3 b;&lt;/p&gt;

&lt;p&gt;/* Constraints */&lt;br/&gt;
R1: +3 a -5 c &amp;lt;= 0;&lt;br/&gt;
R2: +2 a -5 d &amp;lt;= 0;&lt;br/&gt;
R3: +2 b -5 c &amp;lt;= 0;&lt;br/&gt;
R4: +3 b -5 d &amp;lt;= 0;&lt;br/&gt;
R5: +3 a +2 b &amp;lt;= 5;&lt;br/&gt;
R6: +2 a +3 b &amp;lt;= 5;&lt;/p&gt;

&lt;p&gt;/* Variable bounds */&lt;br/&gt;
a &amp;lt;= 1;&lt;br/&gt;
b &amp;lt;= 1;&lt;br/&gt;
=====================&lt;br/&gt;
Results(correct): a = 1, b = 1, value = 10&lt;/p&gt;


&lt;p&gt;Program for SimplexSolve:&lt;br/&gt;
=====================&lt;br/&gt;
LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]{7, 3, 0, 0}, 0);&lt;br/&gt;
Collection&amp;lt;LinearConstraint&amp;gt; podmienky = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{1, 0, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 1, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 0, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 0, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 2, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 3, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 2, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 3, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
RealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);&lt;br/&gt;
=====================&lt;br/&gt;
Results(incorrect): a = 1, b = 0.5, value = 8.5&lt;/p&gt;

&lt;p&gt;P.S. I used the latest software from the repository (including &lt;a href="https://issues.apache.org/jira/browse/MATH-286" title="SimplexSolver not working as expected?"&gt;&lt;del&gt;MATH-286&lt;/del&gt;&lt;/a&gt; fix).&lt;/p&gt;, comments=[&lt;p&gt;Thanks for the bug report.  I've confirmed this is an issue.&lt;/p&gt;

&lt;p&gt;Here's a slightly smaller version of the problem that causes the same bug, which might be easier for debugging:&lt;/p&gt;

&lt;p&gt;MAX 7 a + 3 b&lt;br/&gt;
s.t.&lt;br/&gt;
3 a -5 c &amp;lt;= 0&lt;br/&gt;
2 a -5 d &amp;lt;= 0&lt;br/&gt;
3 b -5 d &amp;lt;= 0&lt;br/&gt;
a &amp;lt;= 1&lt;br/&gt;
b &amp;lt;= 1&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 7, 3, 0, 0 }, 0 );&lt;br/&gt;
        Collection&amp;lt;LinearConstraint&amp;gt; constraints = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 3, 0, -5, 0 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 2, 0, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 3, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0 }, Relationship.LEQ, 1.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 0 }, Relationship.LEQ, 1.0));&lt;/p&gt;

&lt;p&gt;        SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
        RealPointValuePair solution = solver.optimize(f, constraints, GoalType.MAXIMIZE, true);&lt;br/&gt;
        assertEquals(10.0, solution.getValue(), .0000001);&lt;/p&gt;
, &lt;p&gt;Patch attached.  It was a 1 character bug.  I was saying to only do the minimum ratio test if the entry is &amp;gt;= 0, but it should have been &amp;gt; 0 (dividing by 0 is never good :o)&lt;br/&gt;
Thanks again for the bug report.&lt;/p&gt;
, &lt;p&gt;resolved in subversion repository as of r807738&lt;br/&gt;
patch applied (except for debug print function)&lt;br/&gt;
thanks for the repoart and thanks for the patch&lt;/p&gt;
], resolution=Fixed, reporter=kefa, assignees=[], commentAuthors=[bmccann, luc], timeEstimate=480, timeSpent=null]
2016-01-13 22:20:32,717 : INFO  : KNIME-Worker-0 : ITSOfflineNodeModel : Jira Adapter (Offline) : 2:2 : Jira table created.
2016-01-13 22:20:32,732 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 End execute (2 secs)
2016-01-13 22:20:32,732 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 doBeforePostExecution
2016-01-13 22:20:32,732 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: POSTEXECUTE
2016-01-13 22:20:32,732 : DEBUG : KNIME-Worker-0 : WorkflowManager : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 doAfterExecute - success
2016-01-13 22:20:32,732 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : Jira Adapter (Offline) 2:2 has new state: EXECUTED
2016-01-13 22:20:32,732 : DEBUG : KNIME-Worker-0 : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:20:32,732 : DEBUG : KNIME-Worker-0 : NodeContainer : Jira Adapter (Offline) : 2:2 : JiraOfflineTest 2 has new state: CONFIGURED
2016-01-13 22:20:32,732 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:20:35,930 : DEBUG : main : NodeContainerEditPart :  :  : Table Difference Checker 0:3 (CONFIGURED)
2016-01-13 22:20:35,930 : DEBUG : main : NodeContainerEditPart :  :  : Git SCM 0:2 (CONFIGURED)
2016-01-13 22:20:37,459 : DEBUG : main : ExecuteAction :  :  : Creating execution job for 1 node(s)...
2016-01-13 22:20:37,459 : DEBUG : main : NodeContainer :  :  : Setting dirty flag on Git SCM 0:2
2016-01-13 22:20:37,459 : DEBUG : main : NodeContainer :  :  : Setting dirty flag on GitOfflineTest 0
2016-01-13 22:20:37,459 : DEBUG : main : NodeContainer :  :  : Git SCM 0:2 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:20:37,459 : DEBUG : main : NodeContainer :  :  : Git SCM 0:2 has new state: CONFIGURED_QUEUED
2016-01-13 22:20:37,459 : DEBUG : main : NodeContainer :  :  : GitOfflineTest 0 has new state: EXECUTING
2016-01-13 22:20:37,459 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: EXECUTING
2016-01-13 22:20:37,459 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=0;old=null;new=null;timestamp=2016-01-13 22:20:37]
2016-01-13 22:20:37,459 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:2 : Git SCM 0:2 doBeforePreExecution
2016-01-13 22:20:37,459 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : Git SCM 0:2 has new state: PREEXECUTE
2016-01-13 22:20:37,459 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:2 : Git SCM 0:2 doBeforeExecution
2016-01-13 22:20:37,475 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : Git SCM 0:2 has new state: EXECUTING
2016-01-13 22:20:37,475 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Git SCM : 0:2 : Adding handler ee38bb6f-cdee-46ee-b4e1-ab0ad13c13c6 (Git SCM 0:2: <no directory>) - 1 in total
2016-01-13 22:20:37,475 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Git SCM : 0:2 : Git SCM 0:2 Start execute
2016-01-13 22:20:37,475 : INFO  : KNIME-Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Reading git logs from file file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/Git%20SCM%20(%232)/drop/git-test-log.txt
2016-01-13 22:20:37,880 : INFO  : KNIME-Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Reading git logs finished
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitTableFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitTableFactory.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.test.org.impressivecode.depress.scm.git.GitTableFactoryTest, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/test/org/impressivecode/depress/scm/git/GitTableFactoryTest.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommit, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommit.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommitFile, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommitFile.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:20:37,896 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:20:37,912 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommitFileOperation, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommitFileOperation.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:20:37,912 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:20:37,912 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-base/src/org/impressivecode/depress/its/ITSAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:20:37,912 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:20:37,912 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.its.ITSAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-base/test/org/impressivecode/depress/its/ITSAdapterTransformerTest.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:20:37,912 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:20:37,912 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:20:37,912 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:20:37,912 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:37,974 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSAdapterTableFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSDataType, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSDataType.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSPriority, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSPriority.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSResolution, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSResolution.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSStatus, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSStatus.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSType, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSType.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.its.ITSAdapterTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/test/org/impressivecode/depress/its/ITSAdapterTableFactoryTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeDialog.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeFactory.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeModel.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:20:38,005 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTableFactory.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformer.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParser.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntry, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntry.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.test.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/test/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformerTest.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.test.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/test/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParserTest.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeDataTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeDataTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberDataTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberDataTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeData, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeDataTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeDataTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetric, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetric.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricProcessor, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricProcessor.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,068 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberDataTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberDataTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.test.org.impressivecode.depress.metric.po.PeopleOrganizationMetricProcessorTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/test/org/impressivecode/depress/metric/po/PeopleOrganizationMetricProcessorTest.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.PluginApp, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/PluginApp.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:20:38,083 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberTransformer.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 907348573f0b3f74a644e962128cc2c855610239
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitTableFactory, extension=java, author=Sawek Kaposki, operation=ADDED, message=#12 Added class GitTableFactory with Input tables creating method. Methods which will generate output table is not created yet, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitTableFactory.java, commitDate=Mon Mar 04 22:29:44 CET 2013, commitID=907348573f0b3f74a644e962128cc2c855610239]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-checkstyle.src.org.impressivecode.depress.metric.checkstyle.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-checkstyle/src/org/impressivecode/depress/metric/checkstyle/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-findbug.src.org.impressivecode.depress.metric.findbug.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-findbug/src/org/impressivecode/depress/metric/findbug/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-pmd.src.org.impressivecode.depress.metric.pmd.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-pmd/src/org/impressivecode/depress/metric/pmd/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-common.src.org.impressivecode.depress.scm.common.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-scm-common/src/org/impressivecode/depress/scm/common/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 added PO Metric plugin draft, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.scm.SCMAdapterTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 added PO Metric plugin draft, path=ic-depress-base/test/org/impressivecode/depress/scm/SCMAdapterTableFactoryTest.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 added PO Metric plugin draft, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterTableFactory.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapterTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapterTableFactoryPluginTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: ef1d2453bf8587aec197ebd60f8d5260f3b02692
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Sat Mar 02 22:05:28 CET 2013, commitID=ef1d2453bf8587aec197ebd60f8d5260f3b02692]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,099 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeDialog.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyXmlResult, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyXmlResult.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeDialog.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#4 added progress, added tests, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b70ca05b7f982cf43d3f86e8a169a5c35ce46eed
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=Test added, #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Tue Feb 26 23:27:48 CET 2013, commitID=b70ca05b7f982cf43d3f86e8a169a5c35ce46eed]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: b70ca05b7f982cf43d3f86e8a169a5c35ce46eed
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Test added, #4, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Tue Feb 26 23:27:48 CET 2013, commitID=b70ca05b7f982cf43d3f86e8a169a5c35ce46eed]
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,114 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeDialog.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeFactory.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyXmlResult, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyXmlResult.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-pitest.src.org.impressivecode.depress.metric.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-pitest/src/org/impressivecode/depress/metric/pitest/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-judy.src.org.impressivecode.depress.metrics.judy.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-judy/src/org/impressivecode/depress/metrics/judy/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-pitest.src.org.impressivecode.depress.metrics.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-pitest/src/org/impressivecode/depress/metrics/pitest/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-data-anonymisation.src.org.impressivecode.depress.data.anonymization.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-data-anonymisation/src/org/impressivecode/depress/data/anonymization/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-data-source.src.org.impressivecode.depress.data.source.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-data-source/src/org/impressivecode/depress/data/source/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-judy.src.org.impressivecode.depress.metrics.judy.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-judy/src/org/impressivecode/depress/metrics/judy/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-pitest.src.org.impressivecode.depress.metrics.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-pitest/src/org/impressivecode/depress/metrics/pitest/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-common.src.org.impressivecode.depress.scm.common.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-common/src/org/impressivecode/depress/scm/common/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:2 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-svn.src.org.impressivecode.depress.scm.svn.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-svn/src/org/impressivecode/depress/scm/svn/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:20:38,130 : INFO  : KNIME-Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Transforming git logs finished.
2016-01-13 22:20:38,130 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Git SCM : 0:2 : Git SCM 0:2 End execute (0 secs)
2016-01-13 22:20:38,130 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:2 : Git SCM 0:2 doBeforePostExecution
2016-01-13 22:20:38,161 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : Git SCM 0:2 has new state: POSTEXECUTE
2016-01-13 22:20:38,239 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:2 : Git SCM 0:2 doAfterExecute - success
2016-01-13 22:20:38,239 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : Git SCM 0:2 has new state: EXECUTED
2016-01-13 22:20:38,239 : DEBUG : KNIME-Worker-0 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:20:38,239 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:2 : GitOfflineTest 0 has new state: CONFIGURED
2016-01-13 22:20:38,255 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:20:40,441 : DEBUG : main : WorkflowEditor :  :  : Saving workflow GitOfflineTest 0
2016-01-13 22:20:40,690 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Replaced node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest\Git SCM (#2)"
2016-01-13 22:20:42,718 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:20:42,718 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:20:42,718 : DEBUG : main : ProjectWorkflowMap :  :  : unregistering org.knime.workbench.editor2.WorkflowEditor@22decfa2 from file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/. 0 left.
2016-01-13 22:20:42,718 : DEBUG : main : ProjectWorkflowMap :  :  : Removing "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/" from project map (1 remaining)
2016-01-13 22:20:42,734 : DEBUG : main : WorkflowManager :  :  : Removing project "GitOfflineTest 0"
2016-01-13 22:20:42,781 : DEBUG : main : DifferenceCheckerNodeModel : Table Difference Checker : 0:3 : Removing all (0) views from model.
2016-01-13 22:20:42,781 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:20:42,781 : DEBUG : main : WorkflowFileStoreHandlerRepository : Git SCM : 0:2 : Removing handler ee38bb6f-cdee-46ee-b4e1-ab0ad13c13c6 (Git SCM 0:2: <no directory>) - 0 remaining
2016-01-13 22:20:42,781 : DEBUG : main : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Removing all (0) views from model.
2016-01-13 22:20:42,781 : DEBUG : main : Git SCM : Git SCM : 0:2 : clean output ports.
2016-01-13 22:20:42,781 : DEBUG : main : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Removing all (0) views from model.
2016-01-13 22:20:42,781 : DEBUG : main : Git SCM : Git SCM : 0:1 : clean output ports.
2016-01-13 22:20:42,796 : DEBUG : main : WorkflowManager :  :  : Project "GitOfflineTest 0" removed (2 remaining)
2016-01-13 22:20:44,122 : DEBUG : main : WorkflowEditor :  :  : Saving workflow JiraOfflineTest 2
2016-01-13 22:20:44,450 : DEBUG : ModalContext : FileSingleNodeContainerPersistor :  :  : Replaced node directory "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest\Jira Adapter _Offline_ (#2)"
2016-01-13 22:20:46,712 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:20:46,712 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:20:46,712 : DEBUG : main : ProjectWorkflowMap :  :  : unregistering org.knime.workbench.editor2.WorkflowEditor@730611a0 from file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/. 0 left.
2016-01-13 22:20:46,712 : DEBUG : main : ProjectWorkflowMap :  :  : Removing "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/" from project map (0 remaining)
2016-01-13 22:20:46,712 : DEBUG : main : WorkflowManager :  :  : Removing project "JiraOfflineTest 2"
2016-01-13 22:20:46,759 : DEBUG : main : DifferenceCheckerNodeModel : Table Difference Checker : 2:3 : Removing all (0) views from model.
2016-01-13 22:20:46,759 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:20:46,759 : DEBUG : main : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 2:2 : Removing handler 7e095683-5535-4a22-a735-aa5fc9aa65a7 (Jira Adapter (Offline) 2:2: <no directory>) - 0 remaining
2016-01-13 22:20:46,759 : DEBUG : main : JiraAdapterNodeModel : Jira Adapter (Offline) : 2:2 : Removing all (0) views from model.
2016-01-13 22:20:46,759 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : clean output ports.
2016-01-13 22:20:46,759 : DEBUG : main : JiraAdapterNodeModel : Jira Adapter (Offline) : 2:1 : Removing all (0) views from model.
2016-01-13 22:20:46,759 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : clean output ports.
2016-01-13 22:20:46,759 : DEBUG : main : WorkflowManager :  :  : Project "JiraOfflineTest 2" removed (1 remaining)
2016-01-13 22:20:48,056 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:20:48,056 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:20:48,134 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:20:48,134 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on workflow.knime
2016-01-13 22:20:48,134 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:20:48,134 : DEBUG : main : WorkflowEditor :  :  : Resource File's project: file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/
2016-01-13 22:20:48,243 : DEBUG : ModalContext : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\SVNOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:20:48,243 : DEBUG : ModalContext : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:20:48,274 : DEBUG : ModalContext : SVNOfflineAdapterNodeFactory : SVNOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:48,274 : DEBUG : ModalContext : DifferenceCheckerNodeFactory : SVNOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:48,290 : DEBUG : ModalContext : SVNOfflineAdapterNodeFactory : SVNOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:20:48,290 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:3(1) to node 0:2(2)
2016-01-13 22:20:48,290 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:2(1)
2016-01-13 22:20:48,290 : DEBUG : ModalContext : SVN SCM : SVN SCM : 0:1 : Configure succeeded. (SVN SCM)
2016-01-13 22:20:48,305 : DEBUG : ModalContext : Table Difference Checker : Table Difference Checker : 0:2 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:20:48,305 : DEBUG : ModalContext : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\SVNOfflineTest"  with no errors
2016-01-13 22:20:48,383 : DEBUG : main : ProjectWorkflowMap :  :  : Adding "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/" to project map (1 in total)
2016-01-13 22:20:48,383 : DEBUG : main : ProjectWorkflowMap :  :  : registering org.knime.workbench.editor2.WorkflowEditor@73b63917 to file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/. 1 registered clients now.
2016-01-13 22:20:48,399 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:20:48,414 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:20:48,414 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:20:48,414 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( SVN SCM 0:1 (CONFIGURED) )
2016-01-13 22:20:48,414 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:2( 1)]
2016-01-13 22:20:48,414 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:48,414 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:2 (CONFIGURED) )
2016-01-13 22:20:48,414 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:2( 1)]
2016-01-13 22:20:48,414 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:48,414 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:3(1) -> 0:2( 2)]
2016-01-13 22:20:48,414 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:48,414 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( SVN SCM 0:3 (EXECUTED) )
2016-01-13 22:20:48,430 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:3(1) -> 0:2( 2)]
2016-01-13 22:20:48,430 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:20:53,484 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:20:53,500 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:20:53,500 : DEBUG : main : ProjectWorkflowMap :  :  : unregistering org.knime.workbench.editor2.WorkflowEditor@73b63917 from file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/. 0 left.
2016-01-13 22:20:53,500 : DEBUG : main : ProjectWorkflowMap :  :  : Removing "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/" from project map (0 remaining)
2016-01-13 22:20:53,500 : DEBUG : main : WorkflowManager :  :  : Removing project "SVNOfflineTest 0"
2016-01-13 22:20:53,547 : DEBUG : main : DifferenceCheckerNodeModel : Table Difference Checker : 0:2 : Removing all (0) views from model.
2016-01-13 22:20:53,547 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:2 : clean output ports.
2016-01-13 22:20:53,547 : DEBUG : main : SVNOfflineAdapterNodeModel : SVN SCM : 0:3 : Removing all (0) views from model.
2016-01-13 22:20:53,547 : DEBUG : main : SVN SCM : SVN SCM : 0:3 : clean output ports.
2016-01-13 22:20:53,547 : DEBUG : main : SVNOfflineAdapterNodeModel : SVN SCM : 0:1 : Removing all (0) views from model.
2016-01-13 22:20:53,547 : DEBUG : main : SVN SCM : SVN SCM : 0:1 : clean output ports.
2016-01-13 22:20:53,547 : DEBUG : main : WorkflowManager :  :  : Project "SVNOfflineTest 0" removed (1 remaining)
2016-01-13 22:21:30,899 : DEBUG : KNIME-Node-Usage-Writer : NodeTimer$GlobalNodeStats :  :  : Successfully wrote node usage stats to file: D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\nodeusage_3.0.json
2016-01-13 22:21:30,899 : DEBUG : KNIME-Node-Usage-Sender : NodeTimer$GlobalNodeStats :  :  : Sending of usage stats disabled.
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # Welcome to the KNIME Analytics Platform v3.1.0.v201512031304 (Build December 06, 2015 #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # Based on Eclipse, http://www.eclipse.org                                              #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # Copyright by KNIME GmbH, Konstanz, Germany and others.                                #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # Website: http://www.knime.org                                                         #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # E-mail: contact@knime.org                                                             #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : #                                                                                       #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # For more details see the KNIME log file:                                              #
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\knime.log
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : #---------------------------------------------------------------------------------------#
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # logging date=Wed Jan 13 22:21:52 CET 2016
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # java.version=1.8.0_60
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # java.vm.version=25.60-b23
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # java.vendor=Oracle Corporation
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # os.name=Windows 7
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # os.arch=amd64
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # number of CPUs=2
2016-01-13 22:21:52,949 : INFO  : main : NodeLogger :  :  : # assertions=off
2016-01-13 22:21:53,199 : INFO  : main : NodeLogger :  :  : # host=SONY-Komputer
2016-01-13 22:21:53,199 : INFO  : main : NodeLogger :  :  : # username=SONY
2016-01-13 22:21:53,199 : INFO  : main : NodeLogger :  :  : # max mem=910MB
2016-01-13 22:21:53,199 : INFO  : main : NodeLogger :  :  : # application=org.knime.product.KNIME_APPLICATION
2016-01-13 22:21:53,215 : INFO  : main : NodeLogger :  :  : # ID=01-9c587cb4eccee8b8
2016-01-13 22:21:53,215 : INFO  : main : NodeLogger :  :  : #########################################################################################
2016-01-13 22:22:02,374 : INFO  : main : StringHistory :  :  : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_database_drivers.txt' does not exist.
2016-01-13 22:22:02,374 : INFO  : main : StringHistory :  :  : History file 'D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\history_database_urls.txt' does not exist.
2016-01-13 22:22:02,374 : DEBUG : main : DatabaseConnectionSettings :  :  : Settings database timeout to 15 seconds
2016-01-13 22:22:02,452 : DEBUG : main : DatabaseConnectionSettings :  :  : Database concurrency (sync via database connection) is true.
2016-01-13 22:22:02,452 : DEBUG : main : KNIMECorePlugin :  :  : Setting KNIME max thread count to 4
2016-01-13 22:22:02,452 : DEBUG : main : KNIMECorePlugin :  :  : Setting KNIME temp dir to "C:\Users\SONY\AppData\Local\Temp"
2016-01-13 22:22:02,545 : INFO  : main : KNIMECorePlugin :  :  : Setting console view log level to WARN
2016-01-13 22:22:02,811 : DEBUG : main : KnimeEncryption :  :  : Replacing current encryption key supplier "null" with this new one "org.knime.workbench.core.EclipseEncryptionKeySupplier@2c77344f".
2016-01-13 22:22:02,811 : DEBUG : main : DatabaseConnectionSettings :  :  : Settings database timeout to 15 seconds
2016-01-13 22:22:02,826 : DEBUG : main : KnimeEncryption :  :  : Replacing current encryption key supplier "org.knime.workbench.core.EclipseEncryptionKeySupplier@2c77344f" with this new one "org.knime.workbench.ui.masterkey.MasterKeyPreferencePage$1@7198ab9a".
2016-01-13 22:22:03,091 : DEBUG : main : SvgPluginActivator :  :  : Added SVG export option to node view class
2016-01-13 22:22:04,870 : DEBUG : main : KnimeEnterpriseFileSystemPlugin :  :  : Started KNIME Enterprise Remote File System plug-in
2016-01-13 22:22:04,917 : INFO  : main : ExplorerMountTable :  :  : Mounted Explorer Temp Space 'knime-temp-space' - com.knime.explorer.tempspace
2016-01-13 22:22:05,244 : DEBUG : main : UpdateManager :  :  : Updating registered ServerSpaces every 2000 msec.
2016-01-13 22:22:07,054 : DEBUG : main : NodeTimer$GlobalNodeStats :  :  : Successfully read node usage stats from file: D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\nodeusage_3.0.json
2016-01-13 22:22:07,116 : DEBUG : main : NodeContainer :  :  : ROOT  has new state: EXECUTED
2016-01-13 22:22:07,116 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 
2016-01-13 22:22:07,116 : DEBUG : main : NodeContainer :  :  : KNIME MetaNode Repository 1 has new state: EXECUTED
2016-01-13 22:22:07,116 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1
2016-01-13 22:22:07,116 : DEBUG : main : WorkflowManager :  :  : Added new subworkflow 1
2016-01-13 22:22:07,116 : DEBUG : main : WorkflowManager :  :  : Created project 1
2016-01-13 22:22:07,116 : DEBUG : main : RepositoryManager :  :  : Found category extension 'io' on path '/'
2016-01-13 22:22:07,132 : DEBUG : main : RepositoryManager :  :  : Found category extension 'manipulation' on path '/'
2016-01-13 22:22:07,132 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database' on path '/'
2016-01-13 22:22:07,132 : DEBUG : main : RepositoryManager :  :  : Found category extension 'view' on path '/'
2016-01-13 22:22:07,132 : DEBUG : main : RepositoryManager :  :  : Found category extension 'analytics' on path '/'
2016-01-13 22:22:07,147 : DEBUG : main : RepositoryManager :  :  : Found category extension 'toolintegration' on path '/'
2016-01-13 22:22:07,147 : DEBUG : main : RepositoryManager :  :  : Found category extension 'misc' on path '/'
2016-01-13 22:22:07,147 : DEBUG : main : RepositoryManager :  :  : Found category extension 'labs' on path '/'
2016-01-13 22:22:07,147 : DEBUG : main : RepositoryManager :  :  : Found category extension 'community' on path '/'
2016-01-13 22:22:07,147 : DEBUG : main : RepositoryManager :  :  : Found category extension 'social-media' on path '/'
2016-01-13 22:22:07,163 : DEBUG : main : RepositoryManager :  :  : Found category extension 'report' on path '/'
2016-01-13 22:22:07,163 : DEBUG : main : RepositoryManager :  :  : Found category extension 'chemistry' on path '/'
2016-01-13 22:22:07,163 : DEBUG : main : RepositoryManager :  :  : Found category extension 'applications' on path '/'
2016-01-13 22:22:07,163 : DEBUG : main : RepositoryManager :  :  : Found category extension 'struct-data' on path '/'
2016-01-13 22:22:07,163 : DEBUG : main : RepositoryManager :  :  : Found category extension 'scripting' on path '/'
2016-01-13 22:22:07,163 : DEBUG : main : RepositoryManager :  :  : Found category extension 'flowcontrol' on path '/'
2016-01-13 22:22:07,179 : DEBUG : main : RepositoryManager :  :  : Found category extension 'uncategorized' on path '/'
2016-01-13 22:22:07,179 : DEBUG : main : RepositoryManager :  :  : Found category extension 'testing' on path '/'
2016-01-13 22:22:07,179 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress' on path '/community'
2016-01-13 22:22:07,179 : DEBUG : main : RepositoryManager :  :  : Found category extension 'read' on path '/io'
2016-01-13 22:22:07,179 : DEBUG : main : RepositoryManager :  :  : Found category extension 'write' on path '/io'
2016-01-13 22:22:07,179 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column' on path '/manipulation'
2016-01-13 22:22:07,194 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row' on path '/manipulation'
2016-01-13 22:22:07,194 : DEBUG : main : RepositoryManager :  :  : Found category extension 'table' on path '/manipulation'
2016-01-13 22:22:07,194 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pmml' on path '/manipulation'
2016-01-13 22:22:07,194 : DEBUG : main : RepositoryManager :  :  : Found category extension 'property' on path '/view'
2016-01-13 22:22:07,194 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mining' on path '/analytics'
2016-01-13 22:22:07,210 : DEBUG : main : RepositoryManager :  :  : Found category extension 'statistics' on path '/analytics'
2016-01-13 22:22:07,210 : DEBUG : main : RepositoryManager :  :  : Found category extension 'io-other' on path '/io'
2016-01-13 22:22:07,210 : DEBUG : main : RepositoryManager :  :  : Found category extension 'java-snippet' on path '/scripting'
2016-01-13 22:22:07,210 : DEBUG : main : RepositoryManager :  :  : Found category extension 'view-util' on path '/view'
2016-01-13 22:22:07,210 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-io' on path '/database'
2016-01-13 22:22:07,225 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-manipulation' on path '/database'
2016-01-13 22:22:07,225 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-connector' on path '/database'
2016-01-13 22:22:07,225 : DEBUG : main : RepositoryManager :  :  : Found category extension 'database-utility' on path '/database'
2016-01-13 22:22:07,225 : DEBUG : main : RepositoryManager :  :  : Found category extension 'automation' on path '/flowcontrol'
2016-01-13 22:22:07,241 : DEBUG : main : RepositoryManager :  :  : Found category extension 'quickforms' on path '/flowcontrol'
2016-01-13 22:22:07,241 : DEBUG : main : RepositoryManager :  :  : Found category extension 'variables' on path '/flowcontrol'
2016-01-13 22:22:07,241 : DEBUG : main : RepositoryManager :  :  : Found category extension 'switches' on path '/flowcontrol'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'trycatch' on path '/flowcontrol'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/flowcontrol'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'filestore' on path '/testing'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'timeseries' on path '/applications'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress.scm' on path '/community/depress'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'depress.its' on path '/community/depress'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-other' on path '/manipulation/row'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-split+combine' on path '/manipulation/column'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-filter' on path '/manipulation/column'
2016-01-13 22:22:07,257 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-transform' on path '/manipulation/column'
2016-01-13 22:22:07,272 : DEBUG : main : RepositoryManager :  :  : Found category extension 'binning' on path '/manipulation/column'
2016-01-13 22:22:07,272 : DEBUG : main : RepositoryManager :  :  : Found category extension 'column-convert+replace' on path '/manipulation/column'
2016-01-13 22:22:07,272 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-filter' on path '/manipulation/row'
2016-01-13 22:22:07,272 : DEBUG : main : RepositoryManager :  :  : Found category extension 'row-transform' on path '/manipulation/row'
2016-01-13 22:22:07,272 : DEBUG : main : RepositoryManager :  :  : Found category extension 'clustering' on path '/analytics/mining'
2016-01-13 22:22:07,272 : DEBUG : main : RepositoryManager :  :  : Found category extension 'nn' on path '/analytics/mining'
2016-01-13 22:22:07,272 : DEBUG : main : RepositoryManager :  :  : Found category extension 'regression' on path '/analytics/statistics'
2016-01-13 22:22:07,272 : DEBUG : main : RepositoryManager :  :  : Found category extension 'rules' on path '/analytics/mining'
2016-01-13 22:22:07,288 : DEBUG : main : RepositoryManager :  :  : Found category extension 'dtree' on path '/analytics/mining'
2016-01-13 22:22:07,288 : DEBUG : main : RepositoryManager :  :  : Found category extension 'modeleval' on path '/analytics/mining'
2016-01-13 22:22:07,288 : DEBUG : main : RepositoryManager :  :  : Found category extension 'subgroup' on path '/analytics/mining'
2016-01-13 22:22:07,288 : DEBUG : main : RepositoryManager :  :  : Found category extension 'miscClass' on path '/analytics/mining'
2016-01-13 22:22:07,288 : DEBUG : main : RepositoryManager :  :  : Found category extension 'bayes' on path '/analytics/mining'
2016-01-13 22:22:07,288 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mds' on path '/analytics/mining'
2016-01-13 22:22:07,288 : DEBUG : main : RepositoryManager :  :  : Found category extension 'svm' on path '/analytics/mining'
2016-01-13 22:22:07,288 : DEBUG : main : RepositoryManager :  :  : Found category extension 'featureselection' on path '/analytics/mining'
2016-01-13 22:22:07,288 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pca' on path '/analytics/mining'
2016-01-13 22:22:07,303 : DEBUG : main : RepositoryManager :  :  : Found category extension 'weka' on path '/analytics/mining'
2016-01-13 22:22:07,303 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mining-pmml' on path '/analytics/mining'
2016-01-13 22:22:07,303 : DEBUG : main : RepositoryManager :  :  : Found category extension 'loopsupport' on path '/flowcontrol/'
2016-01-13 22:22:07,303 : DEBUG : main : RepositoryManager :  :  : Found category extension 'treeensemble' on path '/analytics/mining'
2016-01-13 22:22:07,303 : DEBUG : main : RepositoryManager :  :  : Found category extension 'regression' on path 'analytics/mining/treeensemble'
2016-01-13 22:22:07,303 : DEBUG : main : RepositoryManager :  :  : Found category extension 'ensembles' on path '/analytics/mining'
2016-01-13 22:22:07,303 : DEBUG : main : RepositoryManager :  :  : Found category extension 'hypothesis-testing' on path '/analytics/statistics'
2016-01-13 22:22:07,303 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/applications/timeseries'
2016-01-13 22:22:07,303 : DEBUG : main : RepositoryManager :  :  : Found category extension 'basisfunction' on path '/analytics/mining/rules'
2016-01-13 22:22:07,319 : DEBUG : main : RepositoryManager :  :  : Found category extension 'mlp' on path '/analytics/mining/nn'
2016-01-13 22:22:07,319 : DEBUG : main : RepositoryManager :  :  : Found category extension 'pnn' on path '/analytics/mining/nn'
2016-01-13 22:22:07,319 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/featureselection'
2016-01-13 22:22:07,319 : DEBUG : main : RepositoryManager :  :  : Found category extension 'crossvalidation' on path '/analytics/mining/modeleval'
2016-01-13 22:22:07,319 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/modeleval'
2016-01-13 22:22:07,319 : DEBUG : main : RepositoryManager :  :  : Found category extension 'classification' on path '/analytics/mining/treeensemble'
2016-01-13 22:22:07,319 : DEBUG : main : RepositoryManager :  :  : Found category extension 'ensembles-combine' on path '/analytics/mining/ensembles'
2016-01-13 22:22:07,319 : DEBUG : main : RepositoryManager :  :  : Found category extension 'meta' on path '/analytics/mining/ensembles'
2016-01-13 22:22:08,317 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.its.bugzilla': Bugzilla Adapter (Offline)
2016-01-13 22:22:08,364 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.its.jira': Jira Adapter (Offline)
2016-01-13 22:22:08,411 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.scm.gitoffline': Git SCM
2016-01-13 22:22:08,442 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.impressivecode.depress.scm.svnoffline': SVN SCM
2016-01-13 22:22:08,489 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.smote.SmoteNodeFactory': SMOTE
2016-01-13 22:22:08,536 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.filereader.FileReaderNodeFactory': File Reader
2016-01-13 22:22:08,567 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.ColorManager2NodeFactory': Color Manager
2016-01-13 22:22:08,629 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.size.SizeManager2NodeFactory': Size Manager
2016-01-13 22:22:08,661 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.shape.ShapeManagerNodeFactory': Shape Manager
2016-01-13 22:22:08,676 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.ColorAppenderNodeFactory': Color Appender
2016-01-13 22:22:08,754 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.size.SizeAppenderNodeFactory': Size Appender
2016-01-13 22:22:08,801 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.shape.ShapeAppenderNodeFactory': Shape Appender
2016-01-13 22:22:10,080 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.table.TableNodeFactory': Interactive Table
2016-01-13 22:22:10,158 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.binner.BinnerNodeFactory': Numeric Binner
2016-01-13 22:22:10,205 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.binnerdictionary.BinByDictionaryNodeFactory': Binner (Dictionary)
2016-01-13 22:22:10,236 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.cache.CacheNodeFactory': Cache
2016-01-13 22:22:10,299 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.fuzzy.FuzzyBasisFunctionLearnerNodeFactory': Fuzzy Rule Learner
2016-01-13 22:22:10,439 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.fuzzy.FuzzyBasisFunctionPredictor2NodeFactory': Fuzzy Rule Predictor
2016-01-13 22:22:10,455 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.radial.RadialBasisFunctionLearnerNodeFactory': PNN Learner (DDA)
2016-01-13 22:22:10,470 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bfn.radial.RadialBasisFunctionPredictor2NodeFactory': PNN Predictor
2016-01-13 22:22:10,548 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.csvwriter.CSVWriterNodeFactory': CSV Writer
2016-01-13 22:22:10,564 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.joiner.Joiner2NodeFactory': Joiner
2016-01-13 22:22:10,595 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.crossjoin.CrossJoinerNodeFactory': Cross Joiner
2016-01-13 22:22:10,611 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.split2.SplitNodeFactory2': Column Splitter
2016-01-13 22:22:10,642 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnappend.ColumnAppenderNodeFactory': Column Appender
2016-01-13 22:22:10,657 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.arffwriter.ARFFWriterNodeFactory': ARFF Writer
2016-01-13 22:22:10,657 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.sorter.SorterNodeFactory': Sorter
2016-01-13 22:22:10,673 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.arffreader.ARFFReaderNodeFactory': ARFF Reader
2016-01-13 22:22:10,704 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.csvreader.CSVReaderNodeFactory': CSV Reader
2016-01-13 22:22:10,720 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.linereader.LineReaderNodeFactory': Line Reader
2016-01-13 22:22:10,735 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.crosstable.CrosstabNodeFactory': Crosstab
2016-01-13 22:22:10,751 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.valcount.ValueCounterNodeFactory': Value Counter
2016-01-13 22:22:10,767 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize3.Normalize3NodeFactory': Normalizer
2016-01-13 22:22:10,782 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.PMMLNormalizerApplyNodeFactory': Normalizer Apply (PMML)
2016-01-13 22:22:10,798 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columnfilter.DataColumnSpecFilterPMMLNodeFactory': Column Filter (PMML)
2016-01-13 22:22:10,813 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.append.row.AppendedRowsNodeFactory': Concatenate
2016-01-13 22:22:10,829 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.append.row.AppendedRowsWithOptionalInNodeFactory': Concatenate (Optional in)
2016-01-13 22:22:10,845 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.row.RowFilterNodeFactory': Row Filter
2016-01-13 22:22:10,860 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.row.RowFilter2PortNodeFactory': Row Splitter
2016-01-13 22:22:10,860 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.shuffle.ShuffleNodeFactory': Shuffle
2016-01-13 22:22:10,891 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.sample.SamplingNodeFactory': Row Sampling
2016-01-13 22:22:10,891 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bootstrap.BootstrapNodeFactory': Bootstrap Sampling
2016-01-13 22:22:10,907 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.equalsizesampling.EqualSizeSamplingNodeFactory': Equal Size Sampling
2016-01-13 22:22:10,923 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.partition.PartitionNodeFactory': Partitioning
2016-01-13 22:22:10,938 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.fuzzycmeans.FuzzyClusterNodeFactory2': Fuzzy c-Means
2016-01-13 22:22:10,985 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.neural.mlp2.MLPPredictorNodeFactory': MultiLayerPerceptron Predictor
2016-01-13 22:22:11,016 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.predictor.PredictorReaderNodeFactory': Model Reader
2016-01-13 22:22:11,032 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.transpose.TransposeTableNodeFactory': Transpose
2016-01-13 22:22:11,047 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.extracttabledimension.ExtractTableDimensionNodeFactory': Extract Table Dimension
2016-01-13 22:22:11,063 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.extracttablespec.ExtractTableSpecNodeFactory': Extract Table Spec
2016-01-13 22:22:11,094 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.predictor2.DecTreePredictorNodeFactory': Decision Tree Predictor
2016-01-13 22:22:11,125 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.image.DecTreeToImageNodeFactory': Decision Tree To Image
2016-01-13 22:22:11,141 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.sota.SotaLearnerNodeFactory': SOTA Learner
2016-01-13 22:22:11,157 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rename.RenameNodeFactory': Column Rename
2016-01-13 22:22:11,172 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnrenameregex.ColumnRenameRegexNodeFactory': Column Rename (Regex)
2016-01-13 22:22:11,188 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.constantvalue.ConstantValueColumnNodeFactory': Constant Value Column
2016-01-13 22:22:11,219 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.create.CreateBitVectorNodeFactory': Create Bit Vector
2016-01-13 22:22:11,235 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.subgroupminer.SubgroupMinerFactory2': Association Rule Learner
2016-01-13 22:22:11,250 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.linear2.predict.GeneralRegressionPredictorNodeFactory': Regression Predictor
2016-01-13 22:22:11,266 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.table.read.ReadTableNodeFactory': Table Reader
2016-01-13 22:22:11,281 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.table.write.WriteTableNodeFactory': Table Writer
2016-01-13 22:22:11,297 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.create.CreateBitVectorNodeFactory': Create Bit Vector
2016-01-13 22:22:11,328 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bitvector.expand.ExpandBitVectorNodeFactory': Expand Bit Vector
2016-01-13 22:22:11,359 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.histogram.node.HistogramNodeFactory': Histogram (interactive)
2016-01-13 22:22:11,437 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.histogram.node.FixedColumnHistogramNodeFactory': Histogram
2016-01-13 22:22:11,453 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.NormalizeApplyNodeFactory': Normalizer (Apply)
2016-01-13 22:22:11,469 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.box.BoxPlotNodeFactory': Box Plot
2016-01-13 22:22:11,500 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.line.LinePlotterNodeFactory': Line Plot
2016-01-13 22:22:11,515 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.parcoord.ParallelCoordinateNodeFactory': Parallel Coordinates
2016-01-13 22:22:11,515 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.scatter.ScatterPlotterNodeFactory': Scatter Plot
2016-01-13 22:22:11,531 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.plotter.scattermatrix.ScatterMatrixNodeFactory': Scatter Matrix
2016-01-13 22:22:11,547 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.hilite': HiLite Row Splitter
2016-01-13 22:22:11,593 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.discretization.caim.modelcreator.CAIMDiscretizationNodeFactory': CAIM Binner
2016-01-13 22:22:11,593 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.discretization.caim.modelapply.DiscretizationApplyNodeFactory': CAIM Applier
2016-01-13 22:22:11,609 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rowkey2.RowKeyNodeFactory2': RowID
2016-01-13 22:22:11,625 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.knn.KnnNodeFactory': K Nearest Neighbor
2016-01-13 22:22:11,640 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.hierarchical.HierarchicalClusterNodeFactory': Hierarchical Clustering
2016-01-13 22:22:11,656 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.sota.predictor.SotaPredictorNodeFactory': SOTA Predictor
2016-01-13 22:22:11,656 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.pie.node.fixed.FixedPieNodeFactory': Pie chart
2016-01-13 22:22:11,671 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.pie.node.interactive.InteractivePieNodeFactory': Pie chart (interactive)
2016-01-13 22:22:11,734 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.groupby.GroupByNodeFactory': GroupBy
2016-01-13 22:22:11,749 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.ungroup.UngroupNodeFactory': Ungroup
2016-01-13 22:22:11,765 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pivot.Pivot2NodeFactory': Pivoting
2016-01-13 22:22:11,781 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bayes.naivebayes.predictor3.NaiveBayesPredictorNodeFactory2': Naive Bayes Predictor
2016-01-13 22:22:11,796 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.compute.CorrelationComputeNodeFactory': Linear Correlation
2016-01-13 22:22:11,812 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.compute.CorrelationComputeNodeFactory': Linear Correlation
2016-01-13 22:22:11,827 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.correlation.filter.CorrelationFilterNodeFactory': Correlation Filter
2016-01-13 22:22:11,843 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.lowvarfilter2.LowVarFilter2NodeFactory': Low Variance Filter
2016-01-13 22:22:11,859 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.mds.MDSNodeFactory': MDS
2016-01-13 22:22:11,874 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.mds.mdsprojection.MDSProjectionNodeFactory': MDS Projection
2016-01-13 22:22:11,890 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.svm.predictor2.SVMPredictorNodeFactory': SVM Predictor
2016-01-13 22:22:11,921 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colcompare.ColumnComparatorNodeFactory': Column Comparator
2016-01-13 22:22:11,921 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rowsplit.NumericRowSplitterNodeFactory': Numeric Row Splitter
2016-01-13 22:22:11,937 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringreplacer.StringReplacerNodeFactory': String Replacer
2016-01-13 22:22:11,952 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.dialog2.DomainNodeFactory': Domain Calculator
2016-01-13 22:22:11,983 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnumeric.EditNumericDomainNodeFactory': Edit Numeric Domain
2016-01-13 22:22:12,015 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnominal.dic.EditNominalDomainDicNodeFactory': Edit Nominal Domain (Dictionary)
2016-01-13 22:22:12,015 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.domain.editnominal.EditNominalDomainNodeFactory': Edit Nominal Domain
2016-01-13 22:22:12,030 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.caseconvert.CaseConvertNodeFactory': Case Converter
2016-01-13 22:22:12,030 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringreplacer.dict.SearchReplaceDictNodeFactory': String Replace (Dictionary)
2016-01-13 22:22:12,046 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellsplit.CellSplitterNodeFactory': Cell Splitter
2016-01-13 22:22:12,077 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.numbertostring.NumberToStringNodeFactory': Number To String
2016-01-13 22:22:12,077 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.stringtonumber.StringToNumberNodeFactory': String To Number
2016-01-13 22:22:12,093 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntrans2.One2ManyCol2NodeFactory': One to Many
2016-01-13 22:22:12,108 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntrans2.Many2OneCol2NodeFactory': Many to One
2016-01-13 22:22:12,124 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colcombine2.ColCombine2NodeFactory': Column Combiner
2016-01-13 22:22:12,124 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnmerge.ColumnMergerNodeFactory': Column Merger
2016-01-13 22:22:12,139 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.assign.ClusterAssignerNodeFactory': Cluster Assigner
2016-01-13 22:22:12,155 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.accuracy.AccuracyScorerNodeFactory': Scorer
2016-01-13 22:22:12,202 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.numeric.NumericScorerNodeFactory': Numeric Scorer
2016-01-13 22:22:12,202 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.scorer.entrop.NewEntropyNodeFactory': Entropy Scorer
2016-01-13 22:22:12,217 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.roc.ROCNodeFactory': ROC Curve
2016-01-13 22:22:12,233 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.chem.node.viz.enrich2.EnrichmentPlotterFactory': Enrichment Plotter
2016-01-13 22:22:12,233 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBReaderNodeFactory': Database Reader
2016-01-13 22:22:12,249 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBReaderConnectionNodeFactory': Database Table Connector
2016-01-13 22:22:12,264 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DatabaseLoopingNodeFactory': Database Looping
2016-01-13 22:22:12,295 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBConnectionNodeFactory': Database Connection Table Reader
2016-01-13 22:22:12,295 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBRowFilterNodeFactory': Database Row Filter
2016-01-13 22:22:12,311 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBQueryNodeFactory2': Database Query
2016-01-13 22:22:12,311 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBColumnFilterNodeFactory': Database Column Filter
2016-01-13 22:22:12,327 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBSorterNodeFactory': Database Sorter
2016-01-13 22:22:12,342 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBGroupByNodeFactory': Database GroupBy
2016-01-13 22:22:12,389 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBJoinerNodeFactory': Database Joiner
2016-01-13 22:22:12,436 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBConnectionWriterNodeFactory': Database Connection Table Writer
2016-01-13 22:22:12,451 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBWriterNodeFactory': Database Writer
2016-01-13 22:22:12,467 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBUpdateNodeFactory': Database Update
2016-01-13 22:22:12,467 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBDeleteRowsNodeFactory': Database Delete
2016-01-13 22:22:12,498 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.DBSQLExecutorNodeFactory': Database SQL Executor
2016-01-13 22:22:12,514 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellsplitbypos.CellSplitterByPositionNodeFactory': Cell Splitter By Position
2016-01-13 22:22:12,529 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.condbox.ConditionalBoxPlotNodeFactory': Conditional Box Plot
2016-01-13 22:22:12,529 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnFilterRefNodeFactory': Reference Column Filter
2016-01-13 22:22:12,545 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.MissingValueColumnFilterNodeFactory': Missing Value Column Filter
2016-01-13 22:22:12,561 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowFilterRefNodeFactory': Reference Row Filter
2016-01-13 22:22:12,592 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.collection.list.create2.CollectionCreate2NodeFactory': Create Collection Column
2016-01-13 22:22:12,607 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.collection.list.split.CollectionSplitNodeFactory': Split Collection Column
2016-01-13 22:22:12,623 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.pmml.read.PMMLReaderNodeFactory': PMML Reader
2016-01-13 22:22:12,623 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.regexsplit.RegexSplitNodeFactory': Regex Split
2016-01-13 22:22:12,639 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.pmml.write.PMMLWriterNodeFactory': PMML Writer
2016-01-13 22:22:12,654 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.predictor.PredictorWriterNodeFactory': Model Writer
2016-01-13 22:22:12,670 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.writemage.WriteImageNodeFactory': Image Port Writer
2016-01-13 22:22:12,685 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.imagecolwriter.ImageColumnWriterNodeFactory': Image Column Writer
2016-01-13 22:22:12,701 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.liftchart.LiftChartNodeFactory': Lift Chart
2016-01-13 22:22:12,732 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.setoperator.SetOperatorNodeFactory': Set Operator
2016-01-13 22:22:12,748 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.xvalidation.XValidatePartitionerFactory': X-Partitioner
2016-01-13 22:22:12,748 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.xvalidation.AggregateOutputNodeFactory': X-Aggregator
2016-01-13 22:22:12,763 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopStartCountNodeFactory': Counting Loop Start
2016-01-13 22:22:12,779 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.chunk.LoopStartChunkNodeFactory': Chunk Loop Start
2016-01-13 22:22:12,795 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.columnlist2.ColumnListLoopStartNodeFactory': Column List Loop Start
2016-01-13 22:22:12,810 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.condition.LoopStartGenericNodeFactory': Generic Loop Start
2016-01-13 22:22:12,826 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.variableloophead.LoopStartVariableNodeFactory': Table Row To Variable Loop Start
2016-01-13 22:22:12,826 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopEndNodeFactory': Loop End
2016-01-13 22:22:12,841 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.condition.LoopEndConditionNodeFactory': Variable Condition Loop End
2016-01-13 22:22:12,841 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.extractvariables.ExtractVariablesNodeFactory': Extract Variables (Data)
2016-01-13 22:22:12,888 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.extractvariables.ExtractVariablesDBNodeFactory': Extract Variables (Database)
2016-01-13 22:22:12,919 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopStart1NodeFactory': Backward Feature Elimination Start (1:1)
2016-01-13 22:22:12,919 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopStart2NodeFactory': Backward Feature Elimination Start (2:2)
2016-01-13 22:22:12,935 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimLoopEndNodeFactory': Backward Feature Elimination End
2016-01-13 22:22:12,935 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.feature.backwardelim.BWElimFilterNodeFactory': Backward Feature Elimination Filter
2016-01-13 22:22:12,951 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.appendvariabletotable2.AppendVariableToTable2NodeFactory': Variable to Table Column
2016-01-13 22:22:12,966 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.variabletotablerow2.VariableToTable2NodeFactory': Variable to Table Row
2016-01-13 22:22:12,966 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.tablerowtovariable.TableToVariableNodeFactory': Table Row to Variable
2016-01-13 22:22:12,982 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.injectvariables.InjectVariablesNodeFactory': Inject Variables (Data)
2016-01-13 22:22:12,982 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.injectvariables.InjectVariablesDBNodeFactory': Inject Variables (Database)
2016-01-13 22:22:12,997 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.nominal.NominalValueRowFilterNodeFactory': Nominal Value Row Filter
2016-01-13 22:22:12,997 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopStartIntervalNodeFactory': Interval Loop Start
2016-01-13 22:22:13,013 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.breakpoint.BreakpointNodeFactory': Breakpoint
2016-01-13 22:22:13,029 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.unpivot2.Unpivot2NodeFactory': Unpivoting
2016-01-13 22:22:13,029 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCANodeFactory': PCA
2016-01-13 22:22:13,044 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAComputeNodeFactory': PCA Compute
2016-01-13 22:22:13,060 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAApplyNodeFactory': PCA Apply
2016-01-13 22:22:13,075 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.pca.PCAReverseNodeFactory': PCA Inversion
2016-01-13 22:22:13,075 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.double2int.DoubleToIntNodeFactory': Double To Int
2016-01-13 22:22:13,122 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.hilite.collector.InteractiveHiLiteCollectorNodeFactory': Interactive HiLite Collector
2016-01-13 22:22:13,138 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.exp.node.meta.looper.LoopEnd2NodeFactory': Loop End (2 ports)
2016-01-13 22:22:13,138 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.matcher.SubsetMatcherNodeFactory': Subset Matcher
2016-01-13 22:22:13,153 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.matcher.SubsetMatcherNodeFactory': Subset Matcher
2016-01-13 22:22:13,153 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.ImageToTableNodeFactory': Image To Table
2016-01-13 22:22:13,169 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.tablerowtoimage.TableRowToImageNodeFactory': Table To Image
2016-01-13 22:22:13,169 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.manualif.ManualIfNodeFactory': IF Switch
2016-01-13 22:22:13,185 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endif.EndifNodeFactory': End IF
2016-01-13 22:22:13,200 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.startcase.StartcaseNodeFactory': CASE Switch Data (Start)
2016-01-13 22:22:13,216 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endcase.EndcaseNodeFactory': CASE Switch Data (End)
2016-01-13 22:22:13,231 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.model.CaseStartModelNodeFactory': CASE Switch Model (Start)
2016-01-13 22:22:13,231 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.endmodelcase.EndmodelcaseNodeFactory': CASE Switch Model (End)
2016-01-13 22:22:13,247 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.variable.CaseStartVariableNodeFactory': CASE Switch Variable (Start)
2016-01-13 22:22:13,247 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.caseswitch.variable.CaseEndVariableNodeFactory': CASE Switch Variable (End)
2016-01-13 22:22:13,263 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.switches.emptytableswitch.EmptyTableSwitchNodeFactory': Empty Table Switch
2016-01-13 22:22:13,263 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columntogrid2.ColumnToGrid2NodeFactory': Column to Grid
2016-01-13 22:22:13,278 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnheaderextract.ColumnHeaderExtractorNodeFactory': Extract Column Header
2016-01-13 22:22:13,278 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnheaderinsert.ColumnHeaderInsertNodeFactory': Insert Column Header
2016-01-13 22:22:13,294 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.addemptyrows.AddEmptyRowsNodeFactory': Add Empty Rows
2016-01-13 22:22:13,309 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.cellreplace.CellReplacerNodeFactory': Cell Replacer
2016-01-13 22:22:13,341 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.autobinner3.AutoBinnerLearnNodeFactory': Auto-Binner
2016-01-13 22:22:13,356 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.autobinner.apply.AutoBinnerApplyNodeFactory': Auto-Binner (Apply)
2016-01-13 22:22:13,356 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.LoopEndJoin2NodeFactory': Loop End (Column Append)
2016-01-13 22:22:13,372 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.listfiles2.ListFilesNodeFactory': List Files
2016-01-13 22:22:13,403 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.tablecreator.TableCreator2NodeFactory': Table Creator
2016-01-13 22:22:13,434 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.sampledata.SampleDataNodeFactory': Data Generator
2016-01-13 22:22:13,450 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.createtablestructure.CreateTableStructureNodeFactory': Create Table Structure
2016-01-13 22:22:13,450 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.createtempdir.CreateTempDirectoryNodeFactory': Create Temp Dir
2016-01-13 22:22:13,465 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.sendmail.SendMailNodeFactory': Send Email
2016-01-13 22:22:13,481 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.extractsysprop.ReadSysPropertyNodeFactory': Extract System Properties
2016-01-13 22:22:13,497 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.extractcontextprop.ReadContextPropertyNodeFactory': Extract Context Properties
2016-01-13 22:22:13,512 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.PMMLNormalizerDeNodeFactory': Denormalizer (PMML)
2016-01-13 22:22:13,512 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.normalize.NormalizerDeNodeFactory': Denormalizer
2016-01-13 22:22:13,528 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.property.color.extract.ColorExtractNodeFactory': Extract Color
2016-01-13 22:22:13,528 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.categorytonumber2.CategoryToNumberNodeFactory2': Category To Number
2016-01-13 22:22:13,543 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.categorytonumber.CategoryToNumberApplyNodeFactory': Category To Number (Apply)
2016-01-13 22:22:13,559 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.column.DataColumnSpecFilterNodeFactory': Column Filter
2016-01-13 22:22:13,559 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rounddouble.RoundDoubleNodeFactory': Round Double
2016-01-13 22:22:13,575 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnresorter.ColumnResorterNodeFactory': Column Resorter
2016-01-13 22:22:13,590 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnlag.LagColumnNodeFactory': Lag Column
2016-01-13 22:22:13,621 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.datavalidator.DataValidatorNodeFactory': Table Validator
2016-01-13 22:22:13,637 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.datavalidator.DataValidatorSpecNodeFactory': Table Validator (Reference)
2016-01-13 22:22:13,653 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.mergevariables.MergeVariablesNodeFactory': Merge Variables
2016-01-13 22:22:13,653 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.group.GroupLoopStartNodeFactory': Group Loop Start
2016-01-13 22:22:13,668 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.variableloopend.VariableLoopEndNodeFactory': Variable Loop End
2016-01-13 22:22:13,668 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.columnaggregator.ColumnAggregatorNodeFactory': Column Aggregator
2016-01-13 22:22:13,699 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bytevector.create.CreateByteVectorNodeFactory': Create Byte Vector
2016-01-13 22:22:13,715 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.bytevector.expand.ExpandByteVectorNodeFactory': Expand Byte Vector
2016-01-13 22:22:13,715 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.generictry.DataPortTryNodeFactory': Try (Data Ports)
2016-01-13 22:22:13,731 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.generictry.VariablePortTryNodeFactory': Try (Variable Ports)
2016-01-13 22:22:13,731 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.DataPortCatchNodeFactory': Catch Errors (Data Ports)
2016-01-13 22:22:13,746 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.VariablePortCatchNodeFactory': Catch Errors (Var Ports)
2016-01-13 22:22:13,746 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.DBPortCatchNodeFactory': Catch Errors (DB Ports)
2016-01-13 22:22:13,762 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.genericcatch.GenericPortCatchNodeFactory': Catch Errors (Generic Ports)
2016-01-13 22:22:13,762 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.trycatch.inverter.ActiveBranchInverterNodeFactory': Active Branch Inverter
2016-01-13 22:22:13,777 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowvariable.tablecoltovariable.TableColumnToVariableNodeFactory': Table Column to Variable
2016-01-13 22:22:13,777 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.flowcontrol.sleep.SleepNodeFactory': Wait...
2016-01-13 22:22:13,793 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.workflow.save.SaveWorkflowNodeFactory': Save Workflow
2016-01-13 22:22:13,840 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.timerinfo.TimerinfoNodeFactory': Timer Info
2016-01-13 22:22:13,855 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.util.globaltimerinfo.GlobalTimerinfoNodeFactory': Global Timer Info
2016-01-13 22:22:13,855 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopStartNodeFactory': Recursive Loop Start
2016-01-13 22:22:13,871 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopEndNodeFactory': Recursive Loop End
2016-01-13 22:22:13,887 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopStart2NodeFactory': Recursive Loop Start (2 ports)
2016-01-13 22:22:13,902 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.meta.looper.recursive.RecursiveLoopEnd2NodeFactory': Recursive Loop End (2 ports)
2016-01-13 22:22:13,902 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.xml2pmml.XML2PMMLNodeFactory': XML To PMML
2016-01-13 22:22:13,933 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.JDBCConnectorNodeFactory': Database Connector
2016-01-13 22:22:13,933 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.connection.DBTableSelectorNodeFactory': Database Table Selector
2016-01-13 22:22:13,949 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.SQLInjectNodeFactory': SQL Inject
2016-01-13 22:22:13,949 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.SQLExtractNodeFactory': SQL Extract
2016-01-13 22:22:13,965 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.drop.DBDropTableNodeFactory': Database Drop Table
2016-01-13 22:22:13,965 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.viz.hilite.AutoHiLiteNodeFactory': HiLite Table
2016-01-13 22:22:13,980 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.coltypechanger.ColumnTypeChangerNodeFactory': Column Auto Type Cast
2016-01-13 22:22:13,996 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.fixedwidthfr.FixedWidthFRNodeFactory': Fixed Width File Reader
2016-01-13 22:22:13,996 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.targetshuffling.TargetShufflingNodeFactory': Target Shuffling
2016-01-13 22:22:14,089 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMeanMissingCellHandlerFactory
2016-01-13 22:22:14,261 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMeanMissingCellHandlerFactory
2016-01-13 22:22:14,292 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMovingAverageMissingCellHandlerFactory
2016-01-13 22:22:14,292 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.DoubleMovingAverageMissingCellHandlerFactory
2016-01-13 22:22:14,308 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedDoubleValueMissingCellHandlerFactory
2016-01-13 22:22:14,308 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedDoubleValueMissingCellHandlerFactory
2016-01-13 22:22:14,323 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MaxMissingCellHandlerFactory
2016-01-13 22:22:14,355 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MaxMissingCellHandlerFactory
2016-01-13 22:22:14,386 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.IntegerMeanMissingCellHandlerFactory
2016-01-13 22:22:14,433 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.IntegerMeanMissingCellHandlerFactory
2016-01-13 22:22:14,433 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedIntegerValueMissingCellHandlerFactory
2016-01-13 22:22:14,448 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedIntegerValueMissingCellHandlerFactory
2016-01-13 22:22:14,495 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MinMissingCellHandlerFactory
2016-01-13 22:22:14,495 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MinMissingCellHandlerFactory
2016-01-13 22:22:14,495 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MostFrequentValueMissingCellHandlerFactory
2016-01-13 22:22:14,511 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MostFrequentValueMissingCellHandlerFactory
2016-01-13 22:22:14,526 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.NextMissingCellHandlerFactory
2016-01-13 22:22:14,526 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.NextMissingCellHandlerFactory
2016-01-13 22:22:14,542 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.RemoveRowMissingCellHandlerFactory
2016-01-13 22:22:14,542 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.RemoveRowMissingCellHandlerFactory
2016-01-13 22:22:14,542 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MedianNumberMissingCellHandlerFactory
2016-01-13 22:22:14,542 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.MedianNumberMissingCellHandlerFactory
2016-01-13 22:22:14,557 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.PreviousMissingCellHandlerFactory
2016-01-13 22:22:14,557 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.PreviousMissingCellHandlerFactory
2016-01-13 22:22:14,573 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.LinearInterpolationMissingCellHandlerFactory
2016-01-13 22:22:14,573 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.LinearInterpolationMissingCellHandlerFactory
2016-01-13 22:22:14,573 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedStringValueMissingCellHandlerFactory
2016-01-13 22:22:14,589 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedStringValueMissingCellHandlerFactory
2016-01-13 22:22:14,589 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.AverageInterpolationMissingCellHandlerFactory
2016-01-13 22:22:14,713 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.timeseries.AverageInterpolationMissingCellHandlerFactory
2016-01-13 22:22:14,729 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedLongValueMissingCellHandlerFactory
2016-01-13 22:22:14,729 : DEBUG : main : MissingCellHandlerDescriptionFactory :  :  : Loading description for factory: class org.knime.base.node.preproc.pmml.missingval.handlers.FixedLongValueMissingCellHandlerFactory
2016-01-13 22:22:14,791 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.missingval.compute.MissingValueHandlerNodeFactory': Missing Value
2016-01-13 22:22:14,807 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.missingval.apply.MissingValueApplyNodeFactory': Missing Value (Apply)
2016-01-13 22:22:14,807 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.numbertocategory.NumberToCategoryApplyNodeFactory': Number To Category (Apply)
2016-01-13 22:22:14,823 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.columnrename.DBColumnRenameNodeFactory': Database Column Rename
2016-01-13 22:22:14,823 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.normalize.NormalizerPMMLNodeFactory2': Normalizer (PMML)
2016-01-13 22:22:14,838 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.numbertostring.NumberToStringNodeFactory2': Number To String (PMML)
2016-01-13 22:22:14,854 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.stringtonumber.StringToNumberNodeFactory2': String To Number (PMML)
2016-01-13 22:22:14,869 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.binner.BinnerNodeFactory2': Numeric Binner (PMML)
2016-01-13 22:22:14,869 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columntrans2.One2ManyCol2PMMLNodeFactory2': One to Many (PMML)
2016-01-13 22:22:14,963 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.pmml.columntrans2.Many2OneCol2PMMLNodeFactory2': Many to One (PMML)
2016-01-13 22:22:14,994 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.decisiontree2.learner2.DecisionTreeLearnerNodeFactory3': Decision Tree Learner
2016-01-13 22:22:15,010 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.linear2.learner.LinReg2LearnerNodeFactory2': Linear Regression Learner
2016-01-13 22:22:15,025 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.polynomial.learner2.PolyRegLearnerNodeFactory2': Polynomial Regression Learner
2016-01-13 22:22:15,041 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.regression.logistic.learner3.LogRegLearnerNodeFactory3': Logistic Regression Learner
2016-01-13 22:22:15,057 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.neural.rprop.RPropNodeFactory2': RProp MLP Learner
2016-01-13 22:22:15,072 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.svm.learner.SVMLearnerNodeFactory2': SVM Learner
2016-01-13 22:22:15,088 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.bayes.naivebayes.learner2.NaiveBayesLearnerNodeFactory3': Naive Bayes Learner
2016-01-13 22:22:15,088 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.cluster.kmeans.ClusterNodeFactory': k-Means
2016-01-13 22:22:15,103 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.pivot.DBPivotNodeFactory': Database Pivot
2016-01-13 22:22:15,119 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.sampling.DBSamplingNodeFactory': Database Sampling
2016-01-13 22:22:15,119 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.auto.DBAutoBinnerNodeFactory': Database Auto-Binner
2016-01-13 22:22:15,150 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.numeric.DBNumericBinnerNodeFactory': Database Numeric-Binner
2016-01-13 22:22:15,150 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.io.database.binning.apply.DBApplyBinnerNodeFactory': Database Apply-Binner
2016-01-13 22:22:15,166 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowSplitRefNodeFactory': Reference Row Splitter
2016-01-13 22:22:15,181 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnSplitRefNodeFactory': Reference Column Splitter
2016-01-13 22:22:15,197 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rank.RankNodeFactory': Rank
2016-01-13 22:22:15,197 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.rowref.RowSplitRefNodeFactory': Reference Row Splitter
2016-01-13 22:22:15,213 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.filter.columnref.ColumnSplitRefNodeFactory': Reference Column Splitter
2016-01-13 22:22:15,213 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.rank.RankNodeFactory': Rank
2016-01-13 22:22:15,228 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.learner.classification.TreeEnsembleClassificationLearnerNodeFactory': Tree Ensemble Learner
2016-01-13 22:22:15,244 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.predictor.classification.TreeEnsembleClassificationPredictorNodeFactory': Tree Ensemble Predictor
2016-01-13 22:22:15,244 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.modelextractor.TreeEnsembleModelExtractorNodeFactory': Tree Ensemble Model Extract
2016-01-13 22:22:15,259 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.learner.regression.TreeEnsembleRegressionLearnerNodeFactory': Tree Ensemble Learner (Regression)
2016-01-13 22:22:15,259 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.predictor.regression.TreeEnsembleRegressionPredictorNodeFactory': Tree Ensemble Predictor (Regression)
2016-01-13 22:22:15,275 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.learner.classification.RandomForestClassificationLearnerNodeFactory': Random Forest Learner
2016-01-13 22:22:15,275 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.learner.regression.RandomForestRegressionLearnerNodeFactory': Random Forest Learner (Regression)
2016-01-13 22:22:15,291 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.predictor.classification.RandomForestClassificationPredictorNodeFactory': Random Forest Predictor
2016-01-13 22:22:15,291 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.randomforest.predictor.regression.RandomForestRegressionPredictorNodeFactory': Random Forest Predictor (Regression)
2016-01-13 22:22:15,306 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.regressiontree.learner.RegressionTreeLearnerNodeFactory': Simple Regression Tree Learner
2016-01-13 22:22:15,306 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.mine.treeensemble.node.regressiontree.predictor.RegressionTreePredictorNodeFactory': Simple Regression Tree Predictor
2016-01-13 22:22:15,322 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.metalearning.pmmlporttocell.PMMLPortToCellNodeFactory': PMML To Cell
2016-01-13 22:22:15,337 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.modeltotable.ModelToTableNodeFactory': Model to Cell
2016-01-13 22:22:15,337 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.tabletomodel.TableToModelNodeFactory': Cell To Model
2016-01-13 22:22:15,415 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingLearnerLoopStartNodeFactory': Boosting Learner Loop Start
2016-01-13 22:22:15,447 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingLearnerLoopEndNodeFactory': Boosting Learner Loop End
2016-01-13 22:22:15,447 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingPredictorLoopStartNodeFactory': Boosting Predictor Loop Start
2016-01-13 22:22:15,462 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.boosting.BoostingPredictorLoopEndNodeFactory': Boosting Predictor Loop End
2016-01-13 22:22:15,478 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.bagging.ModelLoopStartNodeFactory': Model Loop Start
2016-01-13 22:22:15,478 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.bagging.ModelLoopEndNodeFactory': Model Loop End
2016-01-13 22:22:15,493 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.tabletopmmlport.TableToPMMLNodeFactory': Cell To PMML
2016-01-13 22:22:15,493 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.voting.VotingLoopEndNodeFactory': Voting Loop End
2016-01-13 22:22:15,509 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmmlpredict2.PMMLPredictor2NodeFactory': PMML Predictor
2016-01-13 22:22:15,509 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.combine.PMMLEnsembleNodeFactory': Table to PMML Ensemble
2016-01-13 22:22:15,525 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.totable.PMMLEnsemble2TableNodeFactory': PMML Ensemble to Table
2016-01-13 22:22:15,525 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.predictor2.PMMLEnsemblePredictor2NodeFactory': PMML Ensemble Predictor
2016-01-13 22:22:15,540 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.pmml.loopend.PMMLEnsembleLoopEndNodeFactory': PMML Ensemble Loop End
2016-01-13 22:22:15,556 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ensembles.predictionfusion.PredictionFusionNodeFactory': Prediction Fusion
2016-01-13 22:22:15,571 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.JavaScriptingNodeFactory': Java Snippet (simple)
2016-01-13 22:22:15,571 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.rowfilter.JavaRowFilterNodeFactory': Java Snippet Row Filter
2016-01-13 22:22:15,587 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.rowsplitter.JavaRowSplitterNodeFactory': Java Snippet Row Splitter
2016-01-13 22:22:15,587 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.editvar.JavaEditVariableNodeFactory': Java Edit Variable (simple)
2016-01-13 22:22:15,603 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.sun.nodes.script.node.ifswitch.JavaIfSwitchNodeFactory': Java IF (Table)
2016-01-13 22:22:15,618 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.svg.node.sparklines.SparkLineNodeFactory': Spark Line Appender
2016-01-13 22:22:15,618 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.ext.svg.node.radarplot.RadarplotAppenderFactory': Radar Plot Appender
2016-01-13 22:22:15,634 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.renderer2image.Renderer2ImageNodeFactory': Renderer to Image
2016-01-13 22:22:15,634 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.image.readimage.ReadImageFromUrlNodeFactory': Read Images
2016-01-13 22:22:15,649 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.colconvert.stringtosvg.StringToSvgNodeFactory': String To SVG
2016-01-13 22:22:15,665 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.jsnippet.JavaSnippetNodeFactory': Java Snippet
2016-01-13 22:22:15,665 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.jsnippet.JavaEditVarNodeFactory': Java Edit Variable
2016-01-13 22:22:15,681 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineVariableNodeFactory': Rule Engine Variable
2016-01-13 22:22:15,681 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngineVariable2PortsNodeFactory': Rule Engine Variable (Dictionary)
2016-01-13 22:22:15,696 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.preproc.stringmanipulation.StringManipulationNodeFactory': String Manipulation
2016-01-13 22:22:15,696 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineNodeFactory': Rule Engine
2016-01-13 22:22:15,712 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineFilterNodeFactory': Rule-based Row Filter
2016-01-13 22:22:15,712 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.RuleEngineSplitterNodeFactory': Rule-based Row Splitter
2016-01-13 22:22:15,727 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngine2PortsNodeFactory': Rule Engine (Dictionary)
2016-01-13 22:22:15,727 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngineFilter2PortsNodeFactory': Rule-based Row Filter (Dictionary)
2016-01-13 22:22:15,743 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.twoports.RuleEngine2PortsSplitterNodeFactory': Rule-based Row Splitter (Dictionary)
2016-01-13 22:22:15,743 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.pmml.PMMLRuleEditorNodeFactory': Ruleset Editor
2016-01-13 22:22:15,759 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.pmml.PMMLRuleSetPredictorNodeFactory': Ruleset Predictor
2016-01-13 22:22:15,759 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.totable.RulesToTableNodeFactory': Ruleset to Table
2016-01-13 22:22:15,774 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.rules.engine.decisiontree.FromDecisionTreeNodeFactory': Decision Tree to Ruleset
2016-01-13 22:22:15,790 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.OneSampleTTestNodeFactory': Single sample t-test
2016-01-13 22:22:15,790 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.TwoSampleTTestNodeFactory': Independent groups t-test
2016-01-13 22:22:15,805 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.PairedTTestNodeFactory': Paired t-test
2016-01-13 22:22:15,805 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.testing.ttest.OneWayANOVANodeFactory': One-way ANOVA
2016-01-13 22:22:15,821 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.base.node.stats.viz.extended.ExtendedStatisticsNodeFactory': Statistics
2016-01-13 22:22:15,837 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.disturber.DisturberNodeFactory': Disturber Node
2016-01-13 22:22:15,837 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.differModelContent.DiffModelContentFactory': Model Content Difference Checker
2016-01-13 22:22:15,837 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.blocking.BlockingNodeFactory': Block Programmatically
2016-01-13 22:22:15,852 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.failing.FailingNodeFactory': Fail in execution
2016-01-13 22:22:15,852 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.credentialsvalidate.CredentialsValidateNodeFactory': Credentials Validate Test
2016-01-13 22:22:15,868 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.datagenerator.TestDataNodeFactory': Test Data Generator
2016-01-13 22:22:15,868 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.executioncount.ExecutionCountNodeFactory': Count Execution Programmatically
2016-01-13 22:22:15,883 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.file.DifferFileNodeFactory': File Difference Checker
2016-01-13 22:22:15,883 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.imagecomp.ImageCompNodeFactory': Image Comparator (deprecated)
2016-01-13 22:22:15,899 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.differ.DifferenceCheckerNodeFactory': Table Difference Checker
2016-01-13 22:22:15,899 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.internal.nodes.image.ImageDifferNodeFactory': Image Difference Checker
2016-01-13 22:22:15,915 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.config.TestConfigNodeFactory': Testflow Configuration
2016-01-13 22:22:15,915 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.internal.nodes.pmml.PMMLDifferenceCheckerNodeFactory': PMML Difference Checker
2016-01-13 22:22:15,930 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.create.FileStoreCreateNodeFactory': Create FileStore Column
2016-01-13 22:22:15,930 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.check.FileStoreTestNodeFactory': Test FileStore Column
2016-01-13 22:22:15,930 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.createloopend.FileStoreCreateLoopEndNodeFactory': Create FileStore Column in LoopEnd
2016-01-13 22:22:15,946 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.fsloopend.LoopEndFileStorePortObjectTestNodeFactory': Test FileStore Port Object Loop End
2016-01-13 22:22:15,946 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.filestore.fsobject2cell.FileStoreObjectToCellNodeFactory': Test FileStore Port Object to Table
2016-01-13 22:22:15,946 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.testing.node.logging.LoggerOptionNodeFactory': Logger Option
2016-01-13 22:22:15,961 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.filter.extract.ExtractFromToNodeFactory': Extract Time Window
2016-01-13 22:22:15,977 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.movavg.MovingAverageNodeFactory': Moving Average
2016-01-13 22:22:15,977 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.stringtotimestamp.String2DateNodeFactory': String to Date/Time
2016-01-13 22:22:15,993 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.diff.TimeDifferenceNodeFactory': Time Difference
2016-01-13 22:22:16,008 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.generator.DateGeneratorNodeFactory': Time Generator
2016-01-13 22:22:16,024 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.extract.TimeFieldExtractorNodeFactory': Time Field Extractor
2016-01-13 22:22:16,024 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.time2string.Time2StringNodeFactory': Time to String
2016-01-13 22:22:16,039 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.preset.TimePresetNodeFactory': Preset Date/Time
2016-01-13 22:22:16,039 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.mask.MaskTimeNodeFactory': Mask Date/Time
2016-01-13 22:22:16,055 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.extract.date.DateFieldExtractorNodeFactory': Date Field Extractor
2016-01-13 22:22:16,055 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.movagg.MovingAggregationNodeFactory': Moving Aggregation
2016-01-13 22:22:16,071 : DEBUG : main : RepositoryManager :  :  : Found node extension 'org.knime.timeseries.node.converter.DateShiftNodeFactory': Date/Time Shift 
2016-01-13 22:22:16,071 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Cross Validation/
2016-01-13 22:22:16,071 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Cross Validation
2016-01-13 22:22:16,149 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Cross Validation") is not locked
2016-01-13 22:22:16,149 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Cross Validation" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:16,242 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:0
2016-01-13 22:22:16,242 : DEBUG : main : NodeContainer :  :  : KNIME MetaNode Repository 1 has new state: IDLE
2016-01-13 22:22:16,273 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("X_Aggregator (#1)") is not locked
2016-01-13 22:22:16,289 : DEBUG : main : AggregateOutputNodeFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,507 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("X_Partitioner (#2)") is not locked
2016-01-13 22:22:16,523 : DEBUG : main : XValidatePartitionerFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,523 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("Decision Tree Learner (#14)") is not locked
2016-01-13 22:22:16,554 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,617 : DEBUG : main : FileNodeContainerMetaPersistor : Cross Validation : 1:0 : Workflow being loaded ("Decision Tree Predictor (#15)") is not locked
2016-01-13 22:22:16,617 : DEBUG : main : DecTreePredictorNodeFactory : Cross Validation : 1:0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,679 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:14(1) to node 1:0:15(1)
2016-01-13 22:22:16,679 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:2(1) to node 1:0:14(1)
2016-01-13 22:22:16,679 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:2(2) to node 1:0:15(2)
2016-01-13 22:22:16,679 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0(0) to node 1:0:2(1)
2016-01-13 22:22:16,695 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:1(2) to node 1:0(1)
2016-01-13 22:22:16,695 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:1(1) to node 1:0(0)
2016-01-13 22:22:16,695 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:0:15(1) to node 1:0:1(1)
2016-01-13 22:22:16,726 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Cross Validation"  with no errors
2016-01-13 22:22:16,726 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'cross_validation': Cross Validation
2016-01-13 22:22:16,726 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Feature Elimination/
2016-01-13 22:22:16,726 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Feature Elimination
2016-01-13 22:22:16,741 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Feature Elimination") is not locked
2016-01-13 22:22:16,741 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Feature Elimination" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:16,757 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:1
2016-01-13 22:22:16,757 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination Start _1_1_ (#1)") is not locked
2016-01-13 22:22:16,773 : DEBUG : main : BWElimLoopStart1NodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,773 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination Filter (#2)") is not locked
2016-01-13 22:22:16,788 : DEBUG : main : BWElimFilterNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,804 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Backward Feature Elimination End (#3)") is not locked
2016-01-13 22:22:16,804 : DEBUG : main : BWElimLoopEndNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,819 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Partitioning (#7)") is not locked
2016-01-13 22:22:16,835 : DEBUG : main : PartitionNodeFactory : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,835 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Naive Bayes Learner (#8)") is not locked
2016-01-13 22:22:16,866 : DEBUG : main : NaiveBayesLearnerNodeFactory2 : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,866 : DEBUG : main : FileNodeContainerMetaPersistor : Feature Elimination : 1:1 : Workflow being loaded ("Naive Bayes Predictor (#9)") is not locked
2016-01-13 22:22:16,882 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Feature Elimination : 1:1 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:16,897 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:3(2) to node 1:1:2(1)
2016-01-13 22:22:16,897 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:8(1) to node 1:1:9(1)
2016-01-13 22:22:16,897 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:1(1) to node 1:1:7(1)
2016-01-13 22:22:16,897 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:9(1) to node 1:1:3(1)
2016-01-13 22:22:16,897 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:3(1) to node 1:1(0)
2016-01-13 22:22:16,897 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1(1) to node 1:1:2(2)
2016-01-13 22:22:16,897 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:2(1) to node 1:1(1)
2016-01-13 22:22:16,913 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:7(2) to node 1:1:9(2)
2016-01-13 22:22:16,913 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1(0) to node 1:1:1(1)
2016-01-13 22:22:16,913 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:1:7(1) to node 1:1:8(1)
2016-01-13 22:22:16,929 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Feature Elimination"  with no errors
2016-01-13 22:22:16,929 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'feature_elimination': Feature Elimination
2016-01-13 22:22:16,929 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Variables Loop (Data)/
2016-01-13 22:22:16,929 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Variables Loop (Data)
2016-01-13 22:22:16,944 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Variables Loop (Data)") is not locked
2016-01-13 22:22:16,944 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Data)" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:16,944 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:2
2016-01-13 22:22:16,944 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 22:22:16,960 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Row To Variable Loop Start (#3)") is not locked
2016-01-13 22:22:16,975 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Data) : 1:2 : Workflow being loaded ("Inject Variables _Data_ (#4)") is not locked
2016-01-13 22:22:16,991 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2:3(1) to node 1:2:4(2)
2016-01-13 22:22:16,991 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2(1) to node 1:2:3(1)
2016-01-13 22:22:16,991 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2(0) to node 1:2:4(1)
2016-01-13 22:22:16,991 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:2:2(1) to node 1:2(0)
2016-01-13 22:22:17,007 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Data)"  with no errors
2016-01-13 22:22:17,022 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'variables_loop': Variables Loop (Data)
2016-01-13 22:22:17,022 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Variables Loop (Database)/
2016-01-13 22:22:17,022 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Variables Loop (Database)
2016-01-13 22:22:17,022 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Variables Loop (Database)") is not locked
2016-01-13 22:22:17,022 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Database)" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:17,038 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:3
2016-01-13 22:22:17,038 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 22:22:17,038 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Row To Variable Loop Start (#3)") is not locked
2016-01-13 22:22:17,053 : DEBUG : main : FileNodeContainerMetaPersistor : Variables Loop (Database) : 1:3 : Workflow being loaded ("Inject Variables _Database_ (#4)") is not locked
2016-01-13 22:22:17,069 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3:3(1) to node 1:3:4(2)
2016-01-13 22:22:17,069 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3(1) to node 1:3:3(1)
2016-01-13 22:22:17,069 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3(0) to node 1:3:4(1)
2016-01-13 22:22:17,069 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:3:2(1) to node 1:3(0)
2016-01-13 22:22:17,085 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Variables Loop (Database)"  with no errors
2016-01-13 22:22:17,085 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'variables_loop_db': Variables Loop (Database)
2016-01-13 22:22:17,085 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Iterate list of files/
2016-01-13 22:22:17,085 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Iterate list of files
2016-01-13 22:22:17,100 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Iterate list of files") is not locked
2016-01-13 22:22:17,100 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Iterate list of files" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:17,100 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:4
2016-01-13 22:22:17,100 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("TableRow To Variable Loop Start (#2)") is not locked
2016-01-13 22:22:17,116 : DEBUG : main : LoopStartVariableNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,116 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("Loop End (#3)") is not locked
2016-01-13 22:22:17,131 : DEBUG : main : LoopEndNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,131 : DEBUG : main : FileNodeContainerMetaPersistor : Iterate List of Files : 1:4 : Workflow being loaded ("File Reader (#4)") is not locked
2016-01-13 22:22:17,194 : DEBUG : main : FileReaderNodeFactory : Iterate List of Files : 1:4 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,209 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:2(1) to node 1:4:4(0)
2016-01-13 22:22:17,209 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:4(1) to node 1:4:3(1)
2016-01-13 22:22:17,209 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4:3(1) to node 1:4(0)
2016-01-13 22:22:17,209 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:4(0) to node 1:4:2(1)
2016-01-13 22:22:17,365 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Iterate list of files"  with no errors
2016-01-13 22:22:17,365 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'iterate_list_of_files': Iterate List of Files
2016-01-13 22:22:17,365 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Looper/
2016-01-13 22:22:17,365 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Looper
2016-01-13 22:22:17,365 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Looper") is not locked
2016-01-13 22:22:17,365 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Looper" (version "V200" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:17,365 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:5
2016-01-13 22:22:17,365 : DEBUG : main : FileNodeContainerMetaPersistor : Loop x-times : 1:5 : Workflow being loaded ("Counting Loop Start (#1)") is not locked
2016-01-13 22:22:17,381 : DEBUG : main : FileNodeContainerMetaPersistor : Loop x-times : 1:5 : Workflow being loaded ("Loop End (#2)") is not locked
2016-01-13 22:22:17,397 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:5:2(1) to node 1:5(0)
2016-01-13 22:22:17,397 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:5(0) to node 1:5:1(1)
2016-01-13 22:22:17,412 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Program Files\KNIME_SDK\plugins\org.knime.base_3.1.0.v201512020906\metanode_templates\Looper"  with no errors
2016-01-13 22:22:17,412 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'looper': Loop x-times
2016-01-13 22:22:17,412 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Boosting Learner/
2016-01-13 22:22:17,428 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Boosting Learner
2016-01-13 22:22:17,428 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Boosting Learner") is not locked
2016-01-13 22:22:17,428 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Learner" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:17,443 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:6
2016-01-13 22:22:17,443 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Boosting Learner Loop Start (#1)") is not locked
2016-01-13 22:22:17,459 : DEBUG : main : BoostingLearnerLoopStartNodeFactory : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,459 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Boosting Learner Loop End (#4)") is not locked
2016-01-13 22:22:17,459 : DEBUG : main : BoostingLearnerLoopEndNodeFactory : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,475 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Naive Bayes Learner (#7)") is not locked
2016-01-13 22:22:17,475 : DEBUG : main : NaiveBayesLearnerNodeFactory2 : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,475 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Learner : 1:6 : Workflow being loaded ("Naive Bayes Predictor (#8)") is not locked
2016-01-13 22:22:17,490 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Boosting Learner : 1:6 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,490 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:7(1) to node 1:6:4(1)
2016-01-13 22:22:17,490 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:1(1) to node 1:6:7(1)
2016-01-13 22:22:17,490 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:1(2) to node 1:6:8(2)
2016-01-13 22:22:17,490 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:4(1) to node 1:6(0)
2016-01-13 22:22:17,490 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:8(1) to node 1:6:4(2)
2016-01-13 22:22:17,490 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6(0) to node 1:6:1(1)
2016-01-13 22:22:17,506 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:6:7(1) to node 1:6:8(1)
2016-01-13 22:22:17,521 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Learner"  with no errors
2016-01-13 22:22:17,521 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.boosting_learner': Boosting Learner
2016-01-13 22:22:17,521 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Boosting Predictor/
2016-01-13 22:22:17,521 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Boosting Predictor
2016-01-13 22:22:17,521 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Boosting Predictor") is not locked
2016-01-13 22:22:17,521 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Predictor" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:17,521 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:7
2016-01-13 22:22:17,537 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Boosting Predictor Loop Start (#1)") is not locked
2016-01-13 22:22:17,537 : DEBUG : main : BoostingPredictorLoopStartNodeFactory : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,553 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Boosting Predictor Loop End (#3)") is not locked
2016-01-13 22:22:17,553 : DEBUG : main : BoostingPredictorLoopEndNodeFactory : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,568 : DEBUG : main : FileNodeContainerMetaPersistor : Boosting Predictor : 1:7 : Workflow being loaded ("Naive Bayes Predictor (#4)") is not locked
2016-01-13 22:22:17,568 : DEBUG : main : NaiveBayesPredictorNodeFactory2 : Boosting Predictor : 1:7 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,568 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:1(1) to node 1:7:4(1)
2016-01-13 22:22:17,568 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:4(1) to node 1:7:3(1)
2016-01-13 22:22:17,568 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7(1) to node 1:7:4(2)
2016-01-13 22:22:17,584 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7:3(1) to node 1:7(0)
2016-01-13 22:22:17,584 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:7(0) to node 1:7:1(1)
2016-01-13 22:22:17,584 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Boosting Predictor"  with no errors
2016-01-13 22:22:17,584 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.boosting_predictor': Boosting Predictor
2016-01-13 22:22:17,584 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Delegating/
2016-01-13 22:22:17,599 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Delegating
2016-01-13 22:22:17,599 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Delegating") is not locked
2016-01-13 22:22:17,599 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Delegating" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:17,599 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:8
2016-01-13 22:22:17,615 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Filter well (#61)") is not locked
2016-01-13 22:22:17,615 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Decision Tree Learner (#62)") is not locked
2016-01-13 22:22:17,631 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,631 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Recursive Loop Start (#63)") is not locked
2016-01-13 22:22:17,631 : DEBUG : main : RecursiveLoopStartNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,646 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Recursive Loop End (#64)") is not locked
2016-01-13 22:22:17,646 : DEBUG : main : RecursiveLoopEndNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,646 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("PMML Predictor (#65)") is not locked
2016-01-13 22:22:17,662 : DEBUG : main : PMMLPredictor2NodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,677 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("Reference Column Filter (#66)") is not locked
2016-01-13 22:22:17,693 : DEBUG : main : ColumnFilterRefNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,693 : DEBUG : main : FileNodeContainerMetaPersistor : Delegating : 1:8 : Workflow being loaded ("PMML To Cell (#67)") is not locked
2016-01-13 22:22:17,709 : DEBUG : main : PMMLPortToCellNodeFactory : Delegating : 1:8 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,709 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:8:61
2016-01-13 22:22:17,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8(0) to node 1:8:63(1)
2016-01-13 22:22:17,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:62(1)
2016-01-13 22:22:17,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:66(1) to node 1:8:64(2)
2016-01-13 22:22:17,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:67(1) to node 1:8:64(1)
2016-01-13 22:22:17,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:65(1) to node 1:8:61(0)
2016-01-13 22:22:17,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:62(1) to node 1:8:67(1)
2016-01-13 22:22:17,709 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:66(2)
2016-01-13 22:22:17,724 : DEBUG : main : Workflow :  :  : Triggering graph analysis on 1:8:61
2016-01-13 22:22:17,724 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:63(1) to node 1:8:65(2)
2016-01-13 22:22:17,724 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:66(1)
2016-01-13 22:22:17,724 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:62(1) to node 1:8:65(1)
2016-01-13 22:22:17,724 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:64(1) to node 1:8(0)
2016-01-13 22:22:17,724 : DEBUG : main : FileNodeContainerMetaPersistor : Filter well predicted rows : 1:8:61 : Workflow being loaded ("Joiner (#61)") is not locked
2016-01-13 22:22:17,740 : DEBUG : main : Joiner2NodeFactory : Filter well predicted rows : 1:8:61 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,755 : DEBUG : main : FileNodeContainerMetaPersistor : Filter well predicted rows : 1:8:61 : Workflow being loaded ("Reference Row Filter (#62)") is not locked
2016-01-13 22:22:17,755 : DEBUG : main : RowFilterRefNodeFactory : Filter well predicted rows : 1:8:61 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,771 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61:62(1) to node 1:8:61(0)
2016-01-13 22:22:17,771 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:62(1)
2016-01-13 22:22:17,771 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:61(1)
2016-01-13 22:22:17,771 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61(0) to node 1:8:61:61(2)
2016-01-13 22:22:17,771 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:8:61:61(1) to node 1:8:61:62(2)
2016-01-13 22:22:17,787 : DEBUG : main : Workflow :  :  : Triggering graph analysis on 1:8:61
2016-01-13 22:22:17,787 : DEBUG : main : NodeContainer :  :  : Recursive Loop Start 1:8:63 has new state: IDLE
2016-01-13 22:22:17,787 : DEBUG : main : NodeContainer :  :  : Decision Tree Learner (deprecated) 1:8:62 has new state: IDLE
2016-01-13 22:22:17,787 : DEBUG : main : NodeContainer :  :  : PMML Predictor 1:8:65 has new state: IDLE
2016-01-13 22:22:17,787 : DEBUG : main : NodeContainer :  :  : PMML To Cell 1:8:67 has new state: IDLE
2016-01-13 22:22:17,802 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Delegating"  with warnings
2016-01-13 22:22:17,802 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.delegated_learning': Delegating
2016-01-13 22:22:17,802 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Bagging/
2016-01-13 22:22:17,802 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Bagging
2016-01-13 22:22:17,802 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Bagging") is not locked
2016-01-13 22:22:17,802 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Bagging" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:17,818 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:9
2016-01-13 22:22:17,818 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Model Loop End (#7)") is not locked
2016-01-13 22:22:17,833 : DEBUG : main : ModelLoopEndNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,833 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Model Loop Start (#8)") is not locked
2016-01-13 22:22:17,849 : DEBUG : main : ModelLoopStartNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,849 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Voting Loop End (#9)") is not locked
2016-01-13 22:22:17,865 : DEBUG : main : VotingLoopEndNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,865 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Chunk Loop Start (#12)") is not locked
2016-01-13 22:22:17,880 : DEBUG : main : LoopStartChunkNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,880 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Shuffle (#13)") is not locked
2016-01-13 22:22:17,880 : DEBUG : main : ShuffleNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,880 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Decision Tree Learner (#14)") is not locked
2016-01-13 22:22:17,896 : DEBUG : main : DecisionTreeLearnerNodeFactory2 : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,896 : DEBUG : main : FileNodeContainerMetaPersistor : Bagging : 1:9 : Workflow being loaded ("Decision Tree Predictor (#15)") is not locked
2016-01-13 22:22:17,896 : DEBUG : main : DecTreePredictorNodeFactory : Bagging : 1:9 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,911 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9(1) to node 1:9:15(2)
2016-01-13 22:22:17,911 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:13(1) to node 1:9:12(1)
2016-01-13 22:22:17,911 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:12(1) to node 1:9:14(1)
2016-01-13 22:22:17,911 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9(0) to node 1:9:13(1)
2016-01-13 22:22:17,911 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:9(1) to node 1:9(0)
2016-01-13 22:22:17,911 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:15(1) to node 1:9:9(1)
2016-01-13 22:22:17,911 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:8(1) to node 1:9:15(1)
2016-01-13 22:22:17,911 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:14(1) to node 1:9:7(1)
2016-01-13 22:22:17,911 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:9:7(1) to node 1:9:8(1)
2016-01-13 22:22:17,943 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\303\0\.cp\metanode_templates\Bagging"  with no errors
2016-01-13 22:22:17,943 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'org.knime.ensembles.bagging': Bagging
2016-01-13 22:22:17,943 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Seasonality Correction/
2016-01-13 22:22:17,943 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Seasonality Correction
2016-01-13 22:22:17,958 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Seasonality Correction") is not locked
2016-01-13 22:22:17,958 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Seasonality Correction" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:17,958 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:10
2016-01-13 22:22:17,958 : DEBUG : main : FileNodeContainerMetaPersistor : Seasonality Correction : 1:10 : Workflow being loaded ("Lag Column (#24)") is not locked
2016-01-13 22:22:17,978 : DEBUG : main : LagColumnNodeFactory : Seasonality Correction : 1:10 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,980 : DEBUG : main : FileNodeContainerMetaPersistor : Seasonality Correction : 1:10 : Workflow being loaded ("Java Snippet _simple_ (#25)") is not locked
2016-01-13 22:22:17,992 : DEBUG : main : JavaScriptingNodeFactory : Seasonality Correction : 1:10 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:17,999 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10:24(1) to node 1:10:25(1)
2016-01-13 22:22:17,999 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10:25(1) to node 1:10(0)
2016-01-13 22:22:17,999 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:10(0) to node 1:10:24(1)
2016-01-13 22:22:18,004 : DEBUG : main : NodeContainer :  :  : Lag Column 1:10:24 has new state: IDLE
2016-01-13 22:22:18,005 : DEBUG : main : NodeContainer :  :  : Java Snippet (simple) 1:10:25 has new state: IDLE
2016-01-13 22:22:18,005 : DEBUG : main : NodeContainer :  :  : Seasonality Correction 1:10 has new state: IDLE
2016-01-13 22:22:18,006 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Seasonality Correction"  with warnings
2016-01-13 22:22:18,006 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'SeasonalityCorrection': Seasonality Correction
2016-01-13 22:22:18,006 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Time Series Auto-Prediction Training/
2016-01-13 22:22:18,009 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Time Series Auto-Prediction Training
2016-01-13 22:22:18,013 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Time Series Auto-Prediction Training") is not locked
2016-01-13 22:22:18,014 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Training" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:18,021 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:11
2016-01-13 22:22:18,022 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Partitioning (#147)") is not locked
2016-01-13 22:22:18,029 : DEBUG : main : PartitionNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:18,030 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Lag Column (#216)") is not locked
2016-01-13 22:22:18,042 : DEBUG : main : LagColumnNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:18,043 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Training : 1:11 : Workflow being loaded ("Linear Regression Learner (#234)") is not locked
2016-01-13 22:22:18,056 : DEBUG : main : LinReg2LearnerNodeFactory : Time Series Auto-Prediction Training : 1:11 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:18,074 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:234(1) to node 1:11(0)
2016-01-13 22:22:18,074 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:234(2) to node 1:11(1)
2016-01-13 22:22:18,074 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11(0) to node 1:11:216(1)
2016-01-13 22:22:18,075 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:147(1) to node 1:11:234(1)
2016-01-13 22:22:18,075 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:216(1) to node 1:11:147(1)
2016-01-13 22:22:18,075 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:11:147(2) to node 1:11(2)
2016-01-13 22:22:18,093 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Training"  with no errors
2016-01-13 22:22:18,094 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'Time-SeriesAuto-PredictionTraining': Time-Series Auto-Prediction Training
2016-01-13 22:22:18,094 : DEBUG : main : RepositoryFactory :  :  : found pre-installed template metanode_templates/Time Series Auto-Prediction Predictor/
2016-01-13 22:22:18,097 : DEBUG : main : RepositoryFactory :  :  : meta node template name: Time Series Auto-Prediction Predictor
2016-01-13 22:22:18,110 : DEBUG : main : FileNodeContainerMetaPersistor :  :  : Workflow being loaded ("Time Series Auto-Prediction Predictor") is not locked
2016-01-13 22:22:18,110 : DEBUG : main : WorkflowManager :  :  : Loading workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Predictor" (version "V2100" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:18,116 : DEBUG : main : WorkflowManager :  :  : Created subworkflow 1:12
2016-01-13 22:22:18,120 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Predictor : 1:12 : Workflow being loaded ("Numeric Scorer (#176)") is not locked
2016-01-13 22:22:18,134 : DEBUG : main : NumericScorerNodeFactory : Time Series Auto-Prediction Predictor : 1:12 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:18,137 : DEBUG : main : FileNodeContainerMetaPersistor : Time Series Auto-Prediction Predictor : 1:12 : Workflow being loaded ("Regression Predictor (#237)") is not locked
2016-01-13 22:22:18,145 : DEBUG : main : RegressionPredictorNodeFactory : Time Series Auto-Prediction Predictor : 1:12 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:18,150 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12(1) to node 1:12:237(2)
2016-01-13 22:22:18,151 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:237(1) to node 1:12(0)
2016-01-13 22:22:18,151 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12(0) to node 1:12:237(1)
2016-01-13 22:22:18,151 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:237(1) to node 1:12:176(1)
2016-01-13 22:22:18,151 : DEBUG : main : WorkflowManager :  :  : Added new connection from node 1:12:176(1) to node 1:12(1)
2016-01-13 22:22:18,158 : DEBUG : main : WorkflowManager :  :  : Loaded workflow from "C:\Users\SONY\workspaceKNIME31\.metadata\.plugins\org.eclipse.pde.core\New_configuration\org.eclipse.osgi\314\0\.cp\metanode_templates\Time Series Auto-Prediction Predictor"  with no errors
2016-01-13 22:22:18,158 : DEBUG : main : RepositoryManager :  :  : Found meta node definition 'Time-SeriesAuto-PredictionPredictor': Time-Series Auto-Prediction Predictor
2016-01-13 22:22:18,485 : DEBUG : main : KNIMEEditorPlugin :  :  : Workflow SVG export not available, unable to instantiate "org.knime.workbench.editor.svgexport.exportservice.WorkflowSVGExportImpl"
2016-01-13 22:22:22,822 : ERROR : main : CategorySorter :  :  : CODING PROBLEM	After-ID 'toolintegration' of [Id: community Name: Community Nodes After-id: toolintegration] does not exist - in plug-in org.knime.base
2016-01-13 22:22:27,210 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".all" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:22:27,210 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".csv" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:22:27,226 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".csv.gz" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:22:27,226 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".pmml" registered for Node Factory: PMMLReaderNodeFactory.
2016-01-13 22:22:27,226 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".table" registered for Node Factory: ReadTableNodeFactory.
2016-01-13 22:22:27,226 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".tsv" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:22:27,226 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".txt" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:22:27,226 : DEBUG : main : ContextAwareNodeFactoryMapper :  :  : File extension: ".txt.gz" registered for Node Factory: FileReaderNodeFactory.
2016-01-13 22:22:33,749 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ================= Starting testflow WorkflowTests\GitOfflineTest =================
2016-01-13 22:22:33,749 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ================= Average load: -1,00 =================
2016-01-13 22:22:33,749 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test load workflow -----------------
2016-01-13 22:22:33,764 : DEBUG : Worker-0 : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:33,780 : DEBUG : Worker-0 : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:22:33,780 : DEBUG : Worker-0 : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:22:33,858 : DEBUG : Worker-0 : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:33,874 : DEBUG : Worker-0 : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:33,889 : DEBUG : Worker-0 : DifferenceCheckerNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:33,905 : DEBUG : Worker-0 : WorkflowManager :  :  : Added new connection from node 0:2(1) to node 0:3(2)
2016-01-13 22:22:33,905 : DEBUG : Worker-0 : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:3(1)
2016-01-13 22:22:34,092 : DEBUG : Worker-0 : Git SCM : Git SCM : 0:1 : Configure succeeded. (Git SCM)
2016-01-13 22:22:34,139 : DEBUG : Worker-0 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:22:34,139 : DEBUG : Worker-0 : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest"  with no errors
2016-01-13 22:22:34,279 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:22:34,326 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:22:34,544 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:22:34,544 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on 0 - GitOfflineTest
2016-01-13 22:22:34,544 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:22:34,919 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:22:35,044 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:22:35,044 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:22:35,059 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:1 (CONFIGURED) )
2016-01-13 22:22:35,215 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:22:35,215 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:35,215 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:2 (EXECUTED) )
2016-01-13 22:22:35,215 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:22:35,215 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:35,215 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:3 (CONFIGURED) )
2016-01-13 22:22:35,231 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:22:35,231 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:35,231 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:22:35,231 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:36,650 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test load workflow -----------------
2016-01-13 22:22:36,650 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test open views -----------------
2016-01-13 22:22:36,713 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test open views -----------------
2016-01-13 22:22:36,713 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test execute workflow -----------------
2016-01-13 22:22:36,713 : DEBUG : Worker-0 : NodeContainer :  :  : Setting dirty flag on Git SCM 0:1
2016-01-13 22:22:36,713 : DEBUG : Worker-0 : NodeContainer :  :  : Setting dirty flag on GitOfflineTest 0
2016-01-13 22:22:36,713 : DEBUG : Worker-0 : NodeContainer :  :  : Git SCM 0:1 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:22:36,713 : DEBUG : Worker-0 : NodeContainer :  :  : Git SCM 0:1 has new state: CONFIGURED_QUEUED
2016-01-13 22:22:36,744 : DEBUG : Worker-0 : NodeContainer :  :  : Setting dirty flag on Table Difference Checker 0:3
2016-01-13 22:22:36,744 : DEBUG : Worker-0 : NodeContainer :  :  : Table Difference Checker 0:3 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:22:36,744 : DEBUG : Worker-0 : NodeContainer :  :  : GitOfflineTest 0 has new state: EXECUTING
2016-01-13 22:22:36,744 : DEBUG : Worker-0 : NodeContainer :  :  : ROOT  has new state: EXECUTING
2016-01-13 22:22:36,760 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=0;old=null;new=null;timestamp=2016-01-13 22:22:36]
2016-01-13 22:22:37,025 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:1 : Git SCM 0:1 doBeforePreExecution
2016-01-13 22:22:37,025 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:1 : Git SCM 0:1 has new state: PREEXECUTE
2016-01-13 22:22:37,025 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:1 : Git SCM 0:1 doBeforeExecution
2016-01-13 22:22:37,025 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:1 : Git SCM 0:1 has new state: EXECUTING
2016-01-13 22:22:37,025 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Git SCM : 0:1 : Adding handler 459a05d6-09b1-43a3-a028-bf9574fe1a97 (Git SCM 0:1: <no directory>) - 1 in total
2016-01-13 22:22:37,025 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Git SCM : 0:1 : Git SCM 0:1 Start execute
2016-01-13 22:22:37,040 : INFO  : KNIME-Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Reading git logs from file file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/Git%20SCM%20(%231)/drop/git-test-log.txt
2016-01-13 22:22:37,165 : INFO  : KNIME-Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Reading git logs finished
2016-01-13 22:22:37,196 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:22:37,196 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitTableFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitTableFactory.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 965885f3c9f03b62a41e79d8f95d3e0b2620215f
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.test.org.impressivecode.depress.scm.git.GitTableFactoryTest, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=GitTableFactory now extends SCMAdapterTableFactory. Also added tests., path=ic-depress-scm-git/test/org/impressivecode/depress/scm/git/GitTableFactoryTest.java, commitDate=Sun Mar 24 23:46:28 CET 2013, commitID=965885f3c9f03b62a41e79d8f95d3e0b2620215f]
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommit, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommit.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommitFile, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommitFile.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 87697b97fd92f7d492f97d5bd3dbc12839f3e11f
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitCommitFileOperation, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Added classes GitCommit, GitCommitFile and enum GitCommitFileOperation, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitCommitFileOperation.java, commitDate=Sun Mar 24 22:37:59 CET 2013, commitID=87697b97fd92f7d492f97d5bd3dbc12839f3e11f]
2016-01-13 22:22:37,274 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:22:37,290 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-base/src/org/impressivecode/depress/its/ITSAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:22:37,290 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:22:37,290 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.its.ITSAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-base/test/org/impressivecode/depress/its/ITSAdapterTransformerTest.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:22:37,290 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:22:37,290 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:22:37,290 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#27 snapshot generated, classpath loading issues fixed, path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformer.java, commitDate=Sun Mar 24 21:15:47 CET 2013, commitID=7cd9a5169dc2acca345ecbc800a5b2e2966eb8dd]
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:22:37,415 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:22:37,430 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:22:37,430 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:22:37,430 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:22:37,430 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:22:37,430 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:22:37,430 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:22:37,477 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754
2016-01-13 22:22:37,477 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-its-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Jira #27 refactored, path=ic-depress-its-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:52:36 CET 2013, commitID=c7e3aa6e9b9616a33dc1c5d8cde471f3f8a00754]
2016-01-13 22:22:37,493 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:22:37,508 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:22:37,508 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:22:37,508 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:22:37,508 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:22:37,508 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:22:37,508 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:22:37,508 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:22:37,508 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:22:37,508 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b720056a3ac5c4376ec848ca23bc102cb1b2adb8
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=Jira #27 refactored, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:52:12 CET 2013, commitID=b720056a3ac5c4376ec848ca23bc102cb1b2adb8]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSAdapterTableFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSDataType, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSDataType.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSPriority, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSPriority.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSResolution, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSResolution.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSStatus, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSStatus.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.its.ITSType, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/src/org/impressivecode/depress/its/ITSType.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.its.ITSAdapterTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-base/test/org/impressivecode/depress/its/ITSAdapterTableFactoryTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,524 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeDialog.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterNodeModel.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTableFactory.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraAdapterTransformer.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.src.org.impressivecode.depress.its.jira.JiraEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/src/org/impressivecode/depress/its/jira/JiraEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraAdapterTransformerTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jira.test.org.impressivecode.depress.its.jira.JiraEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-jira/test/org/impressivecode/depress/its/jira/JiraEntriesParserTest.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: d3c846764dc14788b7fa14cff5992bf4482f7f14
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=JIRA Adapter plugin introduced, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Sun Mar 24 19:42:01 CET 2013, commitID=d3c846764dc14788b7fa14cff5992bf4482f7f14]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeDialog.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeFactory.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:22:37,540 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterNodeModel.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTableFactory.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformer.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParser.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.src.org.impressivecode.depress.metric.jacoco.JaCoCoEntry, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/src/org/impressivecode/depress/metric/jacoco/JaCoCoEntry.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.test.org.impressivecode.depress.metric.jacoco.JaCoCoAdapterTransformerTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/test/org/impressivecode/depress/metric/jacoco/JaCoCoAdapterTransformerTest.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-jacoco.test.org.impressivecode.depress.metric.jacoco.JaCoCoEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#24 JaCoCo Adapter introduced, , path=ic-depress-metric-jacoco/test/org/impressivecode/depress/metric/jacoco/JaCoCoEntriesParserTest.java, commitDate=Wed Mar 20 21:53:38 CET 2013, commitID=8b6ba1135b2a2b70cb22ea15660c6f99f7da2b75]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeDataTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeDataTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:22:37,555 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 102d22f2709dfc9aaee34a1e176bfe1304a4f2f1
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberDataTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 bug fixes, added help, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberDataTransformer.java, commitDate=Tue Mar 19 22:08:42 CET 2013, commitID=102d22f2709dfc9aaee34a1e176bfe1304a4f2f1]
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeData, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,586 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeDataTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeDataTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetric, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetric.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricProcessor, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricProcessor.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberDataTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberDataTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberTransformer, extension=java, author=Marek Majchrzak, operation=DELETED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberTransformer.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 45a2beca9d97777733e1a472e54c003551b7d9b1
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.test.org.impressivecode.depress.metric.po.PeopleOrganizationMetricProcessorTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 base version of PO Metric introduced, #18 this is just matcher test, path=ic-depress-metric-po/test/org/impressivecode/depress/metric/po/PeopleOrganizationMetricProcessorTest.java, commitDate=Mon Mar 18 20:49:14 CET 2013, commitID=45a2beca9d97777733e1a472e54c003551b7d9b1]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:22:37,602 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 777d085008ee849a13885afbcf1c12cc1c8a70f5
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#16 fixed @author tags, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Mon Mar 18 00:56:51 CET 2013, commitID=777d085008ee849a13885afbcf1c12cc1c8a70f5]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 968a800d55cd3a3b5d0acc9266c2efa77e5aa47f
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.PluginApp, extension=java, author=Tomasz Kuzemko, operation=MODIFIED, message=#15 copyright info fixed, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/PluginApp.java, commitDate=Mon Mar 18 00:52:19 CET 2013, commitID=968a800d55cd3a3b5d0acc9266c2efa77e5aa47f]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: aa987c2d809340e77f473a5920f4d6f6e43500ff
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 05 23:34:57 CET 2013, commitID=aa987c2d809340e77f473a5920f4d6f6e43500ff]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.ChangeHistoryTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/ChangeHistoryTransformer.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.MetricProcessor, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/MetricProcessor.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:22:37,618 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberData, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberData.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c2ce7b172902ecf45e8e5ba21893feb993d9cd6f
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.TeamMemberTransformer, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Metric update #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/TeamMemberTransformer.java, commitDate=Tue Mar 05 23:33:28 CET 2013, commitID=c2ce7b172902ecf45e8e5ba21893feb993d9cd6f]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 893f71a008c813fe0daaa50fba184fed66e0230b
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Sawek Kaposki, operation=MODIFIED, message=#12 Added methods for load, save and validating config values, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Mon Mar 04 22:31:08 CET 2013, commitID=893f71a008c813fe0daaa50fba184fed66e0230b]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 907348573f0b3f74a644e962128cc2c855610239
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitTableFactory, extension=java, author=Sawek Kaposki, operation=ADDED, message=#12 Added class GitTableFactory with Input tables creating method. Methods which will generate output table is not created yet, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitTableFactory.java, commitDate=Mon Mar 04 22:29:44 CET 2013, commitID=907348573f0b3f74a644e962128cc2c855610239]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-checkstyle.src.org.impressivecode.depress.metric.checkstyle.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-checkstyle/src/org/impressivecode/depress/metric/checkstyle/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-findbug.src.org.impressivecode.depress.metric.findbug.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-findbug/src/org/impressivecode/depress/metric/findbug/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:22:37,633 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-pmd.src.org.impressivecode.depress.metric.pmd.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-metric-pmd/src/org/impressivecode/depress/metric/pmd/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b4f3088d8894ac224535a31ccf4d1600d3fc0c57
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-common.src.org.impressivecode.depress.scm.common.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=new plugins (findbug, pmd, checkstyle) project introduced, path=ic-depress-scm-common/src/org/impressivecode/depress/scm/common/PluginApp.java, commitDate=Sun Mar 03 23:47:23 CET 2013, commitID=b4f3088d8894ac224535a31ccf4d1600d3fc0c57]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 added PO Metric plugin draft, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.test.org.impressivecode.depress.scm.SCMAdapterTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#9 added PO Metric plugin draft, path=ic-depress-base/test/org/impressivecode/depress/scm/SCMAdapterTableFactoryTest.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: e34c6a9ae18f6228025e1007e04e0f0363b79c92
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#9 added PO Metric plugin draft, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Sun Mar 03 22:49:22 CET 2013, commitID=e34c6a9ae18f6228025e1007e04e0f0363b79c92]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=removed old test, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterTableFactory.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapterTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapterTableFactoryPluginTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fe5cdba6e29b07d222d1a0ea12de9fca61dc9495
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Sun Mar 03 19:49:37 CET 2013, commitID=fe5cdba6e29b07d222d1a0ea12de9fca61dc9495]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: ef1d2453bf8587aec197ebd60f8d5260f3b02692
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=DELETED, message=removed old test, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Sat Mar 02 22:05:28 CET 2013, commitID=ef1d2453bf8587aec197ebd60f8d5260f3b02692]
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,649 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.common.DataTableSpecUtils, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-base/src/org/impressivecode/depress/common/DataTableSpecUtils.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-base.src.org.impressivecode.depress.scm.SCMAdapterTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-base/src/org/impressivecode/depress/scm/SCMAdapterTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeDialog.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyXmlResult, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyXmlResult.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,664 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=PO Plugin draft #9, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.POData, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/POData.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricTableFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeDialog.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeFactory.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: c95b165d6ff6e3472483d23e4f5835efb4e51d99
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-po.src.org.impressivecode.depress.metric.po.PeopleOrganizationMetricsNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=PO Plugin draft #9, path=ic-depress-metric-po/src/org/impressivecode/depress/metric/po/PeopleOrganizationMetricsNodeModel.java, commitDate=Sat Mar 02 21:36:48 CET 2013, commitID=c95b165d6ff6e3472483d23e4f5835efb4e51d99]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Sawek Kaposki, operation=MODIFIED, message= Added config window to knime plugin., path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Sat Mar 02 10:32:02 CET 2013, commitID=791f5f97d1c7b3f5d4d5358af14d1c12f59d9b2c]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeDialog, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeDialog.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeFactory, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeFactory.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeModel, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeModel.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodePlugin, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodePlugin.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:22:37,680 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 9e0bfaf4b2449b2e81f712566f475526d30060cd
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.GitNodeView, extension=java, author=Tomasz Kuzemko, operation=ADDED, message=Importing generated plugin template files, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/GitNodeView.java, commitDate=Fri Mar 01 00:51:58 CET 2013, commitID=9e0bfaf4b2449b2e81f712566f475526d30060cd]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=#4 added progress, added tests, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyEntriesParser, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyEntriesParser.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryPluginTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryPluginTest.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: 677baf983275b6506f8d5404959c873d822bec9c
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyEntriesParserTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=#4 added progress, added tests, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyEntriesParserTest.java, commitDate=Wed Feb 27 23:20:10 CET 2013, commitID=677baf983275b6506f8d5404959c873d822bec9c]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b70ca05b7f982cf43d3f86e8a169a5c35ce46eed
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=MODIFIED, message=Test added, #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Tue Feb 26 23:27:48 CET 2013, commitID=b70ca05b7f982cf43d3f86e8a169a5c35ce46eed]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: b70ca05b7f982cf43d3f86e8a169a5c35ce46eed
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.test.org.impressivecode.depress.metric.judy.JudyAdapteTableFactoryTest, extension=java, author=Marek Majchrzak, operation=ADDED, message=Test added, #4, path=ic-depress-metric-judy/test/org/impressivecode/depress/metric/judy/JudyAdapteTableFactoryTest.java, commitDate=Tue Feb 26 23:27:48 CET 2013, commitID=b70ca05b7f982cf43d3f86e8a169a5c35ce46eed]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapteTableFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapteTableFactory.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeDialog, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeDialog.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeFactory, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeFactory.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyAdapterNodeModel, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyAdapterNodeModel.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-judy.src.org.impressivecode.depress.metric.judy.JudyXmlResult, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-judy/src/org/impressivecode/depress/metric/judy/JudyXmlResult.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metric-pitest.src.org.impressivecode.depress.metric.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=Judy Adapter prototype introduced #4, path=ic-depress-metric-pitest/src/org/impressivecode/depress/metric/pitest/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-judy.src.org.impressivecode.depress.metrics.judy.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-judy/src/org/impressivecode/depress/metrics/judy/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: fd8866f9a38e94af5b2e4eab91e1e23c2656ed41
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-pitest.src.org.impressivecode.depress.metrics.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=DELETED, message=Judy Adapter prototype introduced #4, path=ic-depress-metrics-pitest/src/org/impressivecode/depress/metrics/pitest/PluginApp.java, commitDate=Mon Feb 25 23:12:24 CET 2013, commitID=fd8866f9a38e94af5b2e4eab91e1e23c2656ed41]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-data-anonymisation.src.org.impressivecode.depress.data.anonymization.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-data-anonymisation/src/org/impressivecode/depress/data/anonymization/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:22:37,696 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-data-source.src.org.impressivecode.depress.data.source.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-data-source/src/org/impressivecode/depress/data/source/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-eclipsemetrics.src.org.impressivecode.depress.metrics.eclipsemetrics.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-eclipsemetrics/src/org/impressivecode/depress/metrics/eclipsemetrics/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-judy.src.org.impressivecode.depress.metrics.judy.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-judy/src/org/impressivecode/depress/metrics/judy/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-metrics-pitest.src.org.impressivecode.depress.metrics.pitest.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-metrics-pitest/src/org/impressivecode/depress/metrics/pitest/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-common.src.org.impressivecode.depress.scm.common.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-common/src/org/impressivecode/depress/scm/common/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-git.src.org.impressivecode.depress.scm.git.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-git/src/org/impressivecode/depress/scm/git/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming scm entry, id: a6e818bf4968ba178b982a3e73be7d36fd4f8201
2016-01-13 22:22:37,711 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : Git SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=ic-depress-scm-svn.src.org.impressivecode.depress.scm.svn.PluginApp, extension=java, author=Marek Majchrzak, operation=ADDED, message=#1 initial project structure, path=ic-depress-scm-svn/src/org/impressivecode/depress/scm/svn/PluginApp.java, commitDate=Sun Feb 24 22:12:38 CET 2013, commitID=a6e818bf4968ba178b982a3e73be7d36fd4f8201]
2016-01-13 22:22:37,727 : INFO  : KNIME-Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Transforming git logs finished.
2016-01-13 22:22:37,742 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Git SCM : 0:1 : Git SCM 0:1 End execute (0 secs)
2016-01-13 22:22:37,742 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:1 : Git SCM 0:1 doBeforePostExecution
2016-01-13 22:22:37,742 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:1 : Git SCM 0:1 has new state: POSTEXECUTE
2016-01-13 22:22:37,742 : DEBUG : KNIME-Worker-0 : WorkflowManager : Git SCM : 0:1 : Git SCM 0:1 doAfterExecute - success
2016-01-13 22:22:37,742 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:1 : Git SCM 0:1 has new state: EXECUTED
2016-01-13 22:22:37,758 : DEBUG : KNIME-Worker-0 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:22:37,758 : DEBUG : KNIME-Worker-0 : NodeContainer : Git SCM : 0:1 : Table Difference Checker 0:3 has new state: CONFIGURED_QUEUED
2016-01-13 22:22:37,883 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePreExecution
2016-01-13 22:22:37,883 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: PREEXECUTE
2016-01-13 22:22:37,883 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforeExecution
2016-01-13 22:22:37,883 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTING
2016-01-13 22:22:37,883 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Adding handler dd3a5ca1-f754-4c31-a8d0-3d27efaf8115 (Table Difference Checker 0:3: <no directory>) - 2 in total
2016-01-13 22:22:37,883 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 Start execute
2016-01-13 22:22:38,460 : DEBUG : KNIME-Worker-1 : Buffer : Table Difference Checker : 0:3 : Opening input stream on file "C:\Users\SONY\AppData\Local\Temp\knime_GitOfflineTest81135\knime_container_20160113_975219976485308629.bin.gz", 1 open streams
2016-01-13 22:22:38,554 : DEBUG : KNIME-Worker-1 : Buffer : Table Difference Checker : 0:3 : Closing input stream on "C:\Users\SONY\AppData\Local\Temp\knime_GitOfflineTest81135\knime_container_20160113_975219976485308629.bin.gz", 0 remaining
2016-01-13 22:22:38,554 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 End execute (0 secs)
2016-01-13 22:22:38,554 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePostExecution
2016-01-13 22:22:38,585 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: POSTEXECUTE
2016-01-13 22:22:38,678 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doAfterExecute - success
2016-01-13 22:22:38,678 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTED
2016-01-13 22:22:38,678 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:3 : GitOfflineTest 0 has new state: EXECUTED
2016-01-13 22:22:38,678 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test execute workflow -----------------
2016-01-13 22:22:38,678 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test node messages -----------------
2016-01-13 22:22:38,678 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test node messages -----------------
2016-01-13 22:22:38,678 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test hilite rows -----------------
2016-01-13 22:22:38,788 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:22:38,944 : DEBUG : Worker-0 : Buffer :  :  : Opening input stream on file "C:\Users\SONY\AppData\Local\Temp\knime_GitOfflineTest81135\knime_container_20160113_975219976485308629.bin.gz", 1 open streams
2016-01-13 22:22:38,959 : DEBUG : Worker-0 : Buffer :  :  : Closing input stream on "C:\Users\SONY\AppData\Local\Temp\knime_GitOfflineTest81135\knime_container_20160113_975219976485308629.bin.gz", 0 remaining
2016-01-13 22:22:38,959 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test hilite rows -----------------
2016-01-13 22:22:38,959 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test close views -----------------
2016-01-13 22:22:38,959 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test close views -----------------
2016-01-13 22:22:38,959 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test log messages -----------------
2016-01-13 22:22:38,959 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test log messages -----------------
2016-01-13 22:22:38,975 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test uncaught exceptions -----------------
2016-01-13 22:22:38,975 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test uncaught exceptions -----------------
2016-01-13 22:22:39,942 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ===== Memory statistics: 994,500 MB max, 53,905 MB used, 940,595 MB free ====
2016-01-13 22:22:39,942 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ================= Finished testflow WorkflowTests\GitOfflineTest =================
2016-01-13 22:22:40,004 : DEBUG : Service Thread : MemoryAlertSystem :  :  : Memory usage below threshold of 0.7125915080527087 after GC run
2016-01-13 22:22:41,003 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:22:41,003 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:22:41,034 : DEBUG : Worker-0 : WorkflowManager :  :  : Removing project "GitOfflineTest 0"
2016-01-13 22:22:41,159 : DEBUG : Worker-0 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Removing handler dd3a5ca1-f754-4c31-a8d0-3d27efaf8115 (Table Difference Checker 0:3: <no directory>) - 1 remaining
2016-01-13 22:22:41,174 : DEBUG : Worker-0 : DifferenceCheckerNodeModel : Table Difference Checker : 0:3 : Removing all (0) views from model.
2016-01-13 22:22:41,174 : DEBUG : Worker-0 : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:22:41,174 : DEBUG : Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Removing all (0) views from model.
2016-01-13 22:22:41,174 : DEBUG : Worker-0 : Git SCM : Git SCM : 0:2 : clean output ports.
2016-01-13 22:22:41,174 : DEBUG : Worker-0 : WorkflowFileStoreHandlerRepository : Git SCM : 0:1 : Removing handler 459a05d6-09b1-43a3-a028-bf9574fe1a97 (Git SCM 0:1: <no directory>) - 0 remaining
2016-01-13 22:22:41,174 : DEBUG : Worker-0 : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Removing all (0) views from model.
2016-01-13 22:22:41,174 : DEBUG : Worker-0 : Git SCM : Git SCM : 0:1 : clean output ports.
2016-01-13 22:22:41,174 : DEBUG : Worker-0 : WorkflowManager :  :  : Project "GitOfflineTest 0" removed (1 remaining)
2016-01-13 22:22:41,174 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ================= Starting testflow WorkflowTests\JiraOfflineTest =================
2016-01-13 22:22:41,190 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ================= Average load: -1,00 =================
2016-01-13 22:22:41,190 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test load workflow -----------------
2016-01-13 22:22:41,190 : DEBUG : Worker-0 : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:41,190 : DEBUG : Worker-0 : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:22:41,268 : DEBUG : Worker-0 : JiraAdapterNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:41,284 : DEBUG : Worker-0 : JiraAdapterNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:41,299 : DEBUG : KNIME-Temp-File-Deleter : Buffer :  :  : Deleted temporary file "C:\Users\SONY\AppData\Local\Temp\knime_GitOfflineTest81135\knime_container_20160113_975219976485308629.bin.gz"
2016-01-13 22:22:41,315 : DEBUG : Worker-0 : DifferenceCheckerNodeFactory : JiraOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:41,315 : DEBUG : Worker-0 : WorkflowManager :  :  : Added new connection from node 0:2(1) to node 0:3(2)
2016-01-13 22:22:41,315 : DEBUG : Worker-0 : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:3(1)
2016-01-13 22:22:41,330 : DEBUG : Worker-0 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:22:41,362 : DEBUG : Worker-0 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:22:41,362 : DEBUG : Worker-0 : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest"  with no errors
2016-01-13 22:22:41,408 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:22:41,408 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:22:41,455 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:22:41,455 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on 0 - JiraOfflineTest
2016-01-13 22:22:41,455 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:22:41,471 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:22:41,471 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:22:41,471 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:22:41,471 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 0:1 (CONFIGURED) )
2016-01-13 22:22:41,486 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:22:41,486 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:41,486 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 0:2 (EXECUTED) )
2016-01-13 22:22:41,486 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:22:41,486 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:41,486 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:3 (CONFIGURED) )
2016-01-13 22:22:41,486 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:22:41,486 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:41,486 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:22:41,486 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:42,235 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test load workflow -----------------
2016-01-13 22:22:42,235 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test open views -----------------
2016-01-13 22:22:42,235 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test open views -----------------
2016-01-13 22:22:42,235 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test execute workflow -----------------
2016-01-13 22:22:42,235 : DEBUG : Worker-0 : NodeContainer :  :  : Setting dirty flag on Jira Adapter (Offline) 0:1
2016-01-13 22:22:42,235 : DEBUG : Worker-0 : NodeContainer :  :  : Setting dirty flag on JiraOfflineTest 0
2016-01-13 22:22:42,235 : DEBUG : Worker-0 : NodeContainer :  :  : Jira Adapter (Offline) 0:1 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:22:42,235 : DEBUG : Worker-0 : NodeContainer :  :  : Jira Adapter (Offline) 0:1 has new state: CONFIGURED_QUEUED
2016-01-13 22:22:42,235 : DEBUG : Worker-0 : NodeContainer :  :  : Setting dirty flag on Table Difference Checker 0:3
2016-01-13 22:22:42,235 : DEBUG : Worker-0 : NodeContainer :  :  : Table Difference Checker 0:3 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:22:42,235 : DEBUG : Worker-0 : NodeContainer :  :  : JiraOfflineTest 0 has new state: EXECUTING
2016-01-13 22:22:42,235 : DEBUG : Worker-0 : NodeContainer :  :  : ROOT  has new state: EXECUTING
2016-01-13 22:22:42,235 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doBeforePreExecution
2016-01-13 22:22:42,235 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: PREEXECUTE
2016-01-13 22:22:42,235 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doBeforeExecution
2016-01-13 22:22:42,329 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: EXECUTING
2016-01-13 22:22:42,344 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:1 : Adding handler 9626c955-11ed-4030-98ea-9ccd43cbd604 (Jira Adapter (Offline) 0:1: <no directory>) - 1 in total
2016-01-13 22:22:42,344 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 Start execute
2016-01-13 22:22:42,344 : INFO  : KNIME-Worker-1 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:1 : Preparing to read jira entries.
2016-01-13 22:22:42,360 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=0;old=null;new=null;timestamp=2016-01-13 22:22:42]
2016-01-13 22:22:44,404 : INFO  : KNIME-Worker-1 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:1 : Transforming to jira entries.
2016-01-13 22:22:44,404 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-724
2016-01-13 22:22:44,404 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-724, created=Mon Dec 12 16:03:41 CET 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Tue Dec 20 22:14:16 CET 2011, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=RandomDataImpl.nextInt does not distribute uniformly for negative lower bound, link=https://issues.apache.org/jira/browse/MATH-724, description=&lt;p&gt;When using the RandomDataImpl.nextInt function to get a uniform sample in a &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt; interval, when the lower value is less than zero, the output is not uniformly distributed, as the lowest value is practically never returned.&lt;/p&gt;

&lt;p&gt;See the attached NextIntUniformTest.java file. It uses a &lt;span class="error"&gt;&amp;#91;-3, 5&amp;#93;&lt;/span&gt; interval. For several values between 0 and 1, testNextIntUniform1 prints the return value of RandomDataImpl.nextInt (as double and as int). We see that -2 through 5 are returned several times. The -3 value however, is only returned for 0.0, and is thus under-respresented in the integer samples. The output of test method testNextIntUniform2 also clearly shows that value -3 is never sampled.&lt;/p&gt;, comments=[&lt;p&gt;NextIntUniformTest.java: see issue description&lt;/p&gt;
, &lt;p&gt;Thanks for reporting this. The problem is in the rounding, which does not work correctly for negative values.  My first inclination is to test for negative lower bound and just shift the interval in that case.  Any better ideas?&lt;/p&gt;
, &lt;p&gt;math-724.patch: it first scales the [0..1) interval to [0..length), then discretizes it, and finally shifts it to &lt;span class="error"&gt;&amp;#91;lower, upper&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;It may be a good idea to also add some tests for cases such as &lt;span class="error"&gt;&amp;#91;0,3&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-3,5&amp;#93;&lt;/span&gt;, &lt;span class="error"&gt;&amp;#91;-5, -3&amp;#93;&lt;/span&gt;, and see if the distribution of sampled values is uniform. It seems RandomDataTest.testNextInt does this using chiSquare, but since I'm not familiar with that, I'm not sure how to add more tests for the other lower/upper bound pairs...&lt;/p&gt;
, &lt;p&gt;I just ran the unit tests with my patch applied, an the following test, in RandomDataTest:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;@Test
    &lt;span class="code-keyword"&gt;public&lt;/span&gt; void testNextIntExtremeValues() {
        &lt;span class="code-object"&gt;int&lt;/span&gt; x = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        &lt;span class="code-object"&gt;int&lt;/span&gt; y = randomData.nextInt(&lt;span class="code-object"&gt;Integer&lt;/span&gt;.MIN_VALUE, &lt;span class="code-object"&gt;Integer&lt;/span&gt;.MAX_VALUE);
        Assert.assertFalse(x == y);
    }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails, as does testNextLongExtremeValues. Both x and y become equal to Integer.MIN_VALUE, making x == y to become true, causing the assertion to fail...&lt;/p&gt;
, &lt;p&gt;Also note that RandomDataImpl.nextUniform uses a similar scale/shift method to transform the range. It may thus suffer from the same failure in case of extreme values...&lt;/p&gt;
, &lt;p&gt;math-724-v2.patch: 2nd patch.&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;I think all unit tests work now, including the ones for the Integer.MIN_VALUE to Integer.MAX_VALUE interval.&lt;/li&gt;
	&lt;li&gt;The original problem was that negative values were rounded up by the conversion from double to int, while positive numbers were rounded down. By using floor, we first round the numbers down, and then convert to integer, thus ensuring a proper uniform distribution.&lt;/li&gt;
	&lt;li&gt;Test cases for negative values are still missing... Could someone else add them?&lt;/li&gt;
	&lt;li&gt;RandomDataImpl.nextUniform: I haven't changed this, as the change that I used for integers does not have the desired effect for doubles... This may be caused by the fact that Double.MIN_VALUE is more negative than Double.MAX_VALUE is positive, but I'm not really sure. Maybe it is not even an issue for the nextUniform method?&lt;/li&gt;
&lt;/ul&gt;

, &lt;blockquote&gt;&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; the fact that Double.MIN_VALUE is more negative &lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="http://docs.oracle.com/javase/6/docs/api/java/lang/Double.html#MIN_VALUE"&gt;Double.Min_VALUE&lt;/a&gt; is a &lt;em&gt;positive&lt;/em&gt; number.&lt;/p&gt;
, &lt;blockquote&gt;&lt;p&gt;Double.Min_VALUE is a positive number.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops...&lt;/p&gt;

&lt;p&gt;OK, I uploaded a third version of the patch (math-724-v3.patch), which also applies the new formula for nextUniform. I included two test files (NextUniformTest3.java and NextIntTest3.java), that show the results for nextInt and nextUniform, for both the old and new formulas. As for as I can see, the new formula works equally well or better in all cases. Also, all existing unit tests pass.&lt;/p&gt;
, &lt;p&gt;Thanks for reporting and diagnosing this, Dennis.&lt;/p&gt;

&lt;p&gt;Slightly modified version of the third patch (just removing unecessary parens), along with tests, committed in r1221490.  The "negativeToPositiveRange" tests fail before the fix.  The change to nextUniform is also needed to prevent overflows. I changed the relevant test cases to use the TestUtils chisquare test, which is more straightforward and has better output.  This was added after the original versions of these tests were written.  Others in this class should be similarly updated.  Patches welcome to further tidy the tests, but this issue can be resolved.&lt;/p&gt;
], resolution=Fixed, reporter=dhendriks, assignees=[], commentAuthors=[dhendriks, psteitz, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,435 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-723
2016-01-13 22:22:44,435 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-723, created=Sun Dec 11 22:03:37 CET 2011, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Sun Dec 11 22:59:41 CET 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=BitStreamGenerators (MersenneTwister, Well generators) do not clear normal deviate cache on setSeed, link=https://issues.apache.org/jira/browse/MATH-723, description=&lt;p&gt;The BitStream generators generate normal deviates (for nextGaussian) in pairs, caching the last value generated. When reseeded, the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1213087.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,435 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-719
2016-01-13 22:22:44,435 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-719, created=Tue Dec 06 18:07:24 CET 2011, updated=Sat Mar 24 17:16:38 CET 2012, resolved=Mon Jan 23 12:28:07 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[], priority=Minor, summary=Strange deprecations in API, link=https://issues.apache.org/jira/browse/MATH-719, description=&lt;p&gt;Sorry if this doesn't belong here. I couldn't find any sort of mailing list or other feedback mechanism on the website.&lt;/p&gt;

&lt;p&gt;RealMatrix has some very odd deprecations. In particular inverse(), getDeterminant() and isSingular(). The last has the message:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Deprecated. as of release 2.0, replaced by the boolean negation of new LUDecompositionImpl(m).getSolver().isNonSingular()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's an implementation, not an interface. The whole point of having an interface is that &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I can query whether a matrix is singular withou having to know about LUDecompositions&lt;/li&gt;
	&lt;li&gt;You guys can change the implementation of isSingular() if something better pops up without us guys having to change our code.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I'm not using these methods now, because they're deprecated, but I've basically recreated them in as static methods in a utility class. Wouldn't it be much better to just put code from the deprecation message into the method and remove the deprecation?&lt;/p&gt;, comments=[&lt;blockquote&gt;&lt;p&gt;Sorry if this doesn't belong here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Indeed, you'd better bring this kind of issue to the "dev" ML. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
The more so that there have been recent discussions about changing the matrix API and decisions ought to be made quite soon now.&lt;/p&gt;
, &lt;p&gt;Ah, so there is a mailing list. I guess I should have looked a little harder. I'll bring it up there.&lt;/p&gt;
, &lt;p&gt;It is unlikely that we can come up with a new design before the release of v3.0.&lt;br/&gt;
This must be thoroughly discussed first on the "dev" ML, together with other matrix interface issues.&lt;/p&gt;
], resolution=Unknown, reporter=pbloem, assignees=[], commentAuthors=[erans, pbloem], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,435 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-692
2016-01-13 22:22:44,435 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-692, created=Tue Oct 18 20:01:57 CEST 2011, updated=Sat Mar 24 17:16:26 CET 2012, resolved=Thu Feb 02 07:45:59 CET 2012, status=Closed, type=Bug, version=[1.0
, 1.1
, 1.2
, 1.3
, 2.0
, 2.1
, 2.2
, 2.2.1
, 3.0
], fixVersion=[3.0
], priority=Minor, summary=Cumulative probability and inverse cumulative probability inconsistencies, link=https://issues.apache.org/jira/browse/MATH-692, description=&lt;p&gt;There are some inconsistencies in the documentation and implementation of functions regarding cumulative probabilities and inverse cumulative probabilities. More precisely, '&amp;lt;' and '&amp;lt;=' are not used in a consistent way.&lt;/p&gt;

&lt;p&gt;Besides I would move the function inverseCumulativeProbability(double) to the interface Distribution. A true inverse of the distribution function does neither exist for Distribution nor for ContinuosDistribution. Thus we need to define the inverse in terms of quantiles anyway, and this can already be done for Distribution.&lt;/p&gt;

&lt;p&gt;On the whole I would declare the (inverse) cumulative probability functions in the basic distribution interfaces as follows:&lt;/p&gt;

&lt;p&gt;Distribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(double x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(double x0, double x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1)&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;inverseCumulativeProbability(double p):&lt;br/&gt;
  returns the quantile function inf{x in R | P(X&amp;lt;=x) &amp;gt;= p} &lt;span class="error"&gt;&amp;#91;see also 2), 3), and 4)&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1) An aternative definition could be P(x0 &amp;lt;= X &amp;lt;= x1). But this requires to put the function probability(double x) or another cumulative probability function into the interface Distribution in order be able to calculate P(x0 &amp;lt;= X &amp;lt;= x1) in AbstractDistribution.&lt;br/&gt;
2) This definition is stricter than the definition in ContinuousDistribution, because the definition there does not specify what to do if there are multiple x satisfying P(X&amp;lt;=x) = p.&lt;br/&gt;
3) A modification could be defined for p=0: Returning sup{x in R | P(X&amp;lt;=x) = 0} would yield the infimum of the distribution's support instead of a mandatory -infinity.&lt;br/&gt;
4) This affects issue &lt;a href="https://issues.apache.org/jira/browse/MATH-540" title="AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug"&gt;&lt;del&gt;MATH-540&lt;/del&gt;&lt;/a&gt;. I'd prefere the definition from above for the following reasons:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;This definition simplifies inverse transform sampling (as mentioned in the other issue).&lt;/li&gt;
	&lt;li&gt;It is the standard textbook definition for the quantile function.&lt;/li&gt;
	&lt;li&gt;For integer distributions it has the advantage that the result doesn't change when switching to "x in Z", i.e. the result is independent of considering the intergers as sole set or as part of the reals.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ContinuousDistribution:&lt;br/&gt;
nothing to be added regarding (inverse) cumulative probability functions&lt;/p&gt;

&lt;p&gt;IntegerDistribution:&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;cumulativeProbability(int x): returns P(X &amp;lt;= x)&lt;/li&gt;
	&lt;li&gt;cumulativeProbability(int x0, int x1): returns P(x0 &amp;lt; X &amp;lt;= x1) &lt;span class="error"&gt;&amp;#91;see also 1) above&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;, comments=[&lt;p&gt;Thanks for raising this issue, Christian - especially now as we finalize the 3.0 API.&lt;/p&gt;

&lt;p&gt;I am +1 for these changes.  I agree that the inf-based definition of inverse cum is more standard and we are in a position now make the change, so I say lets do it.  I am also +1 on the move of this up to the distribution interface.  The reason we did not include it there originally was that we thought we might implement distributions for which we could not define inverses.  That has not happened in the last 8 years, so I think its safe enough to push it up.&lt;/p&gt;

&lt;p&gt;The code, test, user guide and doc changes for this have to be done carefully.  Patches most welcome.&lt;/p&gt;

&lt;p&gt;Is everyone else OK with this change?&lt;/p&gt;
, &lt;p&gt;I have neither used nor developed this part of CM, so my view on this is of but little value. Having said that, anything improving consistency can only be desirable, especially at this stage. So I'm all for it, and will be soon available (when I'm done on SYMMLQ) for an (novice on these issues) help.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;+1&lt;/p&gt;
, &lt;p&gt;Thanks for the feedback to all. Sbastien, thanks for offering your help. If you like and find time for it, you could implement AbstractDistribution.inverseCumulativeProbability(double p).&lt;/p&gt;

&lt;p&gt;I will provide some patches next week, but adjusting AbstractContinuousDistribution.inverseCumulativeProbability(double p) will take some more time.&lt;/p&gt;

&lt;p&gt;After thinking a little more about the structure of the interfaces, I'd like to put the function probability(double x) to Distribution anyway (independently of the thought in point 1) above).&lt;/p&gt;

&lt;p&gt;Are there any preferences on P(x0 &amp;lt;= X &amp;lt;= x1) or P(x0 &amp;lt; X &amp;lt;= x1) for cumulativeProbability(double x0, double x1)?&lt;/p&gt;
, &lt;p&gt;I am not sure it is really makes sense to add probability(double x) to the Distribution interface.  It would have to be defined as density (referring to the distribution function) to make sense in the continuous case, since defined as p(X = x) it would in most cases be identically 0 for continuous distributions.&lt;/p&gt;

&lt;p&gt;Regarding the cum definition, I am fine with P(x0 &amp;lt; X &amp;lt;= x1).&lt;/p&gt;
, &lt;p&gt;Happy to help on the inverse cumulative probability. You will have to be patient and forgieving with me, though, as I discover this part of CM.&lt;/p&gt;

&lt;p&gt;As for the definition, I think that one of the bounds should be excluded, so that these cumulative probabilities can be summed&lt;br/&gt;
P(a &amp;lt; X &amp;lt;= c) = P(a &amp;lt; X &amp;lt;= b) + P(b &amp;lt; X &amp;lt;= c),&lt;br/&gt;
even in the case of discrete PDFs.&lt;/p&gt;

&lt;p&gt;Whether the lower or upper bound should be excluded is another matter. I usually work with continuous pdfs, so I don't know if there is a common practice in the probability community. If there is none, I would tend to chose the following definition&lt;br/&gt;
P(x0 &amp;lt;= X &amp;lt; x1)&lt;br/&gt;
(sorry Phil!), because it would be consistent with the way things are usually indexed in java (a&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;.. a&lt;span class="error"&gt;&amp;#91;a.length-1&amp;#93;&lt;/span&gt;). See also &lt;tt&gt;org.apache.commons.math.util.MultidimensionalCounter&lt;/tt&gt;. Although this type of consistency is not an absolute requirement, I think it is nice for the user to have such simple principle: "lower bound always included, upper bound always excluded". Appart from this small point, I really have no objection to any choice.&lt;/p&gt;
, &lt;p&gt;Have a look at the default implementation of cum(x0,x1) now in AbstractDistribution.  I think the incorrectness in the documentation there may have been what triggered Christian to raise this issue.  The equation cum(a,b) = F(b) - F(a) where F is the distribution function is natural and what the impl there is trying to do.  In the discrete case, this equation fails, however, unless you define the cum to exclude the &lt;b&gt;lower&lt;/b&gt; endpoint.  That's why P(x0 &amp;lt; X &amp;lt;= x1) is a better definition.&lt;/p&gt;
, &lt;p&gt;OK, Phil, it makes perfect sense.&lt;/p&gt;
, &lt;p&gt;Good, the definition of cum(x0,x1) will be P(x0 &amp;lt; X &amp;lt;= x1). Phil, you are right: cum(x0,x1) in AbstractDistribution was a reason for raising this issue. Another reason was cum(int x0, int x1) in AbstractIntegerDistribution.&lt;/p&gt;

&lt;p&gt;The idea behind probability(double x) is in fact to define it as p(X = x) and to return 0 for continuous distributions. This function would be useful for discrete distributions not inheriting from IntergerDistribution and for distributions being composed of discrete and continuous parts.&lt;/p&gt;
, &lt;p&gt;I guess I am OK with pushing p&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/error.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt; up.  See related post to follow in commons-dev. &lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
I've started looking into this issue. As I said, you will have to be patient with me &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;.&lt;br/&gt;
I can see there already is a default implementation of &lt;tt&gt;AbstractContinuousDistribution.inverseCumulativeProbability&lt;/tt&gt;. So what exactly would you like me to do? Is this implementation fragile? Would you like me to improve robustness? Provide full testing?&lt;/p&gt;

&lt;p&gt;I think there might be issues when the PDF falls down to zero in a range (in which case the cum exhibits a plateau). The returned value might differ from the mathematical definition you proposed. Is this what you want me to work on? Have you already identified other issues?&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;

&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;

&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;

&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;
, &lt;p&gt;Another point for discussion:&lt;br/&gt;
I'd like to introduce&lt;br/&gt;
getDomainBracket(double p): returns double[]&lt;br/&gt;
to AbstractDistribution as helper function for inverseCumulativeProbability. This allows to avoid searching a bracket where a bracket can be specified directly.&lt;br/&gt;
The function getDomainBracket could be made abstract (which means to remove getInitialDomain, getDomainLowerBound, and getDomainUpperBound as these functions aren't needed any more), or it could have a default implementation (according to the corresponding part of the current implementation of inverseCumulativeProbability) which uses getInitialDomain, getDomainLowerBound, and getDomainUpperBound. However, getInitialDomain, getDomainLowerBound, and getDomainUpperBound should not be abstract in the latter case. Otherwise a derived class would be forced to implement something it potentially doesn't use. Thus the functions getInitialDomain, getDomainLowerBound, and getDomainUpperBound should have default implementations which either return default values (0, -infinity, +infinity) or throw an exception saying something like "has to be implemented".&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;the problem with the plateau is indeed one issue which needs to be solved.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I'm working on it...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Additionally, AbstractDistribution will need an implementation of inverseCumulativeProbability. In fact both implementations should be the same except for the solver to be used. Thus inverseCumulativeProbability should be implemented just once in AbstractDistribution, and invoking the solver should be put to a separate procedure so that it can be overridden in AbstractContinuousDistribution.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK, for now, I'm concentrating on making the current impl in &lt;tt&gt;AbstractContinuousDistribution&lt;/tt&gt; more robust. The other impl should be easier.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A third point is the choice of the solvers. For AbstractDistribution we need a solver which works even for discontinuous cdfs (BisectionSolver can do the job, but maybe the implementations of the faster IllinoisSolver, PegasusSolver, BrentSolver, or another solver can cope with discontinuities, too). For AbstractContinuousDistribution it would be beneficial to use a DifferentiableUnivariateRealSolver. However, the NewtonSolver cannot be used due to uncertainty of convergence and an alternative doesn't seem to exist by now. So we have to choose one of the other solvers for now.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The current implementation uses a Brent solver. I think the solver itself is only one side of the issue. The other point is the algorithm used to bracket the solution, in order to ensure that the result is consistent with the definition of the cumprob. As for the &lt;tt&gt;DifferentiableUnivariateRealSolver&lt;/tt&gt;, I'm not too sure. I guess it depends on what is meant by "continuous distribution". For me, it means that the random variable takes values in a continuous set, and possibly its distribution is defined by a density. However, in my view, nothing prevents occurences of Dirac functions, in which case the cum sum is only piecewise C1. It's all a matter of definition, of course, and I'll ask the question on the forum to check whether or not people want to allow for such a situation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As all these points are interdependent, I guess it's best to solve them as a whole. If you like, you can do this.&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;br/&gt;
Christian&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I'm very interested.&lt;/p&gt;

&lt;p&gt;Best regards,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Please note that &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt; has been created specifically to handle plateaux.&lt;/p&gt;

&lt;p&gt;Sbastien&lt;/p&gt;
, &lt;p&gt;Here is the first patch for this issue (unfortunately with some delay). It adjusts the distributions with real domain to the definitions in this issue, and it mainly changes documentations.&lt;/p&gt;

&lt;p&gt;I could not move inverseCumulativeProbability(double) up to Distribution because there would be a conflict with IntegerDistribution.inverseCumulativeProbability(double): This method returns int. This problem will be removed by solving issue &lt;a href="https://issues.apache.org/jira/browse/MATH-703" title="Splitting up the distribution hierarchy"&gt;&lt;del&gt;MATH-703&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The implementation of inverseCumulativeProbability(double) is not changed as Sbastien is working on this.&lt;/p&gt;

&lt;p&gt;I will provide the patch for the integer distributions as soon as I have adjusted the test data to the new inequalities and reverified the adjusted test data.&lt;/p&gt;
, &lt;p&gt;All,&lt;br/&gt;
since I'm already working on this package, I'm happy to commit the patch on behalf of Christian. However, since I'm a relatively new committer, I would feel more confident if one of the "old, wise committers" could double check the svn log afterwards.&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hey, that's how it always works &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;  &lt;/p&gt;

&lt;p&gt;I don't know about "wise" but I certainly qualify as "old" by any standard, so will have a look once you have reviewed and committed.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
, &lt;p&gt;Patch &lt;tt&gt;Math-692_realDomain_patch1.patch&lt;/tt&gt; (20111108) applied in rev 1200179, with minor modifications (mostly checkstyle fixes).&lt;br/&gt;
Thanks Christian!&lt;/p&gt;
, &lt;p&gt;As mentioned by Sbastien in &lt;a href="https://issues.apache.org/jira/browse/MATH-699" title="inverseCumulativeDistribution fails with cumulative distribution having a plateau"&gt;&lt;del&gt;MATH-699&lt;/del&gt;&lt;/a&gt;, the implementation of &lt;tt&gt;IntegerDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; can benefit from the ideas which came up for &lt;tt&gt;RealDistribution.inverseCumulativeProbability(double p)&lt;/tt&gt; in that thread.&lt;/p&gt;

&lt;p&gt;Thus I will remove &lt;tt&gt;getDomainLowerBound(double p)&lt;/tt&gt; and &lt;tt&gt;getDomainUpperBound(double p)&lt;/tt&gt; from the integer distributions. I checked that all current implementations of the lower/upper bound methods provide the whole support of the distribution as starting bracket. This means that using &lt;tt&gt;getSupportLowerBound()&lt;/tt&gt; and &lt;tt&gt;getSupportUpperBound()&lt;/tt&gt; for the starting bracket won't degrade the performance of the current distribution implementations. However, a user might want the improve the performance of his distribution implementations by providing a more targeted starting bracket for probability &lt;tt&gt;p&lt;/tt&gt;. Thus I will swap the solving step to a protected function &lt;tt&gt;solveInverseCumulativeProbability(double p, int lower, int upper)&lt;/tt&gt;, so that it gets easy to override &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; with an implementation which finds a better starting bracket.&lt;/p&gt;

&lt;p&gt;Furthermore, Phil's idea with Chebyshev's inequality can be applied to the generic implementation of &lt;tt&gt;inverseCumulativeProbability&lt;/tt&gt; in order to get a better starting bracket.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
If you agree with that, I suggest that you also take care of &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;, as the two issues seem to be very much connected.&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Hi Sbastien,&lt;/p&gt;

&lt;p&gt;my changes in the integer distributions don't solve &lt;a href="https://issues.apache.org/jira/browse/MATH-718" title="inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials."&gt;MATH-718&lt;/a&gt;. Instead I found a probably related problem with the Pascal distribution.&lt;/p&gt;

&lt;p&gt;The integer distribution patch for this issue still isn't ready. I will provide it next week.&lt;/p&gt;

&lt;p&gt;Christian&lt;/p&gt;
, &lt;p&gt;This is the patch which adjusts the integer distributions to the agreements above.&lt;/p&gt;

&lt;p&gt;The changes to the test cases for the random generators may be unexpected. But these changes initially were triggered by adjusting &lt;tt&gt;RandomDataTest.checkNextPoissonConsistency(double)&lt;/tt&gt; to the new contract for integer distributions. Then some random generator tests failed due to chance. While adjusting their seeds, I found some other tests with a high failure probability. Thus I also set some failure probabilities to 0.01 in order to find suitable seeds more quickly.&lt;/p&gt;

&lt;p&gt;My next task on this issue is to adjust the user guid.&lt;/p&gt;
, &lt;p&gt;Hi Christian,&lt;br/&gt;
thanks for this contribution. I am away for a few days, but am very happy to commit this patch as soon as I am back, if you are not in too much of a hurry.&lt;br/&gt;
Thanks again,&lt;br/&gt;
Sbastien&lt;/p&gt;
, &lt;p&gt;Well, we've recently run into some troubles with SVN, but it seems everything is working fine again. Patch {{&lt;a href="https://issues.apache.org/jira/browse/MATH-692" title="Cumulative probability and inverse cumulative probability inconsistencies"&gt;&lt;del&gt;MATH-692&lt;/del&gt;&lt;/a&gt;_integerDomain_patch1.patch}} (with minor checkstyle changes) committed in revision &lt;tt&gt;1226041&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Please do not forget to run &lt;tt&gt;mvn clean; mvn site:site&lt;/tt&gt; and check the reports (in particular, &lt;tt&gt;checkstyle&lt;/tt&gt;) prior to submitting a patch!&lt;/p&gt;

&lt;p&gt;Thanks for this contribution.&lt;/p&gt;
, &lt;p&gt;The committed patch actually causes failure of &lt;tt&gt;Well1024Test&lt;/tt&gt; in &lt;tt&gt;o.a.c.m.random&lt;/tt&gt;.&lt;/p&gt;
, &lt;p&gt;Thanks for committing the patch, Sbastien. I see you already changed the seed in &lt;tt&gt;Well1024aTest&lt;/tt&gt;. This hopefully removes the failure.&lt;/p&gt;

&lt;p&gt;I'll have a look into Maven to prepare a better patch next time. &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;I see you already changed the seed in Well1024aTest.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I did, but is this really how we want &lt;tt&gt;Well2004aTest&lt;/tt&gt; to pass?&lt;/p&gt;
, &lt;p&gt;I guess there is no alternative to this way of making probabilistic test cases pass. However, I understand your bad feeling with this kind of failure fixing. The problem is that probabilistic tests are quiet fuzzy: Neither a passed test nor a failed test provides a clear answer whether something is right or wrong in the implementation. There is just a high chance to pass such a test with a correct implementation. The chance for failure increases with an erroneous implementation due to systematic deviations in the generated data. These chances tell whether it is easy to find a seed which passes the tests or not. Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Thus difficulties in finding a suitable seed are an indicator for problems in the code.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That's exactly the point I've raised on the mailing-list: out of three seeds (100, 1000 and 1001), only one works. Of course, I would not dare to call that representative statistics, but I'm wondering whether or not we should be worried...&lt;/p&gt;
, &lt;p&gt;The issue about selection of an appropriate seed has been raised elsewhere. No definitive answer has been provided so far, so I suggest we consider this issue as solved for the time being.&lt;/p&gt;
], resolution=Fixed, reporter=cwinter, assignees=[], commentAuthors=[psteitz, celestin, mikl, cwinter], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-654
2016-01-13 22:22:44,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-654, created=Tue Aug 30 19:23:19 CEST 2011, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Thu Sep 01 02:14:02 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=ValueServer not deterministic for a fixed random number seed, link=https://issues.apache.org/jira/browse/MATH-654, description=&lt;p&gt;I have built an agent-based model using the Apache Commons Math library, which has come in handy.&lt;/p&gt;

&lt;p&gt;The ValueServer seemed particularly helpful, as explained at:&lt;br/&gt;
&lt;a href="http://commons.apache.org/math/userguide/random.html"&gt;http://commons.apache.org/math/userguide/random.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My simulation needs repeatable randomness, so I used this form of the ValueServer constructor:&lt;/p&gt;

&lt;p&gt;    ValueServer(RandomData randomData) &lt;br/&gt;
    Construct a ValueServer instance using a RandomData as its source of random data.&lt;br/&gt;
    // &lt;a href="http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html"&gt;http://commons.apache.org/math/api-2.2/org/apache/commons/math/random/ValueServer.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, in my simulation, I found that the ValueServer did not act deterministically if I supplied the same random number seed.&lt;/p&gt;

&lt;p&gt;I have not inspected the source code, but I suspect that the ValueServer is not using the `randomData` generator correctly. If it was, then it should be deterministic.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  I assume you are using DIGEST_MODE.  If this is the case and you are comfortable compiling the code in trunk, the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-634" title="EmpiricalDistributionImpl should use a pluggable RandomGenerator"&gt;&lt;del&gt;MATH-634&lt;/del&gt;&lt;/a&gt; enables a workaround for this.  Using the reseed method added to EmpiricalDistributionImpl in trunk, you can use ValueServer's getEmpiricalDistribution to get the distribution and then invoke reseed.  Unfortunately, this method does not exist in any released version yet.&lt;/p&gt;

&lt;p&gt;The problem is that ValueServer#getNextDigest (what it does for getNext in DIGEST_MODE) delegates to EmpiricalDistributionImpl#getNextValue.  EmpiricalDistributionImpl has its own RandomData instance.  To fix this issue, EmpiricalDistirbutionImpl should add a constructor taking a RandomData and ValueServer should provide this.&lt;/p&gt;
, &lt;p&gt;Fixed in r1163875. ValueServer now exposes a reSeed method that when supplied a fixed seed will generate a fixed sequence in any stochastic mode. The RandomDataImpl that it uses internally is passed to the EmpiricalDistributionImpl it creates when used in DIGEST_MODE.  The changes for this issue include an incompatible (vs. 2.x) change: the constructor for EmpiricalDistributionImpl that previously took a RandomData now takes a RandomDataImpl.  The plan for 3.0 is to merge these.&lt;/p&gt;
], resolution=Fixed, reporter=d.james, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-640
2016-01-13 22:22:44,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-640, created=Tue Aug 02 21:06:35 CEST 2011, updated=Sat Mar 24 17:16:52 CET 2012, resolved=Wed Aug 03 06:17:43 CEST 2011, status=Closed, type=Bug, version=[1.1
, 1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=AbstractRandomGenerator nextInt() and nextLong() default implementations generate only positive values, link=https://issues.apache.org/jira/browse/MATH-640, description=&lt;p&gt;The javadoc for these methods (and what is specified in the RandomGenerator interface) says that all int / long values should be in the range of these methods.  The default implementations provided in this class do not generate negative values.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1153338&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[psteitz], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-618
2016-01-13 22:22:44,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-618, created=Wed Jul 13 22:23:43 CEST 2011, updated=Sat Mar 24 17:16:27 CET 2012, resolved=Thu Jul 14 08:08:54 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same, link=https://issues.apache.org/jira/browse/MATH-618, description=&lt;p&gt;For both Complex add and subtract, the javadoc states that&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;* If either &lt;span class="code-keyword"&gt;this&lt;/span&gt; or &amp;lt;code&amp;gt;rhs&amp;lt;/code&amp;gt; has a NaN value in either part,
     * {@link #NaN} is returned; otherwise Inifinite and NaN values are
     * returned in the parts of the result according to the rules &lt;span class="code-keyword"&gt;for&lt;/span&gt;
     * {@link java.lang.&lt;span class="code-object"&gt;Double&lt;/span&gt;} arithmetic&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r1146573&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,450 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-588
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-588, created=Sun Jun 12 20:19:07 CEST 2011, updated=Sat Mar 24 17:16:31 CET 2012, resolved=Sun Feb 05 20:54:50 CET 2012, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[3.0
], priority=Major, summary=Weighted Mean evaluation may not have optimal numerics, link=https://issues.apache.org/jira/browse/MATH-588, description=&lt;p&gt;I recently got this in a test run&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;testWeightedConsistency(org.apache.commons.math.stat.descriptive.moment.MeanTest)  Time elapsed: 0 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError: expected:&amp;lt;0.002282165958997601&amp;gt; but was:&amp;lt;0.002282165958997157&amp;gt;
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:441)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:178)
	at org.apache.commons.math.TestUtils.assertRelativelyEquals(TestUtils.java:153)
	at org.apache.commons.math.stat.descriptive.UnivariateStatisticAbstractTest.testWeightedConsistency(UnivariateStatisticAbstractTest.java:170)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The correction formula used to compute the unweighted mean may not be appropriate or optimal in the presence of weights:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// Compute initial estimate using definitional formula
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; sumw = sum.evaluate(weights,begin,length);
&lt;span class="code-object"&gt;double&lt;/span&gt; xbarw = sum.evaluate(values, weights, begin, length) / sumw;

&lt;span class="code-comment"&gt;// Compute correction factor in second pass
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; correction = 0;
&lt;span class="code-keyword"&gt;for&lt;/span&gt; (&lt;span class="code-object"&gt;int&lt;/span&gt; i = begin; i &amp;lt; begin + length; i++) {
  correction += weights[i] * (values[i] - xbarw);
}
&lt;span class="code-keyword"&gt;return&lt;/span&gt; xbarw + (correction/sumw);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;, comments=[&lt;p&gt;Fixed it in r1240790.&lt;/p&gt;

&lt;p&gt;There was a too strict equality test using an relative error of 10-14 which resulted in certain unforunate cases of an absolute error of 10-18.&lt;/p&gt;
, &lt;p&gt;Corrected the equality test in r1240795 as it was leading to failure. In fact the test can range from very small to very large values which really requires a relative error estimate.&lt;/p&gt;

&lt;p&gt;The test is problematic in general, as it may contain values from very different scales (due to its random nature), leading to unavoidable precision errors in the above formula.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[tn], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-575
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-575, created=Sat May 14 18:40:34 CEST 2011, updated=Sat Mar 24 17:16:54 CET 2012, resolved=Thu Feb 02 12:12:52 CET 2012, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=Exceptions in genetics package or not consistent with the rest of [math], link=https://issues.apache.org/jira/browse/MATH-575, description=&lt;p&gt;InvalidRepresentationException is checked and non-localized.  This exception should be placed in the &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; hierarchy.  The AbstractListChromosome constructor also throws a non-localised IAE, which should be replaced by an appropriate &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt; exception.&lt;/p&gt;, comments=[&lt;p&gt;Phil started to work on this issue in r1135025.&lt;/p&gt;

&lt;p&gt;In r1235038 additional cleanups have been performed:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;add localized messages for all exceptions&lt;/li&gt;
	&lt;li&gt;add @throws to javadoc where appropriate&lt;/li&gt;
	&lt;li&gt;add final to method parameters&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What is missing:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;Phil mentioned that InvalidRepresentationException should be placed into &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, although I am not sure why, as it is not used outside the genetics package&lt;/li&gt;
	&lt;li&gt;add more custom exception classes specific to the genetics package (optional). By now mostly MathIllegalArgumentException or other appropriate ones have been used.&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;Thanks for working on this, but before you do start to make modifications, please assign the issue to yourself!&lt;/p&gt;

&lt;p&gt;For the changes themselves, I don't agree with the creation of those many localized messages: We have been trying to rationalize and reduce the number of those, by removing duplicates and combining several ones to convey the full explanation of the problem. See my reply to the commit message.&lt;/p&gt;
, &lt;p&gt;Fixed in r1235197.&lt;/p&gt;

&lt;p&gt;Thanks for your suggestions!&lt;/p&gt;
, &lt;p&gt;Thomas,&lt;br/&gt;
Could please check whether this issue is resolved? And if it is, mark it so? Thanks.&lt;/p&gt;
, &lt;p&gt;As from the original issue description, Phil intended to move the InvalidRepresentationException to the general o.a.c.m.exceptions package. I am not sure about this, that's why I kept it aside for the time being. If we agree on keeping it in the genetics package we can resolve this issue.&lt;/p&gt;
, &lt;p&gt;Phil had always been opposed to having all exceptions grouped in their own package; so I doubt that he meant to move that one over there... &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;br/&gt;
Here, the description just indicates that the exception should become &lt;em&gt;unchecked&lt;/em&gt; and that the "detailed message" should be an element from the "LocalizedFormats" enum (i.e. derive from one of the base CM exceptions).&lt;/p&gt;
, &lt;p&gt;Ah ok, that makes it clear. When reading hierarchy I was just thinking in terms of packages rather than class hierarchy.&lt;/p&gt;

&lt;p&gt;Thus, I resolve this issue.&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[tn], commentAuthors=[tn, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-555
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-555, created=Mon Apr 04 06:13:04 CEST 2011, updated=Sat Mar 24 17:16:43 CET 2012, resolved=Mon Apr 04 06:53:13 CEST 2011, status=Closed, type=Bug, version=[2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=MathUtils round method should propagate rather than wrap Runitme exceptions, link=https://issues.apache.org/jira/browse/MATH-555, description=&lt;p&gt;MathUtils.round(double, int, int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException, the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in trunk in r1088473&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-540
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-540, created=Sun Mar 06 01:43:45 CET 2011, updated=Sat Mar 24 17:16:36 CET 2012, resolved=Sun Jun 12 07:58:50 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=AbstractIntegerDistribution.inverseCumulativeProbability(...) Bug, link=https://issues.apache.org/jira/browse/MATH-540, description=&lt;p&gt;The AbstractIntegerDistribution.inverseCumulativeProbability(...) function attempts to decrement the lower bound of discrete distributions to values that go below the lower bound.&lt;/p&gt;, comments=[&lt;p&gt;I don't think this is a bug.  Per the javadoc, the contract for inverse cum is&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/**
 * For a random variable {@code X} whose values are distributed according
 * to &lt;span class="code-keyword"&gt;this&lt;/span&gt; distribution, &lt;span class="code-keyword"&gt;this&lt;/span&gt; method returns the largest {@code x}, such
 * that {@code P(X &amp;lt; x) &amp;lt; p}.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This implies that if the first non-zero mass point has probability greater than p, the right value to return is one less than that value, which is whet the method will do.  Your example distribution throws NPE when trying to compute probabilities outside of its domain of support. &lt;/p&gt;
, &lt;p&gt;I'm looking at it like this.  I have very simple distribution like the one provided (Four sided dice).  I'm trying to write a simulation that draws values of x for a a set of uniform 0-1 probabilities.  So I'm expecting:&lt;/p&gt;

&lt;p&gt;0 When p is less than or equal to 0.25&lt;br/&gt;
1 When p is greater than 0.25 but less than or equal to 0.50&lt;br/&gt;
2 When p is greater than 0.50 but less than or equal to 0.75&lt;br/&gt;
3 When p is greater than 0.75 but less than or equal to 1.0&lt;/p&gt;

&lt;p&gt;So for the line &lt;/p&gt;

&lt;p&gt;int neverSucceeds = d.inverseCumulativeProbability(0.0001);&lt;/p&gt;

&lt;p&gt;I'm really expecting 0 to be returned.&lt;/p&gt;

&lt;p&gt;Make sense?&lt;/p&gt;
, &lt;p&gt;I see now that there actually does appear to be an error in the javadoc.  The implementation really returns the largest x such that p(X &amp;lt;= x) &amp;lt;= p.  In the discrete case, &amp;lt;= matters and I think both inequalities in the javadoc should be changed.&lt;/p&gt;

&lt;p&gt;In your example, if the probability distribution vanishes outside 0, 1, 2, 3 and puts .25 mass on each of these values, the inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;

&lt;p&gt;If you fix your distribution so that both probability and cumulativeProbability return correct values (rather than throwing NPEs) outside of the mass values, you should get -1 returned.&lt;/p&gt;
, &lt;p&gt;Reading your last comment a little more carefully, it looks like what you are trying to do is implement sampling.  IIUC, something like what you are suggesting should work - you just have an off-by-one problem vis-s-vis the contract of inverse cumulative probabilities as we define them.  I would be +1 for adding direct support for sampling from discrete distributions, but we should open a separate ticket for that.&lt;/p&gt;
, &lt;p&gt;OK - I'll close this one and open a separate ticket.&lt;/p&gt;
, &lt;p&gt;There is a javadoc bug that needs to be fixed here&lt;/p&gt;
, &lt;p&gt;Ooops - Thanks.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;...inverse cumulative probability function evaluated at .0001 should be -1, as this is the largest value such that &lt;br/&gt;
p(X &amp;lt;= x) &amp;lt;= .0001.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems to me that users would be better served if it returned 0 and that it is also correct to do so.&lt;/p&gt;

&lt;p&gt;In the definition we say "For a random variables X whose values are distributed according to this distribution...".&lt;/p&gt;

&lt;p&gt;Suppose the distribution was for a six sided dice.  One could assert that the distribution is only defined for the values 1,2,3,4,5,6.  In this case the inverseCumulativeDistribution returns 0, but that does not have any meaning.  So now developers are forced to define the meaning of 0 for a six sided dice implementation.  &lt;/p&gt;

&lt;p&gt;In Grad school we were taught the the inverse cumulative distribution is for sampling.  So for a six sided dice uniform probabilities less than 1/6 would return 1, less than 2/6 would return 2, etc.&lt;/p&gt;

&lt;p&gt;With the current implementation for values less than 1/6 we get 0 which is meaningless, and the only time we get 6 is when the uniform probability argument is 1.&lt;/p&gt;

&lt;p&gt;So if someone mistakenly tries to use the inverseCumulativeProbability function for sampling the results are going to be wacked.  What is the use case for the inverseCumulativeProbability the way it is right now?&lt;/p&gt;
, &lt;p&gt;You have a choice in defining the inverse cum whether to define it the way we have or to use and inf rather than a sup.  We can implement sampling using the current impl.  We just need to take into account the way the inverse cum is defined in AbstractIntegerDistribution.  &lt;/p&gt;
, &lt;p&gt;OK - I think it's starting to make more sense to me now.  So when implementing sampling we just add one to the value returned by inverseCumulativeDistribution, unless the uniform probability argument is 1?&lt;/p&gt;
, &lt;p&gt;I am sorry.  I forgot that we had in fact already implemented this in version 2.2. See AbstractIntegerDistribution#sample.  The base class implementation delegates to RandomDataImpl#nextInversionDeviate (adding one per the last comment).&lt;/p&gt;
, &lt;p&gt;Sorry for the noise. I closed the wrong ticket.  Still need to fix the javadoc to match behavior and user guide.&lt;/p&gt;
, &lt;p&gt;Javadoc fixed in trunk r1134866&lt;/p&gt;
], resolution=Fixed, reporter=ole, assignees=[], commentAuthors=[psteitz, ole], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-506
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-506, created=Tue Feb 01 19:38:01 CET 2011, updated=Sat Mar 24 17:16:41 CET 2012, resolved=Sat Aug 20 23:14:57 CEST 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
, 2.2
], fixVersion=[3.0
], priority=Minor, summary=The static field ChiSquareTestImpl.distribution serves no purpose, link=https://issues.apache.org/jira/browse/MATH-506, description=&lt;p&gt;The static field ChiSquareTestImpl.distribution serves no purpose.&lt;/p&gt;

&lt;p&gt;There is a setter for it, but in every case where the field is used, it is first overwritten with a new value.&lt;/p&gt;

&lt;p&gt;The field and the setter should be removed, and the methods that create a new instance should create a local variable instead.&lt;/p&gt;

&lt;p&gt;For Math 2.1, the field can be removed and the setter deprecated.&lt;/p&gt;, comments=[&lt;p&gt;Agreed.  Since the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; this instance field is unnecessary.&lt;/p&gt;
, &lt;p&gt;See the discussion in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; where it was decided to remove the distribution pluggability in 3.0.  In 2.x, the distribution is pluggable and the instance field is useful.  The 3.0 code in trunk removes the pluggability and makes the field useless.&lt;/p&gt;
, &lt;p&gt;Sorry - I thought I had checked the 2.x implementation as well, but obviously not, as it does use the field.&lt;/p&gt;

&lt;p&gt;However, we should still deprecate the setter in 2.2, as it is removed in 3.0 - OK?&lt;/p&gt;
, &lt;p&gt;Just tried removing the field and setter in 3.0, and found that the constructors rely on the setter (which is a separate bug, as the setter is not final - but easily fixable if required).&lt;/p&gt;

&lt;p&gt;The fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; merely removed deprecated code.&lt;/p&gt;

&lt;p&gt;It replaced "distribution.setDegreesOfFreedom(dof)" with "distribution = new ChiSquaredDistributionImpl(dof)" which is how the field became useless.&lt;/p&gt;

&lt;p&gt;There are two constructors which still create values for the distribution field.&lt;/p&gt;

&lt;p&gt;I don't know enough about the Math to know whether there would be any use cases for having additional methods that used a distribution provided by the class instance, rather than calculated by the individual methods (as at present).&lt;/p&gt;

&lt;p&gt;If there is no need for external provision of the distribution degree of freedom, then the constructor with parameter can be dropped.&lt;/p&gt;

&lt;p&gt;Otherwise, we need to add some methods that can use the provided distribution (which should be a final instance field).&lt;/p&gt;

&lt;p&gt;In any case, I think the setter needs to be dropped from 3.x&lt;/p&gt;
, &lt;p&gt;The instance field was there originally so that different ChiSquareDistribution implementations could be provided at construction time or via a setter (making the underlying ChiSquareDistribution pluggable).  &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; pointed to a different problem related to mutability of implementation instances.  The simplest solution to both problems is to eliminate the pluggability, which the change in &lt;a href="https://issues.apache.org/jira/browse/MATH-349" title="Dangerous code in &amp;quot;PoissonDistributionImpl&amp;quot;"&gt;&lt;del&gt;MATH-349&lt;/del&gt;&lt;/a&gt; does for this class.  The degrees of freedom are always computed from the data, so there is no need for the constructor that takes a distribution instance as argument.  Both the constructor and setter can be deprecated in 2.2 and removed in 3.0 unless we want to keep pluggability, which would require&lt;/p&gt;

&lt;p&gt;1) making the distribution field final (so removing the setter)&lt;br/&gt;
2) copying, rather than referencing the actual parameter provided to the constructor&lt;/p&gt;

&lt;p&gt;I am on the fence on this.  Maybe others can chime in (next week &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;
, &lt;p&gt;OK, I see now, thanks!&lt;/p&gt;
, &lt;p&gt;I removed the field (hence eliminating pluggability) in r1159916.  As of 3.0, the distribution classes are immutable, so to support pluggability a factory or class name rather than a distribution instance would have to be provided.  There is only one implementation provided by &lt;span class="error"&gt;&amp;#91;math&amp;#93;&lt;/span&gt;, so I do not see this as worth the effort and complexity to retain.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[psteitz], commentAuthors=[psteitz, sebb@apache.org], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,466 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-505
2016-01-13 22:22:44,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-505, created=Tue Feb 01 01:28:56 CET 2011, updated=Sat Mar 24 17:16:40 CET 2012, resolved=Tue Feb 01 19:58:30 CET 2011, status=Closed, type=Bug, version=[1.2
, 2.0
, 2.1
], fixVersion=[3.0
], priority=Major, summary=TestUtils is thread-hostile, link=https://issues.apache.org/jira/browse/MATH-505, description=&lt;p&gt;TestUtils has several mutable static fields which are not synchronised, or volatile.&lt;/p&gt;

&lt;p&gt;If one of the fields is updated by thread A, there is no guarantee that thread B will see the full update - it may see a partially updated object.&lt;/p&gt;

&lt;p&gt;Furthermore, at least some of the static fields reference a mutable object, which can be changed whilst another thread is using it.&lt;/p&gt;

&lt;p&gt;As far as I can tell, this class must only ever be used by a single thread otherwise the results will be unpredictable.&lt;/p&gt;, comments=[&lt;p&gt;What fields, exactly?&lt;/p&gt;
, &lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;/** Singleton TTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; TTest tTest = &lt;span class="code-keyword"&gt;new&lt;/span&gt; TTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; ChiSquareTest chiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton ChiSquareTest instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; UnknownDistributionChiSquareTest unknownDistributionChiSquareTest =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; ChiSquareTestImpl();

/** Singleton OneWayAnova instance using &lt;span class="code-keyword"&gt;default&lt;/span&gt; implementation. */
&lt;span class="code-keyword"&gt;private&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; OneWayAnova oneWayAnova =
        &lt;span class="code-keyword"&gt;new&lt;/span&gt; OneWayAnovaImpl();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of the above may be changed by set methods. There is no synch.&lt;/p&gt;
, &lt;p&gt;OK, I was looking at the wrong TestUtils &lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="20" width="20" align="absmiddle" alt="" border="0"/&gt;&lt;/p&gt;

&lt;p&gt;The reason for this strange-looking setup is to allow the implementations to be pluggable at runtime.  "Hostile" is a harsh word, but this class is certainly &lt;b&gt;not&lt;/b&gt; threadsafe.  Ideas / patches to achieve the design goal with less "hostility" would be appreciated.&lt;/p&gt;

&lt;p&gt;I would have to double-check, but I don't think that there is any test instance state used by the methods in this class. &lt;/p&gt;
, &lt;p&gt;By thread-hostile, I mean that it is not possible in general for two different threads to use the class safely.&lt;br/&gt;
If one thread changes any of the static fields, there is no way of knowing how the methods called by the other thread will behave. This is partly because the values are not safely published currently, but even if they were, the threads don't know what settings will be used as they can be changed at any time by another thread.&lt;/p&gt;

&lt;p&gt;In general, any class which relies on mutable static state for its behaviour is thread-hostile.&lt;br/&gt;
The shared state cannot simultaneously satisfy two threads needing different behaviour.&lt;/p&gt;

&lt;p&gt;I think the only safe way for two threads to use the class as it stands is if they both synchronize on the class.&lt;br/&gt;
This will ensure safe publication of any field changes, and enforce serial usage which can guarantee the setting that will be used (but the lock will have to be held for the set call as well).&lt;/p&gt;

&lt;p&gt;ChiSquareTestImpl has a non-final instance field which means its value won't necessarily be safely published.&lt;br/&gt;
The field also has a setter which could be invoked by one thread while another was using it.&lt;/p&gt;

&lt;p&gt;TTestImpl is immutable (has no fields), and OneWayAnovaImpl can be made immutable, but other implementations of the interfaces might exist which are not immutable.&lt;/p&gt;

&lt;p&gt;The simplest way to make the class thread-safe would be to convert all the methods and fields from static to instance, but I don't know if that is acceptable.&lt;/p&gt;
, &lt;p&gt;Making the methods instance sort of defeats the purpose of the class.  None of the instance data in any of the static singletons is actually used or depended on by the methods of this class.  You are correct though that if one thread changes the impl for one of the singletons while another is using the class, the other could see a different than expected impl.  I think the practical likelihood of this is pretty much nil, as it is hard to imagine an application supplying two different implementations for the tests and wanting different threads to use different impls.  Personally, I would be happy just documenting the fact that the class is not threadsafe and if concurrent threads want to plug in different implementations, they need to synchronize on the class.  If this is not acceptable, my next preference would be to remove the pluggability - i.e., make the singletons final or get rid of them altogether, creating instances as needed for static method calls.  There is no initialization overhead creating the test classes.&lt;/p&gt;
, &lt;p&gt;@Phil: Please also keep in mind that M3 supports now (currently optional) parallel execution and it might be no longer a proper assumption that all tests are executed serially.&lt;/p&gt;
, &lt;p&gt;There is another possible option, which would be to fix the default implementations, and create new static methods that took an extra parameter for the implementation to be used.&lt;/p&gt;

&lt;p&gt;At present, changes to the static fields are not guaranteed to be published correctly. Making them volatile would fix this, but would not help with concurrent access.&lt;/p&gt;
, &lt;p&gt;Thanks, Joerg.  There should be no problems with the unit tests unless and until we introduce different tests that actually test the pluggability.  &lt;/p&gt;

&lt;p&gt;I thought about the additional parameter option, Sebb; but that again defeats the purpose of this "convenience class" - you might as well just instantiate the implementation and use it.&lt;/p&gt;

&lt;p&gt;I think the best solution is to just make the fields final and drop the getters and setters.  This is consistent with StatUtils.  So we should document the "hostility" issues in 2.2 and deprecate there and drop in 3.0.&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[sebb@apache.org], commentAuthors=[psteitz, sebb@apache.org, joehni], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-484
2016-01-13 22:22:44,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-484, created=Tue Jan 18 21:49:51 CET 2011, updated=Wed Mar 23 21:35:01 CET 2011, resolved=Mon Feb 14 15:20:29 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=events detection in ODE solvers is too complex and not robust, link=https://issues.apache.org/jira/browse/MATH-484, description=&lt;p&gt;All ODE solvers support multiple events detection since a long time. Events are specified by users by implementing the EventHandler interface. Events occur when the g(t, y) function evaluates to 0. When an event occurs, the solver step is shortened to make sure the event is located at the end of the step, and the event is triggered by calling the eventOccurred method in the user defined implementation class. Depending on the return value of this method, integration can continue, it can be stopped, or the state vector can be reset.&lt;/p&gt;

&lt;p&gt;Some ODE solvers are adaptive step size solvers. They can modify step size to match an integration error setting, increasing step size when error is low (thus reducing computing costs) or reducing step size when error is high (thus fulfilling accuracy requirements).&lt;/p&gt;

&lt;p&gt;The step adaptations due to events on one side and due to adaptive step size solvers are quite intricate by now, due to numerous fixes (&lt;a href="https://issues.apache.org/jira/browse/MATH-161" title="patch for Mantissa"&gt;&lt;del&gt;MATH-161&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-213" title="FirstOrderIntegrator.integrate does not give back integration stop time when an event handler stops integration"&gt;&lt;del&gt;MATH-213&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-358" title="ODE integrator goes past specified end of integration range"&gt;&lt;del&gt;MATH-358&lt;/del&gt;&lt;/a&gt;, &lt;a href="https://issues.apache.org/jira/browse/MATH-421" title="restarting an ODE solver that has been stopped by an event doesn&amp;#39;t work"&gt;&lt;del&gt;MATH-421&lt;/del&gt;&lt;/a&gt; and also during standard maintenance - see for example r781157). The code is very difficult to maintain. It seems each bug fix introduces new bugs (r781157/&lt;a href="https://issues.apache.org/jira/browse/MATH-322" title="during ODE integration, the last event in a pair of very close event may not be detected"&gt;&lt;del&gt;MATH-322&lt;/del&gt;&lt;/a&gt;) or tighten the link between adaptive step size and event detection (&lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;/r927202).&lt;/p&gt;

&lt;p&gt;A new bug discovered recently on an external library using a slightly modified version of this code could not be retroffitted into commons-math, despite the same problem is present. At the beginning of EventState.evaluateStep, the initial step may be exactly 0 thus preventing root solving, but preventing this size to drop to 0 would reopen &lt;a href="https://issues.apache.org/jira/browse/MATH-388" title="ODE integrator: different size needed for state vector and tolerance error vector dimension"&gt;&lt;del&gt;MATH-388&lt;/del&gt;&lt;/a&gt;. I could not fix both bugs at the same time.&lt;/p&gt;

&lt;p&gt;So it is now time to untangle events detection and adaptive step size, simplify code, and remove some inefficiency (event root solving is always done twice, once before step truncation and another time after truncation, of course with slightly different results, events shortened steps induce high computation load until the integrator recovers its optimal pace again, steps are rejected even when the event does not requires it ...).&lt;/p&gt;, comments=[&lt;p&gt;fixed in subversion repository as of r1061507 for branch 2.X and as of r1061508 for trunk&lt;/p&gt;
, &lt;p&gt;The fix introduced in r1061507 fails in several cases. If several events of the same type occur within a single long step, only the first one is triggered. If several events of different types occur during a backward integration, they are triggered in the wrong order (i.e. they are triggered in forward occurrence time order instead of backward).&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1070498 for branch 2.X and r1070499 for trunk&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-481
2016-01-13 22:22:44,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-481, created=Mon Jan 17 18:15:41 CET 2011, updated=Wed Mar 23 21:33:40 CET 2011, resolved=Mon Jan 17 23:39:52 CET 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=MathUtils.equals(double x, double y) disagrees with Javadoc, link=https://issues.apache.org/jira/browse/MATH-481, description=&lt;p&gt;MathUtils.equals(double x, double y) disagrees with Javadoc.&lt;/p&gt;

&lt;p&gt;The Javadoc says:&lt;/p&gt;

&lt;p&gt;Returns true iff they are equal as defined by  {@link #equals(double,double,int)}&lt;/p&gt;

&lt;p&gt;However, the code actually uses == and checks for NaN:&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; &lt;span class="code-object"&gt;boolean&lt;/span&gt; equals(&lt;span class="code-object"&gt;double&lt;/span&gt; x, &lt;span class="code-object"&gt;double&lt;/span&gt; y) {
    &lt;span class="code-keyword"&gt;return&lt;/span&gt; (&lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(x) &amp;amp;&amp;amp; &lt;span class="code-object"&gt;Double&lt;/span&gt;.isNaN(y)) || x == y;
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The method is deprecated, but it should probably still be consistent with its documentation.&lt;/p&gt;, comments=[&lt;p&gt;Corrected Javadoc in revision 1060117.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-465
2016-01-13 22:22:44,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-465, created=Wed Jan 05 18:34:41 CET 2011, updated=Sat Mar 24 17:17:03 CET 2012, resolved=Wed Jul 20 14:20:51 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Incorrect matrix rank via SVD, link=https://issues.apache.org/jira/browse/MATH-465, description=&lt;p&gt;The getRank() function of SingularValueDecompositionImpl does not work properly. This problem is probably related to the numerical stability problems mentioned in &lt;a href="https://issues.apache.org/jira/browse/MATH-327"&gt;MATH-327&lt;/a&gt; and &lt;a href="https://issues.apache.org/jira/browse/MATH-320"&gt;MATH-320&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Example call with the standard matrix from R (rank 2):&lt;/p&gt;

&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeHeader panelHeader" style="border-bottom-width: 1px;"&gt;&lt;b&gt;TestSVDRank.java&lt;/b&gt;&lt;/div&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.Array2DRowRealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.RealMatrix;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecomposition;
&lt;span class="code-keyword"&gt;import&lt;/span&gt; org.apache.commons.math.linear.SingularValueDecompositionImpl;

&lt;span class="code-keyword"&gt;public&lt;/span&gt; class TestSVDRank {
	&lt;span class="code-keyword"&gt;public&lt;/span&gt; &lt;span class="code-keyword"&gt;static&lt;/span&gt; void main(&lt;span class="code-object"&gt;String&lt;/span&gt;[] args) {
		&lt;span class="code-object"&gt;double&lt;/span&gt;[][] d = { { 1, 1, 1 }, { 0, 0, 0 }, { 1, 2, 3 } };
		RealMatrix m = &lt;span class="code-keyword"&gt;new&lt;/span&gt; Array2DRowRealMatrix(d);
		SingularValueDecomposition svd = &lt;span class="code-keyword"&gt;new&lt;/span&gt; SingularValueDecompositionImpl(m);
		&lt;span class="code-object"&gt;int&lt;/span&gt; r = svd.getRank();
		&lt;span class="code-object"&gt;System&lt;/span&gt;.out.println(&lt;span class="code-quote"&gt;"Rank: "&lt;/span&gt;+r);
	}
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;The rank is computed as 3. This problem also occurs for larger matrices. I discovered the problem when trying to replace the corresponding JAMA method.&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.  Looks like it could as you suggest be related to &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt;.  &lt;/p&gt;
, &lt;p&gt;For now, pushing to 3.0.  If we get a fix for this and &lt;a href="https://issues.apache.org/jira/browse/MATH-327" title=" Maximal number of iterations (540) exceeded"&gt;&lt;del&gt;MATH-327&lt;/del&gt;&lt;/a&gt; before 3.0 is ready, I may propose a 2.2.1 to include it.&lt;/p&gt;
, &lt;p&gt;My apologies if I am missing something, but here is what I noticed about the SVD. &lt;/p&gt;

&lt;p&gt;On lines 124-127 of SingularValueDecompositionImpl we have:&lt;/p&gt;

&lt;p&gt;        for (int i = 0; i &amp;lt; p; i++) {
            singularValues[i] = FastMath.sqrt(FastMath.abs(singularValues[i]));
        }&lt;/p&gt;

&lt;p&gt;This is potentially the offending line. First is the problem of negative eigenvalues. Negative variance in the principal components should probably be dealt with explicitly? Perhaps by throwing a MathException? Second, and the issue which this bug report deals with, is taking a square root of a very small number (&amp;lt;1) will return a larger number. If you apply the threshold test in getRank() (final double threshold = FastMath.max(m, n) * FastMath.ulp(singularValues&lt;span class="error"&gt;&amp;#91;0&amp;#93;&lt;/span&gt;) )  prior to taking the square root, I believe this problem would be resolved. More importantly, philosophically, you test for zero variance. This is the appropriate test.&lt;/p&gt;

&lt;p&gt;Also, rank could be precalculated in the above loop. &lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1148714.&lt;/p&gt;

&lt;p&gt;This issue was fixed by changing SVD implementation according to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-611" title="A fast and stable SVD implementation from JAMA"&gt;&lt;del&gt;MATH-611&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
], resolution=Fixed, reporter=marisa, assignees=[], commentAuthors=[psteitz, gsteri1, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,482 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-464
2016-01-13 22:22:44,497 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-464, created=Fri Dec 31 08:00:42 CET 2010, updated=Sat Mar 24 17:16:48 CET 2012, resolved=Wed Aug 24 00:37:41 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Critical, summary=LegendreGaussIntegrator ignores defaultMaximalIterationCount and does 38 million iterations, link=https://issues.apache.org/jira/browse/MATH-464, description=&lt;p&gt;The following code results in count = 37801710 which is effectively an infinite loop for typical functions we are using&lt;br/&gt;
(in GeoGebra)&lt;/p&gt;

&lt;p&gt;The argument defaultMaximalIterationCount = 100 is being ignored&lt;/p&gt;

&lt;p&gt;This is the version we are using:&lt;br/&gt;
&lt;a href="http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java"&gt;http://www.geogebra.org/trac/browser/trunk/geogebra/org/apache/commons/math/analysis/integration/LegendreGaussIntegrator.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    	LegendreGaussIntegrator gauss = new LegendreGaussIntegrator(5, 100);&lt;/p&gt;

&lt;p&gt;	try {
		double result = gauss.integrate(new testFun(), -10, 0.32462367623786328);
	} catch (Exception ee) {
		ee.printStackTrace();
	}&lt;/p&gt;



&lt;p&gt;class testFun implements UnivariateRealFunction {&lt;/p&gt;

&lt;p&gt;    public double value(double x) throws FunctionEvaluationException {
    	count ++;
        if (x&amp;gt;=0 &amp;amp;&amp;amp; x&amp;lt;=5) return 0.2; else return 0;
    }&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;, comments=[&lt;p&gt;Thanks for reporting this.&lt;/p&gt;

&lt;p&gt;The problem here is not with the iteration count.  In the example above, only 26 iterations are executed and the method returns the correct value.  What is causing the number of function evaluations to be so large is that each iteration involves multiple function evaluations.   I need to dig more deeply into the algorithm to determine what (if anything) the problem is, but what is causing the high number of function evaluations is the following&lt;/p&gt;
&lt;div class="code panel" style="border-width: 1px;"&gt;&lt;div class="codeContent panelContent"&gt;
&lt;pre class="code-java"&gt;&lt;span class="code-comment"&gt;// prepare next iteration
&lt;/span&gt;&lt;span class="code-object"&gt;double&lt;/span&gt; ratio = FastMath.min(4, FastMath.pow(delta / limit, 0.5 / abscissas.length));
n = FastMath.max((&lt;span class="code-object"&gt;int&lt;/span&gt;) (ratio * n), n + 1);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the example, delta / limit becomes large, causing n to increase rapidly.  As n increases, the number of function evaluations increases.&lt;/p&gt;
, &lt;p&gt;I am now thinking that this is not a bug, but a consequence of the fact that the integrand in the example is not at all well-approximated by a polynomial.  With a small-enough stepsize, the algorithm does converge, but requiring the large number of function evaluations above.  Here are some stepsize values for the example and the associated absolute error:&lt;/p&gt;

&lt;p&gt;n 8 error 0.05738431110184819&lt;br/&gt;
n 28 error 0.027423287634332688&lt;br/&gt;
n 100 error 8.62162720248888E-5&lt;br/&gt;
n 249 error 5.308122631570711E-4&lt;br/&gt;
n 650 error 4.3582615516528367E-4&lt;br/&gt;
n 1641 error 2.519984967931377E-4&lt;br/&gt;
n 3829 error 5.838605030586419E-5&lt;br/&gt;
...&lt;br/&gt;
 n 1102593 error 6.71416523906343E-8&lt;/p&gt;

&lt;p&gt;The last entry is from the last (26th) iteration.  I haven't verified the rationale for the updating formula for n above, but it does appear warranted in this case to increase n quickly as large n (= small stepsize) is required to get a decent estimate of the integral using Gaussian quadrature.&lt;/p&gt;
, &lt;p&gt;Perhaps we should also provide higher order formulas, using either a fixed set of precomputed constants or a way to compute the coefficients for any order.&lt;/p&gt;
, &lt;p&gt;Moving to 3.0.  I don't think this is a bug, but points to a couple of possible enhancements:&lt;/p&gt;

&lt;p&gt;1) higher order formulas (+0 on this suggestion from Luc - IMO the example and others like it are not suitable for Legendre-Gauss)&lt;br/&gt;
2) bound on the number of function evaluations (I vaguely recall us talking about this elsewhere, but can't find the reference.  If anyone else can, pls add.)&lt;/p&gt;
, &lt;p&gt;We restarted a thread about this a few days after the previous comment on this issue.&lt;br/&gt;
The thread can be read here: &lt;a href="http://markmail.org/thread/rnazrggnnuehz4qv"&gt;http://markmail.org/thread/rnazrggnnuehz4qv&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think adding maxEvaluations while still preserving the existing maxIterations would be fine.&lt;/p&gt;
, &lt;p&gt;Coming back to this issue.&lt;/p&gt;

&lt;p&gt;I would propose to follow the same pattern we used for root solvers: adding a maxEval parameter in the top level integrate interface declaration. So we would have the same kind of configuration, with tolerances set at integrator/solver level and maxEval and function pointer passed at integrate/solve method call.&lt;/p&gt;

&lt;p&gt;Since we are just in the phase we change interfaces, this would be a good time to add this parameter.&lt;/p&gt;

&lt;p&gt;Does this seems reasonable ?&lt;/p&gt;
, &lt;p&gt;+1 for your suggestion, Luc.  Lets try to get this into 3.0.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1160914.&lt;/p&gt;

&lt;p&gt;The API of the integrators has been changed for consistency with solvers API. Now the main convergence parameters are set in the constructor and remain fixed, but a maximal number of function evaluation must be provided at each call to the integration method.&lt;/p&gt;

&lt;p&gt;Thanks for the report&lt;/p&gt;
], resolution=Fixed, reporter=murkle, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=180, timeSpent=null]
2016-01-13 22:22:44,513 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-453
2016-01-13 22:22:44,513 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-453, created=Mon Dec 06 03:01:08 CET 2010, updated=Sat Mar 24 17:16:32 CET 2012, resolved=Mon Dec 06 13:53:56 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function, link=https://issues.apache.org/jira/browse/MATH-453, description=&lt;p&gt;RealVector Javadoc refers to non-existent package org.apache.commons.math.analysis.function.&lt;/p&gt;

&lt;p&gt;As this explains how to recode deprecated method calls, it ought to be corrected before release.&lt;/p&gt;, comments=[&lt;p&gt;Removed references to the &lt;tt&gt;analysis.function&lt;/tt&gt; package (revision 1042610).&lt;/p&gt;
], resolution=Fixed, reporter=sebb@apache.org, assignees=[erans], commentAuthors=[erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,513 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-434
2016-01-13 22:22:44,513 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-434, created=Sun Nov 07 04:55:32 CET 2010, updated=Sat Mar 24 17:16:29 CET 2012, resolved=Sat Apr 09 21:21:59 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=SimplexSolver returns unfeasible solution, link=https://issues.apache.org/jira/browse/MATH-434, description=&lt;p&gt;The SimplexSolver is returning an unfeasible solution:&lt;/p&gt;

&lt;p&gt;import java.util.ArrayList;&lt;br/&gt;
import java.text.DecimalFormat;&lt;br/&gt;
import org.apache.commons.math.linear.ArrayRealVector;&lt;br/&gt;
import org.apache.commons.math.optimization.GoalType;&lt;br/&gt;
import org.apache.commons.math.optimization.OptimizationException;&lt;br/&gt;
import org.apache.commons.math.optimization.linear.*;&lt;/p&gt;

&lt;p&gt;public class SimplexSolverBug {&lt;/p&gt;

&lt;p&gt;    public static void main(String[] args) throws OptimizationException {&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction c = new LinearObjectiveFunction(new double[]{0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d}, 0.0d);&lt;/p&gt;

&lt;p&gt;        ArrayList&amp;lt;LinearConstraint&amp;gt; cnsts = new ArrayList&amp;lt;LinearConstraint&amp;gt;(5);&lt;br/&gt;
        LinearConstraint cnst;&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, -0.1d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.EQ, -0.1d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, -1e-18d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 1.0d, 0.0d, 0.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 1.0d, 0.0d, -0.0128588d, 1e-5d}, Relationship.EQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 0.0d, 0.0d, 1.0d, 1e-5d, -0.0128586d}, Relationship.EQ, 1e-10d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, -1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 1.0d, 0.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, -1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;br/&gt;
        cnst = new LinearConstraint(new double[] {0.0d, 0.0d, 1.0d, 0.0d, 1.0d, 0.0d, 0.0d}, Relationship.GEQ, 0.0d);&lt;br/&gt;
        cnsts.add(cnst);&lt;/p&gt;

&lt;p&gt;        DecimalFormat df = new java.text.DecimalFormat("0.#####E0");&lt;/p&gt;

&lt;p&gt;        System.out.println("Constraints:");&lt;br/&gt;
        for(LinearConstraint con : cnsts) {
            for (int i = 0; i &amp;lt; con.getCoefficients().getDimension(); ++i)
                System.out.print(df.format(con.getCoefficients().getData()[i]) + " ");
            System.out.println(con.getRelationship() + " " + con.getValue());
        }&lt;/p&gt;

&lt;p&gt;        SimplexSolver simplex = new SimplexSolver(1e-7);&lt;br/&gt;
        double[] sol = simplex.optimize(c, cnsts, GoalType.MINIMIZE, false).getPointRef();&lt;br/&gt;
        System.out.println("Solution:\n" + new ArrayRealVector(sol));&lt;br/&gt;
        System.out.println("Second constraint is violated!");&lt;br/&gt;
    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;It's an odd problem, but something I ran across.  I tracked the problem to the getPivotRow routine in SimplexSolver.  It was choosing a pivot that resulted in a negative right-hand-side.  I recommend a fix by replacing&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
                ...&lt;br/&gt;
with&lt;br/&gt;
                ...&lt;br/&gt;
                if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;br/&gt;
                ...&lt;/p&gt;

&lt;p&gt;I believe this would be more appropriate (and at least resolves this particular problem).&lt;/p&gt;

&lt;p&gt;Also, you may want to consider making a change in getPivotColumn to replace&lt;br/&gt;
            ...&lt;br/&gt;
            if (MathUtils.compareTo(tableau.getEntry(0, i), minValue, epsilon) &amp;lt; 0) {&lt;br/&gt;
            ...&lt;br/&gt;
with&lt;br/&gt;
            ...&lt;br/&gt;
            if (tableau.getEntry(0, i) &amp;lt; minValue) &lt;br/&gt;
            ...&lt;br/&gt;
because I don't see the point of biasing earlier columns when multiple entries are within epsilon of each other.  Why not pick the absolute smallest.  I don't know that any problem can result from doing it the other way, but the latter may be a safer bet.&lt;/p&gt;

&lt;p&gt;VERY IMPORTANT: I discovered another bug that occurs when not restricting to non-negatives.  In SimplexTableu::getSolution(), &lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) &lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = 0;&lt;br/&gt;
          ...&lt;br/&gt;
should be&lt;br/&gt;
          ...          &lt;br/&gt;
          if (basicRows.contains(basicRow)) {&lt;br/&gt;
              // if multiple variables can take a given value&lt;br/&gt;
              // then we choose the first and set the rest equal to 0&lt;br/&gt;
              coefficients&lt;span class="error"&gt;&amp;#91;i&amp;#93;&lt;/span&gt; = (restrictToNonNegative ? 0 : -mostNegative);&lt;br/&gt;
          ...&lt;br/&gt;
If necessary, I can give an example of where this bug causes a problem, but it should be fairly obvious why this was wrong.&lt;/p&gt;, comments=[&lt;p&gt;My original suggested fix had a potential for overflow errors (since minRatio is initialized to Double.MAX_VALUE).  Also, I added another suggestion and pointed out another bug which leads to invalid solutions.&lt;/p&gt;
, &lt;p&gt;Could you attach unit tests that demonstrate each problem?  Thank you.&lt;/p&gt;
, &lt;p&gt;I'll try to send some examples soon.  I'm noticing more problems with the right-hand-side going negative and want to cover all bases (as much as possible).&lt;/p&gt;
, &lt;p&gt;Code, and resulting output, that illustrates issues with the SimplexSolver.&lt;/p&gt;
, &lt;p&gt;Pushing out to 3.0.&lt;/p&gt;
, &lt;p&gt;Hey, sorry I took so long to look at this.  I've had very little time and am not working on this stuff anymore.  I'm honestly not going to be able to look at this stuff much moving forward, so hopefully there's a Commons Math contributor that can act as a reviewer.&lt;/p&gt;

&lt;p&gt;When you say it's choosing a pivot with a negative RHS, I'm assuming that means it's not within the epsilon?&lt;br/&gt;
Why would it be more appropriate to divide by the entry?  I'm not sure I see why you'd want to use a bigger epsilon when the entry is 0.1 and a smaller epsilon when the entry is 10.  Maybe we should just make the default epsilon smaller?  I'm no expert with floating point math so I'm not real sure how to set the epsilon and just made up a value.&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, epsilon)) {&lt;br/&gt;
...&lt;br/&gt;
with&lt;br/&gt;
...&lt;br/&gt;
if (MathUtils.equals(ratio, minRatio, Math.abs(epsilon/entry))) {&lt;/p&gt;
, &lt;p&gt;Attached a patch for the reported problems.&lt;br/&gt;
The problems can be split into two groups:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;wrong solution calculation with negative&lt;br/&gt;
   variables&lt;/li&gt;
	&lt;li&gt;failing to select an appropriate pivot&lt;br/&gt;
   row when values are below a given &lt;br/&gt;
   epsilon&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch addresses both problems:&lt;/p&gt;

&lt;p&gt; 1. fix in SimplexTableau.getSolution()&lt;br/&gt;
 2. use BigReal for arbitrary precision  &lt;br/&gt;
    support when selecting the pivot row&lt;/p&gt;

&lt;p&gt;Additionally, 4 test cases are included, as well as a minor typo fix for a method name.&lt;/p&gt;

&lt;p&gt;The fixed epsilon is also used in some other places of the code, this may also create problems under certain circumstances. So if this patch is accepted, the other places could also be adapted.&lt;/p&gt;
, &lt;p&gt;Thanks Thomas.&lt;/p&gt;

&lt;p&gt;I had a look at the patch. I'm not a big fan of using BigReal, mainly when we don't specify a scale and we don't link it to the choice for epsilon. Also reading back Ben comments, I wonder if we should not replace epsilon by an integer number of ulps with a default set to a very small value (say something like 10 ulps).&lt;/p&gt;

&lt;p&gt;What problem did you see in the accuracy of the variables to use BigReal ?&lt;/p&gt;
, &lt;p&gt;Hi Luc,&lt;/p&gt;

&lt;p&gt;my initial idea was to use an epsilon that is adjusted to the magnitude of the respective value used for comparison. To be honest, I was not aware of &lt;span class="error"&gt;&amp;#91;Math,FastMath&amp;#93;&lt;/span&gt;.ulp, therefore I went with BigReal/BigDecimal to circumvent the problem in another way (by using an arbitrary precision datatype). After reading your comment, I investigated more into the problem, e.g. using &lt;a href="http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm"&gt;http://www.cygnus-software.com/papers/comparingfloats/Comparing%20floating%20point%20numbers.htm&lt;/a&gt;, and addressed it (hopefully correct) in the way you proposed.&lt;/p&gt;

&lt;p&gt;Though, I had to split up the epsilon test into two categories:&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;general comparison of floating-point values: using ulp, as values can be arbitrarily small&lt;/li&gt;
	&lt;li&gt;algorithm convergence check: using a standard epsilon, as the algorithm may not converge due to limited precision of&lt;br/&gt;
    the double datatype otherwise&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Please find attached my updated patch, any comments are welcome (e.g. I was unsure whether to expose the maxUlps parameter in the constructor, or to use a generic comparison epsilon, e.g. using FastMath.ulp(1d) instead of one adjusted to the current value in question).&lt;/p&gt;
, &lt;p&gt;updated patch, incorporating comments from luc&lt;/p&gt;
, &lt;p&gt;&lt;span class="error"&gt;&amp;#91;Pardon the possibly nave questions.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In "SimplexTableau":&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Why not use directly "equals(double, double, int)" from "MathUtils" instead of computing an epsilon with "getEpsilon"?&lt;/li&gt;
	&lt;li&gt;Why is the "isOptimal" method not using the adjusted "epsilon" (at line 385)?&lt;/li&gt;
&lt;/ul&gt;

, &lt;p&gt;hmm, I feel a bit stupid now, as I have re-implemented MathUtils.equals(double, double, int) but in a mediocre way. So all calls to getEpsilon should be replaced with the equivalent MathUtils.equals.&lt;/p&gt;

&lt;p&gt;for the isOptimal:&lt;/p&gt;

&lt;p&gt;the idea was to have a user-defined threshold for the convergence criteria, which defaults to the original value of 1e-6. Using the same adjusted epsilon would possibly lead to more iterations as before. As the feasibility check in SimplexSolver.solvePhase1 has to use a static epsilon for convergence reasons, I thought to use the same epsilon in isOptimal makes sense for symmetry reasons (use the same epsilon to check for convergence /feasibility).&lt;/p&gt;

&lt;p&gt;But it's good that you raise these points, because I was hesitating myself what is the best way to go forward, as I am also not considering myself a floating-point expert. I am mainly interested in the simplex algorithm, that's why I have chosen to provide a patch for this (very nice) implementation of it.&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1090656.&lt;br/&gt;
Path applied with a very small change: adding the maxUlps parameter to the detailed constructor.&lt;/p&gt;

&lt;p&gt;Thanks for the report and thanks for the patch.&lt;/p&gt;
, &lt;p&gt;Thanks for accepting the patch. The comparison using maxUlps has already been adapted according to &lt;a href="https://issues.apache.org/jira/browse/MATH-557" title="add a compareTo method to MathUtils that use a number of ulps for equality tolerance"&gt;&lt;del&gt;MATH-557&lt;/del&gt;&lt;/a&gt;, but it was missing for SimplexTableau. The cleanup patch fixes this and also renames the test names for similarity.&lt;/p&gt;
, &lt;p&gt;Cleanup patch applied.&lt;/p&gt;

&lt;p&gt;thanks again&lt;/p&gt;
], resolution=Fixed, reporter=wmwitzel, assignees=[], commentAuthors=[wmwitzel, erans, psteitz, bmccann, tn, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,513 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-429
2016-01-13 22:22:44,513 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-429, created=Fri Oct 22 10:01:54 CEST 2010, updated=Wed Mar 23 21:25:46 CET 2011, resolved=Sat Oct 23 21:35:26 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Blocker, summary=KMeansPlusPlusClusterer breaks by division by zero, link=https://issues.apache.org/jira/browse/MATH-429, description=&lt;p&gt;For a certain space, KMeansPlusPlusClusterer  breaks. This is a blocker because this space occurs in our domain. &lt;/p&gt;, comments=[&lt;p&gt;The testcase which breaks KMeansPlusPlusClusterer&lt;/p&gt;
, &lt;p&gt;You have encountered one classical problem with k-means: at some stage (here at the first iteration), one of the clusters becomes empty.&lt;br/&gt;
This case is currently no handled by commons-math (which is a bug, so we have to fix it).&lt;br/&gt;
When a cluster is empty, a new centroid must be defined from the other clusters. There are different strategies:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;take the point farthest from any cluster&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest distance variance&lt;/li&gt;
	&lt;li&gt;select a random point from the cluster with the largest number of points&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;My prefered choice would be 2, what do other people think ?&lt;/p&gt;
, &lt;p&gt;How about make it configurable?  Take a look at how the Mallet project did it:&lt;/p&gt;

&lt;p&gt;&lt;a href="http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html"&gt;http://mallet.cs.umass.edu/api/cc/mallet/cluster/KMeans.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By the way, I have suggested that they try to enter the Incubator here at the ASF and they seem somewhat receptive to the idea!&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1026666 for branche 2.X and as of r1026667 for trunk.&lt;br/&gt;
Users can now choose among four different strategies to deal with empty clusters:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;split the cluster with largest distance variance,&lt;/li&gt;
	&lt;li&gt;split the cluster with largest number of points,&lt;/li&gt;
	&lt;li&gt;create a cluster around the point farthest from its centroid,&lt;/li&gt;
	&lt;li&gt;generate an error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The default is to split according to largest variance.&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erikvaningen, assignees=[], commentAuthors=[erikvaningen, luc, jwcarman], timeEstimate=180, timeSpent=null]
2016-01-13 22:22:44,513 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-421
2016-01-13 22:22:44,513 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-421, created=Wed Sep 29 20:24:56 CEST 2010, updated=Wed Mar 23 21:23:12 CET 2011, resolved=Wed Sep 29 21:51:49 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=restarting an ODE solver that has been stopped by an event doesn't work, link=https://issues.apache.org/jira/browse/MATH-421, description=&lt;p&gt;If an ODE solver is setup with an EventHandler that return STOP when the even is triggered, the integrators stops (which is exactly the expected behavior).&lt;br/&gt;
If however the user want to restart the solver from the final state reached at the event with the same configuration (expecting the event to be triggered again at a later time), then the integrator may fail to start. It can get stuck at the previous event.&lt;/p&gt;

&lt;p&gt;The occurrence of the bug depends on the residual sign of the g function which is not exactly 0, it depends on the convergence of the first event.&lt;/p&gt;

&lt;p&gt;As this use case is fairly general, event occurring less than epsilon after the solver start in the first step should be ignored, where epsilon is the convergence threshold of the event. The sign of the g function should be evaluated after this initial ignore zone, not exactly at beginning (if there are no event at the very beginning g(t0) and g(t0+epsilon) have the same sign, so this does not hurt ; if there is an event at the very beginning, g(t0) and g(t0+epsilon) have opposite signs and we want to start with the second one. Of course, the sign of epsilon depend on the integration direction (forward or backward).&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository, as of r1002827 for branch 2.X and 1002829 for trunk (3.0)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=luc, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,513 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-414
2016-01-13 22:22:44,528 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-414, created=Tue Aug 31 13:01:44 CEST 2010, updated=Wed Mar 23 21:20:43 CET 2011, resolved=Tue Nov 30 12:57:23 CET 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=ConvergenceException in NormalDistributionImpl.cumulativeProbability(), link=https://issues.apache.org/jira/browse/MATH-414, description=&lt;p&gt;I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.&lt;br/&gt;
For instance in the following code:&lt;/p&gt;

&lt;p&gt;	@Test&lt;br/&gt;
	public void testCumulative() {&lt;br/&gt;
		final NormalDistribution nd = new NormalDistributionImpl();&lt;br/&gt;
		for (int i = 0; i &amp;lt; 500; i++) {&lt;br/&gt;
			final double val = Math.exp&lt;img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/information.gif" height="16" width="16" align="absmiddle" alt="" border="0"/&gt;;&lt;br/&gt;
			try {
				System.out.println("val = " + val + " cumulative = " + nd.cumulativeProbability(val));
			} catch (MathException e) {
				e.printStackTrace();
				fail();
			}&lt;br/&gt;
		}&lt;br/&gt;
	}&lt;/p&gt;

&lt;p&gt;In version 2.0, I get no exception. &lt;/p&gt;

&lt;p&gt;My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.&lt;/p&gt;, comments=[&lt;p&gt;The difference between 2.0 and 2.1 is due to the changes in ContinuedFraction included in the fix for &lt;a href="https://issues.apache.org/jira/browse/MATH-282" title="ChiSquaredDistributionImpl.cumulativeProbability &amp;gt; 1"&gt;&lt;del&gt;MATH-282&lt;/del&gt;&lt;/a&gt;.  For very large values, continued fractions are diverging to NaN. The suggested fix will work, but at this point, I wonder if we should just move the top-coding out of the catch - i.e., test the arguments and return 0 or 1 for extreme values without attempting the approximation.&lt;/p&gt;
, &lt;p&gt;I am leaning toward adding top-coding outside of the catch.  Based on the inequality p(Z &amp;gt; t) &amp;lt; exp(-t^2/2) derived in &lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; and Double.MIN_VALUE  = 2^-1074, I get that tail probabilities are not distinguishable from 0 for |t| &amp;gt; 39, so I propose that we top-code at 40 outside the catch.  Appreciate others checking my arithmetic.&lt;/p&gt;

&lt;p&gt;&lt;span class="error"&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href="http://www.johndcook.com/normalbounds.pdf"&gt;http://www.johndcook.com/normalbounds.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Your suggestion seems good to me.&lt;br/&gt;
I've check exp(-t^2/2) becomes lower than Double.MIN_VALUE/2 (i.e. rounds to 0) when |t|&amp;gt; 38.604&lt;/p&gt;
, &lt;p&gt;Fixed in r1040471&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=gustav.ryd, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=120, timeSpent=null]
2016-01-13 22:22:44,528 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-411
2016-01-13 22:22:44,528 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-411, created=Sun Aug 29 00:14:32 CEST 2010, updated=Wed Mar 23 21:20:06 CET 2011, resolved=Mon Sep 13 04:04:01 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression newSampleData methods inconsistently create / omit intercepts, link=https://issues.apache.org/jira/browse/MATH-411, description=&lt;p&gt;The newSampleData(double[], nrows, ncols) method used in the unit tests adds a unitary column to the design matrix, resulting in an intercept term being estimated among the regression parameters.  The other newSampleData methods do not do this, forcing users to add the column of "1"s to estimate models with intercept.  Behavior should be consistent and users should not have to add the column.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r993574.  Modified multiple regression newSample methods to ensure that by default in all cases, regression models are estimated with intercept terms.  Prior to the fix for this issue,  newXSampleData(double[][]), newSampleData(double[], double[][]) and newSampleData(double[], double[][], double[][]) all required columns of "1's  to be inserted into the x[][] arrays to create a model with an intercept term;while newSampleData(double[], int, int) created a model including an intercept term without requiring the unitary column.  All methods have  been changed to eliminate the need for users to add unitary columns to specify regression models.&lt;/p&gt;

&lt;p&gt;Leaving open until &lt;a href="https://issues.apache.org/jira/browse/MATH-409" title="Multiple Regression API should allow specification of whether or not to estimate intercept term"&gt;&lt;del&gt;MATH-409&lt;/del&gt;&lt;/a&gt; is resolved. &lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,528 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-409
2016-01-13 22:22:44,528 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-409, created=Tue Aug 24 11:55:32 CEST 2010, updated=Wed Mar 23 21:19:13 CET 2011, resolved=Mon Sep 13 04:02:43 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Multiple Regression API should allow specification of whether or not to estimate intercept term, link=https://issues.apache.org/jira/browse/MATH-409, description=&lt;p&gt;The OLS and GLS regression APIs should support estimating models including intercepts using design matrices including only variable data.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r996404 (both trunk and 2.x branch)&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,528 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-408
2016-01-13 22:22:44,528 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-408, created=Mon Aug 23 05:11:23 CEST 2010, updated=Wed Mar 23 21:18:48 CET 2011, resolved=Sun Dec 12 22:49:44 CET 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=GLSMultipleLinearRegression has no nontrivial validation tests, link=https://issues.apache.org/jira/browse/MATH-408, description=&lt;p&gt;There are no non-trivial tests verifying the computations for GLSMultipleLinearRegression.  Tests verifying computations against analytically determined models, R or some other reference package / datasets should be added to ensure that the statistics reported by this class are valid.&lt;/p&gt;, comments=[&lt;p&gt;Added a non-trivial test in r1044935.  While still not really a full verification test, it does at least verify that the GLS impl provided does better than OLS for models with error structure conforming to its covariance matrix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-407
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-407, created=Mon Aug 23 05:07:08 CEST 2010, updated=Wed Mar 23 21:18:29 CET 2011, resolved=Mon Sep 20 03:57:59 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=Documentation improvements for multiple regression classes, link=https://issues.apache.org/jira/browse/MATH-407, description=&lt;p&gt;The user guide examples showing how to set up and estimate linear models using OLS and GLS multiple regression need to be updated to reflect changes in the API.  The javadoc for these classes and user guide descriptions also need to be improved to make it clear how to estimate a model with an intercept term.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in r998761&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=psteitz, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-406
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-406, created=Sat Aug 14 23:57:56 CEST 2010, updated=Wed Mar 23 21:18:04 CET 2011, resolved=Sun Aug 15 00:02:03 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Wrong weight handling in Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-406, description=&lt;p&gt;A comparison with a Fortran version of Levenberg-Marquardt reveals that when observations have different weights, the 2.1 version reaches a value of the function which does not necessary correspond to the minimum&lt;/p&gt;, comments=[&lt;p&gt;Correction patch.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-405
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-405, created=Wed Aug 11 15:24:39 CEST 2010, updated=Wed Mar 23 21:17:42 CET 2011, resolved=Wed Aug 11 15:46:55 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[Nightly Builds
], priority=Major, summary=Inconsistent result from Levenberg-Marquardt, link=https://issues.apache.org/jira/browse/MATH-405, description=&lt;p&gt;Levenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost&lt;/p&gt;, comments=[&lt;p&gt;Correction patch&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[dimpbx, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-404
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-404, created=Mon Aug 09 13:44:12 CEST 2010, updated=Sat Mar 24 17:17:04 CET 2012, resolved=Mon Aug 30 15:53:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=Confusing interface for "LevenbergMarquardtOptimizer", link=https://issues.apache.org/jira/browse/MATH-404, description=&lt;p&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; which in turn implements &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt;. That interface mandates methods for setting and getting a &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;.&lt;br/&gt;
In v2.1, however, that checker is never used! The convergence check is performed using parameters specific to the Levenberg-Marquardt algorithm. Such circumvention of the superclass interface is confusing and leads to totally unexpected behaviour (such as changing the values of the thresholds of the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; being ineffective).&lt;br/&gt;
In the development version, the default constructor of &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; sets the the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; field to "null" and when such is the case, the behaviour is as in v2.1. Although it is documented, this is still confusing since it is impossible to use &lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; through its &lt;tt&gt;DifferentiableMultivariateVectorialOptimizer&lt;/tt&gt; interface: When using the &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt;, one does not know what parameters to use in order to reproduce the results obtained with the LM-specific convergence check (i.e. how to reproduce the result from v2.1).&lt;br/&gt;
Unless I'm missing something, I think that there should be an LM-specific implementation of &lt;tt&gt;VectorialConvergenceChecker&lt;/tt&gt; that, when given the usual relative and absolute thresholds, can perform a check that will give the same result as the currently specific check (when the "checker" field is "null").&lt;/p&gt;, comments=[&lt;p&gt;The problem was identified and discussed as &lt;a href="https://issues.apache.org/jira/browse/MATH-362" title="LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it"&gt;&lt;del&gt;MATH-362&lt;/del&gt;&lt;/a&gt;. It was decided to let both convergence methods available.&lt;/p&gt;

&lt;p&gt;The reason there are two different way is that the Levenberg-Marquardt implementation originally came from Netlib and I kept the way it behaved. I think the general interface with the new generic convergence was set up later and at that time I forgot to implement it properly, so the settings were ignored.&lt;/p&gt;

&lt;p&gt;Reporter of issue 362 explicitly asked to keep the ortho-tolerance setting and this setting does not fit with the general scheme.&lt;/p&gt;
, &lt;p&gt;Sorry I hadn't followed that other report.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was decided to let both convergence methods available. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is &lt;tt&gt;null&lt;/tt&gt; or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;

&lt;p&gt;As explained above, from an OOP point-of-view, it is surprising that a class completely circumvents its base class interface.&lt;br/&gt;
At least one of the following is wrong:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; inherits from &lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;LevenbergMarquardtOptimizer&lt;/tt&gt; has a second interface for convergence checking&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;AbstractLeastSquaresOptimizer&lt;/tt&gt; defines the interface for  convergence checking&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;span class="error"&gt;&amp;#91;...&amp;#93;&lt;/span&gt; does not fit with the general scheme.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;br/&gt;
Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;

&lt;p&gt;If it is really impossible to fit LM within the hierarchy it currently belongs to, then it should not belong to it, since one cannot leverage the advantages of "interface programming" anyways.&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;Switching between two convergence checking procedures, based on whether a field is null or not, is at best a temporary workaround, but it is not a good solution.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Then maybe the scheme needs to be reviewed so that it is general enough to fit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or LevenbergMarquardtOptimizer needs to be changed and the orthogonality concept be finally discarded.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Allow me to remind what you said: convergence checking is independent from the optimization algorithm.&lt;br/&gt;
But then, in the LM implementation, this doesn't hold...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I know, and I am not happy with this. However, I don't want LevenbergMarquardtOptimizer to be special. It &lt;em&gt;must&lt;/em&gt; fit. We can take the opportunity of a 3.0 major release to fix this problem too, with some incompatible changes. What would you propose for this ?&lt;/p&gt;
, &lt;blockquote&gt;
&lt;p&gt;What would you propose for this ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don't know.&lt;/p&gt;

&lt;p&gt;However, it seems that this "non-fitting checker" case is not isolated. I wanted to replace the original check in "BrentOptimizer" (package "optimization.univariate") by a call to an appropriate subclass of "RealConvergenceChecker", but here too there are more values to be considered than those stored in a pair of "RealPointValuePair". The check needs&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the "current" point&lt;/li&gt;
	&lt;li&gt;the points at both interval ends&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;but it does not use the "previous" point.&lt;/p&gt;

&lt;p&gt;So it seems that this also does not fit with the "converged" method of the "RealConvergenceChecker" interface.&lt;/p&gt;

&lt;p&gt;At first sight, I'd say that there should be a more general "ConvergenceChecker" (not existing yet) interface. Maybe using generics...&lt;/p&gt;
, &lt;p&gt;I'm trying to define a more general "ConvergenceChecker" interface. This is an incompatible change.&lt;/p&gt;
, &lt;p&gt;Final resolution is delegated to issue &lt;a href="https://issues.apache.org/jira/browse/MATH-413"&gt;MATH-413&lt;/a&gt;.&lt;/p&gt;
], resolution=Unknown, reporter=erans, assignees=[erans], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-395
2016-01-13 22:22:44,544 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-395, created=Sun Jul 25 23:26:33 CEST 2010, updated=Wed Mar 23 21:14:58 CET 2011, resolved=Wed Jul 28 14:11:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Bugs in "BrentOptimizer", link=https://issues.apache.org/jira/browse/MATH-395, description=&lt;p&gt;I apologize for having provided a buggy implementation of Brent's optimization algorithm (class "BrentOptimizer" in package "optimization.univariate").&lt;br/&gt;
The unit tests didn't show that there was something wrong, although (from the "changes.xml" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.&lt;br/&gt;
Comparing with an implementation in Python, I could figure out the fixes. I'll modify "BrentOptimizer" and add a test. I also propose to change the name of the unit test class from "BrentMinimizerTest" to "BrentOptimizerTest".&lt;/p&gt;, comments=[&lt;p&gt;Bugs corrected in revision 979257.&lt;br/&gt;
Not resolving yet because the implementation still does not behave as the Python one. I've added a unit test that indicates the discrepancies (with "XXX" markers).&lt;/p&gt;
, &lt;p&gt;Last bug fixed in revision 980032.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;This revision also contains the modifications due to the changes in &amp;quot;AbstractUnivariateRealOptimizer&amp;quot;.&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The test comparing with Python has been removed because a tracing of the execution paths (in Python and Java) showed that the remaining discrepancies were due to different values being used for the "golden ratio" constant.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[erans], commentAuthors=[erans, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,591 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-392
2016-01-13 22:22:44,591 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-392, created=Wed Jul 21 20:43:10 CEST 2010, updated=Wed Mar 23 21:13:58 CET 2011, resolved=Sun Aug 22 15:16:29 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=calculateYVariance in OLS/GLSMultipleLinearRegression uses residuals not Y vars, link=https://issues.apache.org/jira/browse/MATH-392, description=&lt;p&gt;Implementation of OLS/GLSMultipleLinearRegression is:&lt;br/&gt;
@Override&lt;br/&gt;
173        protected double calculateYVariance() {
174            RealVector residuals = calculateResiduals();
175            return residuals.dotProduct(residuals) /
176                   (X.getRowDimension() - X.getColumnDimension());
177        }&lt;/p&gt;

&lt;p&gt;This gives variance of residuals not variance of the dependent (Y) variable as the documentation suggests.&lt;/p&gt;, comments=[&lt;p&gt;Thank you for reporting this.  Patches welcome!&lt;/p&gt;
, &lt;p&gt;Can't test a patch as I'm not able to build current repository version:&lt;br/&gt;
math/src/test/java/org/apache/commons/math/optimization/univariate/BrentOptimizerTest.java:&lt;span class="error"&gt;&amp;#91;28,39&amp;#93;&lt;/span&gt; cannot find symbol&lt;br/&gt;
symbol  : class SincFunction&lt;/p&gt;

&lt;p&gt;Implementation for both GLS/OLS:&lt;/p&gt;

&lt;p&gt;protected double calculateYVariance() {
    return new Variance().evaluate(Y);
}&lt;/p&gt;
, &lt;p&gt;There was an error in a file committed this afternoon. It should be OK now.&lt;/p&gt;
, &lt;p&gt;corrected implementations of calculateYVariance() for OLS/GLSMultipleRegression&lt;/p&gt;

&lt;p&gt;added unit tests for both calculateYVariance implementations&lt;/p&gt;

&lt;p&gt;fixed AbstractMultipleRegression.estimateRegressionParametersStandardErrors() to use residuals &lt;/p&gt;
, &lt;p&gt;Fixed in 987897.   I added calcluate/estimateErrorVariance methods to return what was previously incorrectly reported as "Y variance."&lt;br/&gt;
Thanks for the patch!&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=markdevaney, assignees=[], commentAuthors=[psteitz, markdevaney, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,591 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-391
2016-01-13 22:22:44,591 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-391, created=Wed Jul 21 10:57:46 CEST 2010, updated=Wed Mar 23 21:13:27 CET 2011, resolved=Sun Oct 03 18:43:11 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=Inconsistent behaviour of constructors in ArrayRealVector class, link=https://issues.apache.org/jira/browse/MATH-391, description=&lt;p&gt;ArrayRealVector(double[] d) allows to construct a zero-length vector, but ArrayRealVector(double[] d, boolean copyArray) doesn't. Both should allow this as zero-length vectors are mathematically well-defined objects and they are useful boundary cases in many algorithms.&lt;/p&gt;

&lt;p&gt;This breaks some arithmetic operators (addition) on zero-length real vectors which worked in 2.0 but don't work in 2.1&lt;/p&gt;, comments=[&lt;p&gt;I agree that the code should be consistent.  I agree as well that a zero-dimensional vector is legit.   Can anyone explain why ArrayRealVector(double[] d, boolean copyArray) requires positive length?&lt;/p&gt;
, &lt;p&gt;Most probably my bad ...&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r1003993 for barnch 2.X and r1003994 for trunk.&lt;br/&gt;
Note that the same problem occurred also in ArrayFieldVector but the fix is different. For Field-based vectors, we need to get the field, so either we use a non-empty array and retrieve the field from the first array element or we add a parameter for the field and allow the array to be empty. The two choices are now possible, as new constructors have been added and the javadoc updated to explain this behavior.&lt;br/&gt;
Thanks for reporting the issue.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[psteitz, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-390
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-390, created=Wed Jul 21 00:47:21 CEST 2010, updated=Wed Jul 21 01:32:12 CEST 2010, resolved=Wed Jul 21 01:32:12 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Major, summary=Simplex Solver is very inaccurate on a large problem, even a very low value for epsilon, link=https://issues.apache.org/jira/browse/MATH-390, description=&lt;p&gt;I'm currently playing with a program for solving a rather simple chess puzzle. The goal is to place 12 knights on a 8x8 board, such that each field is either attacked by a knight, or contains a knight. To solve this problem (and different variants) I want to use a handcrafted Branch and Bound algorithm that uses Linear Programming to calculate an upperbound on the number of fields that can be covered by a certain amount of knights.&lt;/p&gt;

&lt;p&gt;The idea is to create variables for each field that has to be covered, and to create variables for each field to contain a knight. A cover variable can only become positive if a corresponding knight variable for an adjacent field is also positive, there is a limit to the amount of knights we may place (so the sum of all knight variables cannot be larger than 12) and the cover variables cannot be larger than one. Also, only the cover variables have a coefficient of one in the objective function, all other variables have zero. Because we want to cover the entire board our goal will be to maximize the objective function, since we want to maximize the number of fields that are covered.&lt;/p&gt;

&lt;p&gt;Since a basic chessboard has 64 fields and since it is possible to cover the chessboard with 12 knights, we know there is an integer solution that has value 64. Since we are solving a relaxed variant of the problem, the value should be at least 64. However, when I use the Simplex Solver, I get a value of around 58.6, which is much too low. Even when I relax the constraints in such a fashion that 64 knights may be placed on the board, the solution value remains the same. I've lowered the value of epsilon as much as I can and it still gives the incorrect value. What makes it worse is that the calculation is totally useless as an upperbound (if the value would have been around 70, it would have been an upperbound at least).&lt;/p&gt;

&lt;p&gt;I've heard that using the revised simplex method is a lot better with respect to stacked errors, so I am not sure this is really a bug, or just a problem that arises when the two phase simplex method is used for large problems.&lt;/p&gt;

&lt;p&gt;I will try to attach a code example that implements the problem (but possibly isn't that readable).&lt;/p&gt;, comments=[&lt;p&gt;Example of the 8x8 Knight covering Chess problem. The objective value should at least be 64, but it is around 59.&lt;/p&gt;
, &lt;p&gt;Hmm, it seems I made a programming mistake in the type of the relationship: I used an equality where I should have used a greater-equals. I created a much nicer version of the example, which actually works. Feel free to use it for an example or something.&lt;/p&gt;

&lt;p&gt;My bad, I will close the issue.&lt;/p&gt;
, &lt;p&gt;The correct and more readable example, which actually works.&lt;/p&gt;
, &lt;p&gt;It seems I made a programming error. I included a correct example to solve the problem.&lt;/p&gt;
], resolution=Fixed, reporter=pcbouman, assignees=[], commentAuthors=[pcbouman], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-380
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-380, created=Thu Jun 24 18:47:54 CEST 2010, updated=Sat Mar 24 17:16:33 CET 2012, resolved=Sat Oct 01 15:54:20 CEST 2011, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Minor, summary=Need to (re)initialize dYdY0 for multiple integrate with FirstOrderIntegratorWithJacobians, link=https://issues.apache.org/jira/browse/MATH-380, description=&lt;p&gt;There is a lack in the method integrate of FirstOrderIntegratorWithJacobians. The jacobian DYDY0 can't be initialized by the user, unlike DFDP with DF0DP.&lt;br/&gt;
So, for several successive integrations, the matrix is reinitialized to identity and that is not what we might want.&lt;/p&gt;, comments=[&lt;p&gt;You are perfectly right.&lt;/p&gt;

&lt;p&gt;The FirstOrderIntegratorWithJacobians class is a brand new one and it clearly has some design flaws.&lt;br/&gt;
It will most probably be deprecated in its current form and replaced by a new mechanism, better integrated (sorry for the joke) with the standard ODE solvers.&lt;br/&gt;
The ability for user to set an initial value for dydy0 will be present in the new design, but will probably not be back-ported to the current one.&lt;br/&gt;
In the meantime, you can save the final value of the jacobian matrix dydy0 after first part of integration, which we could call dy1dy0 as it represents dy(t1)/dy(t0). Start the second part from t1 to t2 that will reset the initial matrix to identity and hence compute compute dy(t2)/dy(t1) and do the multiplication by yourself of the two matrices to really get what you need: dy(t2)/dy(t1) = dy(t2)/dy(t1) * dy(t1)/dy(t0).&lt;/p&gt;

&lt;p&gt;Thanks for reporting the issue &lt;/p&gt;
, &lt;p&gt;changing target fix version to 3.0.&lt;br/&gt;
Fixing this and several other problems requires a complete rewrite of the jacobians computation with ODE, and this rewrite implies user interfaces changes, so it cannot be fixed before 3.0.&lt;/p&gt;
, &lt;p&gt;A first attempt to implement Jacobians computation again in ODE has been committed in subversion repository as of r1175409.&lt;br/&gt;
This implementation still lacks the ability for step handlers to also retrieve the additional equations and their derivatives.&lt;br/&gt;
This implementation is based on the Orekit one described here: &lt;a href="https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf"&gt;https://www.orekit.org/blog/public/vpommier-ISSFD-2011-extended_propagation.pdf&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;fixed in subversion repository as of r1176745.&lt;/p&gt;
], resolution=Fixed, reporter=pparraud, assignees=[luc], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-377
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-377, created=Thu Jun 17 11:06:03 CEST 2010, updated=Wed Mar 23 21:08:36 CET 2011, resolved=Sun Jul 25 21:49:09 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Major, summary=weight versus sigma in AbstractLeastSquares, link=https://issues.apache.org/jira/browse/MATH-377, description=&lt;p&gt;In AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.&lt;/p&gt;

&lt;p&gt; Once corrected, getRMS() can even reduce&lt;/p&gt;

&lt;p&gt; public double getRMS() {return Math.sqrt(getChiSquare()/rows);}&lt;/p&gt;, comments=[&lt;p&gt;It is not clear to me exactly what is being computed in getChiSquare.  Step 0 is to get an actual definition in the javadoc for what it is trying to compute.  I agree it seems odd to be dividing by residual weights; but I could be missing the intent.&lt;/p&gt;
, &lt;p&gt;OK, let us define ChiSquare as the sum of the weighted square of the residual in order to be consistent with the rest of the definitions in that class.  That would also be consistent with what users expect from a parameter labeled 'weight' rather than 'sigma'.  If we reach consensus on that definition, I can take care of that issue.&lt;/p&gt;
, &lt;p&gt;I could be missing something, but I see no reason that the weighted sum of squared residuals computed here (after the proposed change) should in general follow a chi-square distribution or be related to a chi-square test statistic of any kind.   Why is it called chi-square?  Sorry if I am missing something simple here.&lt;/p&gt;
, &lt;p&gt;I guess if you assume normalliy distributed errors, it makes sense, so drop the last comment and I am +1 for the change (with definition added to the javadoc).&lt;/p&gt;
, &lt;p&gt;Indeed, the confusion comes from the fact that, in some textbooks, each residual is divided by 'sigma_i' which leads to a weight of 1/(sigma_i^2).  In CM, we adopted the terminology 'weight' without reference to sigma.  I will change the javadoc accordingly.&lt;/p&gt;
, &lt;p&gt;Patch to correct issue &lt;a href="https://issues.apache.org/jira/browse/MATH-377" title="weight versus sigma in AbstractLeastSquares"&gt;&lt;del&gt;MATH-377&lt;/del&gt;&lt;/a&gt;.  The change in getChiSquare let to a tiny update in one of Levenberg-Marquardt unit tests.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=dimpbx, assignees=[dimpbx], commentAuthors=[psteitz, dimpbx, luc], timeEstimate=1, timeSpent=null]
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-373
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-373, created=Mon Jun 07 16:54:00 CEST 2010, updated=Sat Mar 24 17:16:56 CET 2012, resolved=Thu Sep 02 06:52:33 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[3.0
], priority=Major, summary=StatUtils.sum returns NaN for zero-length arrays, link=https://issues.apache.org/jira/browse/MATH-373, description=&lt;p&gt;StatUtils.sum returns NaN for zero-length arrays, which is:&lt;/p&gt;

&lt;p&gt;1. inconsistent with the mathematical notion of sum: in maths, sum_{i=0}^{N-1} a_i will be 0 for N=0. In particular, the identity&lt;br/&gt;
&lt;br/&gt;
sum_{i=0}^{k-1} a_i + sum_{i=k}^{N-1} = sum_{i=0}^{N-1}&lt;/p&gt;

&lt;p&gt;is broken for k = 0, since NaN + x = NaN, not x.&lt;/p&gt;

&lt;p&gt;2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition, as NaNs propagate silently and require manual tracing during the debugging)&lt;/p&gt;

&lt;p&gt;3. enforces "special case" handling when the user expects that the summed array can have a zero length.&lt;/p&gt;

&lt;p&gt;The correct behaviour is, in my opinion, to return 0.0, not NaN in the above case.&lt;/p&gt;, comments=[&lt;p&gt;I agree with the reasoning here, and we should do it this way in 3.0.  However it is an incompatible change to do in a point release, so I'm going to wait for more feed back from other developers before I make any changes to the current code.&lt;/p&gt;

&lt;p&gt;I'm thinking that adding a method to AbstractUnivariateStatistic that looks like:&lt;br/&gt;
   protected boolean test( final double[] values,  final int begin,   final int length, final boolean allowEmpty)&lt;/p&gt;

&lt;p&gt;that would have the test:&lt;br/&gt;
   if(length == 0 &amp;amp;&amp;amp; !allowEmpty)&lt;br/&gt;
        return false;&lt;/p&gt;

&lt;p&gt;The current test method can call the new one with allowEmpty=false for backwards compatibility.  Then we can decide on which statistics should have a zero value on the empty set.&lt;/p&gt;
, &lt;p&gt;The consensus of the commons-math developers is that, since the current behavior is documented in 2.x, that this will have to wait for 3.0.  Fixing this in 2.x would introduce a too large incompatibility change to include in 2.x.&lt;/p&gt;

&lt;p&gt;I can attach a patch against 2.x that fixes this, as long as anybody using the patch understands that it isn't supported.&lt;/p&gt;

, &lt;p&gt;Possibly crazy idea: &lt;/p&gt;

&lt;p&gt;if Math 3.0 is going to change package names (which may be necessary), one could introduce the fix using a math3 package name?&lt;/p&gt;
, &lt;p&gt;IIRC, changing the package name had been suggested and discussed for 2.0.&lt;br/&gt;
&lt;span class="error"&gt;&amp;#91;One argument is that, to be consistent,  you&amp;#39;d have to change the name at every major release...&amp;#93;&lt;/span&gt;&lt;/p&gt;
, &lt;p&gt;Speaking as a maintainer of client code which uses ACM, I'd rather cope with occasional incompatibilities in the same packages, than have to change ALL my client code to keep up with the package name changes after every release. A reason to change the package name would be if you wanted to use the old and new version side by side, but that would not be a common usage pattern for ACM, I think.&lt;/p&gt;
, &lt;p&gt;As Gilles mentioned, changing the package name for commons-math was discussed and voted on for 2.x.  The result of the vote was to keep the package name, since commons-math won't usually be provided by a third party library.  Since nothing much has changed, I can't see that commons-math would change it's package for version 3.0.&lt;/p&gt;
, &lt;p&gt;This will be fixed in the 3.0 build.&lt;/p&gt;
], resolution=Fixed, reporter=rwerp, assignees=[], commentAuthors=[billbarker, sebb@apache.org, erans, rwerp], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-369
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-369, created=Mon May 03 17:48:27 CEST 2010, updated=Wed Mar 23 21:05:06 CET 2011, resolved=Mon May 03 20:43:59 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[], priority=Minor, summary=BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException, link=https://issues.apache.org/jira/browse/MATH-369, description=&lt;p&gt;Method &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  &lt;/p&gt;

&lt;p&gt;invokes &lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(double min, double max) &lt;/p&gt;

&lt;p&gt;which throws NullPointerException, as member variable&lt;/p&gt;

&lt;p&gt;    UnivariateRealSolverImpl.f &lt;/p&gt;

&lt;p&gt;is null.&lt;/p&gt;

&lt;p&gt;Instead the method:&lt;/p&gt;

&lt;p&gt;    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)&lt;/p&gt;

&lt;p&gt;should be called.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;/p&gt;

&lt;p&gt;invoke:&lt;/p&gt;

&lt;p&gt;     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);&lt;/p&gt;

&lt;p&gt;NullPointerException will be thrown.&lt;/p&gt;, comments=[&lt;p&gt;Fixed in subversion repository as of r940565.&lt;br/&gt;
Thanks for the report and for the fix.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=sasunpundev@abv.bg, assignees=[], commentAuthors=[luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-368
2016-01-13 22:22:44,606 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-368, created=Thu Apr 29 05:41:10 CEST 2010, updated=Wed Mar 23 21:04:17 CET 2011, resolved=Mon May 10 01:07:24 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=OpenMapRealVector.getSparcity should be getSparsity, link=https://issues.apache.org/jira/browse/MATH-368, description=&lt;p&gt;The term for describing the ratio of nonzero elements to zero elements in a matrix/vector is sparsity, not sparcity.  Suggest renaming getSparcity() to getSparsity()&lt;/p&gt;, comments=[&lt;p&gt;The policy of this project is to not remove methods from the public API in a point release.  However, the misspelled method has been deprecated and the correctly spelled method has been added.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,622 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-367
2016-01-13 22:22:44,622 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-367, created=Thu Apr 22 20:31:06 CEST 2010, updated=Wed Mar 23 21:03:42 CET 2011, resolved=Mon May 10 03:17:14 CEST 2010, status=Closed, type=Bug, version=[2.1
, 2.2
], fixVersion=[2.2
], priority=Minor, summary=AbstractRealVector.sparseIterator fails when vector has exactly one non-zero entry, link=https://issues.apache.org/jira/browse/MATH-367, description=&lt;p&gt;The following program:&lt;br/&gt;
===&lt;br/&gt;
import java.util.Iterator;&lt;br/&gt;
import org.apache.commons.math.linear.*;&lt;/p&gt;

&lt;p&gt;public class SparseIteratorTester&lt;br/&gt;
{&lt;br/&gt;
    public static void main(String[] args) {&lt;br/&gt;
        double vdata[] = { 0.0, 1.0, 0.0 };&lt;br/&gt;
        RealVector v = new ArrayRealVector(vdata);&lt;br/&gt;
        Iterator&amp;lt;RealVector.Entry&amp;gt; iter = v.sparseIterator();&lt;br/&gt;
        while(iter.hasNext()) {
            RealVector.Entry entry = iter.next();
            System.out.printf("%d: %f\n", entry.getIndex(), entry.getValue());
        }   &lt;br/&gt;
    }       &lt;br/&gt;
} &lt;br/&gt;
===&lt;br/&gt;
generates this output:&lt;/p&gt;

&lt;p&gt;1: 1.000000&lt;br/&gt;
Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: -1&lt;br/&gt;
	at org.apache.commons.math.linear.ArrayRealVector.getEntry(ArrayRealVector.java:995)&lt;br/&gt;
	at org.apache.commons.math.linear.AbstractRealVector$EntryImpl.getValue(AbstractRealVector.java:850)&lt;br/&gt;
	at test.SparseIteratorTester.main(SparseIteratorTester.java:13)&lt;br/&gt;
===&lt;/p&gt;

&lt;p&gt;This patch fixes it, and simplifies AbstractRealVector.SparseEntryIterator  (sorry, i don't see any form entry for attaching a file)&lt;br/&gt;
===&lt;br/&gt;
Index: src/main/java/org/apache/commons/math/linear/AbstractRealVector.java&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(revision 936985)&lt;br/&gt;
+++ src/main/java/org/apache/commons/math/linear/AbstractRealVector.java	(working copy)&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.commons.math.linear;&lt;/p&gt;

&lt;p&gt; import java.util.Iterator;&lt;br/&gt;
+import java.util.NoSuchElementException;&lt;/p&gt;

&lt;p&gt; import org.apache.commons.math.FunctionEvaluationException;&lt;br/&gt;
 import org.apache.commons.math.MathRuntimeException;&lt;br/&gt;
@@ -875,40 +876,25 @@&lt;br/&gt;
         /** Dimension of the vector. */&lt;br/&gt;
         private final int dim;&lt;/p&gt;

&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Temporary entry (reused on each call to {@link #next()}. */&lt;/li&gt;
	&lt;li&gt;private EntryImpl tmp = new EntryImpl();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;/** Current entry. */&lt;br/&gt;
+        /** Last entry returned by #next(). */&lt;br/&gt;
         private EntryImpl current;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Next entry. */&lt;br/&gt;
+        /** Next entry for #next() to return. */&lt;br/&gt;
         private EntryImpl next;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** Simple constructor. */&lt;br/&gt;
         protected SparseEntryIterator() {&lt;br/&gt;
             dim = getDimension();&lt;br/&gt;
             current = new EntryImpl();&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (current.getValue() == 0) {
-                advance(current);
-            }&lt;/li&gt;
	&lt;li&gt;if(current.getIndex() &amp;gt;= 0){
-                // There is at least one non-zero entry
-                next = new EntryImpl();
-                next.setIndex(current.getIndex());
+            next = new EntryImpl();
+            if(next.getValue() == 0)
                 advance(next);
-            } else {
-                // The vector consists of only zero entries, so deny having a next
-                current = null;
-            }&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;/** Advance an entry up to the next non null one.&lt;br/&gt;
+        /** Advance an entry up to the next nonzero value.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param e entry to advance&lt;br/&gt;
          */&lt;br/&gt;
         protected void advance(EntryImpl e) {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;if (e == null) {
-                return;
-            }&lt;br/&gt;
             do {
                 e.setIndex(e.getIndex() + 1);
             } while (e.getIndex() &amp;lt; dim &amp;amp;&amp;amp; e.getValue() == 0);&lt;br/&gt;
@@ -919,22 +905,17 @@&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;br/&gt;
         public boolean hasNext() {
-            return current != null;
+            return next.getIndex() &amp;gt;= 0;
         }&lt;br/&gt;
 &lt;br/&gt;
         /** {@inheritDoc} */&lt;br/&gt;
         public Entry next() {&lt;/p&gt;
&lt;ul class="alternate" type="square"&gt;
	&lt;li&gt;tmp.setIndex(current.getIndex());&lt;/li&gt;
	&lt;li&gt;if (next != null) {&lt;/li&gt;
	&lt;li&gt;current.setIndex(next.getIndex());&lt;/li&gt;
	&lt;li&gt;advance(next);&lt;/li&gt;
	&lt;li&gt;if (next.getIndex() &amp;lt; 0) {
-                    next = null;
-                }&lt;/li&gt;
	&lt;li&gt;} else {
-                current = null;
-            }&lt;/li&gt;
	&lt;li&gt;return tmp;&lt;br/&gt;
+            int index = next.getIndex();&lt;br/&gt;
+            if(index &amp;lt; 0)&lt;br/&gt;
+                throw new NoSuchElementException();&lt;br/&gt;
+            current.setIndex(index);&lt;br/&gt;
+            advance(next);&lt;br/&gt;
+            return current;&lt;br/&gt;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         /** {@inheritDoc} */&lt;/p&gt;, comments=[&lt;p&gt;patch fixing the bug&lt;/p&gt;
, &lt;p&gt;I've applied your patch (with a couple of style tweaks).  It should be available in the next release of commons-math.&lt;/p&gt;

&lt;p&gt;Thank you for your contribution.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=ashuang, assignees=[billbarker], commentAuthors=[ashuang, billbarker, luc], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,622 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-365
2016-01-13 22:22:44,622 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-365, created=Tue Apr 20 16:21:20 CEST 2010, updated=Wed Mar 23 21:02:52 CET 2011, resolved=Wed Apr 21 16:35:53 CEST 2010, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.2
], priority=Minor, summary=Issue with "SmoothingBicubicSplineInterpolator", link=https://issues.apache.org/jira/browse/MATH-365, description=&lt;p&gt;I figured out that the name of this class is misleading as the implementation doesn't perform the intended smoothing.&lt;/p&gt;

&lt;p&gt;In order to solve this issue, I propose to:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;deprecate the "SmoothingBicubicSplineInterpolator" class&lt;/li&gt;
	&lt;li&gt;create a "BicubicSplineInterpolator" class (similar to the above class but with the useless code removed)&lt;/li&gt;
	&lt;li&gt;remove the "SmoothingBicubicSplineInterpolatorTest" class&lt;/li&gt;
	&lt;li&gt;add a "BicubicSplineInterpolatorTest" with essentially the same contents as the above one&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Then I would also add a new "SmoothingPolynomialBicubicSplineInterpolator" where I used the "PolynomialFitter" class to smooth the input data along both dimensions before the interpolating function is computed.&lt;/p&gt;

&lt;p&gt;Does someone object to these changes?&lt;/p&gt;, comments=[&lt;p&gt;removing the test class would badly impact test coverage, so it would be better to simply deprecae it also and to remove the library class and its associated test class together when releasing 3.0&lt;/p&gt;
, &lt;p&gt;revision 936295.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=erans, assignees=[], commentAuthors=[luc, erans], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,622 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-362
2016-01-13 22:22:44,622 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-362, created=Tue Apr 06 13:38:46 CEST 2010, updated=Wed Mar 23 21:02:00 CET 2011, resolved=Sat May 29 20:16:50 CEST 2010, status=Closed, type=Bug, version=[2.0
, 2.1
], fixVersion=[2.2
], priority=Major, summary=LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it, link=https://issues.apache.org/jira/browse/MATH-362, description=&lt;p&gt;LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.&lt;/p&gt;, comments=[&lt;p&gt;Ooops. You are right.&lt;br/&gt;
The Levenberg-Marquardt optimizer uses specific convergence parameters which can be set by   setInitialStepBoundFactor, setCostRelativeTolerance, setParRelativeTolerance and setOrthoTolerance.&lt;br/&gt;
The most important convergence tuning are either setCostRelativeTolerance for a convergence on the cost itself or setParRelativeTolerance for a convergence on the parameters.&lt;/p&gt;

&lt;p&gt;I'm not sure how to solve this. Do the existing tuning parameters fit your needs or not ? Some convergence criteria can be expressed with both methods, but not all. Should we keep both setting as alternate methods or should we remove one and rely on the remaining one ?&lt;/p&gt;
, &lt;p&gt;I would keep using orthoTolerance as it is used now:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;292                if (maxCosine &amp;lt;= orthoTolerance) {&lt;br/&gt;
293                    // convergence has been reached&lt;br/&gt;
294                    return new VectorialPointValuePair(point, objective);&lt;br/&gt;
295                }&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;and then use costRelativeTolerance &amp;amp; parRelativeTolerance if and only if the convergence checker is null, otherwise use the convergence checker and ignore {costRelativeTolerance, parRelativeTolerance}.&lt;/p&gt;

&lt;p&gt;What I am missing now is the ability to bail out if the absolute distance from the target falls below some value ("close enough").&lt;/p&gt;
, &lt;p&gt;I've spent that last few days trying to find a good curve fitting library for Java and got excited when I learned of Commons Math.  Unfortunately, its curve fitting is very unreliable.  I'm hoping that this bug is what is causing the problems that I'm seeing.  I'm comparing data from NIST and results from DataFitX and it is apparent that Commons Math is not yet up to the task.  My fingers are crossed that its quality in the curve fitting area will be improved in the near future.  Keep up the good work Apache.&lt;/p&gt;

&lt;p&gt;I've opened an issue about the problems I'm seeing, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Double check how you use it, Matt. I have succesfully used this curve fitting in production.&lt;/p&gt;
, &lt;p&gt;Matt, could you please describe the problem you encounter more precisely (i.e. with numerical examples) and preferably in a new JIRA issue ? We will check if the two problems are related and link the issues afterwards if it appears they are.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
, &lt;p&gt;It's good to see such quick responses.  I'll open a new JIRA issue and spend some time putting together code, data and a detailed description of the problem I'm seeing.  Thanks Apache for all your hard work.&lt;/p&gt;

&lt;p&gt;I've opened an issue regarding the problem, &lt;a href="https://issues.apache.org/jira/browse/MATH-372"&gt;https://issues.apache.org/jira/browse/MATH-372&lt;/a&gt;&lt;/p&gt;
, &lt;p&gt;Fixed in subversion repository as of r949433.&lt;br/&gt;
Thanks for reporting the issue&lt;/p&gt;
, &lt;p&gt;Thank you.&lt;/p&gt;
, &lt;p&gt;Closing issue as it was included in version 2.2, which has been released&lt;/p&gt;
], resolution=Fixed, reporter=roman.werpachowski, assignees=[], commentAuthors=[luc, roman.werpachowski, mprice], timeEstimate=null, timeSpent=null]
2016-01-13 22:22:44,622 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry, issueId: MATH-288
2016-01-13 22:22:44,622 : DEBUG : KNIME-Worker-1 : ITSAdapterTransformer : Jira Adapter (Offline) : 0:1 : Transforming issue entry:ITSDataType [issueId=MATH-288, created=Tue Aug 25 00:31:11 CEST 2009, updated=Wed Apr 14 02:30:17 CEST 2010, resolved=Tue Aug 25 20:10:08 CEST 2009, status=Closed, type=Bug, version=[2.1
], fixVersion=[2.1
], priority=Major, summary=SimplexSolver not working as expected 2, link=https://issues.apache.org/jira/browse/MATH-288, description=&lt;p&gt;SimplexSolver didn't find the optimal solution.&lt;/p&gt;

&lt;p&gt;Program for Lpsolve:&lt;br/&gt;
=====================&lt;br/&gt;
/* Objective function */&lt;br/&gt;
max: 7 a 3 b;&lt;/p&gt;

&lt;p&gt;/* Constraints */&lt;br/&gt;
R1: +3 a -5 c &amp;lt;= 0;&lt;br/&gt;
R2: +2 a -5 d &amp;lt;= 0;&lt;br/&gt;
R3: +2 b -5 c &amp;lt;= 0;&lt;br/&gt;
R4: +3 b -5 d &amp;lt;= 0;&lt;br/&gt;
R5: +3 a +2 b &amp;lt;= 5;&lt;br/&gt;
R6: +2 a +3 b &amp;lt;= 5;&lt;/p&gt;

&lt;p&gt;/* Variable bounds */&lt;br/&gt;
a &amp;lt;= 1;&lt;br/&gt;
b &amp;lt;= 1;&lt;br/&gt;
=====================&lt;br/&gt;
Results(correct): a = 1, b = 1, value = 10&lt;/p&gt;


&lt;p&gt;Program for SimplexSolve:&lt;br/&gt;
=====================&lt;br/&gt;
LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]{7, 3, 0, 0}, 0);&lt;br/&gt;
Collection&amp;lt;LinearConstraint&amp;gt; podmienky = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{1, 0, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 1, 0, 0}, Relationship.LEQ, 1));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 0, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 0, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 2, -5, 0}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{0, 3, 0, -5}, Relationship.LEQ, 0));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{3, 2, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
podmienky.add(new LinearConstraint(new double[]{2, 3, 0, 0}, Relationship.LEQ, 5));&lt;br/&gt;
SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
RealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);&lt;br/&gt;
=====================&lt;br/&gt;
Results(incorrect): a = 1, b = 0.5, value = 8.5&lt;/p&gt;

&lt;p&gt;P.S. I used the latest software from the repository (including &lt;a href="https://issues.apache.org/jira/browse/MATH-286" title="SimplexSolver not working as expected?"&gt;&lt;del&gt;MATH-286&lt;/del&gt;&lt;/a&gt; fix).&lt;/p&gt;, comments=[&lt;p&gt;Thanks for the bug report.  I've confirmed this is an issue.&lt;/p&gt;

&lt;p&gt;Here's a slightly smaller version of the problem that causes the same bug, which might be easier for debugging:&lt;/p&gt;

&lt;p&gt;MAX 7 a + 3 b&lt;br/&gt;
s.t.&lt;br/&gt;
3 a -5 c &amp;lt;= 0&lt;br/&gt;
2 a -5 d &amp;lt;= 0&lt;br/&gt;
3 b -5 d &amp;lt;= 0&lt;br/&gt;
a &amp;lt;= 1&lt;br/&gt;
b &amp;lt;= 1&lt;/p&gt;

&lt;p&gt;        LinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 7, 3, 0, 0 }, 0 );&lt;br/&gt;
        Collection&amp;lt;LinearConstraint&amp;gt; constraints = new ArrayList&amp;lt;LinearConstraint&amp;gt;();&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 3, 0, -5, 0 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 2, 0, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 3, 0, -5 }, Relationship.LEQ, 0.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0 }, Relationship.LEQ, 1.0));&lt;br/&gt;
        constraints.add(new LinearConstraint(new double[] { 0, 1, 0, 0 }, Relationship.LEQ, 1.0));&lt;/p&gt;

&lt;p&gt;        SimplexSolver solver = new SimplexSolver();&lt;br/&gt;
        RealPointValuePair solution = solver.optimize(f, constraints, GoalType.MAXIMIZE, true);&lt;br/&gt;
        assertEquals(10.0, solution.getValue(), .0000001);&lt;/p&gt;
, &lt;p&gt;Patch attached.  It was a 1 character bug.  I was saying to only do the minimum ratio test if the entry is &amp;gt;= 0, but it should have been &amp;gt; 0 (dividing by 0 is never good :o)&lt;br/&gt;
Thanks again for the bug report.&lt;/p&gt;
, &lt;p&gt;resolved in subversion repository as of r807738&lt;br/&gt;
patch applied (except for debug print function)&lt;br/&gt;
thanks for the repoart and thanks for the patch&lt;/p&gt;
], resolution=Fixed, reporter=kefa, assignees=[], commentAuthors=[bmccann, luc], timeEstimate=480, timeSpent=null]
2016-01-13 22:22:44,638 : INFO  : KNIME-Worker-1 : ITSOfflineNodeModel : Jira Adapter (Offline) : 0:1 : Jira table created.
2016-01-13 22:22:44,638 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 End execute (2 secs)
2016-01-13 22:22:44,638 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doBeforePostExecution
2016-01-13 22:22:44,638 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: POSTEXECUTE
2016-01-13 22:22:44,638 : DEBUG : KNIME-Worker-1 : WorkflowManager : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 doAfterExecute - success
2016-01-13 22:22:44,638 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:1 : Jira Adapter (Offline) 0:1 has new state: EXECUTED
2016-01-13 22:22:44,669 : DEBUG : KNIME-Worker-1 : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:22:44,669 : DEBUG : KNIME-Worker-1 : NodeContainer : Jira Adapter (Offline) : 0:1 : Table Difference Checker 0:3 has new state: CONFIGURED_QUEUED
2016-01-13 22:22:44,684 : DEBUG : KNIME-Worker-0 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePreExecution
2016-01-13 22:22:44,684 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: PREEXECUTE
2016-01-13 22:22:44,684 : DEBUG : KNIME-Worker-0 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforeExecution
2016-01-13 22:22:44,700 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTING
2016-01-13 22:22:44,716 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Adding handler 8b980cd6-9887-4aeb-9b00-95c3554ea8ef (Table Difference Checker 0:3: <no directory>) - 2 in total
2016-01-13 22:22:44,716 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 Start execute
2016-01-13 22:22:45,074 : DEBUG : KNIME-Worker-0 : Buffer : Table Difference Checker : 0:3 : Opening input stream on file "C:\Users\SONY\AppData\Local\Temp\knime_JiraOfflineTest81136\knime_container_20160113_4440070542200051616.bin.gz", 1 open streams
2016-01-13 22:22:45,137 : DEBUG : KNIME-Worker-0 : Buffer : Table Difference Checker : 0:3 : Closing input stream on "C:\Users\SONY\AppData\Local\Temp\knime_JiraOfflineTest81136\knime_container_20160113_4440070542200051616.bin.gz", 0 remaining
2016-01-13 22:22:45,137 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : Table Difference Checker : 0:3 : Table Difference Checker 0:3 End execute (0 secs)
2016-01-13 22:22:45,137 : DEBUG : KNIME-Worker-0 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doBeforePostExecution
2016-01-13 22:22:45,137 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: POSTEXECUTE
2016-01-13 22:22:45,137 : DEBUG : KNIME-Worker-0 : WorkflowManager : Table Difference Checker : 0:3 : Table Difference Checker 0:3 doAfterExecute - success
2016-01-13 22:22:45,137 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : Table Difference Checker 0:3 has new state: EXECUTED
2016-01-13 22:22:45,137 : DEBUG : KNIME-Worker-0 : NodeContainer : Table Difference Checker : 0:3 : JiraOfflineTest 0 has new state: EXECUTED
2016-01-13 22:22:45,277 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test execute workflow -----------------
2016-01-13 22:22:45,277 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test node messages -----------------
2016-01-13 22:22:45,277 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test node messages -----------------
2016-01-13 22:22:45,277 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test hilite rows -----------------
2016-01-13 22:22:45,355 : DEBUG : Worker-0 : Buffer :  :  : Opening input stream on file "C:\Users\SONY\AppData\Local\Temp\knime_JiraOfflineTest81136\knime_container_20160113_4440070542200051616.bin.gz", 1 open streams
2016-01-13 22:22:45,371 : DEBUG : Worker-0 : Buffer :  :  : Closing input stream on "C:\Users\SONY\AppData\Local\Temp\knime_JiraOfflineTest81136\knime_container_20160113_4440070542200051616.bin.gz", 0 remaining
2016-01-13 22:22:45,371 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test hilite rows -----------------
2016-01-13 22:22:45,371 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test close views -----------------
2016-01-13 22:22:45,371 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test close views -----------------
2016-01-13 22:22:45,371 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test log messages -----------------
2016-01-13 22:22:45,371 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test log messages -----------------
2016-01-13 22:22:45,371 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test uncaught exceptions -----------------
2016-01-13 22:22:45,371 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test uncaught exceptions -----------------
2016-01-13 22:22:46,260 : DEBUG : Service Thread : MemoryAlertSystem :  :  : Memory usage below threshold of 0.7125915080527087 after GC run
2016-01-13 22:22:46,276 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ===== Memory statistics: 993,500 MB max, 52,973 MB used, 940,527 MB free ====
2016-01-13 22:22:46,276 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ================= Finished testflow WorkflowTests\JiraOfflineTest =================
2016-01-13 22:22:46,322 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:22:47,040 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:22:47,056 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:22:47,118 : DEBUG : Worker-0 : WorkflowManager :  :  : Removing project "JiraOfflineTest 0"
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:3 : Removing handler 8b980cd6-9887-4aeb-9b00-95c3554ea8ef (Table Difference Checker 0:3: <no directory>) - 1 remaining
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : DifferenceCheckerNodeModel : Table Difference Checker : 0:3 : Removing all (0) views from model.
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : JiraAdapterNodeModel : Jira Adapter (Offline) : 0:2 : Removing all (0) views from model.
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:2 : clean output ports.
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : WorkflowFileStoreHandlerRepository : Jira Adapter (Offline) : 0:1 : Removing handler 9626c955-11ed-4030-98ea-9ccd43cbd604 (Jira Adapter (Offline) 0:1: <no directory>) - 0 remaining
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : JiraAdapterNodeModel : Jira Adapter (Offline) : 0:1 : Removing all (0) views from model.
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : Jira Adapter (Offline) : Jira Adapter (Offline) : 0:1 : clean output ports.
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : WorkflowManager :  :  : Project "JiraOfflineTest 0" removed (1 remaining)
2016-01-13 22:22:47,134 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ================= Starting testflow WorkflowTests\SVNOfflineTest =================
2016-01-13 22:22:47,134 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ================= Average load: -1,00 =================
2016-01-13 22:22:47,134 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test load workflow -----------------
2016-01-13 22:22:47,134 : DEBUG : Worker-0 : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\SVNOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:47,180 : DEBUG : Worker-0 : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:22:47,212 : DEBUG : Worker-0 : SVNOfflineAdapterNodeFactory : SVNOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:47,212 : DEBUG : Worker-0 : DifferenceCheckerNodeFactory : SVNOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:47,227 : DEBUG : Worker-0 : SVNOfflineAdapterNodeFactory : SVNOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:47,227 : DEBUG : Worker-0 : WorkflowManager :  :  : Added new connection from node 0:3(1) to node 0:2(2)
2016-01-13 22:22:47,227 : DEBUG : Worker-0 : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:2(1)
2016-01-13 22:22:47,227 : DEBUG : Worker-0 : SVN SCM : SVN SCM : 0:1 : Configure succeeded. (SVN SCM)
2016-01-13 22:22:47,243 : DEBUG : Worker-0 : Table Difference Checker : Table Difference Checker : 0:2 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:22:47,243 : DEBUG : Worker-0 : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\SVNOfflineTest"  with no errors
2016-01-13 22:22:47,258 : INFO  : KNIME-Worker-1 : WorkflowManager :  :  : Could not delete temporary directory for workflow JiraOfflineTest at C:\Users\SONY\AppData\Local\Temp\knime_JiraOfflineTest81136
2016-01-13 22:22:47,274 : DEBUG : KNIME-Temp-File-Deleter : Buffer :  :  : Deleted temporary file "C:\Users\SONY\AppData\Local\Temp\knime_JiraOfflineTest81136\knime_container_20160113_4440070542200051616.bin.gz"
2016-01-13 22:22:47,368 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:22:47,368 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:22:47,414 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:22:47,414 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on 0 - SVNOfflineTest
2016-01-13 22:22:47,414 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:22:47,446 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:22:47,446 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:22:47,446 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:22:47,446 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( SVN SCM 0:1 (CONFIGURED) )
2016-01-13 22:22:47,446 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:2( 1)]
2016-01-13 22:22:47,446 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:47,446 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:2 (CONFIGURED) )
2016-01-13 22:22:47,461 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:2( 1)]
2016-01-13 22:22:47,461 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:47,461 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:3(1) -> 0:2( 2)]
2016-01-13 22:22:47,461 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:47,461 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( SVN SCM 0:3 (EXECUTED) )
2016-01-13 22:22:47,461 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:3(1) -> 0:2( 2)]
2016-01-13 22:22:47,461 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:48,288 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test load workflow -----------------
2016-01-13 22:22:48,288 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test open views -----------------
2016-01-13 22:22:48,288 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test open views -----------------
2016-01-13 22:22:48,288 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test execute workflow -----------------
2016-01-13 22:22:48,288 : DEBUG : Worker-0 : NodeContainer :  :  : Setting dirty flag on SVN SCM 0:1
2016-01-13 22:22:48,288 : DEBUG : Worker-0 : NodeContainer :  :  : Setting dirty flag on SVNOfflineTest 0
2016-01-13 22:22:48,288 : DEBUG : Worker-0 : NodeContainer :  :  : SVN SCM 0:1 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:22:48,288 : DEBUG : Worker-0 : NodeContainer :  :  : SVN SCM 0:1 has new state: CONFIGURED_QUEUED
2016-01-13 22:22:48,288 : DEBUG : Worker-0 : NodeContainer :  :  : Setting dirty flag on Table Difference Checker 0:2
2016-01-13 22:22:48,288 : DEBUG : Worker-0 : NodeContainer :  :  : Table Difference Checker 0:2 has new state: CONFIGURED_MARKEDFOREXEC
2016-01-13 22:22:48,288 : DEBUG : Worker-0 : NodeContainer :  :  : SVNOfflineTest 0 has new state: EXECUTING
2016-01-13 22:22:48,288 : DEBUG : Worker-0 : NodeContainer :  :  : ROOT  has new state: EXECUTING
2016-01-13 22:22:48,304 : DEBUG : KNIME-Worker-0 : WorkflowManager : SVN SCM : 0:1 : SVN SCM 0:1 doBeforePreExecution
2016-01-13 22:22:48,304 : DEBUG : KNIME-Worker-0 : NodeContainer : SVN SCM : 0:1 : SVN SCM 0:1 has new state: PREEXECUTE
2016-01-13 22:22:48,304 : DEBUG : KNIME-Worker-0 : WorkflowManager : SVN SCM : 0:1 : SVN SCM 0:1 doBeforeExecution
2016-01-13 22:22:48,397 : DEBUG : KNIME-Worker-0 : NodeContainer : SVN SCM : 0:1 : SVN SCM 0:1 has new state: EXECUTING
2016-01-13 22:22:48,397 : DEBUG : KNIME-Worker-0 : WorkflowFileStoreHandlerRepository : SVN SCM : 0:1 : Adding handler 6a6c0231-7321-479c-a1ce-cb5129a58963 (SVN SCM 0:1: <no directory>) - 1 in total
2016-01-13 22:22:48,397 : DEBUG : KNIME-Worker-0 : LocalNodeExecutionJob : SVN SCM : 0:1 : SVN SCM 0:1 Start execute
2016-01-13 22:22:48,397 : INFO  : KNIME-Worker-0 : SVNOfflineAdapterNodeModel : SVN SCM : 0:1 : Reading logs from file file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/SVN%20SCM%20(%231)/drop/svn.xml
2016-01-13 22:22:48,397 : DEBUG : KNIME-Workflow-Notifier : WorkflowEditor :  :  : Workflow event triggered: WorkflowEvent [type=WORKFLOW_DIRTY;node=0;old=null;new=null;timestamp=2016-01-13 22:22:48]
2016-01-13 22:22:49,723 : INFO  : KNIME-Worker-0 : SVNOfflineAdapterNodeModel : SVN SCM : 0:1 : Reading logs finished
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936295
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.optimization.fitting.PolynomialFitter, extension=java, author=erans, operation=MODIFIED, message=sdsd MATH-365 sdsdsd, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/optimization/fitting/PolynomialFitter.java, commitDate=Wed Apr 21 15:27:44 CEST 2010, commitID=936295]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936295
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.test.java.org.apache.commons.math.analysis.interpolation.SmoothingBicubicSplineInterpolatorTest, extension=java, author=erans, operation=MODIFIED, message=sdsd MATH-365 sdsdsd, path=/commons/proper/math/trunk/src/test/java/org/apache/commons/math/analysis/interpolation/SmoothingBicubicSplineInterpolatorTest.java, commitDate=Wed Apr 21 15:27:44 CEST 2010, commitID=936295]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936295
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.BivariateRealGridInterpolator, extension=java, author=erans, operation=MODIFIED, message=sdsd MATH-365 sdsdsd, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/BivariateRealGridInterpolator.java, commitDate=Wed Apr 21 15:27:44 CEST 2010, commitID=936295]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936295
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.test.java.org.apache.commons.math.analysis.interpolation.SmoothingPolynomialBicubicSplineInterpolatorTest, extension=java, author=erans, operation=ADDED, message=sdsd MATH-365 sdsdsd, path=/commons/proper/math/trunk/src/test/java/org/apache/commons/math/analysis/interpolation/SmoothingPolynomialBicubicSplineInterpolatorTest.java, commitDate=Wed Apr 21 15:27:44 CEST 2010, commitID=936295]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936295
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.SmoothingBicubicSplineInterpolator, extension=java, author=erans, operation=MODIFIED, message=sdsd MATH-365 sdsdsd, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/SmoothingBicubicSplineInterpolator.java, commitDate=Wed Apr 21 15:27:44 CEST 2010, commitID=936295]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936295
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.BivariateRealFunction, extension=java, author=erans, operation=MODIFIED, message=sdsd MATH-365 sdsdsd, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/BivariateRealFunction.java, commitDate=Wed Apr 21 15:27:44 CEST 2010, commitID=936295]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936295
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.test.java.org.apache.commons.math.analysis.interpolation.BicubicSplineInterpolatorTest, extension=java, author=erans, operation=ADDED, message=sdsd MATH-365 sdsdsd, path=/commons/proper/math/trunk/src/test/java/org/apache/commons/math/analysis/interpolation/BicubicSplineInterpolatorTest.java, commitDate=Wed Apr 21 15:27:44 CEST 2010, commitID=936295]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936295
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.SmoothingPolynomialBicubicSplineInterpolator, extension=java, author=erans, operation=ADDED, message=sdsd MATH-365 sdsdsd, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/SmoothingPolynomialBicubicSplineInterpolator.java, commitDate=Wed Apr 21 15:27:44 CEST 2010, commitID=936295]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936295
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.BicubicSplineInterpolator, extension=java, author=erans, operation=ADDED, message=sdsd MATH-365 sdsdsd, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/BicubicSplineInterpolator.java, commitDate=Wed Apr 21 15:27:44 CEST 2010, commitID=936295]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936391
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.test.java.org.apache.commons.math.analysis.interpolation.SmoothingBicubicSplineInterpolatorTest, extension=java, author=erans, operation=MODIFIED, message=Had forgotten to set the svn:keywords property.
, path=/commons/proper/math/trunk/src/test/java/org/apache/commons/math/analysis/interpolation/SmoothingBicubicSplineInterpolatorTest.java, commitDate=Wed Apr 21 19:00:56 CEST 2010, commitID=936391]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936391
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.BivariateRealGridInterpolator, extension=java, author=erans, operation=MODIFIED, message=Had forgotten to set the svn:keywords property.
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/BivariateRealGridInterpolator.java, commitDate=Wed Apr 21 19:00:56 CEST 2010, commitID=936391]
2016-01-13 22:22:49,723 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936391
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.test.java.org.apache.commons.math.analysis.interpolation.SmoothingPolynomialBicubicSplineInterpolatorTest, extension=java, author=erans, operation=MODIFIED, message=Had forgotten to set the svn:keywords property.
, path=/commons/proper/math/trunk/src/test/java/org/apache/commons/math/analysis/interpolation/SmoothingPolynomialBicubicSplineInterpolatorTest.java, commitDate=Wed Apr 21 19:00:56 CEST 2010, commitID=936391]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936391
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.SmoothingBicubicSplineInterpolator, extension=java, author=erans, operation=MODIFIED, message=Had forgotten to set the svn:keywords property.
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/SmoothingBicubicSplineInterpolator.java, commitDate=Wed Apr 21 19:00:56 CEST 2010, commitID=936391]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936391
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.SmoothingPolynomialBicubicSplineInterpolator, extension=java, author=erans, operation=MODIFIED, message=Had forgotten to set the svn:keywords property.
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/SmoothingPolynomialBicubicSplineInterpolator.java, commitDate=Wed Apr 21 19:00:56 CEST 2010, commitID=936391]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936391
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.BicubicSplineInterpolator, extension=java, author=erans, operation=MODIFIED, message=Had forgotten to set the svn:keywords property.
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/BicubicSplineInterpolator.java, commitDate=Wed Apr 21 19:00:56 CEST 2010, commitID=936391]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936471
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.test.java.org.apache.commons.math.analysis.interpolation.SmoothingPolynomialBicubicSplineInterpolatorTest, extension=java, author=erans, operation=MODIFIED, message=Had forgotten to set svn:eol-style.
, path=/commons/proper/math/trunk/src/test/java/org/apache/commons/math/analysis/interpolation/SmoothingPolynomialBicubicSplineInterpolatorTest.java, commitDate=Wed Apr 21 22:02:43 CEST 2010, commitID=936471]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936471
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.SmoothingPolynomialBicubicSplineInterpolator, extension=java, author=erans, operation=MODIFIED, message=Had forgotten to set svn:eol-style.
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/SmoothingPolynomialBicubicSplineInterpolator.java, commitDate=Wed Apr 21 22:02:43 CEST 2010, commitID=936471]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 936471
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.BicubicSplineInterpolator, extension=java, author=erans, operation=MODIFIED, message=Had forgotten to set svn:eol-style.
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/BicubicSplineInterpolator.java, commitDate=Wed Apr 21 22:02:43 CEST 2010, commitID=936471]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 937080
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.test.java.org.apache.commons.math.analysis.interpolation.TricubicSplineInterpolatingFunctionTest, extension=java, author=erans, operation=ADDED, message=MATH-366
, path=/commons/proper/math/trunk/src/test/java/org/apache/commons/math/analysis/interpolation/TricubicSplineInterpolatingFunctionTest.java, commitDate=Fri Apr 23 00:09:21 CEST 2010, commitID=937080]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 937080
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.BicubicSplineInterpolatingFunction, extension=java, author=erans, operation=MODIFIED, message=MATH-366
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/BicubicSplineInterpolatingFunction.java, commitDate=Fri Apr 23 00:09:21 CEST 2010, commitID=937080]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 937080
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.TricubicSplineInterpolator, extension=java, author=erans, operation=ADDED, message=MATH-366
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/TricubicSplineInterpolator.java, commitDate=Fri Apr 23 00:09:21 CEST 2010, commitID=937080]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 937080
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.TricubicSplineInterpolatingFunction, extension=java, author=erans, operation=ADDED, message=MATH-366
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/TricubicSplineInterpolatingFunction.java, commitDate=Fri Apr 23 00:09:21 CEST 2010, commitID=937080]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 937080
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.TrivariateRealGridInterpolator, extension=java, author=erans, operation=ADDED, message=MATH-366
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/TrivariateRealGridInterpolator.java, commitDate=Fri Apr 23 00:09:21 CEST 2010, commitID=937080]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 937080
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.interpolation.SmoothingPolynomialBicubicSplineInterpolator, extension=java, author=erans, operation=MODIFIED, message=MATH-366
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/interpolation/SmoothingPolynomialBicubicSplineInterpolator.java, commitDate=Fri Apr 23 00:09:21 CEST 2010, commitID=937080]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 937080
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.test.java.org.apache.commons.math.analysis.interpolation.BicubicSplineInterpolatingFunctionTest, extension=java, author=erans, operation=MODIFIED, message=MATH-366
, path=/commons/proper/math/trunk/src/test/java/org/apache/commons/math/analysis/interpolation/BicubicSplineInterpolatingFunctionTest.java, commitDate=Fri Apr 23 00:09:21 CEST 2010, commitID=937080]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 937080
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.main.java.org.apache.commons.math.analysis.TrivariateRealFunction, extension=java, author=erans, operation=ADDED, message=MATH-366
, path=/commons/proper/math/trunk/src/main/java/org/apache/commons/math/analysis/TrivariateRealFunction.java, commitDate=Fri Apr 23 00:09:21 CEST 2010, commitID=937080]
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming scm entry, id: 937080
2016-01-13 22:22:49,739 : DEBUG : KNIME-Worker-0 : SCMAdapterTransformer : SVN SCM : 0:1 : Transforming issue entry:SCMDataType [resourceName=.commons.proper.math.trunk.src.test.java.org.apache.commons.math.analysis.interpolation.TricubicSplineInterpolatorTest, extension=java, author=erans, operation=ADDED, message=MATH-366
, path=/commons/proper/math/trunk/src/test/java/org/apache/commons/math/analysis/interpolation/TricubicSplineInterpolatorTest.java, commitDate=Fri Apr 23 00:09:21 CEST 2010, commitID=937080]
2016-01-13 22:22:49,739 : INFO  : KNIME-Worker-0 : SVNOfflineAdapterNodeModel : SVN SCM : 0:1 : Transforming logs finished.
2016-01-13 22:22:49,754 : INFO  : KNIME-Worker-0 : LocalNodeExecutionJob : SVN SCM : 0:1 : SVN SCM 0:1 End execute (1 sec)
2016-01-13 22:22:49,754 : DEBUG : KNIME-Worker-0 : WorkflowManager : SVN SCM : 0:1 : SVN SCM 0:1 doBeforePostExecution
2016-01-13 22:22:49,770 : DEBUG : KNIME-Worker-0 : NodeContainer : SVN SCM : 0:1 : SVN SCM 0:1 has new state: POSTEXECUTE
2016-01-13 22:22:49,786 : DEBUG : KNIME-Worker-0 : WorkflowManager : SVN SCM : 0:1 : SVN SCM 0:1 doAfterExecute - success
2016-01-13 22:22:49,786 : DEBUG : KNIME-Worker-0 : NodeContainer : SVN SCM : 0:1 : SVN SCM 0:1 has new state: EXECUTED
2016-01-13 22:22:49,864 : DEBUG : KNIME-Worker-0 : Table Difference Checker : Table Difference Checker : 0:2 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:22:49,864 : DEBUG : KNIME-Worker-0 : NodeContainer : SVN SCM : 0:1 : Table Difference Checker 0:2 has new state: CONFIGURED_QUEUED
2016-01-13 22:22:49,895 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:2 : Table Difference Checker 0:2 doBeforePreExecution
2016-01-13 22:22:49,942 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:2 : Table Difference Checker 0:2 has new state: PREEXECUTE
2016-01-13 22:22:49,942 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:2 : Table Difference Checker 0:2 doBeforeExecution
2016-01-13 22:22:49,942 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:2 : Table Difference Checker 0:2 has new state: EXECUTING
2016-01-13 22:22:49,942 : DEBUG : KNIME-Worker-1 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:2 : Adding handler 56e16018-9e0f-4e7c-8e35-7d449db29215 (Table Difference Checker 0:2: <no directory>) - 2 in total
2016-01-13 22:22:49,942 : DEBUG : KNIME-Worker-1 : LocalNodeExecutionJob : Table Difference Checker : 0:2 : Table Difference Checker 0:2 Start execute
2016-01-13 22:22:50,129 : DEBUG : KNIME-Worker-1 : Buffer : Table Difference Checker : 0:2 : Opening input stream on file "C:\Users\SONY\AppData\Local\Temp\knime_SVNOfflineTest81137\knime_container_20160113_3119917055730746114.bin.gz", 1 open streams
2016-01-13 22:22:50,129 : DEBUG : KNIME-Worker-1 : Buffer : Table Difference Checker : 0:2 : Closing input stream on "C:\Users\SONY\AppData\Local\Temp\knime_SVNOfflineTest81137\knime_container_20160113_3119917055730746114.bin.gz", 0 remaining
2016-01-13 22:22:50,129 : INFO  : KNIME-Worker-1 : LocalNodeExecutionJob : Table Difference Checker : 0:2 : Table Difference Checker 0:2 End execute (0 secs)
2016-01-13 22:22:50,129 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:2 : Table Difference Checker 0:2 doBeforePostExecution
2016-01-13 22:22:50,160 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:2 : Table Difference Checker 0:2 has new state: POSTEXECUTE
2016-01-13 22:22:50,160 : DEBUG : KNIME-Worker-1 : WorkflowManager : Table Difference Checker : 0:2 : Table Difference Checker 0:2 doAfterExecute - success
2016-01-13 22:22:50,160 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:2 : Table Difference Checker 0:2 has new state: EXECUTED
2016-01-13 22:22:50,160 : DEBUG : KNIME-Worker-1 : NodeContainer : Table Difference Checker : 0:2 : SVNOfflineTest 0 has new state: EXECUTED
2016-01-13 22:22:50,160 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test execute workflow -----------------
2016-01-13 22:22:50,160 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test node messages -----------------
2016-01-13 22:22:50,160 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test node messages -----------------
2016-01-13 22:22:50,160 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test hilite rows -----------------
2016-01-13 22:22:50,160 : DEBUG : KNIME-WFM-Parent-Notifier : NodeContainer :  :  : ROOT  has new state: IDLE
2016-01-13 22:22:50,347 : DEBUG : Worker-0 : Buffer :  :  : Opening input stream on file "C:\Users\SONY\AppData\Local\Temp\knime_SVNOfflineTest81137\knime_container_20160113_3119917055730746114.bin.gz", 1 open streams
2016-01-13 22:22:50,347 : DEBUG : Worker-0 : Buffer :  :  : Closing input stream on "C:\Users\SONY\AppData\Local\Temp\knime_SVNOfflineTest81137\knime_container_20160113_3119917055730746114.bin.gz", 0 remaining
2016-01-13 22:22:50,347 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test hilite rows -----------------
2016-01-13 22:22:50,347 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test close views -----------------
2016-01-13 22:22:50,347 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test close views -----------------
2016-01-13 22:22:50,347 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test log messages -----------------
2016-01-13 22:22:50,347 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test log messages -----------------
2016-01-13 22:22:50,347 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Starting sub-test uncaught exceptions -----------------
2016-01-13 22:22:50,363 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ----------------- Finished sub-test uncaught exceptions -----------------
2016-01-13 22:22:51,096 : DEBUG : Service Thread : MemoryAlertSystem :  :  : Memory usage below threshold of 0.7125915080527087 after GC run
2016-01-13 22:22:51,096 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ===== Memory statistics: 992,500 MB max, 52,247 MB used, 940,253 MB free ====
2016-01-13 22:22:51,096 : INFO  : Worker-0 : GUIWorkflowTestSuite :  :  : ================= Finished testflow WorkflowTests\SVNOfflineTest =================
2016-01-13 22:22:51,860 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:22:51,860 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:22:51,907 : DEBUG : Worker-0 : WorkflowManager :  :  : Removing project "SVNOfflineTest 0"
2016-01-13 22:22:52,063 : DEBUG : Worker-0 : WorkflowFileStoreHandlerRepository : Table Difference Checker : 0:2 : Removing handler 56e16018-9e0f-4e7c-8e35-7d449db29215 (Table Difference Checker 0:2: <no directory>) - 1 remaining
2016-01-13 22:22:52,063 : DEBUG : Worker-0 : DifferenceCheckerNodeModel : Table Difference Checker : 0:2 : Removing all (0) views from model.
2016-01-13 22:22:52,063 : DEBUG : Worker-0 : Table Difference Checker : Table Difference Checker : 0:2 : clean output ports.
2016-01-13 22:22:52,063 : DEBUG : Worker-0 : SVNOfflineAdapterNodeModel : SVN SCM : 0:3 : Removing all (0) views from model.
2016-01-13 22:22:52,063 : DEBUG : Worker-0 : SVN SCM : SVN SCM : 0:3 : clean output ports.
2016-01-13 22:22:52,063 : DEBUG : Worker-0 : WorkflowFileStoreHandlerRepository : SVN SCM : 0:1 : Removing handler 6a6c0231-7321-479c-a1ce-cb5129a58963 (SVN SCM 0:1: <no directory>) - 0 remaining
2016-01-13 22:22:52,063 : DEBUG : Worker-0 : SVNOfflineAdapterNodeModel : SVN SCM : 0:1 : Removing all (0) views from model.
2016-01-13 22:22:52,063 : DEBUG : Worker-0 : SVN SCM : SVN SCM : 0:1 : clean output ports.
2016-01-13 22:22:52,063 : DEBUG : Worker-0 : WorkflowManager :  :  : Project "SVNOfflineTest 0" removed (1 remaining)
2016-01-13 22:22:52,110 : DEBUG : KNIME-Temp-File-Deleter : Buffer :  :  : Deleted temporary file "C:\Users\SONY\AppData\Local\Temp\knime_SVNOfflineTest81137\knime_container_20160113_3119917055730746114.bin.gz"
2016-01-13 22:22:57,586 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:22:57,601 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:22:57,632 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:22:57,632 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on workflow.knime
2016-01-13 22:22:57,632 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:22:57,632 : DEBUG : main : WorkflowEditor :  :  : Resource File's project: file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/
2016-01-13 22:22:57,695 : DEBUG : ModalContext : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:22:57,710 : DEBUG : ModalContext : WorkflowManager :  :  : Created subworkflow 0
2016-01-13 22:22:57,773 : DEBUG : ModalContext : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:57,773 : DEBUG : ModalContext : GitOfflineAdapterNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:57,820 : DEBUG : ModalContext : DifferenceCheckerNodeFactory : GitOfflineTest : 0 : Factory is already initialized. Nothing to do.
2016-01-13 22:22:57,820 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:2(1) to node 0:3(2)
2016-01-13 22:22:57,820 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 0:1(1) to node 0:3(1)
2016-01-13 22:22:57,820 : DEBUG : ModalContext : Git SCM : Git SCM : 0:1 : Configure succeeded. (Git SCM)
2016-01-13 22:22:57,851 : DEBUG : ModalContext : Table Difference Checker : Table Difference Checker : 0:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:22:57,851 : DEBUG : ModalContext : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\GitOfflineTest"  with no errors
2016-01-13 22:22:57,944 : DEBUG : main : ProjectWorkflowMap :  :  : Adding "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/" to project map (1 in total)
2016-01-13 22:22:57,944 : DEBUG : main : ProjectWorkflowMap :  :  : registering org.knime.workbench.editor2.WorkflowEditor@a49cdd6 to file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/. 1 registered clients now.
2016-01-13 22:22:57,976 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:22:57,976 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:22:57,976 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:22:57,976 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:1 (CONFIGURED) )
2016-01-13 22:22:57,976 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:22:57,976 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:57,976 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Git SCM 0:2 (EXECUTED) )
2016-01-13 22:22:57,991 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:22:57,991 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:57,991 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 0:3 (CONFIGURED) )
2016-01-13 22:22:57,991 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:1(1) -> 0:3( 1)]
2016-01-13 22:22:57,991 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:22:57,991 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[0:2(1) -> 0:3( 2)]
2016-01-13 22:22:57,991 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:23:00,799 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:23:00,799 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:23:00,799 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:23:00,799 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on workflow.knime
2016-01-13 22:23:00,799 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:23:00,799 : DEBUG : main : WorkflowEditor :  :  : Resource File's project: file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/
2016-01-13 22:23:00,846 : DEBUG : ModalContext : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:23:00,862 : DEBUG : ModalContext : WorkflowManager :  :  : Created subworkflow 2
2016-01-13 22:23:00,862 : DEBUG : ModalContext : JiraAdapterNodeFactory : JiraOfflineTest : 2 : Factory is already initialized. Nothing to do.
2016-01-13 22:23:00,877 : DEBUG : ModalContext : JiraAdapterNodeFactory : JiraOfflineTest : 2 : Factory is already initialized. Nothing to do.
2016-01-13 22:23:00,893 : DEBUG : ModalContext : DifferenceCheckerNodeFactory : JiraOfflineTest : 2 : Factory is already initialized. Nothing to do.
2016-01-13 22:23:00,893 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 2:2(1) to node 2:3(2)
2016-01-13 22:23:00,893 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 2:1(1) to node 2:3(1)
2016-01-13 22:23:00,893 : DEBUG : ModalContext : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : Configure succeeded. (Jira Adapter (Offline))
2016-01-13 22:23:00,924 : DEBUG : ModalContext : Table Difference Checker : Table Difference Checker : 2:3 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:23:00,924 : DEBUG : ModalContext : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\JiraOfflineTest"  with no errors
2016-01-13 22:23:00,924 : DEBUG : main : ProjectWorkflowMap :  :  : Adding "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/" to project map (2 in total)
2016-01-13 22:23:00,924 : DEBUG : main : ProjectWorkflowMap :  :  : registering org.knime.workbench.editor2.WorkflowEditor@110b6c78 to file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/. 1 registered clients now.
2016-01-13 22:23:00,955 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:23:00,955 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:23:00,955 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:23:00,955 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 2:1 (CONFIGURED) )
2016-01-13 22:23:00,955 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:1(1) -> 2:3( 1)]
2016-01-13 22:23:00,955 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:23:00,955 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Jira Adapter (Offline) 2:2 (EXECUTED) )
2016-01-13 22:23:00,971 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:2(1) -> 2:3( 2)]
2016-01-13 22:23:00,971 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:23:00,971 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 2:3 (CONFIGURED) )
2016-01-13 22:23:00,971 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:1(1) -> 2:3( 1)]
2016-01-13 22:23:00,971 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:23:00,971 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[2:2(1) -> 2:3( 2)]
2016-01-13 22:23:00,971 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:23:03,950 : DEBUG : main : WorkflowEditor :  :  : Creating WorkflowEditor...
2016-01-13 22:23:03,950 : DEBUG : main : WorkflowEditor :  :  : creating editor actions...
2016-01-13 22:23:03,950 : DEBUG : main : WorkflowEditor :  :  : Initializing editor UI...
2016-01-13 22:23:03,950 : DEBUG : main : WorkflowEditor :  :  : Opening workflow Editor on workflow.knime
2016-01-13 22:23:03,950 : DEBUG : main : WorkflowEditor :  :  : Setting input into editor...
2016-01-13 22:23:03,950 : DEBUG : main : WorkflowEditor :  :  : Resource File's project: file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/
2016-01-13 22:23:04,075 : DEBUG : ModalContext : WorkflowManager :  :  : Loading workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\SVNOfflineTest" (version "V3010" with loader class "FileWorkflowPersistor")
2016-01-13 22:23:04,075 : DEBUG : ModalContext : WorkflowManager :  :  : Created subworkflow 3
2016-01-13 22:23:04,091 : DEBUG : ModalContext : SVNOfflineAdapterNodeFactory : SVNOfflineTest : 3 : Factory is already initialized. Nothing to do.
2016-01-13 22:23:04,106 : DEBUG : ModalContext : DifferenceCheckerNodeFactory : SVNOfflineTest : 3 : Factory is already initialized. Nothing to do.
2016-01-13 22:23:04,122 : DEBUG : ModalContext : SVNOfflineAdapterNodeFactory : SVNOfflineTest : 3 : Factory is already initialized. Nothing to do.
2016-01-13 22:23:04,122 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 3:3(1) to node 3:2(2)
2016-01-13 22:23:04,122 : DEBUG : ModalContext : WorkflowManager :  :  : Added new connection from node 3:1(1) to node 3:2(1)
2016-01-13 22:23:04,122 : DEBUG : ModalContext : SVN SCM : SVN SCM : 3:1 : Configure succeeded. (SVN SCM)
2016-01-13 22:23:04,153 : DEBUG : ModalContext : Table Difference Checker : Table Difference Checker : 3:2 : Configure succeeded. (Table Difference Checker)
2016-01-13 22:23:04,153 : DEBUG : ModalContext : WorkflowManager :  :  : Loaded workflow from "D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\WorkflowTests\SVNOfflineTest"  with no errors
2016-01-13 22:23:04,169 : DEBUG : main : ProjectWorkflowMap :  :  : Adding "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/" to project map (3 in total)
2016-01-13 22:23:04,169 : DEBUG : main : ProjectWorkflowMap :  :  : registering org.knime.workbench.editor2.WorkflowEditor@3b25ce5e to file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/. 1 registered clients now.
2016-01-13 22:23:04,184 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Node under test )
2016-01-13 22:23:04,184 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart(  )
2016-01-13 22:23:04,184 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeAnnotationEditPart( Reference node )
2016-01-13 22:23:04,184 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( SVN SCM 3:1 (CONFIGURED) )
2016-01-13 22:23:04,184 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[3:1(1) -> 3:2( 1)]
2016-01-13 22:23:04,184 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:23:04,184 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( Table Difference Checker 3:2 (CONFIGURED) )
2016-01-13 22:23:04,184 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[3:1(1) -> 3:2( 1)]
2016-01-13 22:23:04,184 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:23:04,184 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[3:3(1) -> 3:2( 2)]
2016-01-13 22:23:04,184 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:23:04,184 : DEBUG : main : WorkflowRootEditPart :  :  : part: NodeContainerEditPart( SVN SCM 3:3 (EXECUTED) )
2016-01-13 22:23:04,200 : DEBUG : main : ConnectionContainerEditPart :  :  : refreshing visuals for: STD[3:3(1) -> 3:2( 2)]
2016-01-13 22:23:04,200 : DEBUG : main : ConnectionContainerEditPart :  :  : modelling info: null
2016-01-13 22:23:07,024 : DEBUG : KNIME-Node-Usage-Writer : NodeTimer$GlobalNodeStats :  :  : Successfully wrote node usage stats to file: D:\Studia\SemII\Agile\Projekt\agile15_4\org.depress.knime.testing\.metadata\knime\nodeusage_3.0.json
2016-01-13 22:23:07,086 : DEBUG : KNIME-Node-Usage-Sender : NodeTimer$GlobalNodeStats :  :  : Sending of usage stats disabled.
2016-01-13 22:23:07,991 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:23:08,006 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:23:08,006 : DEBUG : main : ProjectWorkflowMap :  :  : unregistering org.knime.workbench.editor2.WorkflowEditor@a49cdd6 from file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/. 0 left.
2016-01-13 22:23:08,006 : DEBUG : main : ProjectWorkflowMap :  :  : Removing "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/GitOfflineTest/" from project map (2 remaining)
2016-01-13 22:23:08,006 : DEBUG : main : WorkflowManager :  :  : Removing project "GitOfflineTest 0"
2016-01-13 22:23:08,038 : DEBUG : main : DifferenceCheckerNodeModel : Table Difference Checker : 0:3 : Removing all (0) views from model.
2016-01-13 22:23:08,038 : DEBUG : main : Table Difference Checker : Table Difference Checker : 0:3 : clean output ports.
2016-01-13 22:23:08,038 : DEBUG : main : GitOfflineAdapterNodeModel : Git SCM : 0:2 : Removing all (0) views from model.
2016-01-13 22:23:08,038 : DEBUG : main : Git SCM : Git SCM : 0:2 : clean output ports.
2016-01-13 22:23:08,038 : DEBUG : main : GitOfflineAdapterNodeModel : Git SCM : 0:1 : Removing all (0) views from model.
2016-01-13 22:23:08,038 : DEBUG : main : Git SCM : Git SCM : 0:1 : clean output ports.
2016-01-13 22:23:08,038 : DEBUG : main : WorkflowManager :  :  : Project "GitOfflineTest 0" removed (3 remaining)
2016-01-13 22:23:08,053 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:23:08,069 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:23:08,069 : DEBUG : main : ProjectWorkflowMap :  :  : unregistering org.knime.workbench.editor2.WorkflowEditor@110b6c78 from file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/. 0 left.
2016-01-13 22:23:08,069 : DEBUG : main : ProjectWorkflowMap :  :  : Removing "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/JiraOfflineTest/" from project map (1 remaining)
2016-01-13 22:23:08,069 : DEBUG : main : WorkflowManager :  :  : Removing project "JiraOfflineTest 2"
2016-01-13 22:23:08,084 : DEBUG : main : DifferenceCheckerNodeModel : Table Difference Checker : 2:3 : Removing all (0) views from model.
2016-01-13 22:23:08,084 : DEBUG : main : Table Difference Checker : Table Difference Checker : 2:3 : clean output ports.
2016-01-13 22:23:08,084 : DEBUG : main : JiraAdapterNodeModel : Jira Adapter (Offline) : 2:2 : Removing all (0) views from model.
2016-01-13 22:23:08,084 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:2 : clean output ports.
2016-01-13 22:23:08,084 : DEBUG : main : JiraAdapterNodeModel : Jira Adapter (Offline) : 2:1 : Removing all (0) views from model.
2016-01-13 22:23:08,084 : DEBUG : main : Jira Adapter (Offline) : Jira Adapter (Offline) : 2:1 : clean output ports.
2016-01-13 22:23:08,084 : DEBUG : main : WorkflowManager :  :  : Project "JiraOfflineTest 2" removed (2 remaining)
2016-01-13 22:23:08,100 : DEBUG : main : WorkflowRootEditPart :  :  : WorkflowRootEditPart deactivated
2016-01-13 22:23:08,100 : DEBUG : main : WorkflowEditor :  :  : Disposing editor...
2016-01-13 22:23:08,100 : DEBUG : main : ProjectWorkflowMap :  :  : unregistering org.knime.workbench.editor2.WorkflowEditor@3b25ce5e from file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/. 0 left.
2016-01-13 22:23:08,100 : DEBUG : main : ProjectWorkflowMap :  :  : Removing "file:/D:/Studia/SemII/Agile/Projekt/agile15_4/org.depress.knime.testing/WorkflowTests/SVNOfflineTest/" from project map (0 remaining)
2016-01-13 22:23:08,100 : DEBUG : main : WorkflowManager :  :  : Removing project "SVNOfflineTest 3"
2016-01-13 22:23:08,116 : DEBUG : main : DifferenceCheckerNodeModel : Table Difference Checker : 3:2 : Removing all (0) views from model.
2016-01-13 22:23:08,116 : DEBUG : main : Table Difference Checker : Table Difference Checker : 3:2 : clean output ports.
2016-01-13 22:23:08,116 : DEBUG : main : SVNOfflineAdapterNodeModel : SVN SCM : 3:3 : Removing all (0) views from model.
2016-01-13 22:23:08,116 : DEBUG : main : SVN SCM : SVN SCM : 3:3 : clean output ports.
2016-01-13 22:23:08,116 : DEBUG : main : SVNOfflineAdapterNodeModel : SVN SCM : 3:1 : Removing all (0) views from model.
2016-01-13 22:23:08,116 : DEBUG : main : SVN SCM : SVN SCM : 3:1 : clean output ports.
2016-01-13 22:23:08,116 : DEBUG : main : WorkflowManager :  :  : Project "SVNOfflineTest 3" removed (1 remaining)
